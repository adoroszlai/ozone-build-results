<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="280.201" tests="7" errors="1" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.86.Final/netty-codec-http2-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.86.Final/netty-common-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.86.Final/netty-buffer-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.86.Final/netty-codec-http-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.86.Final/netty-handler-proxy-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.86.Final/netty-codec-socks-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.54.Final/netty-tcnative-classes-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-managed-rocksdb/1.4.0-SNAPSHOT/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.49.v20220914/jetty-client-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.13/httpcore-nio-4.4.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.86.Final/netty-transport-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.86.Final/netty-resolver-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.86.Final/netty-transport-native-epoll-4.1.86.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.86.Final/netty-transport-classes-epoll-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.86.Final/netty-transport-native-unix-common-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/guice/5.1.0/guice-5.1.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/5.1.0/guice-assistedinject-5.1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/5.1.0/guice-servlet-5.1.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.86.Final/netty-codec-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.86.Final/netty-handler-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="java.vm.vendor" value="Temurin"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://adoptium.net/"/>
    <property name="user.timezone" value="Etc/UTC"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter718863855143892371.jar /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire 2023-03-27T23-34-16_031-jvmRun1 surefire922256688675403706tmp surefire_73433173772110444126tmp"/>
    <property name="surefire.test.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.86.Final/netty-codec-http2-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.86.Final/netty-common-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.86.Final/netty-buffer-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.86.Final/netty-codec-http-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.86.Final/netty-handler-proxy-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.86.Final/netty-codec-socks-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.54.Final/netty-tcnative-classes-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-managed-rocksdb/1.4.0-SNAPSHOT/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.49.v20220914/jetty-client-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.13/httpcore-nio-4.4.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.86.Final/netty-transport-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.86.Final/netty-resolver-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.86.Final/netty-transport-native-epoll-4.1.86.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.86.Final/netty-transport-classes-epoll-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.86.Final/netty-transport-native-unix-common-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/guice/5.1.0/guice-5.1.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/5.1.0/guice-assistedinject-5.1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/5.1.0/guice-servlet-5.1.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.86.Final/netty-codec-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.86.Final/netty-handler-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/runner"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="skip.installnpx" value="true"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.fork.timeout" value="3600"/>
    <property name="surefire.real.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter718863855143892371.jar:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_362-b09"/>
    <property name="skip.npx" value="true"/>
    <property name="user.name" value="runner"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="5.15.0-1034-azure"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/runner/.m2/repository"/>
    <property name="jetty.git.hash" value="4231a3b2e4cb8548a412a789936d640a97b1aa0a"/>
    <property name="java.vendor.url.bug" value="https://github.com/adoptium/adoptium-support/issues"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="java.version" value="1.8.0_362"/>
    <property name="surefire.rerunFailingTestsCount" value="5"/>
    <property name="user.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="test.build.classes" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="org.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads" value="false"/>
    <property name="hadoop.tmp.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vendor" value="Temurin"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.362-b09"/>
    <property name="java.specification.maintenance.version" value="4"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testNodeWithOpenPipelineCanBeDecommissionedAndRecommissioned" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="48.981"/>
  <testcase name="testContainerIsReplicatedWhenAllNodesGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="42.933"/>
  <testcase name="testMaintenanceEndsAutomaticallyAtTimeout" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="36.081"/>
  <testcase name="testSingleNodeWithOpenPipelineCanGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="40.248"/>
  <testcase name="testSCMHandlesRestartForMaintenanceNode" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="55.577">
    <error type="java.util.concurrent.TimeoutException"><![CDATA[java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2023-03-27 11:44:38,257

"qtp1940908711-4763" daemon prio=5 tid=4763 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7526a7c7" daemon prio=5 tid=4779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 43801" daemon prio=5 tid=3510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 43165" daemon prio=5 tid=4222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1563-thread-1"  prio=5 tid=3544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-4c0c8e5b-1"  prio=5 tid=5604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-SegmentedRaftLogWorker"  prio=5 tid=5919 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5498 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c1d68bf5-941c-4ef4-97c3-9b8585fa6dbb-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4826 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1607-thread-1"  prio=5 tid=3911 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 36479" daemon prio=5 tid=5365 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1955-thread-1" daemon prio=5 tid=4527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 38901" daemon prio=5 tid=6217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=3873 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 37647" daemon prio=5 tid=5462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 7 on default port 38901" daemon prio=5 tid=6222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-9"  prio=5 tid=5684 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6159 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-StateMachineUpdater" daemon prio=5 tid=5910 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp571581767-5396-acceptor-0@26c107e-ServerConnector@4d557709{HTTP/1.1, (http/1.1)}{0.0.0.0:39587}" daemon prio=3 tid=5396 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4773 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 38815" daemon prio=5 tid=6241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=4675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"prometheus" daemon prio=5 tid=6194 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"qtp1863303266-3602" daemon prio=5 tid=3602 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState" daemon prio=5 tid=5957 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 0 on default port 36479" daemon prio=5 tid=5363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=3875 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6280 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4856 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@44367f2f" daemon prio=5 tid=3781 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 43801" daemon prio=5 tid=3509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3258 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3779 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=473 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@38e0b949" daemon prio=5 tid=5384 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp1076523403-4630" daemon prio=5 tid=4630 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp7351632-5716" daemon prio=5 tid=5716 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4726 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp472636590-3671" daemon prio=5 tid=3671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2437-thread-1" daemon prio=5 tid=5482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4869 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=6190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-3"  prio=5 tid=5632 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3795 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=4170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$414/175091021.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36479 - 0 "  prio=5 tid=5871 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 37215" daemon prio=5 tid=5340 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer4" daemon prio=5 tid=544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"501a6ba0-4aa7-4660-9456-a414ab3e4b55@group-6F499BE2D5A5-LeaderStateImpl" daemon prio=5 tid=5045 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"JvmPauseMonitor46" daemon prio=5 tid=4892 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4858 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor52" daemon prio=5 tid=5735 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 46647" daemon prio=5 tid=4482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState" daemon prio=5 tid=5958 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=6166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/807543346.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 33863" daemon prio=5 tid=5362 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-StateMachineUpdater" daemon prio=5 tid=6006 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 43165" daemon prio=5 tid=4224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 38901" daemon prio=5 tid=6225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp714067911-3545" daemon prio=5 tid=3545 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 38901" daemon prio=5 tid=6231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-LeaderStateImpl" daemon prio=5 tid=3992 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp714067911-3549" daemon prio=5 tid=3549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:45153 - 0 "  prio=5 tid=4887 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-SegmentedRaftLogWorker"  prio=5 tid=5915 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@722c9fca" daemon prio=5 tid=3618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 36479" daemon prio=5 tid=5368 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 45153" daemon prio=5 tid=4257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3613 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-5"  prio=5 tid=5643 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3692 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-2" daemon prio=5 tid=537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4924 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp472636590-3668-acceptor-0@446e634a-ServerConnector@4a8e84dd{HTTP/1.1, (http/1.1)}{0.0.0.0:45327}" daemon prio=3 tid=3668 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4890 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4747 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4592 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState" daemon prio=5 tid=5982 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"DirectoryDeletingService#0" daemon prio=5 tid=5444 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=5281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$414/175091021.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=5286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:140)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4878 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp276108260-3579" daemon prio=5 tid=3579 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5845 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5757 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"null-request--thread1" daemon prio=5 tid=5414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4841 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1158040657-3742" daemon prio=5 tid=3742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 37215" daemon prio=5 tid=5334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"3fee8600-457c-478d-8bf5-017cc394a56c@group-8A2418B3C9EC-LeaderStateImpl" daemon prio=5 tid=4018 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp508294491-6262" daemon prio=5 tid=6262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5754 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer0" daemon prio=5 tid=573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5527 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4817 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread #1" daemon prio=5 tid=1785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2496-thread-1"  prio=5 tid=5544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp571581767-5399" daemon prio=5 tid=5399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 33863" daemon prio=5 tid=5361 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=693 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 44865" daemon prio=5 tid=4245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3679 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderStateImpl" daemon prio=5 tid=5969 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 15 on default port 46647" daemon prio=5 tid=4497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=5118 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4813 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5135 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 38815" daemon prio=5 tid=6249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4925 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5291 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"qtp1272541579-5596" daemon prio=5 tid=5596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5698 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 38815" daemon prio=5 tid=6237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3556 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp7351632-5715" daemon prio=5 tid=5715 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3676 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4913 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 37215" daemon prio=5 tid=5335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5c066ef7" daemon prio=5 tid=4502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-3"  prio=5 tid=5633 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 44865" daemon prio=5 tid=4238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-0"  prio=5 tid=5417 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1987065550) connection to 0.0.0.0/0.0.0.0:45153 from runner" daemon prio=5 tid=4801 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4774 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-2"  prio=5 tid=5423 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-6"  prio=5 tid=5667 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3697 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp7351632-5712" daemon prio=5 tid=5712 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-2525-thread-1" daemon prio=5 tid=5617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 38815" daemon prio=5 tid=6243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 46647" daemon prio=5 tid=4501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DatanodeAdminManager-0" daemon prio=5 tid=5287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@632316d4" daemon prio=5 tid=3726 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3688 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4749 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 46647" daemon prio=5 tid=4492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3777 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4596 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1158040657-3741" daemon prio=5 tid=3741 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1576391952-3497" daemon prio=5 tid=3497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7d580945" daemon prio=5 tid=4752 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5825 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6178 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"qtp1024951597-4830" daemon prio=5 tid=4830 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5660 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"69c31795-da41-43dd-a637-b3015d9175ea-server-thread2" daemon prio=5 tid=5963 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"501a6ba0-4aa7-4660-9456-a414ab3e4b55@group-DA29AE892420-LeaderStateImpl" daemon prio=5 tid=5034 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"SnapshotDeletingService#0" daemon prio=5 tid=3493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5733 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-StateMachineUpdater" daemon prio=5 tid=5928 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4814 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4809 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4dc9bffe" daemon prio=5 tid=5621 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4772 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=694 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2090 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp508294491-6261" daemon prio=5 tid=6261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp448963796-4734" daemon prio=5 tid=4734 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1158040657-3745" daemon prio=5 tid=3745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4594 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-StateMachineUpdater" daemon prio=5 tid=5898 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 37647" daemon prio=5 tid=5471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=5793 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3845 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp571581767-5395" daemon prio=5 tid=5395 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 39209" daemon prio=5 tid=6202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderStateImpl" daemon prio=5 tid=5959 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"SnapshotDeletingService#0" daemon prio=5 tid=5447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-SegmentedRaftLogWorker"  prio=5 tid=5931 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=4194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2146-thread-1"  prio=5 tid=4762 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp714067911-3550" daemon prio=5 tid=3550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3558 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor53" daemon prio=5 tid=5756 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5144 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 33863" daemon prio=5 tid=5347 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b6ec7ff8-4fb1-4237-b084-632f2f252394-server-thread2" daemon prio=5 tid=3988 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-4"  prio=5 tid=5642 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=4902 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 44865" daemon prio=5 tid=4248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4158 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 0.0.0.0/39209"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
        at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:589)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
        at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
        at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$164/2001223946.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall$$Lambda$165/794075965.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$$Lambda$322/1066513687.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$1236/1734902032.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/20853837.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/1158258131.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/252277567.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/510276116.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/20853837.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/1158258131.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/252277567.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/510276116.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/20853837.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/1158258131.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/252277567.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$220/262445056.accept(Unknown Source)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
        at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
"ChunkWriter-3-0" daemon prio=5 tid=5828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5783 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 37647" daemon prio=5 tid=5469 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-6"  prio=5 tid=5665 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-5"  prio=5 tid=5647 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 46647" daemon prio=5 tid=4498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 39209" daemon prio=5 tid=6206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"timer2" daemon prio=5 tid=540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3700 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2503-thread-1" daemon prio=5 tid=5573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=3488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp508294491-6264" daemon prio=5 tid=6264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 38815" daemon prio=5 tid=6248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->b6ec7ff8-4fb1-4237-b084-632f2f252394-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=3984 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"fda26913-bdfb-48f8-b38a-a95200d457c8@group-6FA68D6DBDE7-LeaderStateImpl" daemon prio=5 tid=4020 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"pool-2510-thread-1"  prio=5 tid=5918 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2068667046-5522" daemon prio=5 tid=5522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 39209" daemon prio=5 tid=6205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5d223bb9" daemon prio=5 tid=5564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 36479" daemon prio=5 tid=5378 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5762 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1888992557-4690" daemon prio=5 tid=4690 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:38815 - 0 "  prio=5 tid=3789 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1576391952-3499" daemon prio=5 tid=3499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 37647" daemon prio=5 tid=5470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=5282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/807543346.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=475 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-1"  prio=5 tid=5419 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 38901" daemon prio=5 tid=6216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp7351632-5719" daemon prio=5 tid=5719 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp863502069-5549" daemon prio=5 tid=5549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3eb46789" daemon prio=5 tid=5513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4810 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5872 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 45153" daemon prio=5 tid=4260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-SegmentedRaftLogWorker"  prio=5 tid=3905 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4897 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d214675b-6525-49c2-82fc-0766bb958e6c-server-thread1" daemon prio=5 tid=5039 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 44865" daemon prio=5 tid=4232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderStateImpl" daemon prio=5 tid=6011 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Session-HouseKeeper-304702f3-1"  prio=5 tid=5553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 37215" daemon prio=5 tid=5339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5142 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5d01a853-2762-48e2-9549-a3e9717c76c4-server-thread3" daemon prio=5 tid=5066 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-5"  prio=5 tid=4466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Socket Reader #1 for port 0"  prio=5 tid=5435 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->fda26913-bdfb-48f8-b38a-a95200d457c8-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4188 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4844 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4026 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5848 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=4898 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5d01a853-2762-48e2-9549-a3e9717c76c4@group-F313ACE4FCDA-LeaderStateImpl" daemon prio=5 tid=5068 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 1 on default port 45153" daemon prio=5 tid=4252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6287 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5664 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 45153" daemon prio=5 tid=4256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=5302 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3856 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5133 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@e6c9a33" daemon prio=5 tid=5612 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36479 - 0 "  prio=5 tid=5790 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36479 - 0 "  prio=5 tid=5751 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3699 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp508294491-6265" daemon prio=5 tid=6265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-SegmentedRaftLogWorker"  prio=5 tid=5895 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3833 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3837 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5499 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 39209" daemon prio=5 tid=6179 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6304 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-7"  prio=5 tid=5670 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=6184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1076523403-4635" daemon prio=5 tid=4635 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor56" daemon prio=5 tid=5843 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"501a6ba0-4aa7-4660-9456-a414ab3e4b55@group-DA29AE892420->3d3cc5bc-4c5c-47d7-a20a-a694733df5c2-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5035 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp796383693-5495" daemon prio=5 tid=5495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3790 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=6169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:140)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5662 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3678 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3234 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2466-thread-1"  prio=5 tid=5902 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp796383693-5490" daemon prio=5 tid=5490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1540-thread-1"  prio=5 tid=3471 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-8ac37d9-1"  prio=5 tid=4481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36479 - 0 "  prio=5 tid=5856 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=6191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 39209" daemon prio=5 tid=6198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-StateMachineUpdater" daemon prio=5 tid=5999 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp776989826-4479" daemon prio=5 tid=4479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 43801" daemon prio=5 tid=3514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=5841 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 33863" daemon prio=5 tid=5346 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-3b0d4d71-1"  prio=5 tid=4798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4891 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1576391952-3498" daemon prio=5 tid=3498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp863502069-5552" daemon prio=5 tid=5552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 43165" daemon prio=5 tid=4219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3689 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2637-thread-1"  prio=5 tid=5770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5289 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"5d01a853-2762-48e2-9549-a3e9717c76c4-server-thread2" daemon prio=5 tid=5065 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 33863" daemon prio=5 tid=5343 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"69c31795-da41-43dd-a637-b3015d9175ea-server-thread1" daemon prio=5 tid=5962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:45153 - 0 "  prio=5 tid=4917 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6282 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1655-thread-1"  prio=5 tid=3950 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5799 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-3"  prio=5 tid=5424 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2068667046-5515" daemon prio=5 tid=5515 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"5d01a853-2762-48e2-9549-a3e9717c76c4@group-5E5C27C83E0F-StateMachineUpdater" daemon prio=5 tid=4975 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4895 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137308388-3714" daemon prio=5 tid=3714 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3724 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=5305 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"2829ccc8-889f-48cc-a62b-b3954aa0680c@group-05A935A1F922-SegmentedRaftLogWorker"  prio=5 tid=3960 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1577-thread-1"  prio=5 tid=3904 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4697 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c0e1ff4" daemon prio=5 tid=5504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-8" daemon prio=5 tid=3770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137308388-3710" daemon prio=5 tid=3710 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp645241368-4794" daemon prio=5 tid=4794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4881 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=5301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3115 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@444130ca" daemon prio=5 tid=4625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 39209" daemon prio=5 tid=6200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-server-thread1" daemon prio=5 tid=5987 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=3491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 39209" daemon prio=5 tid=6204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=4808 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1863303266-3607" daemon prio=5 tid=3607 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2532-thread-1"  prio=5 tid=5925 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 43165" daemon prio=5 tid=4226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Mini-Cluster-Provider-Reap"  prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$reapClusters$0(MiniOzoneClusterProvider.java:199)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$343/1175418534.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3691 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5800 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=3565 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1->69c31795-da41-43dd-a637-b3015d9175ea-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5960 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4670 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-8"  prio=5 tid=5679 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@71b1e93d" daemon prio=5 tid=3591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3763 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"2829ccc8-889f-48cc-a62b-b3954aa0680c-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3663 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5782 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 43165" daemon prio=5 tid=4215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1863303266-3603-acceptor-0@2c85ca8c-ServerConnector@7357e93e{HTTP/1.1, (http/1.1)}{0.0.0.0:36707}" daemon prio=3 tid=3603 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1888992557-4688-acceptor-0@25c5d080-ServerConnector@74485cb0{HTTP/1.1, (http/1.1)}{0.0.0.0:42685}" daemon prio=3 tid=4688 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp645241368-4792" daemon prio=5 tid=4792 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"7a5fc61e-353f-4ae0-a1a2-0b863c4aace9@group-5E5C27C83E0F-SegmentedRaftLogWorker"  prio=5 tid=4969 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4865 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5525 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6182 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"BlockDeletingService#1" daemon prio=5 tid=5833 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4815 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-33-thread-1"  prio=5 tid=125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp128943676-5774" daemon prio=5 tid=5774 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2600-thread-1"  prio=5 tid=5711 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=4185 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=5850 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7a5fc61e-353f-4ae0-a1a2-0b863c4aace9@group-5E5C27C83E0F-StateMachineUpdater" daemon prio=5 tid=4971 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-2194-thread-1"  prio=5 tid=4829 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2153-thread-1" daemon prio=5 tid=4784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 37215" daemon prio=5 tid=5319 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=5830 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 36479" daemon prio=5 tid=5381 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 46647" daemon prio=5 tid=4493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=4807 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"7a5fc61e-353f-4ae0-a1a2-0b863c4aace9-server-thread2" daemon prio=5 tid=5064 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 46647" daemon prio=5 tid=4488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 7 on default port 33863" daemon prio=5 tid=5350 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 2 on default port 37647" daemon prio=5 tid=5460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3247 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 38901"  prio=5 tid=6176 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=5308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5120 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3725 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3249 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=6276 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5788 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 37647" daemon prio=5 tid=5475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=4879 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp508294491-6258" daemon prio=5 tid=6258 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"3a4aa664-0d4f-4943-bed7-1a9050fc989f-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3541 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"fda26913-bdfb-48f8-b38a-a95200d457c8-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3734 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@75ad2f8c" daemon prio=5 tid=4732 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-5"  prio=5 tid=5648 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState" daemon prio=5 tid=6144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6305 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-StateMachineUpdater" daemon prio=5 tid=5901 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:38815 - 0 "  prio=5 tid=3755 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b6ec7ff8-4fb1-4237-b084-632f2f252394-server-thread1" daemon prio=5 tid=3987 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 44865" daemon prio=5 tid=4250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4595 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=5307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7a5fc61e-353f-4ae0-a1a2-0b863c4aace9@group-66E5D0307CD6-SegmentedRaftLogWorker"  prio=5 tid=4966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp276108260-3580" daemon prio=5 tid=3580 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5794 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1711-thread-1"  prio=5 tid=3737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5434 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5559 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderStateImpl" daemon prio=5 tid=5951 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 3 on default port 36479" daemon prio=5 tid=5366 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker"  prio=5 tid=5997 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3835 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1076523403-4633" daemon prio=5 tid=4633 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3852 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2430-thread-1"  prio=5 tid=5431 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1648-thread-1" daemon prio=5 tid=3661 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4915 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-0" daemon prio=5 tid=6292 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4755 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=4899 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3113 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 45153" daemon prio=5 tid=4268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4820 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:38815 - 0 "  prio=5 tid=3680 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 37647" daemon prio=5 tid=5465 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4750 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3853 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137308388-3711-acceptor-0@4d67feb-ServerConnector@38d6af62{HTTP/1.1, (http/1.1)}{0.0.0.0:40573}" daemon prio=3 tid=3711 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4704 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 45153" daemon prio=5 tid=4254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=3659 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 46647" daemon prio=5 tid=4459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ChunkWriter-1-0" daemon prio=5 tid=3686 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor38" daemon prio=5 tid=3834 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5268 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 43801" daemon prio=5 tid=3521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5565 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1576391952-3502" daemon prio=5 tid=3502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4803 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6297 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=5849 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@74403d38" daemon prio=5 tid=4272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"b6ec7ff8-4fb1-4237-b084-632f2f252394-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3598 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-SegmentedRaftLogWorker"  prio=5 tid=5926 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp128943676-5778" daemon prio=5 tid=5778 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1053690125-4553" daemon prio=5 tid=4553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-33528925-1"  prio=5 tid=4282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@63b8ce7f" daemon prio=5 tid=3665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp1940908711-4767" daemon prio=5 tid=4767 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"117526ec-9427-41bf-9dbd-c8f743595c9c-server-thread3" daemon prio=5 tid=5967 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"2829ccc8-889f-48cc-a62b-b3954aa0680c@group-05A935A1F922-StateMachineUpdater" daemon prio=5 tid=3962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5122 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1158040657-3744" daemon prio=5 tid=3744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5299 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"3d3cc5bc-4c5c-47d7-a20a-a694733df5c2-server-thread2" daemon prio=5 tid=5038 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1980-thread-1"  prio=5 tid=4545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 43801" daemon prio=5 tid=3507 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp645241368-4797" daemon prio=5 tid=4797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3245 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=4900 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp276108260-3581" daemon prio=5 tid=3581 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor51" daemon prio=5 tid=5441 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=3480 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"qtp776989826-4473" daemon prio=5 tid=4473 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 44865" daemon prio=5 tid=4233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp863502069-5547" daemon prio=5 tid=5547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1079985712-5626" daemon prio=5 tid=5626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4852 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp128943676-5772-acceptor-0@57a5befb-ServerConnector@502601ed{HTTP/1.1, (http/1.1)}{0.0.0.0:33853}" daemon prio=3 tid=5772 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=5306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4839 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1272541579-5602" daemon prio=5 tid=5602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"d214675b-6525-49c2-82fc-0766bb958e6c@group-DA29AE892420-SegmentedRaftLogWorker"  prio=5 tid=4955 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3698 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 43801" daemon prio=5 tid=3481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3557 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1863303266-3609" daemon prio=5 tid=3609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6158 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp7351632-5713-acceptor-0@1d7239a1-ServerConnector@7cca3187{HTTP/1.1, (http/1.1)}{0.0.0.0:46857}" daemon prio=3 tid=5713 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5296 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server handler 2 on default port 39209" daemon prio=5 tid=6197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4883 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp276108260-3577" daemon prio=5 tid=3577 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"b6ec7ff8-4fb1-4237-b084-632f2f252394@group-E79B029C057B-StateMachineUpdater" daemon prio=5 tid=3914 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=6192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 45153" daemon prio=5 tid=4266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 39209" daemon prio=5 tid=6195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5847 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d214675b-6525-49c2-82fc-0766bb958e6c@group-00B73C10D651-SegmentedRaftLogWorker"  prio=5 tid=4959 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1488333729-4280" daemon prio=5 tid=4280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@f67e5dc" daemon prio=5 tid=4761 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6303 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d214675b-6525-49c2-82fc-0766bb958e6c@group-DA29AE892420-FollowerState" daemon prio=5 tid=5033 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-4"  prio=5 tid=5646 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 37647" daemon prio=5 tid=5468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"fda26913-bdfb-48f8-b38a-a95200d457c8@group-6FA68D6DBDE7-StateMachineUpdater" daemon prio=5 tid=3969 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor44" daemon prio=5 tid=4866 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 38901" daemon prio=5 tid=6175 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"69c31795-da41-43dd-a637-b3015d9175ea-impl-thread1"  prio=5 tid=5512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2131-thread-1" daemon prio=5 tid=4757 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=4171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/807543346.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2186-thread-1"  prio=5 tid=4996 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=715 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-StateMachineUpdater" daemon prio=5 tid=5914 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1076523403-4632" daemon prio=5 tid=4632 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3869 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1506-thread-1"  prio=5 tid=3427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 45153" daemon prio=5 tid=4251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-1c45cbe6-1"  prio=5 tid=3503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5736 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 43165" daemon prio=5 tid=4227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=2084 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1488333729-4275-acceptor-0@6724ce52-ServerConnector@6e9bb6f1{HTTP/1.1, (http/1.1)}{0.0.0.0:35815}" daemon prio=3 tid=4275 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=5383 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 43801" daemon prio=5 tid=3517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=4882 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-1" daemon prio=5 tid=6293 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp796383693-5492" daemon prio=5 tid=5492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4912 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 46647" daemon prio=5 tid=4500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 37215" daemon prio=5 tid=5336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=4457 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"ChunkReader-ELG-0" daemon prio=5 tid=5844 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 46647" daemon prio=5 tid=4491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 9 on default port 38815" daemon prio=5 tid=6244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5610 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7a02b2c7" daemon prio=5 tid=4544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4847 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 39209" daemon prio=5 tid=6181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 19 on default port 36479" daemon prio=5 tid=5382 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=5758 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2109-thread-1" daemon prio=5 tid=4728 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3850 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5878 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4877 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6300 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor39" daemon prio=5 tid=3848 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1674-thread-1" daemon prio=5 tid=3704 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"501a6ba0-4aa7-4660-9456-a414ab3e4b55-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4683 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6174 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"5d01a853-2762-48e2-9549-a3e9717c76c4@group-5E5C27C83E0F-SegmentedRaftLogWorker"  prio=5 tid=4973 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2488-thread-1"  prio=5 tid=5907 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 37647" daemon prio=5 tid=5474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 18 on default port 37647" daemon prio=5 tid=5476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c6848394-c9b5-4662-b948-5f3170864dbf@group-47CDFE3ECD8B-SegmentedRaftLogWorker"  prio=5 tid=4993 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4025 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4893 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5831 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 33863" daemon prio=5 tid=5345 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 46647" daemon prio=5 tid=4495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5230 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1934-thread-1"  prio=5 tid=4472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5796 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=6170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"501a6ba0-4aa7-4660-9456-a414ab3e4b55@group-6F499BE2D5A5-SegmentedRaftLogWorker"  prio=5 tid=4962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 39209" daemon prio=5 tid=6214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1076523403-4637" daemon prio=5 tid=4637 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=6168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:140)
        at java.lang.Thread.run(Thread.java:750)
"qtp2068667046-5517" daemon prio=5 tid=5517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 37215" daemon prio=5 tid=5337 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 37215" daemon prio=5 tid=5323 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5121 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3838 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"501a6ba0-4aa7-4660-9456-a414ab3e4b55@group-DA29AE892420-SegmentedRaftLogWorker"  prio=5 tid=4950 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4799 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3a4aa664-0d4f-4943-bed7-1a9050fc989f@group-E79B029C057B-FollowerState" daemon prio=5 tid=3980 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=6285 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp276108260-3578" daemon prio=5 tid=3578 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6269 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 37647" daemon prio=5 tid=5466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=5288 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"b6ec7ff8-4fb1-4237-b084-632f2f252394@group-E79B029C057B-FollowerState" daemon prio=5 tid=3981 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"ChunkWriter-1-0" daemon prio=5 tid=5753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 46647" daemon prio=5 tid=4499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1158040657-3738" daemon prio=5 tid=3738 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1940908711-4768" daemon prio=5 tid=4768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6296 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState" daemon prio=5 tid=6143 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5745 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5507 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor47" daemon prio=5 tid=4910 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3719 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4921 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1272541579-5603" daemon prio=5 tid=5603 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5857 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=5283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/807543346.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 36479" daemon prio=5 tid=5379 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=5503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6278 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6302 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3722 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=5854 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4178 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server handler 14 on default port 43801" daemon prio=5 tid=3518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 43165" daemon prio=5 tid=4230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Timer-4"  prio=5 tid=3487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4024 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c1d68bf5-941c-4ef4-97c3-9b8585fa6dbb@group-6EF5E8121392-LeaderStateImpl" daemon prio=5 tid=5072 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"b6ec7ff8-4fb1-4237-b084-632f2f252394@group-E79B029C057B-SegmentedRaftLogWorker"  prio=5 tid=3912 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=5891 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=6255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@323d2ddb" daemon prio=5 tid=5594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5837 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=4173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:876)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$424/524446063.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1024951597-4833" daemon prio=5 tid=4833 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5873 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5295 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4673 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp508294491-6260" daemon prio=5 tid=6260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=6186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@49408f63" daemon prio=5 tid=4846 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@397ff938" daemon prio=5 tid=4828 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp1488333729-4277" daemon prio=5 tid=4277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=4901 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5785 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1076523403-4636" daemon prio=5 tid=4636 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp128943676-5771" daemon prio=5 tid=5771 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp276108260-3575" daemon prio=5 tid=3575 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=5304 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4863 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 39209" daemon prio=5 tid=6210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-0"  prio=5 tid=5415 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1f60a1d7" daemon prio=5 tid=3573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp1576391952-3500" daemon prio=5 tid=3500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5760 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2068667046-5521" daemon prio=5 tid=5521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderStateImpl" daemon prio=5 tid=6145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 6 on default port 43165" daemon prio=5 tid=4217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4776 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp448963796-4740" daemon prio=5 tid=4740 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5742 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 37215" daemon prio=5 tid=5333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp7351632-5717" daemon prio=5 tid=5717 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4027 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 45153" daemon prio=5 tid=4253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4916 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderStateImpl" daemon prio=5 tid=5996 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"pool-2168-thread-1"  prio=5 tid=4789 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1888992557-4692" daemon prio=5 tid=4692 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 45153" daemon prio=5 tid=4267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-681-thread-1"  prio=5 tid=1526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4458 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=4155 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor58" daemon prio=5 tid=5876 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4782 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5608 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp645241368-4793" daemon prio=5 tid=4793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4777 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3677 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=6163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-StateMachineUpdater" daemon prio=5 tid=3908 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4920 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1076523403-4634" daemon prio=5 tid=4634 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 37647" daemon prio=5 tid=5472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 44865" daemon prio=5 tid=4231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=4896 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 45153" daemon prio=5 tid=4258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6160 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4822 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1272541579-5601" daemon prio=5 tid=5601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5d01a853-2762-48e2-9549-a3e9717c76c4@group-F313ACE4FCDA-StateMachineUpdater" daemon prio=5 tid=4984 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp714067911-3551" daemon prio=5 tid=3551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5842 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5437 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"OMDoubleBufferFlushThread" daemon prio=5 tid=4379 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:614)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$553/216087484.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 46647" daemon prio=5 tid=4496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1863303266-3604" daemon prio=5 tid=3604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 38901" daemon prio=5 tid=6221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=3485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5870 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6279 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5858 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp448963796-4736" daemon prio=5 tid=4736 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1488333729-4281" daemon prio=5 tid=4281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5528 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp863502069-5546-acceptor-0@775dfcd2-ServerConnector@140401bd{HTTP/1.1, (http/1.1)}{0.0.0.0:41213}" daemon prio=3 tid=5546 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@cef23a8" daemon prio=5 tid=6256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5859 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4751 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 45153" daemon prio=5 tid=4264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5746 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 43165" daemon prio=5 tid=4221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2160-thread-1"  prio=5 tid=4977 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3798 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4871 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=4942 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5832 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4906 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1987065550) connection to 0.0.0.0/0.0.0.0:38815 from runner" daemon prio=5 tid=6162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1c00254f" daemon prio=5 tid=4788 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3727 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 43801" daemon prio=5 tid=3504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=6274 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5562 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 38901" daemon prio=5 tid=6230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4599 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1940908711-4765" daemon prio=5 tid=4765 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1987065550) connection to 0.0.0.0/0.0.0.0:36479 from runner" daemon prio=5 tid=5728 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"3d3cc5bc-4c5c-47d7-a20a-a694733df5c2@group-DA29AE892420-StateMachineUpdater" daemon prio=5 tid=4948 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-StateMachineUpdater" daemon prio=5 tid=5933 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-9"  prio=5 tid=5682 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1548-thread-1" daemon prio=5 tid=3539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor54" daemon prio=5 tid=5795 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2622-thread-1" daemon prio=5 tid=5764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"0da438f1-d8bd-4523-91d3-cbc74717487d-client-thread1" daemon prio=5 tid=5413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 38901" daemon prio=5 tid=6218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2452-thread-1"  prio=5 tid=5487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5879 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2481-thread-1" daemon prio=5 tid=5536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SnapshotDeletingService#0" daemon prio=5 tid=4471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5752 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-2"  prio=5 tid=5425 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 46647" daemon prio=5 tid=4487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=3844 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-StateMachineUpdater" daemon prio=5 tid=6002 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108->4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5985 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5880 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OMDoubleBufferFlushThread" daemon prio=5 tid=5429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:614)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$553/216087484.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"fda26913-bdfb-48f8-b38a-a95200d457c8@group-6FA68D6DBDE7-SegmentedRaftLogWorker"  prio=5 tid=3967 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3830 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3768 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1158040657-3743" daemon prio=5 tid=3743 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=6188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3684 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1966-thread-1"  prio=5 tid=4941 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1576391952-3501" daemon prio=5 tid=3501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5791 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp448963796-4735-acceptor-0@1dd1ae00-ServerConnector@302889ff{HTTP/1.1, (http/1.1)}{0.0.0.0:44885}" daemon prio=3 tid=4735 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp863502069-5545" daemon prio=5 tid=5545 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5293 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLogWorker"  prio=5 tid=5908 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"3a4aa664-0d4f-4943-bed7-1a9050fc989f@group-E79B029C057B-SegmentedRaftLogWorker"  prio=5 tid=3901 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 127.0.0.1/37647"  prio=5 tid=14 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:353)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$createClusters$1(MiniOzoneClusterProvider.java:237)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$342/299819831.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1->117526ec-9427-41bf-9dbd-c8f743595c9c-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5961 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1158040657-3740" daemon prio=5 tid=3740 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"c6848394-c9b5-4662-b948-5f3170864dbf@group-5E5C27C83E0F-LeaderStateImpl" daemon prio=5 tid=5059 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ChunkWriter-2-0" daemon prio=5 tid=5827 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5613 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5501 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5532 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 36479" daemon prio=5 tid=5367 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=3594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2042-thread-1"  prio=5 tid=4954 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4889 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2406-thread-1"  prio=5 tid=5428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-SegmentedRaftLogWorker"  prio=5 tid=5912 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3614 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=4191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"null-request--thread1" daemon prio=5 tid=5273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2068667046-5516-acceptor-0@6a88c7b5-ServerConnector@490c3030{HTTP/1.1, (http/1.1)}{0.0.0.0:40255}" daemon prio=3 tid=5516 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3585 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-428ebfc3-1"  prio=5 tid=3583 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp645241368-4790" daemon prio=5 tid=4790 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp472636590-3669" daemon prio=5 tid=3669 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2179-thread-1" daemon prio=5 tid=4824 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3687 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5558 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 36479" daemon prio=5 tid=5370 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ReplicationMonitor" daemon prio=5 tid=6167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:876)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$424/524446063.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 37215" daemon prio=5 tid=5325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=4929 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1488333729-4276" daemon prio=5 tid=4276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=5300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1488333729-4278" daemon prio=5 tid=4278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-SegmentedRaftLogWorker"  prio=5 tid=6000 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7cc40786" daemon prio=5 tid=5478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=5280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 36479" daemon prio=5 tid=5371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"3a4aa664-0d4f-4943-bed7-1a9050fc989f-server-thread2" daemon prio=5 tid=3986 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2444-thread-1"  prio=5 tid=5893 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2390-thread-1"  prio=5 tid=5392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3612 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp714067911-3548" daemon prio=5 tid=3548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5697 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5725 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4842 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3a4aa664-0d4f-4943-bed7-1a9050fc989f-server-thread1" daemon prio=5 tid=3985 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36479 - 0 "  prio=5 tid=5838 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5823 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=4470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 43165" daemon prio=5 tid=4216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Socket Reader #1 for port 0"  prio=5 tid=4182 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server handler 18 on default port 43801" daemon prio=5 tid=3522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp796383693-5489-acceptor-0@39be3e7e-ServerConnector@64750fdd{HTTP/1.1, (http/1.1)}{0.0.0.0:41875}" daemon prio=3 tid=5489 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 43165" daemon prio=5 tid=4212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 43801" daemon prio=5 tid=3523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=4196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1079985712-5625" daemon prio=5 tid=5625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 44865" daemon prio=5 tid=4239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@78ca1945" daemon prio=5 tid=5486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 43801" daemon prio=5 tid=3519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-1"  prio=5 tid=5420 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7a5fc61e-353f-4ae0-a1a2-0b863c4aace9@group-66E5D0307CD6-StateMachineUpdater" daemon prio=5 tid=4968 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5792 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5592 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6288 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5217 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3a4aa664-0d4f-4943-bed7-1a9050fc989f@group-B33483349863-LeaderStateImpl" daemon prio=5 tid=3990 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 0 on default port 38815" daemon prio=5 tid=6235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp571581767-5397" daemon prio=5 tid=5397 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6286 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5138 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1863303266-3606" daemon prio=5 tid=3606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=4654 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server listener on 0" daemon prio=5 tid=4181 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server handler 16 on default port 38815" daemon prio=5 tid=6251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4914 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp571581767-5402" daemon prio=5 tid=5402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4702 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 38815" daemon prio=5 tid=6242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 39209" daemon prio=5 tid=6208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 3 on default port 44865" daemon prio=5 tid=4234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=6271 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 36479" daemon prio=5 tid=5376 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=4462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2459-thread-1" daemon prio=5 tid=5509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@cb3863" daemon prio=5 tid=3543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4888 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp7351632-5718" daemon prio=5 tid=5718 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"3a4aa664-0d4f-4943-bed7-1a9050fc989f@group-E79B029C057B-StateMachineUpdater" daemon prio=5 tid=3903 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5739 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137308388-3715" daemon prio=5 tid=3715 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2518-thread-1"  prio=5 tid=5595 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor48" daemon prio=5 tid=4922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-SegmentedRaftLogWorker"  prio=5 tid=6004 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"69c31795-da41-43dd-a637-b3015d9175ea-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5511 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5502 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor33" daemon prio=5 tid=3486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=6273 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2094-thread-1"  prio=5 tid=4949 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1689-thread-1"  prio=5 tid=3709 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 37215" daemon prio=5 tid=5298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-2029-thread-1" daemon prio=5 tid=4614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3799 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a-server-thread2" daemon prio=5 tid=5991 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4908 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=4193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3fee8600-457c-478d-8bf5-017cc394a56c-server-thread2" daemon prio=5 tid=6149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 37647" daemon prio=5 tid=5459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=4804 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-6"  prio=5 tid=5442 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1940908711-4764-acceptor-0@4037ebb7-ServerConnector@515b3e2a{HTTP/1.1, (http/1.1)}{0.0.0.0:38909}" daemon prio=3 tid=4764 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"b6ec7ff8-4fb1-4237-b084-632f2f252394@group-EA2D11851ACC-LeaderStateImpl" daemon prio=5 tid=3994 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"timer7" daemon prio=5 tid=572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c-impl-thread1"  prio=5 tid=5707 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=5446 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1272541579-5600" daemon prio=5 tid=5600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7642476f" daemon prio=5 tid=3600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 36479" daemon prio=5 tid=5377 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp645241368-4795" daemon prio=5 tid=4795 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 43801" daemon prio=5 tid=3512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=6284 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5659 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-4"  prio=5 tid=5644 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1888992557-4693" daemon prio=5 tid=4693 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"fda26913-bdfb-48f8-b38a-a95200d457c8-server-thread1" daemon prio=5 tid=6150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5881 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"501a6ba0-4aa7-4660-9456-a414ab3e4b55@group-DA29AE892420-StateMachineUpdater" daemon prio=5 tid=4952 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4868 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 38901" daemon prio=5 tid=6227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 39209" daemon prio=5 tid=6209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1555-thread-1"  prio=5 tid=3896 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"38de582e-58a6-400e-852c-9e1084927a05-impl-thread1"  prio=5 tid=5768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 36479" daemon prio=5 tid=5369 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5744 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=4172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/807543346.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4186 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Command processor thread" daemon prio=5 tid=3617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-6"  prio=5 tid=5666 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 37215" daemon prio=5 tid=5341 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=3766 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=5303 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:45153 - 0 "  prio=5 tid=4800 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4886 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=4468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3849 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-SegmentedRaftLogWorker"  prio=5 tid=5899 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4850 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 38901" daemon prio=5 tid=6220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=6189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4926 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3fee8600-457c-478d-8bf5-017cc394a56c-server-thread1" daemon prio=5 tid=6148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d3cc5bc-4c5c-47d7-a20a-a694733df5c2@group-6A3096E10B0F-LeaderStateImpl" daemon prio=5 tid=5025 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 7 on default port 43165" daemon prio=5 tid=4218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=3793 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"501a6ba0-4aa7-4660-9456-a414ab3e4b55@group-6F499BE2D5A5-StateMachineUpdater" daemon prio=5 tid=4964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5863 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2116-thread-1"  prio=5 tid=4965 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4698 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer1" daemon prio=5 tid=536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 7 on default port 43801" daemon prio=5 tid=3511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=6165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/807543346.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4911 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp128943676-5776" daemon prio=5 tid=5776 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2474-thread-1"  prio=5 tid=5514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 43801" daemon prio=5 tid=3508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=4876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=5309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4699 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d3cc5bc-4c5c-47d7-a20a-a694733df5c2-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4532 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5619 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 44865" daemon prio=5 tid=4242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor34" daemon prio=5 tid=3695 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5741 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1024951597-4834" daemon prio=5 tid=4834 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp863502069-5548" daemon prio=5 tid=5548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=5284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:876)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$424/524446063.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 38815" daemon prio=5 tid=6246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-43ada085-1"  prio=5 tid=5523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=6156 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-9" daemon prio=5 tid=6127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-impl-thread1"  prio=5 tid=5593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-server-thread2" daemon prio=5 tid=5988 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1696-thread-1" daemon prio=5 tid=3731 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 37215" daemon prio=5 tid=5332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3696 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3774 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 37647" daemon prio=5 tid=5436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3588 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5866 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3842 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp7351632-5714" daemon prio=5 tid=5714 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-7ea30226-1"  prio=5 tid=4838 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4672 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4923 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5656 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=3479 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"BlockDeletingService#2" daemon prio=5 tid=6289 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1053690125-4548" daemon prio=5 tid=4548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=6185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderStateImpl" daemon prio=5 tid=6009 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-2"  prio=5 tid=5422 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4862 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a-impl-thread1"  prio=5 tid=5620 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1888992557-4687" daemon prio=5 tid=4687 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36479 - 0 "  prio=5 tid=5726 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c6848394-c9b5-4662-b948-5f3170864dbf@group-5E5C27C83E0F-StateMachineUpdater" daemon prio=5 tid=4980 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 33863" daemon prio=5 tid=5358 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-37569ad6-1"  prio=5 tid=3746 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp714067911-3546-acceptor-0@3a66c4ef-ServerConnector@6f9257f4{HTTP/1.1, (http/1.1)}{0.0.0.0:37745}" daemon prio=3 tid=3546 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 45153" daemon prio=5 tid=4263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"5d01a853-2762-48e2-9549-a3e9717c76c4@group-F313ACE4FCDA-SegmentedRaftLogWorker"  prio=5 tid=4982 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp776989826-4477" daemon prio=5 tid=4477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5846 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3562 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=3483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp796383693-5494" daemon prio=5 tid=5494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 38901" daemon prio=5 tid=6224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-SegmentedRaftLogWorker"  prio=5 tid=5903 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3589 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"117526ec-9427-41bf-9dbd-c8f743595c9c-server-thread2" daemon prio=5 tid=5964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 44865" daemon prio=5 tid=4236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp776989826-4474-acceptor-0@5b097052-ServerConnector@62d972f3{HTTP/1.1, (http/1.1)}{0.0.0.0:41501}" daemon prio=3 tid=4474 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 39209"  prio=5 tid=6180 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"b6ec7ff8-4fb1-4237-b084-632f2f252394@group-EA2D11851ACC-SegmentedRaftLogWorker"  prio=5 tid=3940 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=5440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3584 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5855 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 37215" daemon prio=5 tid=5326 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"grpc-default-executor-5" daemon prio=5 tid=541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=5852 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c6848394-c9b5-4662-b948-5f3170864dbf@group-5E5C27C83E0F->7a5fc61e-353f-4ae0-a1a2-0b863c4aace9-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5060 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 45153" daemon prio=5 tid=4270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 43165" daemon prio=5 tid=4211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2629-thread-1"  prio=5 tid=5941 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=4174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:140)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5877 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-7" daemon prio=5 tid=3563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp709761675-5454" daemon prio=5 tid=5454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:38815 - 0 "  prio=5 tid=3829 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1576391952-3495" daemon prio=5 tid=3495 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"process reaper" daemon prio=10 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@579e22a1" daemon prio=5 tid=4598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5266 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3114 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 33863" daemon prio=5 tid=5352 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=4919 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1488333729-4274" daemon prio=5 tid=4274 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 38815" daemon prio=5 tid=6240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"117526ec-9427-41bf-9dbd-c8f743595c9c-impl-thread1"  prio=5 tid=5542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3761 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d3cc5bc-4c5c-47d7-a20a-a694733df5c2@group-DA29AE892420-FollowerState" daemon prio=5 tid=5032 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"qtp448963796-4737" daemon prio=5 tid=4737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1940908711-4770" daemon prio=5 tid=4770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 43801" daemon prio=5 tid=3516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1137308388-3716" daemon prio=5 tid=3716 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 43165" daemon prio=5 tid=4223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2102-thread-1"  prio=5 tid=4686 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 38815" daemon prio=5 tid=6250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d214675b-6525-49c2-82fc-0766bb958e6c-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4622 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-22823b5a-1"  prio=5 tid=3553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp709761675-5450-acceptor-0@33f67930-ServerConnector@6be4bbe9{HTTP/1.1, (http/1.1)}{0.0.0.0:40617}" daemon prio=3 tid=5450 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=140 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5763 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7b966160" daemon prio=5 tid=5748 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@27cb8295" daemon prio=5 tid=5543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3694 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3839 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3702 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4700 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp472636590-3674" daemon prio=5 tid=3674 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"3fee8600-457c-478d-8bf5-017cc394a56c-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3706 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=5445 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 33863" daemon prio=5 tid=5360 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"3fee8600-457c-478d-8bf5-017cc394a56c@group-8A2418B3C9EC-StateMachineUpdater" daemon prio=5 tid=3965 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=4175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:140)
        at java.lang.Thread.run(Thread.java:750)
"qtp776989826-4476" daemon prio=5 tid=4476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 33863" daemon prio=5 tid=5356 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1863303266-3608" daemon prio=5 tid=3608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 43801" daemon prio=5 tid=3520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7799fc02" daemon prio=5 tid=4685 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-7f35e69e-1"  prio=5 tid=5720 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4918 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 44865" daemon prio=5 tid=4249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1053690125-4547-acceptor-0@11d73ea9-ServerConnector@3202f7a6{HTTP/1.1, (http/1.1)}{0.0.0.0:45771}" daemon prio=3 tid=4547 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4867 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor40" daemon prio=5 tid=3871 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp645241368-4796" daemon prio=5 tid=4796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"3fee8600-457c-478d-8bf5-017cc394a56c@group-8A2418B3C9EC-SegmentedRaftLogWorker"  prio=5 tid=3963 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-6d4dc83b-1"  prio=5 tid=5403 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5560 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-29c25697-1"  prio=5 tid=5457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderStateImpl" daemon prio=5 tid=5984 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5781 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4818 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=6275 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-StateMachineUpdater" daemon prio=5 tid=5944 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5658 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=5443 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@278a5323" daemon prio=5 tid=3524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5747 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1570-thread-1" daemon prio=5 tid=3569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4674 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState" daemon prio=5 tid=5983 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"3d3cc5bc-4c5c-47d7-a20a-a694733df5c2@group-6A3096E10B0F-StateMachineUpdater" daemon prio=5 tid=4945 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3619 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1585-thread-1"  prio=5 tid=3574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp709761675-5453" daemon prio=5 tid=5453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 44865" daemon prio=5 tid=4244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=5826 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1940908711-4766" daemon prio=5 tid=4766 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 43165" daemon prio=5 tid=4214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b6ec7ff8-4fb1-4237-b084-632f2f252394@group-EA2D11851ACC-StateMachineUpdater" daemon prio=5 tid=3942 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4853 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=3490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 38815" daemon prio=5 tid=6171 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"qtp276108260-3582" daemon prio=5 tid=3582 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1079985712-5630" daemon prio=5 tid=5630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor35" daemon prio=5 tid=3764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp796383693-5493" daemon prio=5 tid=5493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1053690125-4546" daemon prio=5 tid=4546 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 36479" daemon prio=5 tid=5375 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=4198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-6" daemon prio=5 tid=2186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-StateMachineUpdater" daemon prio=5 tid=5924 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1272541579-5599" daemon prio=5 tid=5599 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"c6848394-c9b5-4662-b948-5f3170864dbf@group-47CDFE3ECD8B-StateMachineUpdater" daemon prio=5 tid=4995 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4696 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=3492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1079985712-5629" daemon prio=5 tid=5629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 33863" daemon prio=5 tid=5354 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5864 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=5853 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@33b1b09d" daemon prio=5 tid=5531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 44865" daemon prio=5 tid=4243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4857 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6268 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 38901" daemon prio=5 tid=6226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=4180 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5607 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 43165" daemon prio=5 tid=4220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 43801" daemon prio=5 tid=3515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 1 on default port 38815" daemon prio=5 tid=6236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=4147 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3867 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3846 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137308388-3712" daemon prio=5 tid=3712 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3723 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1053690125-4551" daemon prio=5 tid=4551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=4903 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 38815" daemon prio=5 tid=6253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1024951597-4832-acceptor-0@51a2973b-ServerConnector@660b467b{HTTP/1.1, (http/1.1)}{0.0.0.0:33413}" daemon prio=3 tid=4832 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"3d3cc5bc-4c5c-47d7-a20a-a694733df5c2@group-DA29AE892420-SegmentedRaftLogWorker"  prio=5 tid=4946 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5750 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1053690125-4552" daemon prio=5 tid=4552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp128943676-5773" daemon prio=5 tid=5773 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-8"  prio=5 tid=5680 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp709761675-5452" daemon prio=5 tid=5452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5137 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1024951597-4836" daemon prio=5 tid=4836 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"38de582e-58a6-400e-852c-9e1084927a05-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5767 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a33a4e2" daemon prio=5 tid=5787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5731 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5526 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3868 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor43" daemon prio=5 tid=4854 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 36479" daemon prio=5 tid=5290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"timer6" daemon prio=5 tid=571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"BlockDeletingService#2" daemon prio=5 tid=5173 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1615-thread-1"  prio=5 tid=3601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 36479" daemon prio=5 tid=5373 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4874 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OMDoubleBufferFlushThread" daemon prio=5 tid=3468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:614)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$553/216087484.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3847 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLogWorker"  prio=5 tid=5922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1003-thread-1"  prio=5 tid=2378 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5706 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-1852-thread-1"  prio=5 tid=4346 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3767 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=5892 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5136 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4843 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4748 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=6183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2580-thread-1" daemon prio=5 tid=5699 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 37647" daemon prio=5 tid=5461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-SegmentedRaftLogWorker"  prio=5 tid=3917 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 33863" daemon prio=5 tid=5348 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 44865" daemon prio=5 tid=4241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1663-thread-1"  prio=5 tid=3666 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-9"  prio=5 tid=5683 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d3cc5bc-4c5c-47d7-a20a-a694733df5c2@group-6A3096E10B0F-SegmentedRaftLogWorker"  prio=5 tid=4943 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3690 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 39209" daemon prio=5 tid=6212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 18 on default port 39209" daemon prio=5 tid=6213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d214675b-6525-49c2-82fc-0766bb958e6c-server-thread3" daemon prio=5 tid=5041 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4907 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at org.apache.maven.surefire.api.util.internal.Channels$3.readImpl(Channels.java:214)
        at org.apache.maven.surefire.api.util.internal.AbstractNoninterruptibleReadableChannel.read(AbstractNoninterruptibleReadableChannel.java:54)
        at org.apache.maven.surefire.booter.spi.LegacyMasterProcessChannelDecoder.decode(LegacyMasterProcessChannelDecoder.java:80)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:343)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2089 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-impl-thread1"  prio=5 tid=5430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3792 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 46647" daemon prio=5 tid=4484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"69c31795-da41-43dd-a637-b3015d9175ea-server-thread3" daemon prio=5 tid=5965 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3832 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp776989826-4475" daemon prio=5 tid=4475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5174 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@679727b" daemon prio=5 tid=3736 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5761 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 43801" daemon prio=5 tid=3513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-StateMachineUpdater" daemon prio=5 tid=5917 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1888992557-4691" daemon prio=5 tid=4691 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp128943676-5777" daemon prio=5 tid=5777 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"3d3cc5bc-4c5c-47d7-a20a-a694733df5c2-server-thread1" daemon prio=5 tid=5037 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5875 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4679 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp709761675-5455" daemon prio=5 tid=5455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"c6848394-c9b5-4662-b948-5f3170864dbf@group-47CDFE3ECD8B-LeaderStateImpl" daemon prio=5 tid=5070 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp863502069-5550" daemon prio=5 tid=5550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-1"  prio=5 tid=5418 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp796383693-5488" daemon prio=5 tid=5488 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 44865" daemon prio=5 tid=4235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2138-thread-1"  prio=5 tid=4972 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5297 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server handler 9 on default port 44865" daemon prio=5 tid=4240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5740 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2087-thread-1" daemon prio=5 tid=4681 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 37215" daemon prio=5 tid=5317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp508294491-6263" daemon prio=5 tid=6263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4802 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1053690125-4550" daemon prio=5 tid=4550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-48a62a76-1"  prio=5 tid=3675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-8"  prio=5 tid=5681 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=3482 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"IPC Server handler 16 on default port 33863" daemon prio=5 tid=5359 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 17 on default port 38815" daemon prio=5 tid=6252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-SegmentedRaftLogWorker"  prio=5 tid=5938 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1272541579-5597-acceptor-0@7aa9177-ServerConnector@d6acd2e{HTTP/1.1, (http/1.1)}{0.0.0.0:34353}" daemon prio=3 tid=5597 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp472636590-3672" daemon prio=5 tid=3672 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4927 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2124-thread-1"  prio=5 tid=4733 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:45153 - 0 "  prio=5 tid=4905 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4860 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1894-thread-1"  prio=5 tid=4381 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 46647" daemon prio=5 tid=4483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5738 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-1" daemon prio=5 tid=530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=4197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 37215" daemon prio=5 tid=5318 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:38815 - 0 "  prio=5 tid=3857 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 33863" daemon prio=5 tid=5353 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp714067911-3547" daemon prio=5 tid=3547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 38815" daemon prio=5 tid=6254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 37215" daemon prio=5 tid=5327 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 36479" daemon prio=5 tid=5374 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1940908711-4769" daemon prio=5 tid=4769 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor41" daemon prio=5 tid=4465 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 45153" daemon prio=5 tid=4265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4904 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 45153" daemon prio=5 tid=4262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1158040657-3739-acceptor-0@111706a9-ServerConnector@21583737{HTTP/1.1, (http/1.1)}{0.0.0.0:35657}" daemon prio=3 tid=3739 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5789 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3616 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 38815" daemon prio=5 tid=6247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 37647" daemon prio=5 tid=5477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp472636590-3667" daemon prio=5 tid=3667 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-StateMachineUpdater" daemon prio=5 tid=5940 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=4192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 33863" daemon prio=5 tid=5355 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f412a53" daemon prio=5 tid=5663 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a-server-thread1" daemon prio=5 tid=5990 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 46647" daemon prio=5 tid=4489 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=699 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 38815" daemon prio=5 tid=6239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3874 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 36479" daemon prio=5 tid=5372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d214675b-6525-49c2-82fc-0766bb958e6c@group-00B73C10D651-LeaderStateImpl" daemon prio=5 tid=5043 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3769 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3555 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7a5fc61e-353f-4ae0-a1a2-0b863c4aace9-server-thread1" daemon prio=5 tid=5062 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-287-thread-1"  prio=5 tid=691 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6157 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-4" daemon prio=5 tid=539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6298 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=5117 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp448963796-4741" daemon prio=5 tid=4741 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 46647" daemon prio=5 tid=4486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#3" daemon prio=5 tid=6294 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3851 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=5438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4864 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@56f5c13b" daemon prio=5 tid=4703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"5d01a853-2762-48e2-9549-a3e9717c76c4-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4759 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-1681-thread-1"  prio=5 tid=3955 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3836 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2068667046-5520" daemon prio=5 tid=5520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 37215" daemon prio=5 tid=5322 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=5141 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3788 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3729 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1888992557-4694" daemon prio=5 tid=4694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-7dc0200e-1"  prio=5 tid=3718 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 38901" daemon prio=5 tid=6233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp2068667046-5519" daemon prio=5 tid=5519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp709761675-5451" daemon prio=5 tid=5451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor42" daemon prio=5 tid=4806 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp714067911-3552" daemon prio=5 tid=3552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"d214675b-6525-49c2-82fc-0766bb958e6c@group-DA29AE892420-StateMachineUpdater" daemon prio=5 tid=4957 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4157 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer5" daemon prio=5 tid=570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3592 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-365293a7-1"  prio=5 tid=5779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 33863" daemon prio=5 tid=5351 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp709761675-5449" daemon prio=5 tid=5449 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 43801" daemon prio=5 tid=3505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3778 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:45153 - 0 "  prio=5 tid=4875 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=4467 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer3" daemon prio=5 tid=542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server idle connection scanner for port 38901" daemon prio=5 tid=6177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"3d5bec3e-3873-417f-9114-370ff3a7c03a-server-thread3" daemon prio=5 tid=5992 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=6272 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor45" daemon prio=5 tid=4880 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5865 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 33863" daemon prio=5 tid=5344 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=5145 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1543-thread-1"  prio=5 tid=3494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3683 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@794df3b0" daemon prio=5 tid=5710 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 37647" daemon prio=5 tid=5467 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:45153 - 0 "  prio=5 tid=4849 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-StateMachineUpdater" daemon prio=5 tid=5905 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5840 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3a4aa664-0d4f-4943-bed7-1a9050fc989f@group-B33483349863-SegmentedRaftLogWorker"  prio=5 tid=3898 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5860 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5609 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2117 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 37647" daemon prio=5 tid=5473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:36479 - 0 "  prio=5 tid=5824 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5c7a3766-4df9-4a62-b680-fc04cc352416-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5484 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-0"  prio=5 tid=5416 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=4176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 37215" daemon prio=5 tid=5342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderStateImpl" daemon prio=5 tid=5972 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 10 on default port 38815" daemon prio=5 tid=6245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1488333729-4279" daemon prio=5 tid=4279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-68be6a69-1"  prio=5 tid=4742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=6193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ChunkWriter-1-0" daemon prio=5 tid=4851 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4778 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 33863" daemon prio=5 tid=5349 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:45153 - 0 "  prio=5 tid=4861 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5786 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4812 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"7a5fc61e-353f-4ae0-a1a2-0b863c4aace9@group-5E5C27C83E0F-FollowerState" daemon prio=5 tid=5057 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5661 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=4195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108->3d5bec3e-3873-417f-9114-370ff3a7c03a-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5986 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"117526ec-9427-41bf-9dbd-c8f743595c9c-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5541 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=6187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1272541579-5598" daemon prio=5 tid=5598 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"d214675b-6525-49c2-82fc-0766bb958e6c@group-00B73C10D651-StateMachineUpdater" daemon prio=5 tid=4961 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4612 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 43165" daemon prio=5 tid=4228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=4805 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1836-thread-1"  prio=5 tid=4273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 43165" daemon prio=5 tid=4225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5505 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5734 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2068667046-5518" daemon prio=5 tid=5518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=5285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:140)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5839 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1076523403-4631-acceptor-0@57c71f2c-ServerConnector@5b0653fb{HTTP/1.1, (http/1.1)}{0.0.0.0:41963}" daemon prio=3 tid=4631 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 33863" daemon prio=5 tid=5357 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=3870 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3685 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 46647" daemon prio=5 tid=4494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=4169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4460 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=4928 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 37215" daemon prio=5 tid=5324 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6301 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4669 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 46647" daemon prio=5 tid=4485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-7c999a17-1"  prio=5 tid=4695 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-SegmentedRaftLogWorker"  prio=5 tid=5935 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5657 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4855 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4840 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 38901" daemon prio=5 tid=6234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"7a5fc61e-353f-4ae0-a1a2-0b863c4aace9@group-66E5D0307CD6-LeaderStateImpl" daemon prio=5 tid=5047 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"3a4aa664-0d4f-4943-bed7-1a9050fc989f@group-B33483349863-StateMachineUpdater" daemon prio=5 tid=3900 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp776989826-4480" daemon prio=5 tid=4480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5732 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4746 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=4189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5874 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5292 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"ChunkWriter-3-0" daemon prio=5 tid=4909 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4845 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-10" daemon prio=5 tid=6128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-45accd44-1"  prio=5 tid=3610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6267 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1024951597-4831" daemon prio=5 tid=4831 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=2087 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c6848394-c9b5-4662-b948-5f3170864dbf@group-5E5C27C83E0F-SegmentedRaftLogWorker"  prio=5 tid=4978 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor36" daemon prio=5 tid=3794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4859 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 38901" daemon prio=5 tid=6219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerReplicationThread-0" daemon prio=5 tid=6291 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp796383693-5491" daemon prio=5 tid=5491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 33863" daemon prio=5 tid=5294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 8 on default port 45153" daemon prio=5 tid=4259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 3 on default port 38815" daemon prio=5 tid=6238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5743 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp571581767-5401" daemon prio=5 tid=5401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp472636590-3673" daemon prio=5 tid=3673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 38815"  prio=5 tid=6172 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"qtp1888992557-4689" daemon prio=5 tid=4689 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 38901" daemon prio=5 tid=6215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp508294491-6259-acceptor-0@165064d7-ServerConnector@790ea58f{HTTP/1.1, (http/1.1)}{0.0.0.0:34629}" daemon prio=3 tid=6259 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 44865" daemon prio=5 tid=4247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=4464 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 39209" daemon prio=5 tid=6203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 15 on default port 37215" daemon prio=5 tid=5338 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 45153" daemon prio=5 tid=4261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1137308388-3713" daemon prio=5 tid=3713 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ba688d8" daemon prio=5 tid=3693 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 45153" daemon prio=5 tid=4179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1137308388-3717" daemon prio=5 tid=3717 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 39209" daemon prio=5 tid=6196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1053690125-4549" daemon prio=5 tid=4549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"117526ec-9427-41bf-9dbd-c8f743595c9c-server-thread1" daemon prio=5 tid=5966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1600-thread-1" daemon prio=5 tid=3596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp128943676-5775" daemon prio=5 tid=5775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"c1d68bf5-941c-4ef4-97c3-9b8585fa6dbb@group-6EF5E8121392-StateMachineUpdater" daemon prio=5 tid=4999 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-1703-thread-1"  prio=5 tid=3966 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-StateMachineUpdater" daemon prio=5 tid=5937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-7"  prio=5 tid=5668 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 39209" daemon prio=5 tid=6199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5834 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 37647" daemon prio=5 tid=5463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=698 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-7b44011e-1"  prio=5 tid=5631 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->3a4aa664-0d4f-4943-bed7-1a9050fc989f-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=3983 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=4469 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3615 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 44865" daemon prio=5 tid=4183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1024951597-4837" daemon prio=5 tid=4837 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1863303266-3605" daemon prio=5 tid=3605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2432-thread-1"  prio=5 tid=5448 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4811 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6299 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-49616310-1"  prio=5 tid=6266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->3fee8600-457c-478d-8bf5-017cc394a56c-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp448963796-4738" daemon prio=5 tid=4738 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-3b76112f-1"  prio=5 tid=4554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4884 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@50e11626" daemon prio=5 tid=4819 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5755 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5765 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp645241368-4791-acceptor-0@311d7d2d-ServerConnector@308f5a1c{HTTP/1.1, (http/1.1)}{0.0.0.0:46553}" daemon prio=3 tid=4791 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:38815 - 0 "  prio=5 tid=3843 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 44865" daemon prio=5 tid=4246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4780 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 38901" daemon prio=5 tid=6232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp776989826-4478" daemon prio=5 tid=4478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3762 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor55" daemon prio=5 tid=5829 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4870 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"fda26913-bdfb-48f8-b38a-a95200d457c8-server-thread2" daemon prio=5 tid=6151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$830/1787815093.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 38901" daemon prio=5 tid=6223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 38901" daemon prio=5 tid=6228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp571581767-5400" daemon prio=5 tid=5400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4894 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5d01a853-2762-48e2-9549-a3e9717c76c4@group-5E5C27C83E0F-FollowerState" daemon prio=5 tid=5058 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server listener on 0" daemon prio=5 tid=4177 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"c1d68bf5-941c-4ef4-97c3-9b8585fa6dbb@group-6EF5E8121392-SegmentedRaftLogWorker"  prio=5 tid=4997 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=5851 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1079985712-5624-acceptor-0@79ec695b-ServerConnector@4024f0bf{HTTP/1.1, (http/1.1)}{0.0.0.0:43721}" daemon prio=3 tid=5624 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 43165" daemon prio=5 tid=4213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=5896 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp571581767-5398" daemon prio=5 tid=5398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1024951597-4835" daemon prio=5 tid=4835 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=4190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderStateImpl" daemon prio=5 tid=5994 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"c6848394-c9b5-4662-b948-5f3170864dbf-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4786 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1079985712-5623" daemon prio=5 tid=5623 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/1918811471.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3791 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp709761675-5456" daemon prio=5 tid=5456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5c7a3766-4df9-4a62-b680-fc04cc352416-impl-thread1"  prio=5 tid=5485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-33933a7b-1"  prio=5 tid=4771 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=6155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5749 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 37647" daemon prio=5 tid=5458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3c96c39d" daemon prio=5 tid=3561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 38901" daemon prio=5 tid=6229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=4184 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-StateMachineUpdater" daemon prio=5 tid=3920 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4677 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp863502069-5551" daemon prio=5 tid=5551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 36479" daemon prio=5 tid=5364 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"2829ccc8-889f-48cc-a62b-b3954aa0680c@group-05A935A1F922-LeaderStateImpl" daemon prio=5 tid=4016 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6295 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 45153" daemon prio=5 tid=4255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 39209" daemon prio=5 tid=6201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 2 on default port 43801" daemon prio=5 tid=3506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-DatanodeCommandForSCMNodeManager" daemon prio=5 tid=6290 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3721 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-StateMachineUpdater" daemon prio=5 tid=5921 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 43165" daemon prio=5 tid=4187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1576391952-3496-acceptor-0@7aa957a9-ServerConnector@457471db{HTTP/1.1, (http/1.1)}{0.0.0.0:43639}" daemon prio=3 tid=3496 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3782 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 43165" daemon prio=5 tid=4229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=5566 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6283 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1079985712-5627" daemon prio=5 tid=5627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 38815" daemon prio=5 tid=6173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-SegmentedRaftLogWorker"  prio=5 tid=5942 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/1610213515.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-a2f5aba9-6fca-43ef-ba3d-e79b029c057b-7"  prio=5 tid=5669 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5862 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"0da438f1-d8bd-4523-91d3-cbc74717487d-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3571 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"pool-2540-thread-1"  prio=5 tid=5622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2056-thread-1"  prio=5 tid=4629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-26e5a8f7-1"  prio=5 tid=4638 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@436f89d0" daemon prio=5 tid=5769 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 36479" daemon prio=5 tid=5380 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4c78576d" daemon prio=5 tid=3708 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"pool-2591-thread-1"  prio=5 tid=5930 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 39209" daemon prio=5 tid=6211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4885 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3720 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp472636590-3670" daemon prio=5 tid=3670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"7a5fc61e-353f-4ae0-a1a2-0b863c4aace9-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4730 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@18087c0a" daemon prio=5 tid=4676 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=6164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$414/175091021.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-LeaderStateImpl" daemon prio=5 tid=3982 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5134 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4848 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3872 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-2755-thread-1"  prio=5 tid=6257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-server-thread3" daemon prio=5 tid=5989 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3775 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor57" daemon prio=5 tid=5861 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/582196149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5119 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4701 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=4271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 44865" daemon prio=5 tid=4237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3776 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5f5120a0-1"  prio=5 tid=5496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 46647" daemon prio=5 tid=4490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"501a6ba0-4aa7-4660-9456-a414ab3e4b55@group-DA29AE892420->d214675b-6525-49c2-82fc-0766bb958e6c-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5036 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3765 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$832/1099939557.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp448963796-4739" daemon prio=5 tid=4739 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 45153" daemon prio=5 tid=4269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3587 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6281 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1079985712-5628" daemon prio=5 tid=5628 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp276108260-3576-acceptor-0@2f7b5370-ServerConnector@6199c2c5{HTTP/1.1, (http/1.1)}{0.0.0.0:36813}" daemon prio=3 tid=3576 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6270 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 39209" daemon prio=5 tid=6207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c6848394-c9b5-4662-b948-5f3170864dbf@group-5E5C27C83E0F->5d01a853-2762-48e2-9549-a3e9717c76c4-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5061 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1122/1732820149.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 37647" daemon prio=5 tid=5464 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)


	at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:589)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
    <system-out><![CDATA[2023-03-27 23:43:42,782 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(455)) - Shutting down the Mini Ozone Cluster
2023-03-27 23:43:42,784 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(471)) - Stopping the Mini Ozone Cluster
2023-03-27 23:43:42,784 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(553)) - Stopping the OzoneManager
2023-03-27 23:43:42,784 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(2155)) - om1[localhost:0]: Stopping Ozone Manager
2023-03-27 23:43:42,786 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 34651
2023-03-27 23:43:42,789 [Listener at 127.0.0.1/46647] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:43:42,791 [Listener at 127.0.0.1/46647] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:43:42,791 [Listener at 127.0.0.1/46647] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-27 23:43:42,791 [Listener at 127.0.0.1/46647] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-27 23:43:42,791 [Listener at 127.0.0.1/46647] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:43:42,791 [Listener at 127.0.0.1/46647] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:43:42,819 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-27 23:43:42,819 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:43:42,819 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-03-27 23:43:42,822 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-03-27 23:43:42,822 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-03-27 23:43:42,822 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-03-27 23:43:42,822 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-03-27 23:43:42,822 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:42,826 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:43:42,860 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 166
2023-03-27 23:43:42,860 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:166)
2023-03-27 23:43:42,861 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(476)) - Creating Volume: vol1, with user11324 as owner and space quota set to -1 bytes, counts quota set to -1
2023-03-27 23:43:42,873 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(195)) - created volume:vol1 for user:user11324
2023-03-27 23:43:42,882 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(698)) - Creating Bucket: vol1/bucket1, with bucket layout LEGACY, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2023-03-27 23:43:42,885 [OM StateMachine ApplyTransaction Thread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(262)) - created bucket: bucket1 of layout LEGACY in volume: vol1
2023-03-27 23:43:42,915 [IPC Server handler 0 on default port 38901] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2023-03-27 23:43:42,916 [IPC Server handler 0 on default port 38901] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(237)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-03-27 23:43:42,916 [IPC Server handler 0 on default port 38901] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
2023-03-27 23:43:42,926 [Listener at 127.0.0.1/46647] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-27 23:43:42,926 [Listener at 127.0.0.1/46647] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-27 23:43:42,929 [Listener at 127.0.0.1/46647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:42,929 [Listener at 127.0.0.1/46647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:42,929 [Listener at 127.0.0.1/46647] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:43:43,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:43,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 6 milliseconds for processing 1 containers.
2023-03-27 23:43:43,415 [JvmPauseMonitor41] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 141829265ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=384ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:43:43,418 [JvmPauseMonitor47] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-c6848394-c9b5-4662-b948-5f3170864dbf: Detected pause in JVM or host machine (eg GC): pause of approximately 192055222ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=384ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:43:43,418 [JvmPauseMonitor43] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-d214675b-6525-49c2-82fc-0766bb958e6c: Detected pause in JVM or host machine (eg GC): pause of approximately 251778976ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=384ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:43:43,419 [JvmPauseMonitor44] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-501a6ba0-4aa7-4660-9456-a414ab3e4b55: Detected pause in JVM or host machine (eg GC): pause of approximately 313589208ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=384ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:43:43,419 [JvmPauseMonitor48] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-c1d68bf5-941c-4ef4-97c3-9b8585fa6dbb: Detected pause in JVM or host machine (eg GC): pause of approximately 313610708ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=384ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:43:43,419 [JvmPauseMonitor50] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-afc9dc98-3375-40f1-a491-e988cc0b175c: Detected pause in JVM or host machine (eg GC): pause of approximately 354120371ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=384ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:43:43,419 [JvmPauseMonitor42] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-3d3cc5bc-4c5c-47d7-a20a-a694733df5c2: Detected pause in JVM or host machine (eg GC): pause of approximately 391379368ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=384ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:43:43,420 [JvmPauseMonitor45] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-7a5fc61e-353f-4ae0-a1a2-0b863c4aace9: Detected pause in JVM or host machine (eg GC): pause of approximately 409075576ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=384ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:43:43,429 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1148)) - Container #1 is over replicated. Expected replica count is 3, but found 4.
2023-03-27 23:43:43,429 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1477)) - Sending delete container command for container #1 to datanode 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:43,429 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1148)) - Container #4 is over replicated. Expected replica count is 3, but found 4.
2023-03-27 23:43:43,429 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1477)) - Sending delete container command for container #4 to datanode 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:43,429 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1148)) - Container #5 is over replicated. Expected replica count is 3, but found 4.
2023-03-27 23:43:43,429 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1477)) - Sending delete container command for container #5 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:43,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-03-27 23:43:43,436 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 166
2023-03-27 23:43:43,436 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 166
2023-03-27 23:43:43,436 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-27 23:43:43,436 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(540)) - Stopping OMDoubleBuffer flush thread
2023-03-27 23:43:43,436 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(625)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-03-27 23:43:43,437 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 166
2023-03-27 23:43:43,437 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:43,438 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-03-27 23:43:43,438 [JvmPauseMonitor25] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-03-27 23:43:43,438 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-27 23:43:43,439 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(549)) - OMDoubleBuffer flush thread is not running.
2023-03-27 23:43:43,439 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-03-27 23:43:43,439 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-03-27 23:43:43,439 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-03-27 23:43:43,439 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-03-27 23:43:43,439 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SnapshotDeletingService
2023-03-27 23:43:43,440 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4cb25b0c{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-27 23:43:43,440 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4dc4222b{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:43:43,440 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:43,440 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2ba87567{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-27 23:43:43,440 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@787f693b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:43:43,446 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(530)) - Stopping the HddsDatanodes
2023-03-27 23:43:43,454 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:43:43,455 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - ebbb6892-a89a-4074-adec-249bdede4c6b: close
2023-03-27 23:43:43,458 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B: shutdown
2023-03-27 23:43:43,458 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DCE8A982E78B,id=ebbb6892-a89a-4074-adec-249bdede4c6b
2023-03-27 23:43:43,458 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - ebbb6892-a89a-4074-adec-249bdede4c6b: shutdown ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-LeaderStateImpl
2023-03-27 23:43:43,458 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:43,459 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-DCE8A982E78B: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-4/data/ratis/66422011-1c0d-4681-8ef6-dce8a982e78b/sm/snapshot.1_0
2023-03-27 23:43:43,459 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:43,459 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - ebbb6892-a89a-4074-adec-249bdede4c6b: shutdown server GrpcServerProtocolService now
2023-03-27 23:43:43,460 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 549101de-1cf2-4583-b7e6-903b03646e7c Close channels
2023-03-27 23:43:43,468 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D: shutdown
2023-03-27 23:43:43,468 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4AAA5B89608D,id=ebbb6892-a89a-4074-adec-249bdede4c6b
2023-03-27 23:43:43,468 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - ebbb6892-a89a-4074-adec-249bdede4c6b: shutdown ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-LeaderStateImpl
2023-03-27 23:43:43,468 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-27 23:43:43,468 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->549101de-1cf2-4583-b7e6-903b03646e7c-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->549101de-1cf2-4583-b7e6-903b03646e7c-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-27 23:43:43,468 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:43,469 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:43,469 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: Completed APPEND_ENTRIES, lastRequest: ebbb6892-a89a-4074-adec-249bdede4c6b->6bc3ba6a-9ae7-448c-8b94-c4229f9fc915#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "6bc3ba6a-9ae7-448c-8b94-c4229f9fc915"
address: "10.1.0.32:42989"
dataStreamAddress: "10.1.0.32:39037"
clientAddress: "10.1.0.32:42989"
adminAddress: "10.1.0.32:42989"
startupRole: FOLLOWER
,id: "549101de-1cf2-4583-b7e6-903b03646e7c"
address: "10.1.0.32:38061"
dataStreamAddress: "10.1.0.32:32871"
clientAddress: "10.1.0.32:38061"
adminAddress: "10.1.0.32:38061"
startupRole: FOLLOWER
,id: "ebbb6892-a89a-4074-adec-249bdede4c6b"
address: "10.1.0.32:42371"
priority: 1
dataStreamAddress: "10.1.0.32:45871"
clientAddress: "10.1.0.32:42371"
adminAddress: "10.1.0.32:42371"
startupRole: FOLLOWER
, old:)
2023-03-27 23:43:43,469 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-4AAA5B89608D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-4/data/ratis/c888fd41-72df-4b6a-837e-4aaa5b89608d/sm/snapshot.1_0
2023-03-27 23:43:43,469 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: Completed APPEND_ENTRIES, lastRequest: null
2023-03-27 23:43:43,473 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-4AAA5B89608D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-4/data/ratis/c888fd41-72df-4b6a-837e-4aaa5b89608d/sm/snapshot.1_0 took: 4 ms
2023-03-27 23:43:43,473 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:43,473 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:43,471 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-DCE8A982E78B: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-4/data/ratis/66422011-1c0d-4681-8ef6-dce8a982e78b/sm/snapshot.1_0 took: 13 ms
2023-03-27 23:43:43,473 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:43,473 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D: closes. applyIndex: 0
2023-03-27 23:43:43,474 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:43,474 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 549101de-1cf2-4583-b7e6-903b03646e7c: Completed APPEND_ENTRIES, lastRequest: null
2023-03-27 23:43:43,474 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D-SegmentedRaftLogWorker close()
2023-03-27 23:43:43,473 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:43,484 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 549101de-1cf2-4583-b7e6-903b03646e7c: Completed APPEND_ENTRIES, lastRequest: ebbb6892-a89a-4074-adec-249bdede4c6b->549101de-1cf2-4583-b7e6-903b03646e7c#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "6bc3ba6a-9ae7-448c-8b94-c4229f9fc915"
address: "10.1.0.32:42989"
dataStreamAddress: "10.1.0.32:39037"
clientAddress: "10.1.0.32:42989"
adminAddress: "10.1.0.32:42989"
startupRole: FOLLOWER
,id: "549101de-1cf2-4583-b7e6-903b03646e7c"
address: "10.1.0.32:38061"
dataStreamAddress: "10.1.0.32:32871"
clientAddress: "10.1.0.32:38061"
adminAddress: "10.1.0.32:38061"
startupRole: FOLLOWER
,id: "ebbb6892-a89a-4074-adec-249bdede4c6b"
address: "10.1.0.32:42371"
priority: 1
dataStreamAddress: "10.1.0.32:45871"
clientAddress: "10.1.0.32:42371"
adminAddress: "10.1.0.32:42371"
startupRole: FOLLOWER
, old:)
2023-03-27 23:43:43,484 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:43:43,484 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: nextIndex: updateUnconditionally 1 -> 0
2023-03-27 23:43:43,485 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->549101de-1cf2-4583-b7e6-903b03646e7c-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:43:43,485 [grpc-default-executor-8] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->549101de-1cf2-4583-b7e6-903b03646e7c-GrpcLogAppender: Failed to getClient for 549101de-1cf2-4583-b7e6-903b03646e7c
org.apache.ratis.protocol.exceptions.AlreadyClosedException: ebbb6892-a89a-4074-adec-249bdede4c6b is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:43,485 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B: closes. applyIndex: 0
2023-03-27 23:43:43,485 [ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:43,485 [ebbb6892-a89a-4074-adec-249bdede4c6b-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-DCE8A982E78B-SegmentedRaftLogWorker close()
2023-03-27 23:43:43,500 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->549101de-1cf2-4583-b7e6-903b03646e7c-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:43:43,500 [grpc-default-executor-1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->549101de-1cf2-4583-b7e6-903b03646e7c-GrpcLogAppender: Failed to getClient for 549101de-1cf2-4583-b7e6-903b03646e7c
org.apache.ratis.protocol.exceptions.AlreadyClosedException: ebbb6892-a89a-4074-adec-249bdede4c6b is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:432)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:465)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:43,501 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:43:43,501 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - ebbb6892-a89a-4074-adec-249bdede4c6b@group-4AAA5B89608D->6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: nextIndex: updateUnconditionally 0 -> 0
2023-03-27 23:43:43,513 [Listener at 127.0.0.1/46647] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 580 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:43:43,514 [Listener at 127.0.0.1/46647] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(349)) - upgrade localId to 111677748019200000
2023-03-27 23:43:43,514 [Listener at 127.0.0.1/46647] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(359)) - upgrade delTxnId to 0
2023-03-27 23:43:43,519 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915 Close channels
2023-03-27 23:43:43,521 [Listener at 127.0.0.1/46647] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(376)) - upgrade containerId to 0
2023-03-27 23:43:43,521 [Listener at 127.0.0.1/46647] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-27 23:43:43,521 [Listener at 127.0.0.1/46647] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-27 23:43:43,521 [Listener at 127.0.0.1/46647] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-27 23:43:43,522 [Listener at 127.0.0.1/46647] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-27 23:43:43,522 [Listener at 127.0.0.1/46647] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2023-03-27 23:43:43,522 [Listener at 127.0.0.1/46647] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-27 23:43:43,522 [Listener at 127.0.0.1/46647] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-27 23:43:43,522 [Listener at 127.0.0.1/46647] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-27 23:43:43,522 [Listener at 127.0.0.1/46647] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-27 23:43:43,522 [Listener at 127.0.0.1/46647] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-27 23:43:43,522 [Listener at 127.0.0.1/46647] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-27 23:43:43,522 [Listener at 127.0.0.1/46647] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-27 23:43:43,523 [Listener at 127.0.0.1/46647] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-27 23:43:43,523 [Listener at 127.0.0.1/46647] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-27 23:43:43,523 [Listener at 127.0.0.1/46647] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-27 23:43:43,524 [Listener at 127.0.0.1/46647] INFO  replication.ReplicationManager (ReplicationManager.java:start(277)) - Starting Replication Monitor Thread.
2023-03-27 23:43:43,524 [Listener at 127.0.0.1/46647] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-27 23:43:43,525 [Listener at 127.0.0.1/46647] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2023-03-27 23:43:43,525 [Listener at 127.0.0.1/46647] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2023-03-27 23:43:43,525 [Listener at 127.0.0.1/46647] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-03-27 23:43:43,525 [Listener at 127.0.0.1/46647] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(398)) - SCM start with adminUsers: [runner]
2023-03-27 23:43:43,525 [Listener at 127.0.0.1/46647] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:43:43,526 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-27 23:43:43,526 [Listener at 0.0.0.0/36479] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:43:43,527 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-27 23:43:43,527 [Listener at 0.0.0.0/33863] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:43:43,528 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-27 23:43:43,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:43,539 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - afc9dc98-3375-40f1-a491-e988cc0b175c Close channels
2023-03-27 23:43:43,539 [Listener at 0.0.0.0/37215] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-27 23:43:43,539 [Listener at 0.0.0.0/37215] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(415)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-27 23:43:43,539 [Listener at 0.0.0.0/37215] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-27 23:43:43,539 [Listener at 0.0.0.0/37215] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1449)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:37215
2023-03-27 23:43:43,539 [Listener at 0.0.0.0/37215] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2023-03-27 23:43:43,569 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - ebbb6892-a89a-4074-adec-249bdede4c6b: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:43:43,587 [ebbb6892-a89a-4074-adec-249bdede4c6b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x526e7b34, L:/0:0:0:0:0:0:0:0:45871] CLOSE
2023-03-27 23:43:43,588 [ebbb6892-a89a-4074-adec-249bdede4c6b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x526e7b34, L:/0:0:0:0:0:0:0:0:45871] INACTIVE
2023-03-27 23:43:43,588 [ebbb6892-a89a-4074-adec-249bdede4c6b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x526e7b34, L:/0:0:0:0:0:0:0:0:45871] UNREGISTERED
2023-03-27 23:43:43,591 [Listener at 0.0.0.0/37215] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(197)) - RPC server for Client  is listening at /0.0.0.0:37215
2023-03-27 23:43:43,596 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - afc9dc98-3375-40f1-a491-e988cc0b175c: addNew group-CB860B84100E:[afc9dc98-3375-40f1-a491-e988cc0b175c|rpc:10.1.0.32:44001|dataStream:10.1.0.32:46075|priority:1|startupRole:FOLLOWER] returns group-CB860B84100E:java.util.concurrent.CompletableFuture@198c010d[Not completed]
2023-03-27 23:43:43,600 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:43:43,601 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-27 23:43:43,604 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - afc9dc98-3375-40f1-a491-e988cc0b175c: new RaftServerImpl for group-CB860B84100E:[afc9dc98-3375-40f1-a491-e988cc0b175c|rpc:10.1.0.32:44001|dataStream:10.1.0.32:46075|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E: ConfigurationManager, init=-1: peers:[afc9dc98-3375-40f1-a491-e988cc0b175c|rpc:10.1.0.32:44001|dataStream:10.1.0.32:46075|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-5/data/ratis] (custom)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:43,615 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:43,616 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:43,616 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:43,616 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:43,617 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:43,617 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:43,617 [pool-2314-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-5/data/ratis/6ea8ff4c-1d6e-498c-be21-cb860b84100e does not exist. Creating ...
2023-03-27 23:43:43,622 [pool-2314-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-5/data/ratis/6ea8ff4c-1d6e-498c-be21-cb860b84100e/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:43,624 [pool-2314-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-5/data/ratis/6ea8ff4c-1d6e-498c-be21-cb860b84100e has been successfully formatted.
2023-03-27 23:43:43,624 [pool-2314-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-CB860B84100E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:43,624 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:43,624 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:43,624 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:43,624 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:43,624 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:43,624 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-5/data/ratis/6ea8ff4c-1d6e-498c-be21-cb860b84100e
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:43,625 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:43,626 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:43,626 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:43,626 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 6ea8ff4c-1d6e-498c-be21-cb860b84100e, Nodes: afc9dc98-3375-40f1-a491-e988cc0b175c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:afc9dc98-3375-40f1-a491-e988cc0b175c, CreationTimestamp2023-03-27T23:43:40.743Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:43,629 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:43,629 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:43,629 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:43,630 [pool-2314-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:43,630 [pool-2314-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:43,630 [pool-2314-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E: start as a follower, conf=-1: peers:[afc9dc98-3375-40f1-a491-e988cc0b175c|rpc:10.1.0.32:44001|dataStream:10.1.0.32:46075|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:43,630 [pool-2314-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:43,630 [pool-2314-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - afc9dc98-3375-40f1-a491-e988cc0b175c: start afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState
2023-03-27 23:43:43,633 [pool-2314-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CB860B84100E,id=afc9dc98-3375-40f1-a491-e988cc0b175c
2023-03-27 23:43:43,633 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:43,633 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:43,633 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:43,633 [pool-2314-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:43,634 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:43,634 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:43,637 [Listener at 0.0.0.0/37215] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1463)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33863
2023-03-27 23:43:43,637 [Listener at 0.0.0.0/37215] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:33863
2023-03-27 23:43:43,637 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:43:43,638 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-27 23:43:43,644 [Listener at 0.0.0.0/37215] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:36479
2023-03-27 23:43:43,645 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:43:43,645 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-27 23:43:43,651 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38e0b949] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:43:43,651 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: close
2023-03-27 23:43:43,652 [Listener at 0.0.0.0/37215] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:0
2023-03-27 23:43:43,652 [Listener at 0.0.0.0/37215] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:43:43,653 [Listener at 0.0.0.0/37215] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:43:43,659 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=6ea8ff4c-1d6e-498c-be21-cb860b84100e
2023-03-27 23:43:43,659 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=6ea8ff4c-1d6e-498c-be21-cb860b84100e.
2023-03-27 23:43:43,666 [Listener at 0.0.0.0/37215] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:43:43,667 [Listener at 0.0.0.0/37215] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:43:43,667 [Listener at 0.0.0.0/37215] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-27 23:43:43,667 [Listener at 0.0.0.0/37215] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:43:43,667 [Listener at 0.0.0.0/37215] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:43:43,668 [Listener at 0.0.0.0/37215] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/ozone-meta/webserver
2023-03-27 23:43:43,668 [Listener at 0.0.0.0/37215] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 39587
2023-03-27 23:43:43,668 [Listener at 0.0.0.0/37215] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:43:43,674 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: shutdown server GrpcServerProtocolService now
2023-03-27 23:43:43,675 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-27 23:43:43,676 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: installSnapshot onError, lastRequest: 2fe3edb7-8e87-4db1-bb8e-5ae441beb787->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf#162-t1,previous=(t:1, i:35),leaderCommit=34,initializing? true,entries: size=1, first=(t:1, i:36), METADATAENTRY(c:34): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-27 23:43:43,676 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-27 23:43:43,676 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 37 -> 36
2023-03-27 23:43:43,677 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-27 23:43:43,677 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 36 -> 35
2023-03-27 23:43:43,677 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:43:43,677 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x97cda084, L:/0:0:0:0:0:0:0:0:44503] CLOSE
2023-03-27 23:43:43,677 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x97cda084, L:/0:0:0:0:0:0:0:0:44503] INACTIVE
2023-03-27 23:43:43,677 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x97cda084, L:/0:0:0:0:0:0:0:0:44503] UNREGISTERED
2023-03-27 23:43:43,679 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331: shutdown
2023-03-27 23:43:43,679 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CE70BD6F3331,id=1bfcd852-ea3f-4c7a-9193-c23bc5754bdf
2023-03-27 23:43:43,679 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: shutdown 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-FollowerState
2023-03-27 23:43:43,679 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88: shutdown
2023-03-27 23:43:43,679 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D53E1E11A88,id=1bfcd852-ea3f-4c7a-9193-c23bc5754bdf
2023-03-27 23:43:43,679 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: shutdown 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-LeaderStateImpl
2023-03-27 23:43:43,679 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:43,681 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:43,682 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 36 -> 35
2023-03-27 23:43:43,682 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:43,682 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 35 -> 34
2023-03-27 23:43:43,682 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-6D53E1E11A88: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-1/data/ratis/e304f524-3200-488a-9b4c-6d53e1e11a88/sm/snapshot.1_0
2023-03-27 23:43:43,683 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-6D53E1E11A88: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-1/data/ratis/e304f524-3200-488a-9b4c-6d53e1e11a88/sm/snapshot.1_0 took: 1 ms
2023-03-27 23:43:43,683 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:43,683 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:43,682 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:43,689 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88: closes. applyIndex: 0
2023-03-27 23:43:43,689 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:43,689 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-6D53E1E11A88-SegmentedRaftLogWorker close()
2023-03-27 23:43:43,690 [JvmPauseMonitor30] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-ebbb6892-a89a-4074-adec-249bdede4c6b: Stopped
2023-03-27 23:43:43,702 [Listener at 0.0.0.0/37215] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:43:43,702 [Listener at 0.0.0.0/37215] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:43:43,702 [Listener at 0.0.0.0/37215] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-27 23:43:43,706 [Listener at 0.0.0.0/37215] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5e44a3dc{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:43:43,706 [Listener at 0.0.0.0/37215] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@67b4299d{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-27 23:43:43,707 [Listener at 0.0.0.0/37215] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@c6b123d{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-27 23:43:43,708 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-StateMachineUpdater: set stopIndex = 36
2023-03-27 23:43:43,708 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-FollowerState was interrupted
2023-03-27 23:43:43,708 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-CE70BD6F3331: Taking a snapshot at:(t:1, i:36) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-1/data/ratis/3d1ae31f-ffee-4866-9493-ce70bd6f3331/sm/snapshot.1_36
2023-03-27 23:43:43,710 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-CE70BD6F3331: Finished taking a snapshot at:(t:1, i:36) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-1/data/ratis/3d1ae31f-ffee-4866-9493-ce70bd6f3331/sm/snapshot.1_36 took: 2 ms
2023-03-27 23:43:43,710 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-StateMachineUpdater: Took a snapshot at index 36
2023-03-27 23:43:43,710 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 36
2023-03-27 23:43:43,711 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331: closes. applyIndex: 36
2023-03-27 23:43:43,711 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:43,711 [1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf@group-CE70BD6F3331-SegmentedRaftLogWorker close()
2023-03-27 23:43:43,716 [Listener at 0.0.0.0/37215] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4d557709{HTTP/1.1, (http/1.1)}{0.0.0.0:39587}
2023-03-27 23:43:43,716 [Listener at 0.0.0.0/37215] INFO  server.Server (Server.java:doStart(415)) - Started @170608ms
2023-03-27 23:43:43,716 [Listener at 0.0.0.0/37215] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:43:43,717 [Listener at 0.0.0.0/37215] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:39587
2023-03-27 23:43:43,717 [Listener at 0.0.0.0/37215] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:43:43,722 [JvmPauseMonitor27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: Stopped
2023-03-27 23:43:43,725 [Listener at 0.0.0.0/37215] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-03-27 23:43:43,725 [Listener at 0.0.0.0/37215] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2023-03-27 23:43:43,725 [Listener at 0.0.0.0/37215] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-03-27 23:43:43,725 [Listener at 0.0.0.0/37215] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2023-03-27 23:43:43,733 [Listener at 0.0.0.0/37215] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:43:43,735 [Listener at 0.0.0.0/37215] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2023-03-27 23:43:43,866 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:43,867 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 34 -> 33
2023-03-27 23:43:43,871 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:43,871 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 33 -> 32
2023-03-27 23:43:43,882 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:43,883 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 33 -> 32
2023-03-27 23:43:43,883 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:43,883 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 32 -> 31
2023-03-27 23:43:43,928 [Listener at 0.0.0.0/37215] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 192 ms to scan 2 urls, producing 168 keys and 466 values [using 2 cores]
2023-03-27 23:43:43,928 [Listener at 0.0.0.0/37215] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2023-03-27 23:43:43,928 [Listener at 0.0.0.0/37215] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:43:43,929 [Listener at 0.0.0.0/37215] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:33863]
2023-03-27 23:43:43,929 [Listener at 0.0.0.0/37215] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:33863]
2023-03-27 23:43:43,942 [Listener at 0.0.0.0/37215] INFO  om.OzoneManager (OzoneManager.java:<init>(619)) - OM start with adminUsers: [runner]
2023-03-27 23:43:43,942 [Listener at 0.0.0.0/37215] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:43:43,942 [Listener at 0.0.0.0/37215] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2023-03-27 23:43:43,942 [Listener at 0.0.0.0/37215] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2023-03-27 23:43:44,117 [Listener at 0.0.0.0/37215] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(749)) - S3 Multi-Tenancy is disabled
2023-03-27 23:43:44,117 [Listener at 0.0.0.0/37215] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:43:44,141 [Listener at 0.0.0.0/37215] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4222)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2023-03-27 23:43:44,141 [Listener at 0.0.0.0/37215] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-27 23:43:44,141 [Listener at 0.0.0.0/37215] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(446)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2023-03-27 23:43:44,141 [Listener at 0.0.0.0/37215] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:44,141 [Listener at 0.0.0.0/37215] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:44,141 [Listener at 0.0.0.0/37215] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(163)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:37867
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(636)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 37867 (fallback to raft.grpc.server.port)
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 37867 (fallback to raft.grpc.server.port)
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 37867 (custom)
2023-03-27 23:43:44,142 [Listener at 0.0.0.0/37215] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2023-03-27 23:43:44,143 [Listener at 0.0.0.0/37215] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:44,143 [Listener at 0.0.0.0/37215] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-03-27 23:43:44,143 [Listener at 0.0.0.0/37215] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-03-27 23:43:44,143 [Listener at 0.0.0.0/37215] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:44,143 [Listener at 0.0.0.0/37215] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-27 23:43:44,143 [Listener at 0.0.0.0/37215] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-27 23:43:44,144 [Listener at 0.0.0.0/37215] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2023-03-27 23:43:44,144 [Listener at 0.0.0.0/37215] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-27 23:43:44,144 [Listener at 0.0.0.0/37215] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-27 23:43:44,144 [Listener at 0.0.0.0/37215] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-27 23:43:44,144 [Listener at 0.0.0.0/37215] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:44,144 [Listener at 0.0.0.0/37215] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/ozone-meta/ratis] (custom)
2023-03-27 23:43:44,146 [Listener at 0.0.0.0/37215] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:37867|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@6a4e631a[Not completed]
2023-03-27 23:43:44,146 [Listener at 0.0.0.0/37215] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2096)) - OzoneManager Ratis server initialized at port 37867
2023-03-27 23:43:44,146 [Listener at 0.0.0.0/37215] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1132)) - Creating RPC Server
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:37867|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:localhost:37867|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/ozone-meta/ratis] (custom)
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:44,147 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2023-03-27 23:43:44,148 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2023-03-27 23:43:44,148 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:44,149 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:44,149 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:44,149 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:44,149 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:44,149 [pool-2430-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:44,403 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [deleteContainerCommand: containerID: 7, replicaIndex: 2, force: true] for container ContainerInfo{id=#7, state=CLOSED, pipelineID=PipelineID=54a98196-8d16-4967-afa2-2513fb96a42d, stateEnterTime=2023-03-27T23:43:03.869Z, owner=om1} to afc9dc98-3375-40f1-a491-e988cc0b175c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962394403 and scm deadline 1679962424403
2023-03-27 23:43:44,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:44,403 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [deleteContainerCommand: containerID: 8, replicaIndex: 3, force: true] for container ContainerInfo{id=#8, state=CLOSED, pipelineID=PipelineID=1e587659-c8fa-4a0d-bdde-7de27438666b, stateEnterTime=2023-03-27T23:43:04.161Z, owner=om1} to afc9dc98-3375-40f1-a491-e988cc0b175c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962394403 and scm deadline 1679962424403
2023-03-27 23:43:44,403 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [deleteContainerCommand: containerID: 9, replicaIndex: 2, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=823762e0-d246-498e-9d4d-3b0558e57dbf, stateEnterTime=2023-03-27T23:43:04.393Z, owner=om1} to 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962394403 and scm deadline 1679962424403
2023-03-27 23:43:44,403 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [deleteContainerCommand: containerID: 10, replicaIndex: 2, force: true] for container ContainerInfo{id=#10, state=CLOSED, pipelineID=PipelineID=f957701c-c6ff-4ba8-b21a-580ecb43687b, stateEnterTime=2023-03-27T23:43:04.642Z, owner=om1} to 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962394403 and scm deadline 1679962424403
2023-03-27 23:43:44,403 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(110)) - Processed 4 containers with health state counts {OVER_REPLICATED=4}, failed processing 0
2023-03-27 23:43:44,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2023-03-27 23:43:44,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 11 containers.
2023-03-27 23:43:44,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:44,538 [Listener at 0.0.0.0/37215] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 391 ms to scan 19 urls, producing 68 keys and 4989 values [using 2 cores]
2023-03-27 23:43:44,539 [Listener at 0.0.0.0/37215] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:43:44,539 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-27 23:43:44,558 [Listener at 127.0.0.1/37647] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2023-03-27 23:43:44,569 [Listener at 127.0.0.1/37647] INFO  om.OzoneManager (OzoneManager.java:start(1553)) - OzoneManager RPC server is listening at localhost/127.0.0.1:37647
2023-03-27 23:43:44,569 [Listener at 127.0.0.1/37647] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(558)) - Starting OzoneManagerRatisServer om1 at port 37867
2023-03-27 23:43:44,569 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2023-03-27 23:43:44,570 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:44,571 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2023-03-27 23:43:44,571 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:44,571 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:44,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:44,573 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:44,573 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:44,574 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-03-27 23:43:44,574 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:44,577 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:44,577 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:44,577 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2023-03-27 23:43:44,577 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:44,577 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:44,578 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:localhost:37867|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:44,578 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:44,578 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2023-03-27 23:43:44,583 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-03-27 23:43:44,583 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:44,583 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2023-03-27 23:43:44,583 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2023-03-27 23:43:44,583 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2023-03-27 23:43:44,584 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:44,584 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:44,585 [Listener at 127.0.0.1/37647] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - om1: start RPC server
2023-03-27 23:43:44,586 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - om1: GrpcService started, listening on 37867
2023-03-27 23:43:44,586 [Listener at 127.0.0.1/37647] INFO  om.OzoneManager (OzoneManager.java:start(1569)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2023-03-27 23:43:44,586 [JvmPauseMonitor51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-om1: Started
2023-03-27 23:43:44,598 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2023-03-27 23:43:44,598 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:43:44,599 [Listener at 127.0.0.1/37647] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:43:44,600 [Listener at 127.0.0.1/37647] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:43:44,600 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:43:44,601 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2023-03-27 23:43:44,601 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:43:44,601 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:43:44,601 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/ozone-meta/webserver
2023-03-27 23:43:44,601 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 40617
2023-03-27 23:43:44,601 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:43:44,602 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:43:44,602 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:43:44,603 [Listener at 127.0.0.1/37647] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-27 23:43:44,603 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@af6e13e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:43:44,603 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@43dc53a2{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-27 23:43:44,605 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@77ac711d{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-27 23:43:44,608 [Listener at 127.0.0.1/37647] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6be4bbe9{HTTP/1.1, (http/1.1)}{0.0.0.0:40617}
2023-03-27 23:43:44,608 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(415)) - Started @171500ms
2023-03-27 23:43:44,608 [Listener at 127.0.0.1/37647] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:43:44,608 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of ozoneManager listening at http://0.0.0.0:40617
2023-03-27 23:43:44,609 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:43:44,611 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-27 23:43:44,612 [Listener at 127.0.0.1/37647] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2040)) - Trash Interval set to 0. Files deleted won't move to trash
2023-03-27 23:43:44,618 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7cc40786] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:43:44,629 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:44,629 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:44,629 [Listener at 127.0.0.1/37647] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-27 23:43:44,656 [Listener at 127.0.0.1/37647] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net ip:10.1.0.32
2023-03-27 23:43:44,682 [Listener at 127.0.0.1/37647] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:43:44,736 [Listener at 127.0.0.1/37647] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 51 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:43:44,739 [Listener at 127.0.0.1/37647] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-27 23:43:44,740 [Listener at 127.0.0.1/37647] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-27 23:43:44,740 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data-0/containers/hdds to VolumeSet
2023-03-27 23:43:44,740 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data-0/containers/hdds
2023-03-27 23:43:44,741 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data-0/containers/hdds
2023-03-27 23:43:44,752 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis to VolumeSet
2023-03-27 23:43:44,752 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis
2023-03-27 23:43:44,752 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis
2023-03-27 23:43:44,763 [Thread-3167] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data-0/containers/hdds
2023-03-27 23:43:44,763 [Listener at 127.0.0.1/37647] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(303)) - Build ContainerSet costs 0s
2023-03-27 23:43:44,767 [Listener at 127.0.0.1/37647] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-27 23:43:44,768 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-27 23:43:44,770 [Listener at 127.0.0.1/37647] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-27 23:43:44,770 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-27 23:43:44,771 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-27 23:43:44,771 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-27 23:43:44,771 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-27 23:43:44,771 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-27 23:43:44,771 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-27 23:43:44,771 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-27 23:43:44,773 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-27 23:43:44,773 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-27 23:43:44,773 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-27 23:43:44,773 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-27 23:43:44,773 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-27 23:43:44,773 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:44,773 [5c7a3766-4df9-4a62-b680-fc04cc352416-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcbf6e549] REGISTERED
2023-03-27 23:43:44,773 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:44,773 [5c7a3766-4df9-4a62-b680-fc04cc352416-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcbf6e549] BIND: 0.0.0.0/0.0.0.0:0
2023-03-27 23:43:44,773 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis] (custom)
2023-03-27 23:43:44,773 [5c7a3766-4df9-4a62-b680-fc04cc352416-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcbf6e549, L:/0:0:0:0:0:0:0:0:39875] ACTIVE
2023-03-27 23:43:44,778 [Listener at 127.0.0.1/37647] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-27 23:43:44,780 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-27 23:43:44,780 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:43:44,781 [Listener at 127.0.0.1/37647] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:43:44,781 [Listener at 127.0.0.1/37647] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:43:44,782 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:43:44,782 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-27 23:43:44,782 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:43:44,782 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:43:44,782 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/meta/webserver
2023-03-27 23:43:44,783 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 41875
2023-03-27 23:43:44,783 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:43:44,783 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:43:44,784 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:43:44,784 [Listener at 127.0.0.1/37647] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-27 23:43:44,784 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4a9d4110{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:43:44,784 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@69dc8abc{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-27 23:43:44,993 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@12fb9815{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/meta/webserver/jetty-0_0_0_0-41875-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-3607480942197609544/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:44,996 [Listener at 127.0.0.1/37647] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@64750fdd{HTTP/1.1, (http/1.1)}{0.0.0.0:41875}
2023-03-27 23:43:44,996 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(415)) - Started @171888ms
2023-03-27 23:43:44,996 [Listener at 127.0.0.1/37647] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:43:44,997 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41875
2023-03-27 23:43:44,997 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:44,997 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:44,997 [Listener at 127.0.0.1/37647] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-27 23:43:44,998 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-27 23:43:45,010 [Listener at 127.0.0.1/37647] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net ip:10.1.0.32
2023-03-27 23:43:45,010 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c0e1ff4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:43:45,012 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/meta/datanode.id
2023-03-27 23:43:45,030 [Listener at 127.0.0.1/37647] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:43:45,081 [Listener at 127.0.0.1/37647] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 50 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:43:45,082 [Listener at 127.0.0.1/37647] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-27 23:43:45,083 [Listener at 127.0.0.1/37647] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-27 23:43:45,084 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data-0/containers/hdds to VolumeSet
2023-03-27 23:43:45,084 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data-0/containers/hdds
2023-03-27 23:43:45,085 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data-0/containers/hdds
2023-03-27 23:43:45,096 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis to VolumeSet
2023-03-27 23:43:45,096 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis
2023-03-27 23:43:45,096 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis
2023-03-27 23:43:45,106 [Thread-3181] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data-0/containers/hdds
2023-03-27 23:43:45,106 [Listener at 127.0.0.1/37647] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(303)) - Build ContainerSet costs 0s
2023-03-27 23:43:45,107 [Listener at 127.0.0.1/37647] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-27 23:43:45,107 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:45,107 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-27 23:43:45,107 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:45,107 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-27 23:43:45,108 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-27 23:43:45,108 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-27 23:43:45,108 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-27 23:43:45,108 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:45,108 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-27 23:43:45,108 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:45,108 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:45,108 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-27 23:43:45,108 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-27 23:43:45,109 [Listener at 127.0.0.1/37647] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-27 23:43:45,109 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-27 23:43:45,109 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-27 23:43:45,109 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-27 23:43:45,109 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-27 23:43:45,109 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-27 23:43:45,109 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-27 23:43:45,109 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-27 23:43:45,110 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-27 23:43:45,110 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-27 23:43:45,110 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-27 23:43:45,110 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-27 23:43:45,110 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-27 23:43:45,110 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:45,110 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:45,110 [69c31795-da41-43dd-a637-b3015d9175ea-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd0d2a8ed] REGISTERED
2023-03-27 23:43:45,110 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis] (custom)
2023-03-27 23:43:45,110 [69c31795-da41-43dd-a637-b3015d9175ea-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd0d2a8ed] BIND: 0.0.0.0/0.0.0.0:0
2023-03-27 23:43:45,111 [69c31795-da41-43dd-a637-b3015d9175ea-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd0d2a8ed, L:/0:0:0:0:0:0:0:0:34781] ACTIVE
2023-03-27 23:43:45,111 [Listener at 127.0.0.1/37647] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-27 23:43:45,115 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-27 23:43:45,115 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:43:45,116 [Listener at 127.0.0.1/37647] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:43:45,116 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:45,117 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 31 -> 30
2023-03-27 23:43:45,117 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:45,117 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 30 -> 29
2023-03-27 23:43:45,118 [Listener at 127.0.0.1/37647] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:43:45,118 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:43:45,118 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-27 23:43:45,118 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:43:45,118 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:43:45,119 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/meta/webserver
2023-03-27 23:43:45,119 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 40255
2023-03-27 23:43:45,119 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:43:45,120 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:43:45,120 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:43:45,120 [Listener at 127.0.0.1/37647] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-27 23:43:45,120 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@213e37fa{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:43:45,121 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2efc582f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-27 23:43:45,127 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:45,128 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 30 -> 29
2023-03-27 23:43:45,128 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:45,128 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 29 -> 28
2023-03-27 23:43:45,326 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@62cbd448{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/meta/webserver/jetty-0_0_0_0-40255-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-2464588577223819626/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:45,329 [Listener at 127.0.0.1/37647] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@490c3030{HTTP/1.1, (http/1.1)}{0.0.0.0:40255}
2023-03-27 23:43:45,329 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(415)) - Started @172221ms
2023-03-27 23:43:45,330 [Listener at 127.0.0.1/37647] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:43:45,330 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:40255
2023-03-27 23:43:45,330 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-27 23:43:45,330 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:45,331 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:45,331 [Listener at 127.0.0.1/37647] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-27 23:43:45,341 [Listener at 127.0.0.1/37647] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net ip:10.1.0.32
2023-03-27 23:43:45,342 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@33b1b09d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:43:45,344 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/meta/datanode.id
2023-03-27 23:43:45,361 [Listener at 127.0.0.1/37647] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:43:45,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:45,406 [Listener at 127.0.0.1/37647] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:43:45,407 [Listener at 127.0.0.1/37647] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-27 23:43:45,408 [Listener at 127.0.0.1/37647] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-27 23:43:45,408 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data-0/containers/hdds to VolumeSet
2023-03-27 23:43:45,408 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data-0/containers/hdds
2023-03-27 23:43:45,408 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data-0/containers/hdds
2023-03-27 23:43:45,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2023-03-27 23:43:45,420 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis to VolumeSet
2023-03-27 23:43:45,423 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis
2023-03-27 23:43:45,424 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis
2023-03-27 23:43:45,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-03-27 23:43:45,447 [Thread-3195] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data-0/containers/hdds
2023-03-27 23:43:45,447 [Listener at 127.0.0.1/37647] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(303)) - Build ContainerSet costs 0s
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:45,448 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-27 23:43:45,449 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-27 23:43:45,449 [Listener at 127.0.0.1/37647] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-27 23:43:45,450 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-27 23:43:45,450 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-27 23:43:45,450 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-27 23:43:45,450 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-27 23:43:45,450 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-27 23:43:45,450 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-27 23:43:45,450 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-27 23:43:45,455 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-27 23:43:45,455 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-27 23:43:45,455 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-27 23:43:45,455 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-27 23:43:45,455 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-27 23:43:45,455 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:45,456 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:45,456 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis] (custom)
2023-03-27 23:43:45,456 [117526ec-9427-41bf-9dbd-c8f743595c9c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x6ea126d6] REGISTERED
2023-03-27 23:43:45,456 [117526ec-9427-41bf-9dbd-c8f743595c9c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x6ea126d6] BIND: 0.0.0.0/0.0.0.0:0
2023-03-27 23:43:45,456 [117526ec-9427-41bf-9dbd-c8f743595c9c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x6ea126d6, L:/0:0:0:0:0:0:0:0:33557] ACTIVE
2023-03-27 23:43:45,457 [Listener at 127.0.0.1/37647] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-27 23:43:45,460 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-27 23:43:45,460 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:43:45,461 [Listener at 127.0.0.1/37647] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:43:45,461 [Listener at 127.0.0.1/37647] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:43:45,461 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:43:45,462 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-27 23:43:45,462 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:43:45,462 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:43:45,462 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/meta/webserver
2023-03-27 23:43:45,462 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 41213
2023-03-27 23:43:45,462 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:43:45,464 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:43:45,464 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:43:45,464 [Listener at 127.0.0.1/37647] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-27 23:43:45,466 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@163ee9ee{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:43:45,466 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@427389fb{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-27 23:43:45,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:45,674 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5bb96e91{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/meta/webserver/jetty-0_0_0_0-41213-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6840288004850203819/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:45,677 [Listener at 127.0.0.1/37647] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@140401bd{HTTP/1.1, (http/1.1)}{0.0.0.0:41213}
2023-03-27 23:43:45,677 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(415)) - Started @172569ms
2023-03-27 23:43:45,677 [Listener at 127.0.0.1/37647] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:43:45,678 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41213
2023-03-27 23:43:45,678 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-27 23:43:45,678 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:45,678 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:45,678 [Listener at 127.0.0.1/37647] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-27 23:43:45,691 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1112894474ns, electionTimeout:1107ms
2023-03-27 23:43:45,691 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2023-03-27 23:43:45,691 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:45,694 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:45,694 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection85
2023-03-27 23:43:45,702 [Listener at 127.0.0.1/37647] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net ip:10.1.0.32
2023-03-27 23:43:45,708 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5d223bb9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:43:45,709 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/meta/datanode.id
2023-03-27 23:43:45,714 [om1@group-C5BA1605619E-LeaderElection85] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection85 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|rpc:localhost:37867|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:45,714 [om1@group-C5BA1605619E-LeaderElection85] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection85 PRE_VOTE round 0: result PASSED (term=0)
2023-03-27 23:43:45,715 [om1@group-C5BA1605619E-LeaderElection85] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection85 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:localhost:37867|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:45,715 [om1@group-C5BA1605619E-LeaderElection85] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection85 ELECTION round 0: result PASSED (term=1)
2023-03-27 23:43:45,715 [om1@group-C5BA1605619E-LeaderElection85] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection85
2023-03-27 23:43:45,715 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:45,715 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1567ms
2023-03-27 23:43:45,715 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:45,715 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-27 23:43:45,715 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-03-27 23:43:45,716 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2023-03-27 23:43:45,716 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:45,716 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:45,716 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-27 23:43:45,716 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:45,716 [om1@group-C5BA1605619E-LeaderElection85] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2023-03-27 23:43:45,716 [om1@group-C5BA1605619E-LeaderElection85] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:45,723 [om1@group-C5BA1605619E-LeaderElection85] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:localhost:37867|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:45,727 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2023-03-27 23:43:45,730 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:37867"
startupRole: FOLLOWER
]
2023-03-27 23:43:45,733 [Listener at 127.0.0.1/37647] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:43:45,776 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-1/data-0/containers/hdds/6e26070d-9fdb-4a65-9637-ae4e983202df/DS-67ab8041-18a3-438a-acb1-467eb62c789e/container.db for volume DS-67ab8041-18a3-438a-acb1-467eb62c789e
2023-03-27 23:43:45,776 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-27 23:43:45,779 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-27 23:43:45,780 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-27 23:43:45,797 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-4/data-0/containers/hdds/6e26070d-9fdb-4a65-9637-ae4e983202df/DS-fdc3f7b4-3b1f-4ce8-9253-7565be1ed59c/container.db for volume DS-fdc3f7b4-3b1f-4ce8-9253-7565be1ed59c
2023-03-27 23:43:45,797 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-27 23:43:45,798 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-27 23:43:45,806 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-27 23:43:45,818 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@46f83ca0{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:45,821 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4accd486{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:43:45,821 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:45,821 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@784c8523{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-27 23:43:45,821 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7a45ee12{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:43:45,826 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4d6852d8{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:45,828 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@26edb7b8{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:43:45,828 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:45,828 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@19ec8d44{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-27 23:43:45,828 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@264e22c8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:43:45,845 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:43:45,852 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: close
2023-03-27 23:43:45,854 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8: shutdown
2023-03-27 23:43:45,854 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF8815FB6AA8,id=6bc3ba6a-9ae7-448c-8b94-c4229f9fc915
2023-03-27 23:43:45,854 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: shutdown 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-LeaderStateImpl
2023-03-27 23:43:45,854 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:45,855 [Listener at 127.0.0.1/37647] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 122 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:43:45,856 [Listener at 127.0.0.1/37647] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-27 23:43:45,856 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: shutdown server GrpcServerProtocolService now
2023-03-27 23:43:45,857 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D: shutdown
2023-03-27 23:43:45,857 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4AAA5B89608D,id=6bc3ba6a-9ae7-448c-8b94-c4229f9fc915
2023-03-27 23:43:45,857 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: shutdown 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-FollowerState
2023-03-27 23:43:45,857 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:45,857 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-FollowerState was interrupted
2023-03-27 23:43:45,857 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:45,857 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - ebbb6892-a89a-4074-adec-249bdede4c6b Close channels
2023-03-27 23:43:45,860 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - afc9dc98-3375-40f1-a491-e988cc0b175c Close channels
2023-03-27 23:43:45,862 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:43:45,866 [Listener at 127.0.0.1/37647] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-27 23:43:45,866 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data-0/containers/hdds to VolumeSet
2023-03-27 23:43:45,866 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data-0/containers/hdds
2023-03-27 23:43:45,870 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-BF8815FB6AA8: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-3/data/ratis/6d183de4-1aaf-4fde-a665-bf8815fb6aa8/sm/snapshot.1_0
2023-03-27 23:43:45,870 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-4AAA5B89608D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-3/data/ratis/c888fd41-72df-4b6a-837e-4aaa5b89608d/sm/snapshot.1_0
2023-03-27 23:43:45,871 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data-0/containers/hdds
2023-03-27 23:43:45,871 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x356961af, L:/0:0:0:0:0:0:0:0:39037] CLOSE
2023-03-27 23:43:45,871 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x356961af, L:/0:0:0:0:0:0:0:0:39037] INACTIVE
2023-03-27 23:43:45,871 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x356961af, L:/0:0:0:0:0:0:0:0:39037] UNREGISTERED
2023-03-27 23:43:45,872 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-BF8815FB6AA8: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-3/data/ratis/6d183de4-1aaf-4fde-a665-bf8815fb6aa8/sm/snapshot.1_0 took: 2 ms
2023-03-27 23:43:45,872 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:45,872 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:45,873 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8: closes. applyIndex: 0
2023-03-27 23:43:45,873 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-4AAA5B89608D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-3/data/ratis/c888fd41-72df-4b6a-837e-4aaa5b89608d/sm/snapshot.1_0 took: 3 ms
2023-03-27 23:43:45,874 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:45,874 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:45,874 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D: closes. applyIndex: 0
2023-03-27 23:43:45,881 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:45,881 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:45,881 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-4AAA5B89608D-SegmentedRaftLogWorker close()
2023-03-27 23:43:45,882 [6bc3ba6a-9ae7-448c-8b94-c4229f9fc915-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915@group-BF8815FB6AA8-SegmentedRaftLogWorker close()
2023-03-27 23:43:45,882 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis to VolumeSet
2023-03-27 23:43:45,882 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis
2023-03-27 23:43:45,883 [JvmPauseMonitor29] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-6bc3ba6a-9ae7-448c-8b94-c4229f9fc915: Stopped
2023-03-27 23:43:45,883 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:43:45,884 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 02b664bf-3432-424d-aeb2-fd50259d9f48: close
2023-03-27 23:43:45,884 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis
2023-03-27 23:43:45,885 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331: shutdown
2023-03-27 23:43:45,885 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CE70BD6F3331,id=02b664bf-3432-424d-aeb2-fd50259d9f48
2023-03-27 23:43:45,885 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 02b664bf-3432-424d-aeb2-fd50259d9f48: shutdown 02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-FollowerState
2023-03-27 23:43:45,885 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 02b664bf-3432-424d-aeb2-fd50259d9f48: shutdown server GrpcServerProtocolService now
2023-03-27 23:43:45,887 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf Close channels
2023-03-27 23:43:45,888 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 02b664bf-3432-424d-aeb2-fd50259d9f48: installSnapshot onError, lastRequest: 2fe3edb7-8e87-4db1-bb8e-5ae441beb787->02b664bf-3432-424d-aeb2-fd50259d9f48#164-t1,previous=(t:1, i:35),leaderCommit=34,initializing? true,entries: size=1, first=(t:1, i:36), METADATAENTRY(c:34): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-27 23:43:45,889 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 02b664bf-3432-424d-aeb2-fd50259d9f48: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-27 23:43:45,896 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787 Close channels
2023-03-27 23:43:45,896 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-FollowerState was interrupted
2023-03-27 23:43:45,896 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-StateMachineUpdater: set stopIndex = 36
2023-03-27 23:43:45,896 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-CE70BD6F3331: Taking a snapshot at:(t:1, i:36) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-2/data/ratis/3d1ae31f-ffee-4866-9493-ce70bd6f3331/sm/snapshot.1_36
2023-03-27 23:43:45,902 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-27 23:43:45,902 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 37 -> 36
2023-03-27 23:43:45,903 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 02b664bf-3432-424d-aeb2-fd50259d9f48: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:43:45,903 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-27 23:43:45,903 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-CE70BD6F3331: Finished taking a snapshot at:(t:1, i:36) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-2/data/ratis/3d1ae31f-ffee-4866-9493-ce70bd6f3331/sm/snapshot.1_36 took: 7 ms
2023-03-27 23:43:45,903 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-StateMachineUpdater: Took a snapshot at index 36
2023-03-27 23:43:45,903 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 36
2023-03-27 23:43:45,903 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 36 -> 35
2023-03-27 23:43:45,906 [02b664bf-3432-424d-aeb2-fd50259d9f48-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3d2cda94, L:/0:0:0:0:0:0:0:0:41299] CLOSE
2023-03-27 23:43:45,906 [02b664bf-3432-424d-aeb2-fd50259d9f48-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3d2cda94, L:/0:0:0:0:0:0:0:0:41299] INACTIVE
2023-03-27 23:43:45,906 [02b664bf-3432-424d-aeb2-fd50259d9f48-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3d2cda94, L:/0:0:0:0:0:0:0:0:41299] UNREGISTERED
2023-03-27 23:43:45,906 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331: closes. applyIndex: 36
2023-03-27 23:43:45,935 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:45,935 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 36 -> 35
2023-03-27 23:43:45,936 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E: shutdown
2023-03-27 23:43:45,936 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0AF437366E3E,id=02b664bf-3432-424d-aeb2-fd50259d9f48
2023-03-27 23:43:45,936 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:45,936 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 35 -> 34
2023-03-27 23:43:45,936 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 02b664bf-3432-424d-aeb2-fd50259d9f48: shutdown 02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-LeaderStateImpl
2023-03-27 23:43:45,936 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:45,937 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:45,937 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-0AF437366E3E: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-2/data/ratis/ebc7c1df-c892-4dfc-a821-0af437366e3e/sm/snapshot.1_0
2023-03-27 23:43:45,938 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-0AF437366E3E: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-2/data/ratis/ebc7c1df-c892-4dfc-a821-0af437366e3e/sm/snapshot.1_0 took: 1 ms
2023-03-27 23:43:45,938 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:45,938 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:45,939 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E: closes. applyIndex: 0
2023-03-27 23:43:45,939 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:45,939 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-CE70BD6F3331-SegmentedRaftLogWorker close()
2023-03-27 23:43:45,939 [02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:45,940 [02b664bf-3432-424d-aeb2-fd50259d9f48-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 02b664bf-3432-424d-aeb2-fd50259d9f48@group-0AF437366E3E-SegmentedRaftLogWorker close()
2023-03-27 23:43:45,940 [JvmPauseMonitor28] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-02b664bf-3432-424d-aeb2-fd50259d9f48: Stopped
2023-03-27 23:43:45,941 [Thread-3223] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data-0/containers/hdds
2023-03-27 23:43:45,941 [Listener at 127.0.0.1/37647] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(303)) - Build ContainerSet costs 0s
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-27 23:43:45,950 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:45,951 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:45,951 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-27 23:43:45,951 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-27 23:43:45,951 [Listener at 127.0.0.1/37647] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-27 23:43:45,952 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-27 23:43:45,952 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-27 23:43:45,952 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-27 23:43:45,952 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-27 23:43:45,952 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-27 23:43:45,952 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-27 23:43:45,953 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-27 23:43:45,953 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-27 23:43:45,953 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-27 23:43:45,954 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-27 23:43:45,954 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-27 23:43:45,954 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-27 23:43:45,954 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:45,954 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:45,954 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis] (custom)
2023-03-27 23:43:45,954 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x944e34a6] REGISTERED
2023-03-27 23:43:45,955 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x944e34a6] BIND: 0.0.0.0/0.0.0.0:0
2023-03-27 23:43:45,955 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x944e34a6, L:/0:0:0:0:0:0:0:0:45739] ACTIVE
2023-03-27 23:43:45,956 [Listener at 127.0.0.1/37647] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-27 23:43:45,958 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-27 23:43:45,958 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:43:45,959 [Listener at 127.0.0.1/37647] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:43:45,959 [Listener at 127.0.0.1/37647] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:43:45,960 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:43:45,960 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-27 23:43:45,960 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:43:45,960 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:43:45,961 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/meta/webserver
2023-03-27 23:43:45,961 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34353
2023-03-27 23:43:45,961 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:43:45,961 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:43:45,962 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:43:45,962 [Listener at 127.0.0.1/37647] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-27 23:43:45,962 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@33bf219e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:43:45,962 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@51db7e86{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-27 23:43:46,175 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@20dbcc46{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/meta/webserver/jetty-0_0_0_0-34353-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-257958346704496006/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:46,178 [Listener at 127.0.0.1/37647] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@d6acd2e{HTTP/1.1, (http/1.1)}{0.0.0.0:34353}
2023-03-27 23:43:46,178 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(415)) - Started @173070ms
2023-03-27 23:43:46,178 [Listener at 127.0.0.1/37647] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:43:46,179 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34353
2023-03-27 23:43:46,180 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-27 23:43:46,180 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:46,181 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:46,181 [Listener at 127.0.0.1/37647] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-27 23:43:46,192 [Listener at 127.0.0.1/37647] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net ip:10.1.0.32
2023-03-27 23:43:46,192 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@e6c9a33] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:43:46,195 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/meta/datanode.id
2023-03-27 23:43:46,212 [Listener at 127.0.0.1/37647] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:43:46,260 [Listener at 127.0.0.1/37647] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 47 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:43:46,261 [Listener at 127.0.0.1/37647] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-27 23:43:46,263 [Listener at 127.0.0.1/37647] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-27 23:43:46,263 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data-0/containers/hdds to VolumeSet
2023-03-27 23:43:46,263 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data-0/containers/hdds
2023-03-27 23:43:46,264 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data-0/containers/hdds
2023-03-27 23:43:46,274 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis to VolumeSet
2023-03-27 23:43:46,274 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis
2023-03-27 23:43:46,274 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis
2023-03-27 23:43:46,287 [Thread-3243] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data-0/containers/hdds
2023-03-27 23:43:46,287 [Listener at 127.0.0.1/37647] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(303)) - Build ContainerSet costs 0s
2023-03-27 23:43:46,288 [Listener at 127.0.0.1/37647] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-27 23:43:46,288 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:46,288 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-27 23:43:46,288 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:46,288 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-27 23:43:46,288 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-27 23:43:46,288 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-27 23:43:46,289 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-27 23:43:46,289 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:46,289 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-27 23:43:46,289 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:46,289 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:46,289 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-27 23:43:46,289 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-27 23:43:46,290 [Listener at 127.0.0.1/37647] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-27 23:43:46,290 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-27 23:43:46,290 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-27 23:43:46,290 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-27 23:43:46,290 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-27 23:43:46,290 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-27 23:43:46,290 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-27 23:43:46,290 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-27 23:43:46,290 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-27 23:43:46,291 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-27 23:43:46,291 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-27 23:43:46,291 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-27 23:43:46,291 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-27 23:43:46,291 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:46,291 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:46,291 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis] (custom)
2023-03-27 23:43:46,291 [3d5bec3e-3873-417f-9114-370ff3a7c03a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9ced37f1] REGISTERED
2023-03-27 23:43:46,291 [3d5bec3e-3873-417f-9114-370ff3a7c03a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9ced37f1] BIND: 0.0.0.0/0.0.0.0:0
2023-03-27 23:43:46,292 [3d5bec3e-3873-417f-9114-370ff3a7c03a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9ced37f1, L:/0:0:0:0:0:0:0:0:39907] ACTIVE
2023-03-27 23:43:46,293 [Listener at 127.0.0.1/37647] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-27 23:43:46,295 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-27 23:43:46,295 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:43:46,295 [Listener at 127.0.0.1/37647] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:43:46,298 [Listener at 127.0.0.1/37647] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:43:46,299 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:43:46,299 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-27 23:43:46,299 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:43:46,299 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:43:46,299 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/meta/webserver
2023-03-27 23:43:46,299 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 43721
2023-03-27 23:43:46,299 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:43:46,307 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:43:46,308 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:43:46,308 [Listener at 127.0.0.1/37647] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-27 23:43:46,308 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@196adc9e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:43:46,308 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1e426412{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-27 23:43:46,367 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:46,368 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 28 -> 27
2023-03-27 23:43:46,367 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:46,369 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 27 -> 26
2023-03-27 23:43:46,378 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:46,378 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:46,378 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 27 -> 26
2023-03-27 23:43:46,379 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 26 -> 25
2023-03-27 23:43:46,381 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:46,382 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 34 -> 33
2023-03-27 23:43:46,382 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:46,382 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 33 -> 32
2023-03-27 23:43:46,392 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:46,392 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 33 -> 32
2023-03-27 23:43:46,393 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:46,393 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 32 -> 31
2023-03-27 23:43:46,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:46,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2023-03-27 23:43:46,426 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode ebbb6892-a89a-4074-adec-249bdede4c6b(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) moved to stale state. Finalizing its pipelines [PipelineID=66422011-1c0d-4681-8ef6-dce8a982e78b, PipelineID=c888fd41-72df-4b6a-837e-4aaa5b89608d]
2023-03-27 23:43:46,426 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 66422011-1c0d-4681-8ef6-dce8a982e78b, Nodes: ebbb6892-a89a-4074-adec-249bdede4c6b(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:ebbb6892-a89a-4074-adec-249bdede4c6b, CreationTimestamp2023-03-27T23:41:54.221Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:46,426 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: c888fd41-72df-4b6a-837e-4aaa5b89608d, Nodes: 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)ebbb6892-a89a-4074-adec-249bdede4c6b(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:ebbb6892-a89a-4074-adec-249bdede4c6b, CreationTimestamp2023-03-27T23:43:11.849Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:46,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 11 containers.
2023-03-27 23:43:46,527 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) moved to stale state. Finalizing its pipelines [PipelineID=3d1ae31f-ffee-4866-9493-ce70bd6f3331, PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, PipelineID=e304f524-3200-488a-9b4c-6d53e1e11a88]
2023-03-27 23:43:46,527 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #2 closed for pipeline=PipelineID=3d1ae31f-ffee-4866-9493-ce70bd6f3331
2023-03-27 23:43:46,527 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #3 closed for pipeline=PipelineID=3d1ae31f-ffee-4866-9493-ce70bd6f3331
2023-03-27 23:43:46,527 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #6 closed for pipeline=PipelineID=3d1ae31f-ffee-4866-9493-ce70bd6f3331
2023-03-27 23:43:46,527 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 3d1ae31f-ffee-4866-9493-ce70bd6f3331, Nodes: 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:2fe3edb7-8e87-4db1-bb8e-5ae441beb787, CreationTimestamp2023-03-27T23:41:53.104Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:46,528 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #11 closed for pipeline=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798
2023-03-27 23:43:46,528 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: b04b75f6-7f4f-41e0-a051-b79c09c49798, Nodes: 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: EC{rs-3-2-1024k}, State:OPEN, leaderId:, CreationTimestamp2023-03-27T23:43:05.757Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:46,528 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: e304f524-3200-488a-9b4c-6d53e1e11a88, Nodes: 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:1bfcd852-ea3f-4c7a-9193-c23bc5754bdf, CreationTimestamp2023-03-27T23:41:52.739Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:46,528 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #2, current state: CLOSING
2023-03-27 23:43:46,528 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #3, current state: CLOSING
2023-03-27 23:43:46,528 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #6, current state: CLOSING
2023-03-27 23:43:46,528 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #11, current state: CLOSING
2023-03-27 23:43:46,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:46,655 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5d363e12{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/meta/webserver/jetty-0_0_0_0-43721-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-7858526215770132360/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:46,667 [Listener at 127.0.0.1/37647] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4024f0bf{HTTP/1.1, (http/1.1)}{0.0.0.0:43721}
2023-03-27 23:43:46,668 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(415)) - Started @173559ms
2023-03-27 23:43:46,668 [Listener at 127.0.0.1/37647] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:43:46,668 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:43721
2023-03-27 23:43:46,670 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-27 23:43:46,670 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:46,670 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:46,670 [Listener at 127.0.0.1/37647] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-27 23:43:46,680 [Listener at 127.0.0.1/37647] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net ip:10.1.0.32
2023-03-27 23:43:46,685 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f412a53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:43:46,688 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/meta/datanode.id
2023-03-27 23:43:46,727 [Listener at 127.0.0.1/37647] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:43:46,835 [Listener at 127.0.0.1/37647] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 107 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:43:46,838 [Listener at 127.0.0.1/37647] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-27 23:43:46,842 [Listener at 127.0.0.1/37647] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-27 23:43:46,842 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data-0/containers/hdds to VolumeSet
2023-03-27 23:43:46,842 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data-0/containers/hdds
2023-03-27 23:43:46,844 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data-0/containers/hdds
2023-03-27 23:43:46,869 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis to VolumeSet
2023-03-27 23:43:46,869 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis
2023-03-27 23:43:46,872 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis
2023-03-27 23:43:46,927 [Thread-3260] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data-0/containers/hdds
2023-03-27 23:43:46,928 [Listener at 127.0.0.1/37647] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(303)) - Build ContainerSet costs 0s
2023-03-27 23:43:46,929 [Listener at 127.0.0.1/37647] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-27 23:43:46,930 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:46,930 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-27 23:43:46,930 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:46,930 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-27 23:43:46,930 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-27 23:43:46,930 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-27 23:43:46,930 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-27 23:43:46,930 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:46,930 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-27 23:43:46,931 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:46,931 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:46,931 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-27 23:43:46,931 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-27 23:43:46,933 [Listener at 127.0.0.1/37647] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-27 23:43:46,933 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-27 23:43:46,934 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-27 23:43:46,934 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-27 23:43:46,934 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-27 23:43:46,934 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-27 23:43:46,934 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-27 23:43:46,934 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-27 23:43:46,934 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-27 23:43:46,934 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-27 23:43:46,934 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-27 23:43:46,942 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-27 23:43:46,942 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-27 23:43:46,942 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:46,942 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:46,942 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis] (custom)
2023-03-27 23:43:46,943 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5d73c947] REGISTERED
2023-03-27 23:43:46,943 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5d73c947] BIND: 0.0.0.0/0.0.0.0:0
2023-03-27 23:43:46,943 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5d73c947, L:/0:0:0:0:0:0:0:0:33491] ACTIVE
2023-03-27 23:43:46,946 [Listener at 127.0.0.1/37647] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-27 23:43:46,952 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-27 23:43:46,952 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:43:46,952 [Listener at 127.0.0.1/37647] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:43:46,953 [Listener at 127.0.0.1/37647] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:43:46,954 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:43:46,955 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-27 23:43:46,955 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:43:46,955 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:43:46,955 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/meta/webserver
2023-03-27 23:43:46,955 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 46857
2023-03-27 23:43:46,955 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:43:46,958 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:43:46,958 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:43:46,958 [Listener at 127.0.0.1/37647] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-27 23:43:46,959 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2ade6a3e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:43:46,959 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@44c0bab2{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-27 23:43:47,102 [IPC Server handler 9 on default port 39209] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(366)) - Starting Maintenance for node 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:47,103 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) moved to HEALTHY state.
2023-03-27 23:43:47,103 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:47,103 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1. Excluded 5.
2023-03-27 23:43:47,140 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-08ed37e7-dbf1-4734-bfa4-4979a235ddb3/container.db to cache
2023-03-27 23:43:47,142 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-08ed37e7-dbf1-4734-bfa4-4979a235ddb3/container.db for volume DS-08ed37e7-dbf1-4734-bfa4-4979a235ddb3
2023-03-27 23:43:47,143 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(397)) - Attempting to start container services.
2023-03-27 23:43:47,143 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(314)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-27 23:43:47,143 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 37229
2023-03-27 23:43:47,145 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:47,156 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: start RPC server
2023-03-27 23:43:47,156 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: GrpcService started, listening on 39339
2023-03-27 23:43:47,156 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 5c7a3766-4df9-4a62-b680-fc04cc352416 is started using port 39339 for RATIS
2023-03-27 23:43:47,156 [JvmPauseMonitor52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-5c7a3766-4df9-4a62-b680-fc04cc352416: Started
2023-03-27 23:43:47,156 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 5c7a3766-4df9-4a62-b680-fc04cc352416 is started using port 39339 for RATIS_ADMIN
2023-03-27 23:43:47,156 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 5c7a3766-4df9-4a62-b680-fc04cc352416 is started using port 39339 for RATIS_SERVER
2023-03-27 23:43:47,156 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 5c7a3766-4df9-4a62-b680-fc04cc352416 is started using port 39875 for RATIS_DATASTREAM
2023-03-27 23:43:47,157 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 5c7a3766-4df9-4a62-b680-fc04cc352416 is started using port 35783
2023-03-27 23:43:47,157 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:43:47,286 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1e87133{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/meta/webserver/jetty-0_0_0_0-46857-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6109825976621266841/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:47,291 [Listener at 127.0.0.1/37647] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7cca3187{HTTP/1.1, (http/1.1)}{0.0.0.0:46857}
2023-03-27 23:43:47,291 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(415)) - Started @174183ms
2023-03-27 23:43:47,291 [Listener at 127.0.0.1/37647] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:43:47,291 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:46857
2023-03-27 23:43:47,298 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:47,298 [Listener at 127.0.0.1/37647] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-27 23:43:47,298 [Listener at 127.0.0.1/37647] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-27 23:43:47,302 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-27 23:43:47,311 [Listener at 127.0.0.1/37647] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net ip:10.1.0.32
2023-03-27 23:43:47,322 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7b966160] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:43:47,323 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/meta/datanode.id
2023-03-27 23:43:47,339 [Listener at 127.0.0.1/37647] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:43:47,386 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-8f2c999a-9287-4f75-898c-b499bc0119c9/container.db to cache
2023-03-27 23:43:47,386 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-8f2c999a-9287-4f75-898c-b499bc0119c9/container.db for volume DS-8f2c999a-9287-4f75-898c-b499bc0119c9
2023-03-27 23:43:47,386 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(397)) - Attempting to start container services.
2023-03-27 23:43:47,386 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(314)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-27 23:43:47,387 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 39507
2023-03-27 23:43:47,389 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 69c31795-da41-43dd-a637-b3015d9175ea
2023-03-27 23:43:47,403 [Listener at 127.0.0.1/37647] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 63 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:43:47,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:47,406 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 69c31795-da41-43dd-a637-b3015d9175ea: start RPC server
2023-03-27 23:43:47,406 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 69c31795-da41-43dd-a637-b3015d9175ea: GrpcService started, listening on 40539
2023-03-27 23:43:47,407 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 69c31795-da41-43dd-a637-b3015d9175ea is started using port 40539 for RATIS
2023-03-27 23:43:47,407 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 69c31795-da41-43dd-a637-b3015d9175ea is started using port 40539 for RATIS_ADMIN
2023-03-27 23:43:47,407 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 69c31795-da41-43dd-a637-b3015d9175ea is started using port 40539 for RATIS_SERVER
2023-03-27 23:43:47,407 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 69c31795-da41-43dd-a637-b3015d9175ea is started using port 34781 for RATIS_DATASTREAM
2023-03-27 23:43:47,407 [JvmPauseMonitor53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-69c31795-da41-43dd-a637-b3015d9175ea: Started
2023-03-27 23:43:47,407 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 69c31795-da41-43dd-a637-b3015d9175ea is started using port 40779
2023-03-27 23:43:47,407 [Listener at 127.0.0.1/37647] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-27 23:43:47,409 [Listener at 127.0.0.1/37647] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-27 23:43:47,409 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data-0/containers/hdds to VolumeSet
2023-03-27 23:43:47,409 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data-0/containers/hdds
2023-03-27 23:43:47,418 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:43:47,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 9 milliseconds for processing 6 containers.
2023-03-27 23:43:47,421 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data-0/containers/hdds
2023-03-27 23:43:47,431 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:47,431 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:47,431 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:47,431 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:47,431 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:47,431 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:47,432 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:47,432 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:47,432 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:47,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962397432 and scm deadline 1679962427432
2023-03-27 23:43:47,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962397432 and scm deadline 1679962427432
2023-03-27 23:43:47,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962397432 and scm deadline 1679962427432
2023-03-27 23:43:47,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962397432 and scm deadline 1679962427432
2023-03-27 23:43:47,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962397432 and scm deadline 1679962427432
2023-03-27 23:43:47,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-03-27 23:43:47,435 [Listener at 127.0.0.1/37647] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis to VolumeSet
2023-03-27 23:43:47,435 [Listener at 127.0.0.1/37647] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis
2023-03-27 23:43:47,435 [Listener at 127.0.0.1/37647] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis
2023-03-27 23:43:47,448 [Thread-3289] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data-0/containers/hdds
2023-03-27 23:43:47,448 [Listener at 127.0.0.1/37647] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(303)) - Build ContainerSet costs 0s
2023-03-27 23:43:47,450 [Listener at 127.0.0.1/37647] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-27 23:43:47,450 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:47,450 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-27 23:43:47,450 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-27 23:43:47,450 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-27 23:43:47,450 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-27 23:43:47,450 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-27 23:43:47,450 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-27 23:43:47,450 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:47,451 [Listener at 127.0.0.1/37647] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-27 23:43:47,451 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:47,451 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:47,451 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-27 23:43:47,451 [Listener at 127.0.0.1/37647] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-27 23:43:47,452 [Listener at 127.0.0.1/37647] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-27 23:43:47,452 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-27 23:43:47,452 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-27 23:43:47,452 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-27 23:43:47,452 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-27 23:43:47,452 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-27 23:43:47,452 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-27 23:43:47,452 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-27 23:43:47,453 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-27 23:43:47,453 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-27 23:43:47,453 [Listener at 127.0.0.1/37647] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-27 23:43:47,453 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-27 23:43:47,454 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-27 23:43:47,454 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:47,454 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:47,454 [38de582e-58a6-400e-852c-9e1084927a05-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x82777c4c] REGISTERED
2023-03-27 23:43:47,454 [Listener at 127.0.0.1/37647] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis] (custom)
2023-03-27 23:43:47,454 [38de582e-58a6-400e-852c-9e1084927a05-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x82777c4c] BIND: 0.0.0.0/0.0.0.0:0
2023-03-27 23:43:47,454 [38de582e-58a6-400e-852c-9e1084927a05-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x82777c4c, L:/0:0:0:0:0:0:0:0:40501] ACTIVE
2023-03-27 23:43:47,455 [Listener at 127.0.0.1/37647] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-27 23:43:47,458 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-27 23:43:47,458 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:43:47,459 [Listener at 127.0.0.1/37647] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:43:47,459 [Listener at 127.0.0.1/37647] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:43:47,460 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:43:47,460 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-27 23:43:47,460 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:43:47,460 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:43:47,460 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/meta/webserver
2023-03-27 23:43:47,460 [Listener at 127.0.0.1/37647] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 33853
2023-03-27 23:43:47,460 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:43:47,461 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:43:47,461 [Listener at 127.0.0.1/37647] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:43:47,461 [Listener at 127.0.0.1/37647] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-27 23:43:47,462 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@9fe9c5e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:43:47,462 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6ca442a9{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-27 23:43:47,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:47,618 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,618 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 25 -> 24
2023-03-27 23:43:47,618 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,619 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 24 -> 23
2023-03-27 23:43:47,628 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,628 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 24 -> 23
2023-03-27 23:43:47,629 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,629 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 23 -> 22
2023-03-27 23:43:47,632 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,632 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 31 -> 30
2023-03-27 23:43:47,632 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,632 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 30 -> 29
2023-03-27 23:43:47,643 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,644 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 30 -> 29
2023-03-27 23:43:47,644 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,644 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 29 -> 28
2023-03-27 23:43:47,646 [IPC Server handler 13 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-03-27 23:43:47,698 [Listener at 127.0.0.1/37647] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@20fa0e4{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/meta/webserver/jetty-0_0_0_0-33853-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-9177946553388411443/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:47,701 [Listener at 127.0.0.1/37647] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@502601ed{HTTP/1.1, (http/1.1)}{0.0.0.0:33853}
2023-03-27 23:43:47,701 [Listener at 127.0.0.1/37647] INFO  server.Server (Server.java:doStart(415)) - Started @174593ms
2023-03-27 23:43:47,701 [Listener at 127.0.0.1/37647] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:43:47,701 [Listener at 127.0.0.1/37647] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:33853
2023-03-27 23:43:47,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-27 23:43:47,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:47,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:47,702 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-27 23:43:47,703 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a33a4e2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:43:47,704 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/meta/datanode.id
2023-03-27 23:43:47,775 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-1b4169bc-bf3d-4b1f-a06f-137923cd2706/container.db to cache
2023-03-27 23:43:47,775 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-1b4169bc-bf3d-4b1f-a06f-137923cd2706/container.db for volume DS-1b4169bc-bf3d-4b1f-a06f-137923cd2706
2023-03-27 23:43:47,775 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(397)) - Attempting to start container services.
2023-03-27 23:43:47,775 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(314)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-27 23:43:47,776 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 41381
2023-03-27 23:43:47,779 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 117526ec-9427-41bf-9dbd-c8f743595c9c
2023-03-27 23:43:47,792 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: start RPC server
2023-03-27 23:43:47,793 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: GrpcService started, listening on 44893
2023-03-27 23:43:47,793 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 117526ec-9427-41bf-9dbd-c8f743595c9c is started using port 44893 for RATIS
2023-03-27 23:43:47,793 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 117526ec-9427-41bf-9dbd-c8f743595c9c is started using port 44893 for RATIS_ADMIN
2023-03-27 23:43:47,793 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 117526ec-9427-41bf-9dbd-c8f743595c9c is started using port 44893 for RATIS_SERVER
2023-03-27 23:43:47,793 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 117526ec-9427-41bf-9dbd-c8f743595c9c is started using port 33557 for RATIS_DATASTREAM
2023-03-27 23:43:47,794 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 117526ec-9427-41bf-9dbd-c8f743595c9c is started using port 39037
2023-03-27 23:43:47,794 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:43:47,798 [JvmPauseMonitor54] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-117526ec-9427-41bf-9dbd-c8f743595c9c: Started
2023-03-27 23:43:47,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(326)) - Waiting for pipelines to close for 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). There are 2 pipelines
2023-03-27 23:43:47,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:47,823 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Finalizing its pipelines [PipelineID=7e260818-9050-4cf0-9395-3bacc333d725, PipelineID=49e77fc3-0a0a-47b0-8720-e918c3435c33]
2023-03-27 23:43:47,823 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #1 closed for pipeline=PipelineID=7e260818-9050-4cf0-9395-3bacc333d725
2023-03-27 23:43:47,823 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #1, current state: CLOSING
2023-03-27 23:43:47,825 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #4 closed for pipeline=PipelineID=7e260818-9050-4cf0-9395-3bacc333d725
2023-03-27 23:43:47,825 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #4, current state: CLOSING
2023-03-27 23:43:47,826 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #6 closed for pipeline=PipelineID=7e260818-9050-4cf0-9395-3bacc333d725
2023-03-27 23:43:47,826 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 7e260818-9050-4cf0-9395-3bacc333d725, Nodes: 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:2829ccc8-889f-48cc-a62b-b3954aa0680c, CreationTimestamp2023-03-27T23:42:36.108Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:47,826 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 close command to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:43:47,826 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 close command to datanode 49220674-b9b6-430a-b99a-f5474fac1494
2023-03-27 23:43:47,826 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 close command to datanode 3fee8600-457c-478d-8bf5-017cc394a56c
2023-03-27 23:43:47,826 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #6, current state: CLOSING
2023-03-27 23:43:47,829 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 7e260818-9050-4cf0-9395-3bacc333d725, Nodes: 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:2829ccc8-889f-48cc-a62b-b3954aa0680c, CreationTimestamp2023-03-27T23:42:36.108Z[Etc/UTC]] removed.
2023-03-27 23:43:47,830 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 49e77fc3-0a0a-47b0-8720-e918c3435c33, Nodes: 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:49220674-b9b6-430a-b99a-f5474fac1494, CreationTimestamp2023-03-27T23:42:35.173Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:47,830 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=49e77fc3-0a0a-47b0-8720-e918c3435c33 close command to datanode 49220674-b9b6-430a-b99a-f5474fac1494
2023-03-27 23:43:47,830 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 49e77fc3-0a0a-47b0-8720-e918c3435c33, Nodes: 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:49220674-b9b6-430a-b99a-f5474fac1494, CreationTimestamp2023-03-27T23:42:35.173Z[Etc/UTC]] removed.
2023-03-27 23:43:47,916 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-3/data-0/containers/hdds/6e26070d-9fdb-4a65-9637-ae4e983202df/DS-8658ae59-0fbc-4ee2-a283-77888ce6cc69/container.db for volume DS-8658ae59-0fbc-4ee2-a283-77888ce6cc69
2023-03-27 23:43:47,916 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-27 23:43:47,916 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-27 23:43:47,917 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-27 23:43:47,926 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3579f6c{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:47,927 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1b8e569f{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:43:47,927 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:47,927 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4ee6c88b{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-27 23:43:47,927 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@58113194{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:43:47,933 [Datanode State Machine Daemon Thread] WARN  statemachine.StateContext (StateContext.java:setState(253)) - Ignore disallowed transition from SHUTDOWN to RUNNING
2023-03-27 23:43:47,933 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:43:47,934 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 549101de-1cf2-4583-b7e6-903b03646e7c: close
2023-03-27 23:43:47,934 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D: shutdown
2023-03-27 23:43:47,934 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 549101de-1cf2-4583-b7e6-903b03646e7c: shutdown server GrpcServerProtocolService now
2023-03-27 23:43:47,934 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4AAA5B89608D,id=549101de-1cf2-4583-b7e6-903b03646e7c
2023-03-27 23:43:47,934 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 549101de-1cf2-4583-b7e6-903b03646e7c: shutdown 549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-FollowerState
2023-03-27 23:43:47,937 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915 Close channels
2023-03-27 23:43:47,937 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49: shutdown
2023-03-27 23:43:47,937 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC66810DBE49,id=549101de-1cf2-4583-b7e6-903b03646e7c
2023-03-27 23:43:47,942 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 549101de-1cf2-4583-b7e6-903b03646e7c: shutdown 549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-LeaderStateImpl
2023-03-27 23:43:47,942 [549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-4AAA5B89608D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-6/data/ratis/c888fd41-72df-4b6a-837e-4aaa5b89608d/sm/snapshot.1_0
2023-03-27 23:43:47,942 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:47,942 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - ebbb6892-a89a-4074-adec-249bdede4c6b Close channels
2023-03-27 23:43:47,942 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:47,942 [549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-FollowerState was interrupted
2023-03-27 23:43:47,945 [549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-4AAA5B89608D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-6/data/ratis/c888fd41-72df-4b6a-837e-4aaa5b89608d/sm/snapshot.1_0 took: 3 ms
2023-03-27 23:43:47,945 [549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:47,945 [549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:47,946 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D: closes. applyIndex: 0
2023-03-27 23:43:47,945 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 549101de-1cf2-4583-b7e6-903b03646e7c: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:43:47,946 [549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:47,946 [549101de-1cf2-4583-b7e6-903b03646e7c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x749e5e18, L:/0:0:0:0:0:0:0:0:32871] CLOSE
2023-03-27 23:43:47,946 [549101de-1cf2-4583-b7e6-903b03646e7c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x749e5e18, L:/0:0:0:0:0:0:0:0:32871] INACTIVE
2023-03-27 23:43:47,946 [549101de-1cf2-4583-b7e6-903b03646e7c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x749e5e18, L:/0:0:0:0:0:0:0:0:32871] UNREGISTERED
2023-03-27 23:43:47,946 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-4AAA5B89608D-SegmentedRaftLogWorker close()
2023-03-27 23:43:47,947 [549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-DC66810DBE49: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-6/data/ratis/31ed04c6-2ac2-4da5-bd63-dc66810dbe49/sm/snapshot.1_0
2023-03-27 23:43:47,947 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:47,947 [549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-DC66810DBE49: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-6/data/ratis/31ed04c6-2ac2-4da5-bd63-dc66810dbe49/sm/snapshot.1_0 took: 0 ms
2023-03-27 23:43:47,948 [549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:47,948 [549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:47,951 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,951 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 23 -> 22
2023-03-27 23:43:47,951 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,951 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf: nextIndex: updateUnconditionally 22 -> 21
2023-03-27 23:43:47,953 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,953 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 29 -> 28
2023-03-27 23:43:47,954 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-27 23:43:47,954 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48: nextIndex: updateUnconditionally 28 -> 27
2023-03-27 23:43:47,958 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49: closes. applyIndex: 0
2023-03-27 23:43:47,958 [549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:47,959 [549101de-1cf2-4583-b7e6-903b03646e7c-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 549101de-1cf2-4583-b7e6-903b03646e7c@group-DC66810DBE49-SegmentedRaftLogWorker close()
2023-03-27 23:43:47,962 [JvmPauseMonitor32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-549101de-1cf2-4583-b7e6-903b03646e7c: Stopped
2023-03-27 23:43:47,964 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-2/data-0/containers/hdds/6e26070d-9fdb-4a65-9637-ae4e983202df/DS-ba2b06c8-4752-4776-99ed-79fe9ba64c14/container.db for volume DS-ba2b06c8-4752-4776-99ed-79fe9ba64c14
2023-03-27 23:43:47,964 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-27 23:43:47,965 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-27 23:43:47,967 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-27 23:43:47,975 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2bff5576{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:47,975 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@408682a2{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:43:47,975 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:47,976 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@fe83ba1{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-27 23:43:47,976 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3c315583{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:43:47,995 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:43:47,995 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(133)) - Can't close container #2
java.io.IOException
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:630)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:105)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:642)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.InterruptedException
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:347)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1928)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:625)
	... 4 more
2023-03-27 23:43:47,996 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787: close
2023-03-27 23:43:47,996 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331: shutdown
2023-03-27 23:43:47,996 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CE70BD6F3331,id=2fe3edb7-8e87-4db1-bb8e-5ae441beb787
2023-03-27 23:43:47,996 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787: shutdown 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-LeaderStateImpl
2023-03-27 23:43:47,996 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787: shutdown server GrpcServerProtocolService now
2023-03-27 23:43:47,996 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->1bfcd852-ea3f-4c7a-9193-c23bc5754bdf-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-27 23:43:47,996 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331->02b664bf-3432-424d-aeb2-fd50259d9f48-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-27 23:43:47,997 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 02b664bf-3432-424d-aeb2-fd50259d9f48 Close channels
2023-03-27 23:43:47,997 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf Close channels
2023-03-27 23:43:47,997 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:43:47,997 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:47,999 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe9df7afd, L:/0:0:0:0:0:0:0:0:33563] CLOSE
2023-03-27 23:43:48,000 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe9df7afd, L:/0:0:0:0:0:0:0:0:33563] INACTIVE
2023-03-27 23:43:48,000 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe9df7afd, L:/0:0:0:0:0:0:0:0:33563] UNREGISTERED
2023-03-27 23:43:48,001 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-StateMachineUpdater: set stopIndex = 36
2023-03-27 23:43:48,001 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-CE70BD6F3331: Taking a snapshot at:(t:1, i:36) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-0/data/ratis/3d1ae31f-ffee-4866-9493-ce70bd6f3331/sm/snapshot.1_36
2023-03-27 23:43:48,002 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-CE70BD6F3331: Finished taking a snapshot at:(t:1, i:36) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-0/data/ratis/3d1ae31f-ffee-4866-9493-ce70bd6f3331/sm/snapshot.1_36 took: 1 ms
2023-03-27 23:43:48,002 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-StateMachineUpdater: Took a snapshot at index 36
2023-03-27 23:43:48,002 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 36
2023-03-27 23:43:48,013 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47: shutdown
2023-03-27 23:43:48,013 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F644ED0EAD47,id=2fe3edb7-8e87-4db1-bb8e-5ae441beb787
2023-03-27 23:43:48,013 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787: shutdown 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-LeaderStateImpl
2023-03-27 23:43:48,013 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:48,013 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:48,014 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-F644ED0EAD47: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-0/data/ratis/616f38e7-5b90-485b-b681-f644ed0ead47/sm/snapshot.1_0
2023-03-27 23:43:48,014 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331: closes. applyIndex: 36
2023-03-27 23:43:48,014 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:48,014 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-F644ED0EAD47: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-0/data/ratis/616f38e7-5b90-485b-b681-f644ed0ead47/sm/snapshot.1_0 took: 0 ms
2023-03-27 23:43:48,015 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-CE70BD6F3331-SegmentedRaftLogWorker close()
2023-03-27 23:43:48,015 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:48,015 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:48,015 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47: closes. applyIndex: 0
2023-03-27 23:43:48,015 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:48,016 [2fe3edb7-8e87-4db1-bb8e-5ae441beb787-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 2fe3edb7-8e87-4db1-bb8e-5ae441beb787@group-F644ED0EAD47-SegmentedRaftLogWorker close()
2023-03-27 23:43:48,017 [JvmPauseMonitor26] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-2fe3edb7-8e87-4db1-bb8e-5ae441beb787: Stopped
2023-03-27 23:43:48,222 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-593b6d2d-ab0c-4af9-bec2-4416d1bbf16d/container.db to cache
2023-03-27 23:43:48,223 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-593b6d2d-ab0c-4af9-bec2-4416d1bbf16d/container.db for volume DS-593b6d2d-ab0c-4af9-bec2-4416d1bbf16d
2023-03-27 23:43:48,223 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(397)) - Attempting to start container services.
2023-03-27 23:43:48,223 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(314)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-27 23:43:48,223 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 42877
2023-03-27 23:43:48,231 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6
2023-03-27 23:43:48,233 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: start RPC server
2023-03-27 23:43:48,233 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: GrpcService started, listening on 36455
2023-03-27 23:43:48,233 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6 is started using port 36455 for RATIS
2023-03-27 23:43:48,233 [JvmPauseMonitor55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: Started
2023-03-27 23:43:48,233 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6 is started using port 36455 for RATIS_ADMIN
2023-03-27 23:43:48,234 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6 is started using port 36455 for RATIS_SERVER
2023-03-27 23:43:48,234 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6 is started using port 45739 for RATIS_DATASTREAM
2023-03-27 23:43:48,234 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6 is started using port 45363
2023-03-27 23:43:48,235 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:43:48,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:43:48,432 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,432 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,432 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,432 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,432 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,432 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,433 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,433 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,433 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:48,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962398433 and scm deadline 1679962428433
2023-03-27 23:43:48,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962398433 and scm deadline 1679962428433
2023-03-27 23:43:48,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962398433 and scm deadline 1679962428433
2023-03-27 23:43:48,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962398433 and scm deadline 1679962428433
2023-03-27 23:43:48,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962398433 and scm deadline 1679962428433
2023-03-27 23:43:48,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-03-27 23:43:48,467 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) moved to stale state. Finalizing its pipelines [PipelineID=3d1ae31f-ffee-4866-9493-ce70bd6f3331, PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, PipelineID=ebc7c1df-c892-4dfc-a821-0af437366e3e]
2023-03-27 23:43:48,468 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: ebc7c1df-c892-4dfc-a821-0af437366e3e, Nodes: 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:02b664bf-3432-424d-aeb2-fd50259d9f48, CreationTimestamp2023-03-27T23:41:53.103Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:48,468 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) moved to stale state. Finalizing its pipelines [PipelineID=6d183de4-1aaf-4fde-a665-bf8815fb6aa8, PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, PipelineID=c888fd41-72df-4b6a-837e-4aaa5b89608d]
2023-03-27 23:43:48,468 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 6d183de4-1aaf-4fde-a665-bf8815fb6aa8, Nodes: 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:6bc3ba6a-9ae7-448c-8b94-c4229f9fc915, CreationTimestamp2023-03-27T23:41:53.821Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:48,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:48,644 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 is not found
2023-03-27 23:43:48,647 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 is not found
2023-03-27 23:43:48,647 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=49e77fc3-0a0a-47b0-8720-e918c3435c33 is not found
2023-03-27 23:43:48,648 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 is not found
2023-03-27 23:43:48,675 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5045211557ns, electionTimeout:5041ms
2023-03-27 23:43:48,675 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - afc9dc98-3375-40f1-a491-e988cc0b175c: shutdown afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState
2023-03-27 23:43:48,675 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:48,676 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:48,676 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - afc9dc98-3375-40f1-a491-e988cc0b175c: start afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86
2023-03-27 23:43:48,676 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[afc9dc98-3375-40f1-a491-e988cc0b175c|rpc:10.1.0.32:44001|dataStream:10.1.0.32:46075|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:48,676 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86 PRE_VOTE round 0: result PASSED (term=0)
2023-03-27 23:43:48,678 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86 ELECTION round 0: submit vote requests at term 1 for -1: peers:[afc9dc98-3375-40f1-a491-e988cc0b175c|rpc:10.1.0.32:44001|dataStream:10.1.0.32:46075|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:48,678 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86 ELECTION round 0: result PASSED (term=1)
2023-03-27 23:43:48,678 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - afc9dc98-3375-40f1-a491-e988cc0b175c: shutdown afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86
2023-03-27 23:43:48,678 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:48,678 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-CB860B84100E with new leaderId: afc9dc98-3375-40f1-a491-e988cc0b175c
2023-03-27 23:43:48,678 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E: change Leader from null to afc9dc98-3375-40f1-a491-e988cc0b175c at term 1 for becomeLeader, leader elected after 5062ms
2023-03-27 23:43:48,678 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:48,678 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:48,678 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:48,679 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:48,679 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:48,679 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:48,679 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:48,679 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:48,679 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - afc9dc98-3375-40f1-a491-e988cc0b175c: start afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderStateImpl
2023-03-27 23:43:48,679 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:48,692 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderElection86] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E: set configuration 0: peers:[afc9dc98-3375-40f1-a491-e988cc0b175c|rpc:10.1.0.32:44001|dataStream:10.1.0.32:46075|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:48,695 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-5/data/ratis/6ea8ff4c-1d6e-498c-be21-cb860b84100e/current/log_inprogress_0
2023-03-27 23:43:48,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-27 23:43:48,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:48,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:48,721 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-610da581-dc70-4f49-adfc-b35b89e99e28/container.db to cache
2023-03-27 23:43:48,721 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-610da581-dc70-4f49-adfc-b35b89e99e28/container.db for volume DS-610da581-dc70-4f49-adfc-b35b89e99e28
2023-03-27 23:43:48,721 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(397)) - Attempting to start container services.
2023-03-27 23:43:48,721 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(314)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-27 23:43:48,722 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 40011
2023-03-27 23:43:48,722 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 3d5bec3e-3873-417f-9114-370ff3a7c03a
2023-03-27 23:43:48,732 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: start RPC server
2023-03-27 23:43:48,732 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: GrpcService started, listening on 37315
2023-03-27 23:43:48,732 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 3d5bec3e-3873-417f-9114-370ff3a7c03a is started using port 37315 for RATIS
2023-03-27 23:43:48,732 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 3d5bec3e-3873-417f-9114-370ff3a7c03a is started using port 37315 for RATIS_ADMIN
2023-03-27 23:43:48,732 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 3d5bec3e-3873-417f-9114-370ff3a7c03a is started using port 37315 for RATIS_SERVER
2023-03-27 23:43:48,732 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 3d5bec3e-3873-417f-9114-370ff3a7c03a is started using port 39907 for RATIS_DATASTREAM
2023-03-27 23:43:48,733 [JvmPauseMonitor56] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-3d5bec3e-3873-417f-9114-370ff3a7c03a: Started
2023-03-27 23:43:48,733 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 3d5bec3e-3873-417f-9114-370ff3a7c03a is started using port 46793
2023-03-27 23:43:48,733 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:43:48,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:48,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:48,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #1 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=26, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=26, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=26, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:48,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #1 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=26, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=26, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=26, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:48,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #4 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=OPEN, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=OPEN, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:48,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #4 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=OPEN, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=OPEN, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:48,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 0 sufficientlyReplicated, 3 underReplicated and 3 unhealthy containers
2023-03-27 23:43:48,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:49,013 [IPC Server handler 2 on default port 36479] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:49,013 [IPC Server handler 2 on default port 36479] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 5c7a3766-4df9-4a62-b680-fc04cc352416{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=37229, RATIS=39339, RATIS_ADMIN=39339, RATIS_SERVER=39339, RATIS_DATASTREAM=39875, STANDALONE=35783], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:43:49,018 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:49,018 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=4ad1ff11-ec4e-4398-8b83-da2952889f03 to datanode:5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:49,019 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-27 23:43:49,019 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-27 23:43:49,022 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-27 23:43:49,022 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 4ad1ff11-ec4e-4398-8b83-da2952889f03, Nodes: 5c7a3766-4df9-4a62-b680-fc04cc352416(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:49.018Z[Etc/UTC]].
2023-03-27 23:43:49,350 [IPC Server handler 3 on default port 36479] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/69c31795-da41-43dd-a637-b3015d9175ea
2023-03-27 23:43:49,350 [IPC Server handler 3 on default port 36479] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 69c31795-da41-43dd-a637-b3015d9175ea{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=39507, RATIS=40539, RATIS_ADMIN=40539, RATIS_SERVER=40539, RATIS_DATASTREAM=34781, STANDALONE=40779], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:43:49,351 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:49,351 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=07dee5f9-4a37-447e-ae5a-39fcc8af315c to datanode:69c31795-da41-43dd-a637-b3015d9175ea
2023-03-27 23:43:49,351 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 07dee5f9-4a37-447e-ae5a-39fcc8af315c, Nodes: 69c31795-da41-43dd-a637-b3015d9175ea(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:49.351Z[Etc/UTC]].
2023-03-27 23:43:49,363 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-27 23:43:49,366 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-5e7befd8-40dc-428b-afd4-b407ef04b89a/container.db to cache
2023-03-27 23:43:49,366 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-5e7befd8-40dc-428b-afd4-b407ef04b89a/container.db for volume DS-5e7befd8-40dc-428b-afd4-b407ef04b89a
2023-03-27 23:43:49,367 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(397)) - Attempting to start container services.
2023-03-27 23:43:49,367 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(314)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-27 23:43:49,367 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 41399
2023-03-27 23:43:49,367 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:49,371 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: start RPC server
2023-03-27 23:43:49,372 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: GrpcService started, listening on 44901
2023-03-27 23:43:49,372 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 476d332c-e00b-4a08-bd5a-0b3284a7ea0c is started using port 44901 for RATIS
2023-03-27 23:43:49,372 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 476d332c-e00b-4a08-bd5a-0b3284a7ea0c is started using port 44901 for RATIS_ADMIN
2023-03-27 23:43:49,372 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 476d332c-e00b-4a08-bd5a-0b3284a7ea0c is started using port 44901 for RATIS_SERVER
2023-03-27 23:43:49,372 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 476d332c-e00b-4a08-bd5a-0b3284a7ea0c is started using port 33491 for RATIS_DATASTREAM
2023-03-27 23:43:49,372 [JvmPauseMonitor57] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-476d332c-e00b-4a08-bd5a-0b3284a7ea0c: Started
2023-03-27 23:43:49,372 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 476d332c-e00b-4a08-bd5a-0b3284a7ea0c is started using port 36519
2023-03-27 23:43:49,373 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:43:49,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:49,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,419 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-27 23:43:49,433 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,433 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,433 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,433 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,433 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962399434 and scm deadline 1679962429434
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962399434 and scm deadline 1679962429434
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962399434 and scm deadline 1679962429434
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962399434 and scm deadline 1679962429434
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962399434 and scm deadline 1679962429434
2023-03-27 23:43:49,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-03-27 23:43:49,472 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(83)) - A dead datanode is detected. ebbb6892-a89a-4074-adec-249bdede4c6b(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:49,472 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=66422011-1c0d-4681-8ef6-dce8a982e78b close command to datanode ebbb6892-a89a-4074-adec-249bdede4c6b
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 66422011-1c0d-4681-8ef6-dce8a982e78b, Nodes: ebbb6892-a89a-4074-adec-249bdede4c6b(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:ebbb6892-a89a-4074-adec-249bdede4c6b, CreationTimestamp2023-03-27T23:41:54.221Z[Etc/UTC]] removed.
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=c888fd41-72df-4b6a-837e-4aaa5b89608d close command to datanode 549101de-1cf2-4583-b7e6-903b03646e7c
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=c888fd41-72df-4b6a-837e-4aaa5b89608d close command to datanode 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=c888fd41-72df-4b6a-837e-4aaa5b89608d close command to datanode ebbb6892-a89a-4074-adec-249bdede4c6b
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: c888fd41-72df-4b6a-837e-4aaa5b89608d, Nodes: 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)ebbb6892-a89a-4074-adec-249bdede4c6b(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:ebbb6892-a89a-4074-adec-249bdede4c6b, CreationTimestamp2023-03-27T23:43:11.849Z[Etc/UTC]] removed.
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(96)) - Clearing command queue of size 2 for DN ebbb6892-a89a-4074-adec-249bdede4c6b(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/ebbb6892-a89a-4074-adec-249bdede4c6b
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(83)) - A dead datanode is detected. 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=3d1ae31f-ffee-4866-9493-ce70bd6f3331 close command to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=3d1ae31f-ffee-4866-9493-ce70bd6f3331 close command to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=3d1ae31f-ffee-4866-9493-ce70bd6f3331 close command to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 3d1ae31f-ffee-4866-9493-ce70bd6f3331, Nodes: 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:2fe3edb7-8e87-4db1-bb8e-5ae441beb787, CreationTimestamp2023-03-27T23:41:53.104Z[Etc/UTC]] removed.
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: b04b75f6-7f4f-41e0-a051-b79c09c49798, Nodes: 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: EC{rs-3-2-1024k}, State:CLOSED, leaderId:, CreationTimestamp2023-03-27T23:43:05.757Z[Etc/UTC]] removed.
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=e304f524-3200-488a-9b4c-6d53e1e11a88 close command to datanode 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf
2023-03-27 23:43:49,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: e304f524-3200-488a-9b4c-6d53e1e11a88, Nodes: 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:1bfcd852-ea3f-4c7a-9193-c23bc5754bdf, CreationTimestamp2023-03-27T23:41:52.739Z[Etc/UTC]] removed.
2023-03-27 23:43:49,474 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(96)) - Clearing command queue of size 19 for DN 1bfcd852-ea3f-4c7a-9193-c23bc5754bdf(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:49,474 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/1bfcd852-ea3f-4c7a-9193-c23bc5754bdf
2023-03-27 23:43:49,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:49,644 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 is not found
2023-03-27 23:43:49,654 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 49220674-b9b6-430a-b99a-f5474fac1494: remove  FOLLOWER 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725:t1, leader=2829ccc8-889f-48cc-a62b-b3954aa0680c, voted=2829ccc8-889f-48cc-a62b-b3954aa0680c, raftlog=Memoized:49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-SegmentedRaftLog:OPENED:c37, conf=0: peers:[49220674-b9b6-430a-b99a-f5474fac1494|rpc:10.1.0.32:45963|dataStream:10.1.0.32:32953|priority:0|startupRole:FOLLOWER, 3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-27 23:43:49,654 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725: shutdown
2023-03-27 23:43:49,654 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3BACC333D725,id=49220674-b9b6-430a-b99a-f5474fac1494
2023-03-27 23:43:49,654 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 49220674-b9b6-430a-b99a-f5474fac1494: shutdown 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-FollowerState
2023-03-27 23:43:49,654 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater: set stopIndex = 37
2023-03-27 23:43:49,654 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-FollowerState was interrupted
2023-03-27 23:43:49,655 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-3BACC333D725: Taking a snapshot at:(t:1, i:36) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-3/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_36
2023-03-27 23:43:49,656 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 3fee8600-457c-478d-8bf5-017cc394a56c: remove  FOLLOWER 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725:t1, leader=2829ccc8-889f-48cc-a62b-b3954aa0680c, voted=2829ccc8-889f-48cc-a62b-b3954aa0680c, raftlog=Memoized:3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-SegmentedRaftLog:OPENED:c37, conf=0: peers:[49220674-b9b6-430a-b99a-f5474fac1494|rpc:10.1.0.32:45963|dataStream:10.1.0.32:32953|priority:0|startupRole:FOLLOWER, 3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-27 23:43:49,656 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725: shutdown
2023-03-27 23:43:49,656 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-3BACC333D725: Finished taking a snapshot at:(t:1, i:36) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-3/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_36 took: 1 ms
2023-03-27 23:43:49,656 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3BACC333D725,id=3fee8600-457c-478d-8bf5-017cc394a56c
2023-03-27 23:43:49,656 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3fee8600-457c-478d-8bf5-017cc394a56c: shutdown 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-FollowerState
2023-03-27 23:43:49,656 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater: set stopIndex = 37
2023-03-27 23:43:49,656 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater: Took a snapshot at index 36
2023-03-27 23:43:49,656 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-FollowerState was interrupted
2023-03-27 23:43:49,656 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 36
2023-03-27 23:43:49,656 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-3BACC333D725: Taking a snapshot at:(t:1, i:36) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-3/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_36
2023-03-27 23:43:49,656 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-3BACC333D725: Taking a snapshot at:(t:1, i:36) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_36
2023-03-27 23:43:49,657 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-3BACC333D725: Finished taking a snapshot at:(t:1, i:36) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-3/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_36 took: 1 ms
2023-03-27 23:43:49,657 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater: Took a snapshot at index 36
2023-03-27 23:43:49,657 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-StateMachineUpdater: snapshotIndex: updateIncreasingly 36 -> 36
2023-03-27 23:43:49,657 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-3BACC333D725: Finished taking a snapshot at:(t:1, i:36) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_36 took: 0 ms
2023-03-27 23:43:49,658 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater: Took a snapshot at index 36
2023-03-27 23:43:49,658 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 36
2023-03-27 23:43:49,658 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-3BACC333D725: Taking a snapshot at:(t:1, i:36) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_36
2023-03-27 23:43:49,658 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725: closes. applyIndex: 36
2023-03-27 23:43:49,658 [49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:49,658 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725-SegmentedRaftLogWorker close()
2023-03-27 23:43:49,659 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-3BACC333D725: Finished taking a snapshot at:(t:1, i:36) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_36 took: 1 ms
2023-03-27 23:43:49,659 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater: Took a snapshot at index 36
2023-03-27 23:43:49,659 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-StateMachineUpdater: snapshotIndex: updateIncreasingly 36 -> 36
2023-03-27 23:43:49,660 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725: closes. applyIndex: 36
2023-03-27 23:43:49,660 [3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:49,660 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725-SegmentedRaftLogWorker close()
2023-03-27 23:43:49,672 [ContainerOp-7e260818-9050-4cf0-9395-3bacc333d725-8] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 26.
2023-03-27 23:43:49,672 [ContainerOp-7e260818-9050-4cf0-9395-3bacc333d725-8] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 26.
2023-03-27 23:43:49,673 [ContainerOp-7e260818-9050-4cf0-9395-3bacc333d725-8] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 1 is closed with bcsId 26.
2023-03-27 23:43:49,674 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(292)) - Moving container #1 to CLOSED state, datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) reported CLOSED replica.
2023-03-27 23:43:49,678 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 3fee8600-457c-478d-8bf5-017cc394a56c: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->3fee8600-457c-478d-8bf5-017cc394a56c#641-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:49,680 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 49220674-b9b6-430a-b99a-f5474fac1494: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->49220674-b9b6-430a-b99a-f5474fac1494#643-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:49,685 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:49,685 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:49,686 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:49,686 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:49,687 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 3fee8600-457c-478d-8bf5-017cc394a56c: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->3fee8600-457c-478d-8bf5-017cc394a56c#642-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:49,689 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 49220674-b9b6-430a-b99a-f5474fac1494: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->49220674-b9b6-430a-b99a-f5474fac1494#644-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:49,690 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:49,691 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:49,692 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:49,692 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:49,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 2 of 7 DN Heartbeats.
2023-03-27 23:43:49,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:49,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:49,709 [ContainerOp-7e260818-9050-4cf0-9395-3bacc333d725-8] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 26.
2023-03-27 23:43:49,709 [ContainerOp-7e260818-9050-4cf0-9395-3bacc333d725-8] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 26.
2023-03-27 23:43:49,709 [IPC Server handler 1 on default port 36479] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/117526ec-9427-41bf-9dbd-c8f743595c9c
2023-03-27 23:43:49,709 [IPC Server handler 1 on default port 36479] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 117526ec-9427-41bf-9dbd-c8f743595c9c{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=41381, RATIS=44893, RATIS_ADMIN=44893, RATIS_SERVER=44893, RATIS_DATASTREAM=33557, STANDALONE=39037], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:43:49,709 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:49,712 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-27 23:43:49,713 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-27 23:43:49,713 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-27 23:43:49,713 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-27 23:43:49,713 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:49,714 [ContainerOp-7e260818-9050-4cf0-9395-3bacc333d725-8] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 1 is closed with bcsId 26.
2023-03-27 23:43:49,714 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:49,715 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:49,717 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=c1cfb39d-45de-41c7-b94b-ab61cf327f9c to datanode:117526ec-9427-41bf-9dbd-c8f743595c9c
2023-03-27 23:43:49,717 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: c1cfb39d-45de-41c7-b94b-ab61cf327f9c, Nodes: 117526ec-9427-41bf-9dbd-c8f743595c9c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:49.717Z[Etc/UTC]].
2023-03-27 23:43:49,718 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=964b688c-b4b5-456b-baaf-e7a0b9c7dba1 to datanode:69c31795-da41-43dd-a637-b3015d9175ea
2023-03-27 23:43:49,718 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=964b688c-b4b5-456b-baaf-e7a0b9c7dba1 to datanode:117526ec-9427-41bf-9dbd-c8f743595c9c
2023-03-27 23:43:49,718 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=964b688c-b4b5-456b-baaf-e7a0b9c7dba1 to datanode:5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:49,718 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 964b688c-b4b5-456b-baaf-e7a0b9c7dba1, Nodes: 69c31795-da41-43dd-a637-b3015d9175ea(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)117526ec-9427-41bf-9dbd-c8f743595c9c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)5c7a3766-4df9-4a62-b680-fc04cc352416(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:49.718Z[Etc/UTC]].
2023-03-27 23:43:49,719 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0. Excluded 3.
2023-03-27 23:43:49,719 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0. Excluded 3.
2023-03-27 23:43:49,718 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:49,719 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:49,718 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #4 to QUASI_CLOSED state, datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) reported QUASI_CLOSED replica.
2023-03-27 23:43:49,721 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #6 to QUASI_CLOSED state, datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) reported QUASI_CLOSED replica.
2023-03-27 23:43:49,723 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-3BACC333D725: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725
2023-03-27 23:43:49,724 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 command on datanode 3fee8600-457c-478d-8bf5-017cc394a56c.
2023-03-27 23:43:49,741 [ContainerOp-7e260818-9050-4cf0-9395-3bacc333d725-8] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 26.
2023-03-27 23:43:49,741 [ContainerOp-7e260818-9050-4cf0-9395-3bacc333d725-8] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 26.
2023-03-27 23:43:49,742 [ContainerOp-7e260818-9050-4cf0-9395-3bacc333d725-8] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 1 is closed with bcsId 26.
2023-03-27 23:43:49,743 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:49,743 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:49,745 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:49,745 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:49,747 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-3BACC333D725: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-3/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725
2023-03-27 23:43:49,747 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 command on datanode 49220674-b9b6-430a-b99a-f5474fac1494.
2023-03-27 23:43:49,747 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 49220674-b9b6-430a-b99a-f5474fac1494: remove    LEADER 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33:t1, leader=49220674-b9b6-430a-b99a-f5474fac1494, voted=49220674-b9b6-430a-b99a-f5474fac1494, raftlog=Memoized:49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-SegmentedRaftLog:OPENED:c0, conf=0: peers:[49220674-b9b6-430a-b99a-f5474fac1494|rpc:10.1.0.32:45963|dataStream:10.1.0.32:32953|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-27 23:43:49,747 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33: shutdown
2023-03-27 23:43:49,747 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E918C3435C33,id=49220674-b9b6-430a-b99a-f5474fac1494
2023-03-27 23:43:49,747 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 49220674-b9b6-430a-b99a-f5474fac1494: shutdown 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-LeaderStateImpl
2023-03-27 23:43:49,748 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:49,748 [49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-E918C3435C33: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-3/data/ratis/49e77fc3-0a0a-47b0-8720-e918c3435c33/sm/snapshot.1_0
2023-03-27 23:43:49,748 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:49,749 [49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-E918C3435C33: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-3/data/ratis/49e77fc3-0a0a-47b0-8720-e918c3435c33/sm/snapshot.1_0 took: 1 ms
2023-03-27 23:43:49,749 [49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:49,749 [49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:49,749 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33: closes. applyIndex: 0
2023-03-27 23:43:49,749 [49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:49,750 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33-SegmentedRaftLogWorker close()
2023-03-27 23:43:49,750 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 49220674-b9b6-430a-b99a-f5474fac1494@group-E918C3435C33: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-3/data/ratis/49e77fc3-0a0a-47b0-8720-e918c3435c33
2023-03-27 23:43:49,750 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=49e77fc3-0a0a-47b0-8720-e918c3435c33 command on datanode 49220674-b9b6-430a-b99a-f5474fac1494.
2023-03-27 23:43:49,762 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-f09ca2a0-f971-4524-943e-c58b1caa77fd/container.db to cache
2023-03-27 23:43:49,762 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data-0/containers/hdds/c78ba74d-d893-4100-8e6e-4798e738ee0d/DS-f09ca2a0-f971-4524-943e-c58b1caa77fd/container.db for volume DS-f09ca2a0-f971-4524-943e-c58b1caa77fd
2023-03-27 23:43:49,762 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(397)) - Attempting to start container services.
2023-03-27 23:43:49,762 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(314)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-27 23:43:49,762 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 42481
2023-03-27 23:43:49,762 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 38de582e-58a6-400e-852c-9e1084927a05
2023-03-27 23:43:49,772 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 38de582e-58a6-400e-852c-9e1084927a05: start RPC server
2023-03-27 23:43:49,772 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 38de582e-58a6-400e-852c-9e1084927a05: GrpcService started, listening on 33063
2023-03-27 23:43:49,773 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 38de582e-58a6-400e-852c-9e1084927a05 is started using port 33063 for RATIS
2023-03-27 23:43:49,773 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 38de582e-58a6-400e-852c-9e1084927a05 is started using port 33063 for RATIS_ADMIN
2023-03-27 23:43:49,773 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 38de582e-58a6-400e-852c-9e1084927a05 is started using port 33063 for RATIS_SERVER
2023-03-27 23:43:49,773 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 38de582e-58a6-400e-852c-9e1084927a05 is started using port 40501 for RATIS_DATASTREAM
2023-03-27 23:43:49,773 [JvmPauseMonitor58] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-38de582e-58a6-400e-852c-9e1084927a05: Started
2023-03-27 23:43:49,773 [EndpointStateMachine task thread for /0.0.0.0:36479 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 38de582e-58a6-400e-852c-9e1084927a05 is started using port 44451
2023-03-27 23:43:49,774 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:43:49,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:49,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:49,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #4 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:49,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #4 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:49,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 1 sufficientlyReplicated, 2 underReplicated and 2 unhealthy containers
2023-03-27 23:43:49,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:49,976 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-6/data-0/containers/hdds/6e26070d-9fdb-4a65-9637-ae4e983202df/DS-dcb9e720-24ef-402e-9ca3-42cad452bc4f/container.db for volume DS-dcb9e720-24ef-402e-9ca3-42cad452bc4f
2023-03-27 23:43:49,977 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-27 23:43:49,985 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-27 23:43:49,985 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-27 23:43:49,996 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@756158b6{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:49,996 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@29c5639d{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:43:49,996 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:49,998 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2df944e6{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-27 23:43:50,005 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@179976f9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:43:50,008 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:43:50,008 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - afc9dc98-3375-40f1-a491-e988cc0b175c: close
2023-03-27 23:43:50,008 [afc9dc98-3375-40f1-a491-e988cc0b175c-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E: shutdown
2023-03-27 23:43:50,008 [afc9dc98-3375-40f1-a491-e988cc0b175c-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CB860B84100E,id=afc9dc98-3375-40f1-a491-e988cc0b175c
2023-03-27 23:43:50,008 [afc9dc98-3375-40f1-a491-e988cc0b175c-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - afc9dc98-3375-40f1-a491-e988cc0b175c: shutdown afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-LeaderStateImpl
2023-03-27 23:43:50,008 [afc9dc98-3375-40f1-a491-e988cc0b175c-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:50,009 [afc9dc98-3375-40f1-a491-e988cc0b175c-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:43:50,009 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - afc9dc98-3375-40f1-a491-e988cc0b175c: shutdown server GrpcServerProtocolService now
2023-03-27 23:43:50,009 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-CB860B84100E: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-5/data/ratis/6ea8ff4c-1d6e-498c-be21-cb860b84100e/sm/snapshot.1_0
2023-03-27 23:43:50,010 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - afc9dc98-3375-40f1-a491-e988cc0b175c: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:43:50,010 [afc9dc98-3375-40f1-a491-e988cc0b175c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd65dcb01, L:/0:0:0:0:0:0:0:0:42083] CLOSE
2023-03-27 23:43:50,010 [afc9dc98-3375-40f1-a491-e988cc0b175c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd65dcb01, L:/0:0:0:0:0:0:0:0:42083] INACTIVE
2023-03-27 23:43:50,010 [afc9dc98-3375-40f1-a491-e988cc0b175c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd65dcb01, L:/0:0:0:0:0:0:0:0:42083] UNREGISTERED
2023-03-27 23:43:50,010 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-CB860B84100E: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-5/data/ratis/6ea8ff4c-1d6e-498c-be21-cb860b84100e/sm/snapshot.1_0 took: 1 ms
2023-03-27 23:43:50,011 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:43:50,011 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:43:50,011 [afc9dc98-3375-40f1-a491-e988cc0b175c-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E: closes. applyIndex: 0
2023-03-27 23:43:50,011 [afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:50,011 [afc9dc98-3375-40f1-a491-e988cc0b175c-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - afc9dc98-3375-40f1-a491-e988cc0b175c@group-CB860B84100E-SegmentedRaftLogWorker close()
2023-03-27 23:43:50,016 [JvmPauseMonitor50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-afc9dc98-3375-40f1-a491-e988cc0b175c: Stopped
2023-03-27 23:43:50,020 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-0/data-0/containers/hdds/6e26070d-9fdb-4a65-9637-ae4e983202df/DS-8d78d835-e183-4b6a-b119-f759a0f0b408/container.db for volume DS-8d78d835-e183-4b6a-b119-f759a0f0b408
2023-03-27 23:43:50,020 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-27 23:43:50,020 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-27 23:43:50,021 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-27 23:43:50,029 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@63b04bbb{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:50,029 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3b3ea569{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:43:50,029 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:50,029 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5e50ee44{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-27 23:43:50,029 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@35e5d895{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:43:50,192 [IPC Server handler 3 on default port 36479] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6
2023-03-27 23:43:50,192 [IPC Server handler 3 on default port 36479] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=42877, RATIS=36455, RATIS_ADMIN=36455, RATIS_SERVER=36455, RATIS_DATASTREAM=45739, STANDALONE=45363], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:43:50,196 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:50,196 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=1d842bc1-3603-4066-a0a1-ecaf8ef23efd to datanode:4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6
2023-03-27 23:43:50,196 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 1d842bc1-3603-4066-a0a1-ecaf8ef23efd, Nodes: 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:50.196Z[Etc/UTC]].
2023-03-27 23:43:50,196 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1. Excluded 3.
2023-03-27 23:43:50,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:50,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1080)) - Force closing container #4 with BCSID 30, which is in QUASI_CLOSED state.
2023-03-27 23:43:50,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1080)) - Force closing container #6 with BCSID 34, which is in QUASI_CLOSED state.
2023-03-27 23:43:50,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,420 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:43:50,434 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-03-27 23:43:50,434 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=1, replicaIndex=0, sourceNodes=[afc9dc98-3375-40f1-a491-e988cc0b175c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)], priority=NORMAL to 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #4 is under replicated. Expected replica count is 3, but found 2.
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=4, replicaIndex=0, sourceNodes=[afc9dc98-3375-40f1-a491-e988cc0b175c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)], priority=NORMAL to 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #5 is under replicated. Expected replica count is 3, but found 2.
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=5, replicaIndex=0, sourceNodes=[afc9dc98-3375-40f1-a491-e988cc0b175c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)], priority=NORMAL to 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962400435 and scm deadline 1679962430435
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962400435 and scm deadline 1679962430435
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962400435 and scm deadline 1679962430435
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962400435 and scm deadline 1679962430435
2023-03-27 23:43:50,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-03-27 23:43:50,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:50,695 [IPC Server handler 0 on default port 36479] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3d5bec3e-3873-417f-9114-370ff3a7c03a
2023-03-27 23:43:50,696 [IPC Server handler 0 on default port 36479] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 3d5bec3e-3873-417f-9114-370ff3a7c03a{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=40011, RATIS=37315, RATIS_ADMIN=37315, RATIS_SERVER=37315, RATIS_DATASTREAM=39907, STANDALONE=46793], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:43:50,696 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:50,696 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1 to datanode:3d5bec3e-3873-417f-9114-370ff3a7c03a
2023-03-27 23:43:50,696 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1, Nodes: 3d5bec3e-3873-417f-9114-370ff3a7c03a(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:50.696Z[Etc/UTC]].
2023-03-27 23:43:50,696 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2. Excluded 3.
2023-03-27 23:43:50,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 5 of 7 DN Heartbeats.
2023-03-27 23:43:50,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:50,702 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:50,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:50,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:50,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #4 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:50,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #4 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:50,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 1 sufficientlyReplicated, 2 underReplicated and 2 unhealthy containers
2023-03-27 23:43:50,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:50,979 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) moved to stale state. Finalizing its pipelines [PipelineID=616f38e7-5b90-485b-b681-f644ed0ead47]
2023-03-27 23:43:50,979 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 616f38e7-5b90-485b-b681-f644ed0ead47, Nodes: 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:2fe3edb7-8e87-4db1-bb8e-5ae441beb787, CreationTimestamp2023-03-27T23:41:52.122Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:50,979 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) moved to stale state. Finalizing its pipelines [PipelineID=31ed04c6-2ac2-4da5-bd63-dc66810dbe49]
2023-03-27 23:43:50,979 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 31ed04c6-2ac2-4da5-bd63-dc66810dbe49, Nodes: 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:549101de-1cf2-4583-b7e6-903b03646e7c, CreationTimestamp2023-03-27T23:41:55.091Z[Etc/UTC]] moved to CLOSED state
2023-03-27 23:43:51,325 [IPC Server handler 7 on default port 36479] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:51,325 [IPC Server handler 7 on default port 36479] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 476d332c-e00b-4a08-bd5a-0b3284a7ea0c{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=41399, RATIS=44901, RATIS_ADMIN=44901, RATIS_SERVER=44901, RATIS_DATASTREAM=33491, STANDALONE=36519], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:43:51,325 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:51,328 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e to datanode:476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:51,328 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e, Nodes: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:51.328Z[Etc/UTC]].
2023-03-27 23:43:51,328 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=b5657b85-1b7c-4d62-99bb-5beef9ef3108 to datanode:4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6
2023-03-27 23:43:51,328 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=b5657b85-1b7c-4d62-99bb-5beef9ef3108 to datanode:3d5bec3e-3873-417f-9114-370ff3a7c03a
2023-03-27 23:43:51,328 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=b5657b85-1b7c-4d62-99bb-5beef9ef3108 to datanode:476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:51,329 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: b5657b85-1b7c-4d62-99bb-5beef9ef3108, Nodes: 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)3d5bec3e-3873-417f-9114-370ff3a7c03a(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)476d332c-e00b-4a08-bd5a-0b3284a7ea0c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:51.328Z[Etc/UTC]].
2023-03-27 23:43:51,329 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0. Excluded 6.
2023-03-27 23:43:51,405 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(329)) - Cannot proceed for EC container reconstruction for #7, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 0. Available sources are: {}
2023-03-27 23:43:51,405 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndSendCommands(212)) - Container #7 is under replicated, but no commands were created to correct it
2023-03-27 23:43:51,405 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(329)) - Cannot proceed for EC container reconstruction for #8, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 0. Available sources are: {}
2023-03-27 23:43:51,405 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndSendCommands(212)) - Container #8 is under replicated, but no commands were created to correct it
2023-03-27 23:43:51,406 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(329)) - Cannot proceed for EC container reconstruction for #9, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {2=(ContainerReplica{containerID=#9, state=CLOSED, datanodeDetails=afc9dc98-3375-40f1-a491-e988cc0b175c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=afc9dc98-3375-40f1-a491-e988cc0b175c, sequenceId=0, keyCount=4, bytesUsed=0,replicaIndex=2},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-03-27 23:43:51,406 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndSendCommands(212)) - Container #9 is under replicated, but no commands were created to correct it
2023-03-27 23:43:51,406 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(110)) - Processed 3 containers with health state counts {UNDER_REPLICATED=3}, failed processing 0
2023-03-27 23:43:51,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:51,421 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1080)) - Force closing container #4 with BCSID 30, which is in QUASI_CLOSED state.
2023-03-27 23:43:51,421 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,421 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,421 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1080)) - Force closing container #6 with BCSID 34, which is in QUASI_CLOSED state.
2023-03-27 23:43:51,421 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,421 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-27 23:43:51,436 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-27 23:43:51,436 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:367)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:875)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:51,436 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,436 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,436 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,436 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,436 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-27 23:43:51,436 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:367)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:875)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:51,436 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-27 23:43:51,437 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:367)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:875)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:51,437 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,437 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:51,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962401439 and scm deadline 1679962431439
2023-03-27 23:43:51,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 2fe3edb7-8e87-4db1-bb8e-5ae441beb787(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962401440 and scm deadline 1679962431440
2023-03-27 23:43:51,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962401440 and scm deadline 1679962431440
2023-03-27 23:43:51,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(626)) - Sending command [closeContainerCommand: containerID: 11, pipelineID: PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, force: true] for container ContainerInfo{id=#11, state=CLOSING, pipelineID=PipelineID=b04b75f6-7f4f-41e0-a051-b79c09c49798, stateEnterTime=2023-03-27T23:43:05.758Z, owner=om1} to 549101de-1cf2-4583-b7e6-903b03646e7c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) with datanode deadline 1679962401440 and scm deadline 1679962431440
2023-03-27 23:43:51,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 4 milliseconds for processing 11 containers.
2023-03-27 23:43:51,479 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(83)) - A dead datanode is detected. 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:51,479 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=ebc7c1df-c892-4dfc-a821-0af437366e3e close command to datanode 02b664bf-3432-424d-aeb2-fd50259d9f48
2023-03-27 23:43:51,479 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: ebc7c1df-c892-4dfc-a821-0af437366e3e, Nodes: 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:02b664bf-3432-424d-aeb2-fd50259d9f48, CreationTimestamp2023-03-27T23:41:53.103Z[Etc/UTC]] removed.
2023-03-27 23:43:51,480 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(96)) - Clearing command queue of size 26 for DN 02b664bf-3432-424d-aeb2-fd50259d9f48(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:51,480 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/02b664bf-3432-424d-aeb2-fd50259d9f48
2023-03-27 23:43:51,480 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(83)) - A dead datanode is detected. 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:51,480 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=6d183de4-1aaf-4fde-a665-bf8815fb6aa8 close command to datanode 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915
2023-03-27 23:43:51,480 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 6d183de4-1aaf-4fde-a665-bf8815fb6aa8, Nodes: 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:6bc3ba6a-9ae7-448c-8b94-c4229f9fc915, CreationTimestamp2023-03-27T23:41:53.821Z[Etc/UTC]] removed.
2023-03-27 23:43:51,480 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(96)) - Clearing command queue of size 7 for DN 6bc3ba6a-9ae7-448c-8b94-c4229f9fc915(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:43:51,480 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/6bc3ba6a-9ae7-448c-8b94-c4229f9fc915
2023-03-27 23:43:51,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:51,677 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 is not found
2023-03-27 23:43:51,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 6 of 7 DN Heartbeats.
2023-03-27 23:43:51,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:51,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:51,711 [IPC Server handler 3 on default port 36479] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/38de582e-58a6-400e-852c-9e1084927a05
2023-03-27 23:43:51,711 [IPC Server handler 3 on default port 36479] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 38de582e-58a6-400e-852c-9e1084927a05{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=42481, RATIS=33063, RATIS_ADMIN=33063, RATIS_SERVER=33063, RATIS_DATASTREAM=40501, STANDALONE=44451], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:43:51,711 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:51,712 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=4e1a23bf-fbb6-4c74-99b8-b3fc760a9277 to datanode:38de582e-58a6-400e-852c-9e1084927a05
2023-03-27 23:43:51,712 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 4e1a23bf-fbb6-4c74-99b8-b3fc760a9277, Nodes: 38de582e-58a6-400e-852c-9e1084927a05(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:51.712Z[Etc/UTC]].
2023-03-27 23:43:51,712 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1. Excluded 6.
2023-03-27 23:43:51,739 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:51,739 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:51,741 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 4 is closed with bcsId 30.
2023-03-27 23:43:51,741 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:51,741 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:51,742 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #4 to CLOSED state, datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) reported CLOSED replica.
2023-03-27 23:43:51,743 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 6 is closed with bcsId 34.
2023-03-27 23:43:51,743 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #6 to CLOSED state, datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) reported CLOSED replica.
2023-03-27 23:43:51,783 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:51,783 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:51,784 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 4 is closed with bcsId 30.
2023-03-27 23:43:51,785 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:51,785 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:51,786 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 6 is closed with bcsId 34.
2023-03-27 23:43:51,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:51,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:51,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:51,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:51,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 1 sufficientlyReplicated, 2 underReplicated and 2 unhealthy containers
2023-03-27 23:43:51,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:52,011 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: addNew group-DA2952889F03:[5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER] returns group-DA2952889F03:java.util.concurrent.CompletableFuture@37394f9f[Not completed]
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: new RaftServerImpl for group-DA2952889F03:[5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03: ConfigurationManager, init=-1: peers:[5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis] (custom)
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:52,012 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:52,013 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:52,013 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:52,013 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:52,014 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:52,014 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:52,014 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:52,014 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:52,014 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:52,014 [pool-2444-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/4ad1ff11-ec4e-4398-8b83-da2952889f03 does not exist. Creating ...
2023-03-27 23:43:52,016 [pool-2444-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/4ad1ff11-ec4e-4398-8b83-da2952889f03/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:52,017 [pool-2444-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/4ad1ff11-ec4e-4398-8b83-da2952889f03 has been successfully formatted.
2023-03-27 23:43:52,017 [pool-2444-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-DA2952889F03: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:52,017 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:52,017 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:52,017 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,017 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:52,018 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:52,018 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 4ad1ff11-ec4e-4398-8b83-da2952889f03, Nodes: 5c7a3766-4df9-4a62-b680-fc04cc352416(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:5c7a3766-4df9-4a62-b680-fc04cc352416, CreationTimestamp2023-03-27T23:43:49.018Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:52,018 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/4ad1ff11-ec4e-4398-8b83-da2952889f03
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:52,019 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:52,023 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:52,024 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,026 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:52,027 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:52,027 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:52,029 [pool-2444-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,029 [pool-2444-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,030 [pool-2444-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03: start as a follower, conf=-1: peers:[5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:52,030 [pool-2444-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:52,030 [pool-2444-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: start 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState
2023-03-27 23:43:52,033 [pool-2444-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DA2952889F03,id=5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:52,033 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:52,034 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:52,034 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:52,034 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:52,040 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:52,040 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=4ad1ff11-ec4e-4398-8b83-da2952889f03
2023-03-27 23:43:52,040 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=4ad1ff11-ec4e-4398-8b83-da2952889f03.
2023-03-27 23:43:52,040 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: addNew group-E7A0B9C7DBA1:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER] returns group-E7A0B9C7DBA1:java.util.concurrent.CompletableFuture@3306cda0[Not completed]
2023-03-27 23:43:52,040 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:52,040 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: new RaftServerImpl for group-E7A0B9C7DBA1:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1: ConfigurationManager, init=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis] (custom)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:52,041 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:52,044 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:52,044 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:52,044 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:52,044 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:52,045 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:52,045 [pool-2444-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1 does not exist. Creating ...
2023-03-27 23:43:52,047 [pool-2444-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:52,047 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6e26070d-9fdb-4a65-9637-ae4e983202df/datanode-5/data-0/containers/hdds/6e26070d-9fdb-4a65-9637-ae4e983202df/DS-a8dfd49e-10ab-4875-9724-69d26cf53f39/container.db for volume DS-a8dfd49e-10ab-4875-9724-69d26cf53f39
2023-03-27 23:43:52,049 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-27 23:43:52,050 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-27 23:43:52,050 [pool-2444-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1 has been successfully formatted.
2023-03-27 23:43:52,050 [pool-2444-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-E7A0B9C7DBA1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:52,050 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:52,050 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:52,050 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,050 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:52,050 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:52,051 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:52,052 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:52,053 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,054 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:52,061 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-27 23:43:52,066 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:52,066 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:52,066 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:52,066 [pool-2444-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,066 [pool-2444-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,073 [pool-2444-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1: start as a follower, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:52,073 [pool-2444-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:52,073 [pool-2444-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: start 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:52,073 [pool-2444-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E7A0B9C7DBA1,id=5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:52,073 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:52,073 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:52,073 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:52,073 [pool-2444-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:52,074 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:52,074 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:52,074 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=964b688c-b4b5-456b-baaf-e7a0b9c7dba1
2023-03-27 23:43:52,078 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3b18009f{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:43:52,081 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6a30f6b1{HTTP/1.1, (http/1.1)}{0.0.0.0:44353}
2023-03-27 23:43:52,081 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:52,086 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 69c31795-da41-43dd-a637-b3015d9175ea: addNew group-E7A0B9C7DBA1:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER] returns group-E7A0B9C7DBA1:java.util.concurrent.CompletableFuture@404cb234[Not completed]
2023-03-27 23:43:52,095 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@f245168{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-27 23:43:52,096 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@707b38a1{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:43:52,097 [pool-2466-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 69c31795-da41-43dd-a637-b3015d9175ea: new RaftServerImpl for group-E7A0B9C7DBA1:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:52,097 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:52,097 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:52,097 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:52,097 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:52,097 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:52,097 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:52,097 [pool-2466-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: ConfigurationManager, init=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:52,097 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis] (custom)
2023-03-27 23:43:52,098 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:52,098 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:52,098 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:52,098 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:52,098 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:52,099 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:52,099 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:52,099 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:52,099 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:52,099 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:52,099 [pool-2466-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1 does not exist. Creating ...
2023-03-27 23:43:52,101 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(545)) - Stopping the StorageContainerManager
2023-03-27 23:43:52,101 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1546)) - Container Balancer is not running.
2023-03-27 23:43:52,101 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1660)) - Stopping Replication Manager Service.
2023-03-27 23:43:52,101 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(310)) - Stopping Replication Monitor Thread.
2023-03-27 23:43:52,101 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Over Replicated Processor interrupted. Exiting...
2023-03-27 23:43:52,101 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Under Replicated Processor interrupted. Exiting...
2023-03-27 23:43:52,104 [pool-2466-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:52,104 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1555)) - Stopping the Datanode Admin Monitor.
2023-03-27 23:43:52,104 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1562)) - Stopping datanode service RPC server
2023-03-27 23:43:52,104 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-03-27 23:43:52,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(880)) - Replication Monitor Thread is stopped
2023-03-27 23:43:52,107 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42409
2023-03-27 23:43:52,108 [pool-2466-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1 has been successfully formatted.
2023-03-27 23:43:52,111 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-27 23:43:52,112 [pool-2466-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-E7A0B9C7DBA1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:52,112 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:52,113 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,114 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:52,114 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:52,114 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:52,114 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:52,114 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:52,115 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:52,115 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,118 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:43:52,119 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:52,120 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:52,120 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:52,120 [pool-2466-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,120 [pool-2466-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,122 [pool-2466-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: start as a follower, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:52,122 [pool-2466-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:52,122 [pool-2466-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 69c31795-da41-43dd-a637-b3015d9175ea: start 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:52,126 [pool-2466-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E7A0B9C7DBA1,id=69c31795-da41-43dd-a637-b3015d9175ea
2023-03-27 23:43:52,126 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:52,126 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:52,126 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:52,126 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:52,138 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:52,138 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:52,151 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: addNew group-E7A0B9C7DBA1:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER] returns group-E7A0B9C7DBA1:java.util.concurrent.CompletableFuture@52414a2a[Not completed]
2023-03-27 23:43:52,158 [pool-2488-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: new RaftServerImpl for group-E7A0B9C7DBA1:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:52,158 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:52,161 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:52,161 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:52,161 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:52,161 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:52,161 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:52,161 [pool-2488-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1: ConfigurationManager, init=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:52,162 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis] (custom)
2023-03-27 23:43:52,162 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:52,162 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:52,162 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:52,162 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:52,162 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:52,163 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 49220674-b9b6-430a-b99a-f5474fac1494: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->49220674-b9b6-430a-b99a-f5474fac1494#646-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:52,163 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:52,163 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:52,163 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:52,163 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:52,163 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:52,164 [pool-2488-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1 does not exist. Creating ...
2023-03-27 23:43:52,165 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:52,165 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:52,166 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 3fee8600-457c-478d-8bf5-017cc394a56c: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->3fee8600-457c-478d-8bf5-017cc394a56c#644-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:52,175 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:52,176 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:52,176 [pool-2488-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:52,177 [pool-2488-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1 has been successfully formatted.
2023-03-27 23:43:52,178 [pool-2488-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-E7A0B9C7DBA1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:52,178 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:52,178 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:52,178 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,178 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:52,178 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:52,179 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,180 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:52,180 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:52,181 [pool-2488-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1
2023-03-27 23:43:52,181 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:52,181 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:52,181 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,181 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:52,181 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:52,181 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:52,181 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:52,181 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:52,181 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-03-27 23:43:52,182 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1570)) - Stopping block service RPC server
2023-03-27 23:43:52,182 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-03-27 23:43:52,184 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 45991
2023-03-27 23:43:52,187 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:52,188 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,193 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:52,196 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:43:52,196 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1577)) - Stopping the StorageContainerLocationProtocol RPC server
2023-03-27 23:43:52,197 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(206)) - Stopping the RPC server for Client Protocol
2023-03-27 23:43:52,196 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-27 23:43:52,197 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:52,200 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 46497
2023-03-27 23:43:52,202 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:52,202 [pool-2488-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,209 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-27 23:43:52,209 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1584)) - Stopping Storage Container Manager HTTP server.
2023-03-27 23:43:52,209 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:43:52,209 [pool-2488-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,212 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4bffecc6{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-27 23:43:52,213 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@70295a56{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:43:52,213 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:52,217 [pool-2488-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1: start as a follower, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:52,217 [pool-2488-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:52,217 [pool-2488-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: start 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:52,217 [pool-2488-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E7A0B9C7DBA1,id=117526ec-9427-41bf-9dbd-c8f743595c9c
2023-03-27 23:43:52,217 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@32d7389a{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-27 23:43:52,217 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@36eabb10{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:43:52,217 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:52,218 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:52,218 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:52,218 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:52,218 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1592)) - Stopping SCM LayoutVersionManager Service.
2023-03-27 23:43:52,219 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1600)) - Stopping Block Manager Service.
2023-03-27 23:43:52,219 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:52,219 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-27 23:43:52,219 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:52,219 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-27 23:43:52,220 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1622)) - Stopping SCM Event Queue.
2023-03-27 23:43:52,221 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1633)) - Stopping SCM HA services.
2023-03-27 23:43:52,221 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-03-27 23:43:52,221 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-03-27 23:43:52,223 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-03-27 23:43:52,223 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-03-27 23:43:52,223 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2023-03-27 23:43:52,226 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-03-27 23:43:52,232 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2023-03-27 23:43:52,232 [Mini-Cluster-Provider-Reap] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-03-27 23:43:52,232 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-03-27 23:43:52,232 [Mini-Cluster-Provider-Reap] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-03-27 23:43:52,232 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-27 23:43:52,232 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-03-27 23:43:52,232 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(320)) - Replication Monitor Thread is not running.
2023-03-27 23:43:52,232 [Mini-Cluster-Provider-Reap] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(324)) - Cannot stop Container Balancer because it's not running or stopping
2023-03-27 23:43:52,233 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1651)) - Stopping SCM MetadataStore.
2023-03-27 23:43:52,239 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=964b688c-b4b5-456b-baaf-e7a0b9c7dba1.
2023-03-27 23:43:52,342 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 69c31795-da41-43dd-a637-b3015d9175ea: addNew group-39FCC8AF315C:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:1|startupRole:FOLLOWER] returns group-39FCC8AF315C:java.util.concurrent.CompletableFuture@2f4d9879[Not completed]
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 69c31795-da41-43dd-a637-b3015d9175ea: new RaftServerImpl for group-39FCC8AF315C:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C: ConfigurationManager, init=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis] (custom)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:52,343 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:52,345 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:52,345 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:52,345 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:52,345 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:52,345 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:52,345 [pool-2466-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/07dee5f9-4a37-447e-ae5a-39fcc8af315c does not exist. Creating ...
2023-03-27 23:43:52,348 [pool-2466-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/07dee5f9-4a37-447e-ae5a-39fcc8af315c/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:52,349 [pool-2466-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/07dee5f9-4a37-447e-ae5a-39fcc8af315c has been successfully formatted.
2023-03-27 23:43:52,349 [pool-2466-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-39FCC8AF315C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:52,349 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:52,349 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:52,349 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,349 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:52,350 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:52,350 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 07dee5f9-4a37-447e-ae5a-39fcc8af315c, Nodes: 69c31795-da41-43dd-a637-b3015d9175ea(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:69c31795-da41-43dd-a637-b3015d9175ea, CreationTimestamp2023-03-27T23:43:49.351Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:52,350 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/07dee5f9-4a37-447e-ae5a-39fcc8af315c
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:52,351 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:52,352 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:52,353 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,356 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:52,356 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:52,356 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:52,356 [pool-2466-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,357 [pool-2466-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,357 [pool-2466-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C: start as a follower, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:52,357 [pool-2466-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:52,357 [pool-2466-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 69c31795-da41-43dd-a637-b3015d9175ea: start 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState
2023-03-27 23:43:52,357 [pool-2466-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-39FCC8AF315C,id=69c31795-da41-43dd-a637-b3015d9175ea
2023-03-27 23:43:52,357 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:52,357 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:52,357 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:52,357 [pool-2466-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:52,358 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=07dee5f9-4a37-447e-ae5a-39fcc8af315c
2023-03-27 23:43:52,358 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=07dee5f9-4a37-447e-ae5a-39fcc8af315c.
2023-03-27 23:43:52,358 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:52,358 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:52,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:52,421 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:52,421 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:52,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:43:52,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:52,678 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 is not found
2023-03-27 23:43:52,709 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: addNew group-AB61CF327F9C:[117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:1|startupRole:FOLLOWER] returns group-AB61CF327F9C:java.util.concurrent.CompletableFuture@4504bebb[Not completed]
2023-03-27 23:43:52,710 [pool-2488-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: new RaftServerImpl for group-AB61CF327F9C:[117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:52,710 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:52,710 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:52,710 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:52,710 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:52,710 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:52,710 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:52,710 [pool-2488-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C: ConfigurationManager, init=-1: peers:[117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:52,710 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis] (custom)
2023-03-27 23:43:52,711 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:52,711 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:52,711 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:52,711 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:52,711 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:52,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-27 23:43:52,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:52,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:52,712 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:52,712 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:52,712 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:52,712 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:52,712 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:52,712 [pool-2488-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/c1cfb39d-45de-41c7-b94b-ab61cf327f9c does not exist. Creating ...
2023-03-27 23:43:52,713 [pool-2488-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/c1cfb39d-45de-41c7-b94b-ab61cf327f9c/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:52,714 [pool-2488-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/c1cfb39d-45de-41c7-b94b-ab61cf327f9c has been successfully formatted.
2023-03-27 23:43:52,714 [pool-2488-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-AB61CF327F9C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:52,715 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:52,715 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:52,715 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,715 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: c1cfb39d-45de-41c7-b94b-ab61cf327f9c, Nodes: 117526ec-9427-41bf-9dbd-c8f743595c9c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:117526ec-9427-41bf-9dbd-c8f743595c9c, CreationTimestamp2023-03-27T23:43:49.717Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:52,715 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:52,715 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:52,716 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/c1cfb39d-45de-41c7-b94b-ab61cf327f9c
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:52,716 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:52,717 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:52,718 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:52,720 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:52,720 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:52,720 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:52,720 [pool-2488-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,720 [pool-2488-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:52,721 [pool-2488-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C: start as a follower, conf=-1: peers:[117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:52,721 [pool-2488-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:52,721 [pool-2488-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: start 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState
2023-03-27 23:43:52,721 [pool-2488-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AB61CF327F9C,id=117526ec-9427-41bf-9dbd-c8f743595c9c
2023-03-27 23:43:52,721 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:52,721 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:52,721 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:52,721 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:52,721 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:52,721 [pool-2488-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:52,722 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=c1cfb39d-45de-41c7-b94b-ab61cf327f9c
2023-03-27 23:43:52,722 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=c1cfb39d-45de-41c7-b94b-ab61cf327f9c.
2023-03-27 23:43:52,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:52,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:52,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:52,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:52,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 1 sufficientlyReplicated, 2 underReplicated and 2 unhealthy containers
2023-03-27 23:43:52,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:53,193 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: addNew group-ECAF8EF23EFD:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:1|startupRole:FOLLOWER] returns group-ECAF8EF23EFD:java.util.concurrent.CompletableFuture@20b733ea[Not completed]
2023-03-27 23:43:53,193 [pool-2510-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: new RaftServerImpl for group-ECAF8EF23EFD:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:53,193 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD: ConfigurationManager, init=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis] (custom)
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:53,194 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:53,195 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:53,195 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:53,196 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:53,196 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:53,196 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:53,196 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:53,196 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:53,196 [pool-2510-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/1d842bc1-3603-4066-a0a1-ecaf8ef23efd does not exist. Creating ...
2023-03-27 23:43:53,198 [pool-2510-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/1d842bc1-3603-4066-a0a1-ecaf8ef23efd/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:53,199 [pool-2510-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/1d842bc1-3603-4066-a0a1-ecaf8ef23efd has been successfully formatted.
2023-03-27 23:43:53,199 [pool-2510-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-ECAF8EF23EFD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:53,199 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:53,199 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:53,200 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 1d842bc1-3603-4066-a0a1-ecaf8ef23efd, Nodes: 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6, CreationTimestamp2023-03-27T23:43:50.196Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:53,200 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,200 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:53,200 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:53,200 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:53,200 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,200 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:53,200 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:53,201 [pool-2510-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/1d842bc1-3603-4066-a0a1-ecaf8ef23efd
2023-03-27 23:43:53,201 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:53,201 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:53,201 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,201 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:53,201 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:53,201 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:53,201 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:53,201 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:53,202 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:53,202 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD: start as a follower, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: start 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ECAF8EF23EFD,id=4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6
2023-03-27 23:43:53,205 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:53,205 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:53,205 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:53,247 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=1d842bc1-3603-4066-a0a1-ecaf8ef23efd
2023-03-27 23:43:53,247 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=1d842bc1-3603-4066-a0a1-ecaf8ef23efd.
2023-03-27 23:43:53,247 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: addNew group-5BEEF9EF3108:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER] returns group-5BEEF9EF3108:java.util.concurrent.CompletableFuture@2488b324[Not completed]
2023-03-27 23:43:53,247 [pool-2510-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: new RaftServerImpl for group-5BEEF9EF3108:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108: ConfigurationManager, init=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis] (custom)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:53,248 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:53,249 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:53,249 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:53,249 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:53,249 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:53,249 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:53,249 [pool-2510-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108 does not exist. Creating ...
2023-03-27 23:43:53,252 [pool-2510-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:53,254 [pool-2510-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108 has been successfully formatted.
2023-03-27 23:43:53,254 [pool-2510-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-5BEEF9EF3108: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:53,254 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:53,254 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:53,254 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:53,255 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,255 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:53,255 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:53,255 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,255 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:53,255 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:53,255 [pool-2510-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108
2023-03-27 23:43:53,256 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:53,256 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:53,256 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,256 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:53,256 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:53,256 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:53,256 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:53,256 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:53,257 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:53,257 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,260 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:53,260 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:53,260 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108: start as a follower, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: start 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5BEEF9EF3108,id=4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:53,261 [pool-2510-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:53,262 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=b5657b85-1b7c-4d62-99bb-5beef9ef3108
2023-03-27 23:43:53,267 [grpc-default-executor-6] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: addNew group-5BEEF9EF3108:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER] returns group-5BEEF9EF3108:java.util.concurrent.CompletableFuture@3e84d3cb[Not completed]
2023-03-27 23:43:53,267 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:53,267 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:53,267 [pool-2532-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: new RaftServerImpl for group-5BEEF9EF3108:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:53,267 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:53,267 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:53,267 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:53,267 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:53,268 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:53,268 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:53,268 [pool-2532-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: ConfigurationManager, init=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:53,268 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis] (custom)
2023-03-27 23:43:53,268 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:53,268 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:53,268 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:53,268 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:53,268 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:53,269 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:53,269 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:53,269 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:53,269 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:53,269 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:53,269 [pool-2532-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108 does not exist. Creating ...
2023-03-27 23:43:53,271 [pool-2532-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:53,272 [pool-2532-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108 has been successfully formatted.
2023-03-27 23:43:53,272 [pool-2532-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-5BEEF9EF3108: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:53,272 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:53,272 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,273 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:53,274 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:53,274 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:53,274 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:53,274 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:53,275 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:53,275 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,278 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:53,278 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:53,278 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:53,278 [pool-2532-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,278 [pool-2532-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,279 [pool-2532-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: start as a follower, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:53,279 [pool-2532-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:53,279 [pool-2532-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: start 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:53,279 [pool-2532-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5BEEF9EF3108,id=3d5bec3e-3873-417f-9114-370ff3a7c03a
2023-03-27 23:43:53,279 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:53,279 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:53,279 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:53,279 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:53,279 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:53,279 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:53,288 [grpc-default-executor-6] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: addNew group-5BEEF9EF3108:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER] returns group-5BEEF9EF3108:java.util.concurrent.CompletableFuture@21a298df[Not completed]
2023-03-27 23:43:53,289 [pool-2591-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: new RaftServerImpl for group-5BEEF9EF3108:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:53,289 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:53,289 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:53,289 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:53,289 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:53,289 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:53,289 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:53,289 [pool-2591-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108: ConfigurationManager, init=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:53,289 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis] (custom)
2023-03-27 23:43:53,290 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:53,290 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:53,290 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:53,290 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:53,290 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:53,291 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:53,291 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:53,291 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:53,291 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:53,291 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:53,291 [pool-2591-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108 does not exist. Creating ...
2023-03-27 23:43:53,292 [pool-2591-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:53,293 [pool-2591-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108 has been successfully formatted.
2023-03-27 23:43:53,293 [pool-2591-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-5BEEF9EF3108: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:53,293 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:53,293 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:53,294 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,294 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:53,294 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:53,294 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,294 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:53,294 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:53,294 [pool-2591-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108
2023-03-27 23:43:53,295 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:53,295 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:53,295 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,295 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:53,295 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:53,295 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:53,295 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:53,295 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:53,296 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:53,297 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,300 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:53,300 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:53,300 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:53,300 [pool-2591-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,300 [pool-2591-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,300 [pool-2591-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108: start as a follower, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:53,300 [pool-2591-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:53,300 [pool-2591-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: start 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:53,301 [pool-2591-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5BEEF9EF3108,id=476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:53,301 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:53,301 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:53,301 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:53,301 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:53,301 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:53,301 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:53,310 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=b5657b85-1b7c-4d62-99bb-5beef9ef3108.
2023-03-27 23:43:53,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:53,413 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 49220674-b9b6-430a-b99a-f5474fac1494: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->49220674-b9b6-430a-b99a-f5474fac1494#648-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:53,415 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 3fee8600-457c-478d-8bf5-017cc394a56c: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->3fee8600-457c-478d-8bf5-017cc394a56c#646-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:53,415 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:53,416 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:53,418 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:53,418 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:53,422 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:53,422 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:53,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:43:53,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:53,677 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 is not found
2023-03-27 23:43:53,692 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: addNew group-1C7C2F9DC6C1:[3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:1|startupRole:FOLLOWER] returns group-1C7C2F9DC6C1:java.util.concurrent.CompletableFuture@3c5335fa[Not completed]
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: new RaftServerImpl for group-1C7C2F9DC6C1:[3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1: ConfigurationManager, init=-1: peers:[3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis] (custom)
2023-03-27 23:43:53,693 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:53,694 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:53,694 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:53,694 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:53,694 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:53,695 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:53,695 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:53,695 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:53,695 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:53,695 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:53,695 [pool-2532-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1 does not exist. Creating ...
2023-03-27 23:43:53,696 [pool-2532-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:53,698 [pool-2532-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1 has been successfully formatted.
2023-03-27 23:43:53,698 [pool-2532-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-1C7C2F9DC6C1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:53,698 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:53,698 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:53,698 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1, Nodes: 3d5bec3e-3873-417f-9114-370ff3a7c03a(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3d5bec3e-3873-417f-9114-370ff3a7c03a, CreationTimestamp2023-03-27T23:43:50.696Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:53,698 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,699 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:53,699 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:53,699 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:53,699 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,699 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:53,699 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:53,699 [pool-2532-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1
2023-03-27 23:43:53,699 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:53,699 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:53,700 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:53,700 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:53,700 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:53,700 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:53,700 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:53,700 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:53,701 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:53,701 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:53,704 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:53,704 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:53,704 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:53,704 [pool-2532-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,704 [pool-2532-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:53,705 [pool-2532-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1: start as a follower, conf=-1: peers:[3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:53,705 [pool-2532-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:53,705 [pool-2532-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: start 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState
2023-03-27 23:43:53,705 [pool-2532-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1C7C2F9DC6C1,id=3d5bec3e-3873-417f-9114-370ff3a7c03a
2023-03-27 23:43:53,705 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:53,705 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:53,705 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:53,705 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:53,705 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:53,705 [pool-2532-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:53,706 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1
2023-03-27 23:43:53,706 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1.
2023-03-27 23:43:53,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-27 23:43:53,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:53,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:53,716 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:53,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:53,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:53,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:53,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:53,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 1 sufficientlyReplicated, 2 underReplicated and 2 unhealthy containers
2023-03-27 23:43:53,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:54,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:54,254 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:54,322 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: addNew group-65F4DC8ECF0E:[476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER] returns group-65F4DC8ECF0E:java.util.concurrent.CompletableFuture@3a2bb9f2[Not completed]
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: new RaftServerImpl for group-65F4DC8ECF0E:[476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E: ConfigurationManager, init=-1: peers:[476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis] (custom)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:54,323 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:54,325 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:54,325 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:54,325 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:54,325 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:54,325 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:54,325 [pool-2591-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e does not exist. Creating ...
2023-03-27 23:43:54,326 [pool-2591-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:54,327 [pool-2591-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e has been successfully formatted.
2023-03-27 23:43:54,328 [pool-2591-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-65F4DC8ECF0E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:54,328 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:54,328 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:54,328 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:54,328 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:54,328 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:54,328 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:54,328 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e, Nodes: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:476d332c-e00b-4a08-bd5a-0b3284a7ea0c, CreationTimestamp2023-03-27T23:43:51.328Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:54,328 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:54,329 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:54,330 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:54,330 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:54,333 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:54,333 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:54,333 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:54,333 [pool-2591-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:54,333 [pool-2591-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:54,334 [pool-2591-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E: start as a follower, conf=-1: peers:[476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:54,334 [pool-2591-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:54,334 [pool-2591-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: start 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState
2023-03-27 23:43:54,334 [pool-2591-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-65F4DC8ECF0E,id=476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:54,334 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:54,334 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:54,334 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:54,334 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:54,334 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:54,334 [pool-2591-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:54,335 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e
2023-03-27 23:43:54,335 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e.
2023-03-27 23:43:54,351 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:54,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:54,422 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:54,422 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:54,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:43:54,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:54,664 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 49220674-b9b6-430a-b99a-f5474fac1494: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->49220674-b9b6-430a-b99a-f5474fac1494#650-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:54,672 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 3fee8600-457c-478d-8bf5-017cc394a56c: Failed APPEND_ENTRIES request 2829ccc8-889f-48cc-a62b-b3954aa0680c->3fee8600-457c-478d-8bf5-017cc394a56c#648-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), STATEMACHINELOGENTRY, 124@client-0F79B1EF091A
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-27 23:43:54,672 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 49220674-b9b6-430a-b99a-f5474fac1494: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:54,673 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:54,677 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 3fee8600-457c-478d-8bf5-017cc394a56c: group-3BACC333D725 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-27 23:43:54,678 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c: nextIndex: updateUnconditionally 40 -> 39
2023-03-27 23:43:54,678 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 is not found
2023-03-27 23:43:54,711 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 38de582e-58a6-400e-852c-9e1084927a05: addNew group-B3FC760A9277:[38de582e-58a6-400e-852c-9e1084927a05|rpc:10.1.0.32:33063|dataStream:10.1.0.32:40501|priority:1|startupRole:FOLLOWER] returns group-B3FC760A9277:java.util.concurrent.CompletableFuture@611d78cd[Not completed]
2023-03-27 23:43:54,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-27 23:43:54,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:54,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:54,711 [pool-2629-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 38de582e-58a6-400e-852c-9e1084927a05: new RaftServerImpl for group-B3FC760A9277:[38de582e-58a6-400e-852c-9e1084927a05|rpc:10.1.0.32:33063|dataStream:10.1.0.32:40501|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:54,711 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:54,711 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:54,711 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:54,711 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:54,711 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:54,711 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:54,712 [pool-2629-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277: ConfigurationManager, init=-1: peers:[38de582e-58a6-400e-852c-9e1084927a05|rpc:10.1.0.32:33063|dataStream:10.1.0.32:40501|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:54,712 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis] (custom)
2023-03-27 23:43:54,712 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:54,712 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:54,712 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:54,712 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:54,712 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:54,713 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:54,713 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:54,713 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:54,713 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:54,713 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:54,714 [pool-2629-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis/4e1a23bf-fbb6-4c74-99b8-b3fc760a9277 does not exist. Creating ...
2023-03-27 23:43:54,715 [pool-2629-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis/4e1a23bf-fbb6-4c74-99b8-b3fc760a9277/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:54,717 [pool-2629-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis/4e1a23bf-fbb6-4c74-99b8-b3fc760a9277 has been successfully formatted.
2023-03-27 23:43:54,717 [pool-2629-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-B3FC760A9277: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:54,717 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:54,717 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:54,717 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:54,717 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:54,717 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:54,717 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 4e1a23bf-fbb6-4c74-99b8-b3fc760a9277, Nodes: 38de582e-58a6-400e-852c-9e1084927a05(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:38de582e-58a6-400e-852c-9e1084927a05, CreationTimestamp2023-03-27T23:43:51.712Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:54,717 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:54,718 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis/4e1a23bf-fbb6-4c74-99b8-b3fc760a9277
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:54,718 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:54,719 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:54,720 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277: start as a follower, conf=-1: peers:[38de582e-58a6-400e-852c-9e1084927a05|rpc:10.1.0.32:33063|dataStream:10.1.0.32:40501|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 38de582e-58a6-400e-852c-9e1084927a05: start 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B3FC760A9277,id=38de582e-58a6-400e-852c-9e1084927a05
2023-03-27 23:43:54,723 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:54,723 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:54,723 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:54,724 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:54,724 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:54,724 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=4e1a23bf-fbb6-4c74-99b8-b3fc760a9277
2023-03-27 23:43:54,724 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=4e1a23bf-fbb6-4c74-99b8-b3fc760a9277.
2023-03-27 23:43:54,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:54,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:54,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:54,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSING, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:54,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 1 sufficientlyReplicated, 2 underReplicated and 2 unhealthy containers
2023-03-27 23:43:54,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:54,883 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderStateImpl] WARN  server.RaftServer$Division (LeaderStateImpl.java:checkLeadership(1021)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderStateImpl: Lost leadership on term: 1. Election timeout: 5200ms. In charge for: 71604ms. Conf: 0: peers:[49220674-b9b6-430a-b99a-f5474fac1494|rpc:10.1.0.32:45963|dataStream:10.1.0.32:32953|priority:0|startupRole:FOLLOWER, 3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:54,883 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderStateImpl] WARN  server.RaftServer$Division (LeaderStateImpl.java:lambda$checkLeadership$17(1025)) - Follower 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494(c37,m38,n39, attendVote=true, lastRpcSendTime=219, lastRpcResponseTime=5230)
2023-03-27 23:43:54,883 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderStateImpl] WARN  server.RaftServer$Division (LeaderStateImpl.java:lambda$checkLeadership$17(1025)) - Follower 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c(c37,m38,n39, attendVote=true, lastRpcSendTime=211, lastRpcResponseTime=5229)
2023-03-27 23:43:54,883 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderStateImpl] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725: changes role from    LEADER to FOLLOWER at term 1 for StepDownReason:LOST_MAJORITY_HEARTBEATS
2023-03-27 23:43:54,883 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderStateImpl] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: shutdown 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderStateImpl
2023-03-27 23:43:54,883 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-27 23:43:54,883 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderStateImpl] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-PendingRequests: sendNotLeaderResponses
2023-03-27 23:43:54,886 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->3fee8600-457c-478d-8bf5-017cc394a56c-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-27 23:43:54,886 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: remove  FOLLOWER 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725:t1, leader=2829ccc8-889f-48cc-a62b-b3954aa0680c, voted=2829ccc8-889f-48cc-a62b-b3954aa0680c, raftlog=Memoized:2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-SegmentedRaftLog:OPENED:c38, conf=0: peers:[49220674-b9b6-430a-b99a-f5474fac1494|rpc:10.1.0.32:45963|dataStream:10.1.0.32:32953|priority:0|startupRole:FOLLOWER, 3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-27 23:43:54,886 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725: shutdown
2023-03-27 23:43:54,886 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3BACC333D725,id=2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:43:54,887 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-StateMachineUpdater: set stopIndex = 38
2023-03-27 23:43:54,890 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-3BACC333D725: Taking a snapshot at:(t:1, i:38) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_38
2023-03-27 23:43:54,890 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderStateImpl] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: start 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState
2023-03-27 23:43:54,894 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-3BACC333D725: Finished taking a snapshot at:(t:1, i:38) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725/sm/snapshot.1_38 took: 4 ms
2023-03-27 23:43:54,894 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-StateMachineUpdater: Took a snapshot at index 38
2023-03-27 23:43:54,894 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 38
2023-03-27 23:43:54,894 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725: closes. applyIndex: 38
2023-03-27 23:43:54,895 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:43:54,895 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-SegmentedRaftLogWorker close()
2023-03-27 23:43:54,908 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:54,908 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:54,912 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:54,912 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:54,914 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/7e260818-9050-4cf0-9395-3bacc333d725
2023-03-27 23:43:54,914 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=7e260818-9050-4cf0-9395-3bacc333d725 command on datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c.
2023-03-27 23:43:55,054 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:55,254 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:55,328 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:55,350 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:55,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:55,423 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:55,423 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:55,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:43:55,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:55,699 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:55,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-27 23:43:55,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:55,711 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:55,716 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:55,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:55,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:55,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:55,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:55,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 1 sufficientlyReplicated, 2 underReplicated and 2 unhealthy containers
2023-03-27 23:43:55,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:56,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:56,350 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:56,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:56,423 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:56,423 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32).
2023-03-27 23:43:56,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:43:56,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:56,699 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:56,712 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-27 23:43:56,712 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:43:56,712 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:56,718 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:56,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:56,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=QUASI_CLOSED, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:56,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:56,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #4 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=49220674-b9b6-430a-b99a-f5474fac1494, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=CLOSED, datanodeDetails=3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=3fee8600-457c-478d-8bf5-017cc394a56c, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#4, state=QUASI_CLOSED, datanodeDetails=2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), placeOfBirth=2829ccc8-889f-48cc-a62b-b3954aa0680c, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-27 23:43:56,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 1 sufficientlyReplicated, 2 underReplicated and 2 unhealthy containers
2023-03-27 23:43:56,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:56,914 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:56,914 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 30.
2023-03-27 23:43:56,915 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 4 is closed with bcsId 30.
2023-03-27 23:43:56,915 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:56,916 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-27 23:43:56,917 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 6 is closed with bcsId 34.
2023-03-27 23:43:57,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:57,181 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5059264542ns, electionTimeout:5043ms
2023-03-27 23:43:57,182 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 69c31795-da41-43dd-a637-b3015d9175ea: shutdown 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:57,182 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:57,182 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:57,182 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 69c31795-da41-43dd-a637-b3015d9175ea: start 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87
2023-03-27 23:43:57,182 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,183 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:57,183 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:57,183 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:57,183 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 117526ec-9427-41bf-9dbd-c8f743595c9c
2023-03-27 23:43:57,197 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5166893344ns, electionTimeout:5156ms
2023-03-27 23:43:57,197 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: shutdown 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState
2023-03-27 23:43:57,197 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:57,197 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:57,197 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: start 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88
2023-03-27 23:43:57,198 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1: receive requestVote(PRE_VOTE, 69c31795-da41-43dd-a637-b3015d9175ea, group-E7A0B9C7DBA1, 0, (t:0, i:0))
2023-03-27 23:43:57,198 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FOLLOWER: reject PRE_VOTE from 69c31795-da41-43dd-a637-b3015d9175ea: our priority 1 > candidate's priority 0
2023-03-27 23:43:57,198 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1 replies to PRE_VOTE vote request: 69c31795-da41-43dd-a637-b3015d9175ea<-5c7a3766-4df9-4a62-b680-fc04cc352416#0:FAIL-t0. Peer's state: 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1:t0, leader=null, voted=, raftlog=Memoized:5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,199 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1: receive requestVote(PRE_VOTE, 69c31795-da41-43dd-a637-b3015d9175ea, group-E7A0B9C7DBA1, 0, (t:0, i:0))
2023-03-27 23:43:57,199 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FOLLOWER: accept PRE_VOTE from 69c31795-da41-43dd-a637-b3015d9175ea: our priority 0 <= candidate's priority 0
2023-03-27 23:43:57,199 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,199 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1 replies to PRE_VOTE vote request: 69c31795-da41-43dd-a637-b3015d9175ea<-117526ec-9427-41bf-9dbd-c8f743595c9c#0:OK-t0. Peer's state: 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1:t0, leader=null, voted=, raftlog=Memoized:117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,199 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88 PRE_VOTE round 0: result PASSED (term=0)
2023-03-27 23:43:57,199 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2023-03-27 23:43:57,199 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 69c31795-da41-43dd-a637-b3015d9175ea<-5c7a3766-4df9-4a62-b680-fc04cc352416#0:FAIL-t0
2023-03-27 23:43:57,199 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87 PRE_VOTE round 0: result REJECTED
2023-03-27 23:43:57,199 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-27 23:43:57,199 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 69c31795-da41-43dd-a637-b3015d9175ea: shutdown 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87
2023-03-27 23:43:57,199 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-LeaderElection87] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 69c31795-da41-43dd-a637-b3015d9175ea: start 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:57,200 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:57,200 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:57,200 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88 ELECTION round 0: submit vote requests at term 1 for -1: peers:[5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,200 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88 ELECTION round 0: result PASSED (term=1)
2023-03-27 23:43:57,200 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: shutdown 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88
2023-03-27 23:43:57,201 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:57,201 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-DA2952889F03 with new leaderId: 5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:57,201 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03: change Leader from null to 5c7a3766-4df9-4a62-b680-fc04cc352416 at term 1 for becomeLeader, leader elected after 5188ms
2023-03-27 23:43:57,201 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:57,201 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:43:57,201 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:57,201 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:57,202 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:57,202 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:57,202 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:57,202 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:57,202 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:57,202 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: start 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderStateImpl
2023-03-27 23:43:57,202 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:57,212 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-LeaderElection88] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03: set configuration 0: peers:[5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,214 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-DA2952889F03-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/4ad1ff11-ec4e-4398-8b83-da2952889f03/current/log_inprogress_0
2023-03-27 23:43:57,228 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5155168885ns, electionTimeout:5154ms
2023-03-27 23:43:57,228 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: shutdown 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:57,228 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:57,228 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:57,228 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: start 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89
2023-03-27 23:43:57,229 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,229 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:57,229 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 69c31795-da41-43dd-a637-b3015d9175ea
2023-03-27 23:43:57,229 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:57,229 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 117526ec-9427-41bf-9dbd-c8f743595c9c
2023-03-27 23:43:57,230 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:57,230 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:57,236 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1: receive requestVote(PRE_VOTE, 5c7a3766-4df9-4a62-b680-fc04cc352416, group-E7A0B9C7DBA1, 0, (t:0, i:0))
2023-03-27 23:43:57,236 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FOLLOWER: accept PRE_VOTE from 5c7a3766-4df9-4a62-b680-fc04cc352416: our priority 0 <= candidate's priority 1
2023-03-27 23:43:57,236 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1 replies to PRE_VOTE vote request: 5c7a3766-4df9-4a62-b680-fc04cc352416<-117526ec-9427-41bf-9dbd-c8f743595c9c#0:OK-t0. Peer's state: 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1:t0, leader=null, voted=, raftlog=Memoized:117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,242 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: receive requestVote(PRE_VOTE, 5c7a3766-4df9-4a62-b680-fc04cc352416, group-E7A0B9C7DBA1, 0, (t:0, i:0))
2023-03-27 23:43:57,243 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FOLLOWER: accept PRE_VOTE from 5c7a3766-4df9-4a62-b680-fc04cc352416: our priority 0 <= candidate's priority 1
2023-03-27 23:43:57,243 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1 replies to PRE_VOTE vote request: 5c7a3766-4df9-4a62-b680-fc04cc352416<-69c31795-da41-43dd-a637-b3015d9175ea#0:OK-t0. Peer's state: 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1:t0, leader=null, voted=, raftlog=Memoized:69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,243 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-27 23:43:57,243 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 5c7a3766-4df9-4a62-b680-fc04cc352416<-117526ec-9427-41bf-9dbd-c8f743595c9c#0:OK-t0
2023-03-27 23:43:57,243 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89 PRE_VOTE round 0: result PASSED
2023-03-27 23:43:57,245 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89 ELECTION round 0: submit vote requests at term 1 for -1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,246 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: receive requestVote(ELECTION, 5c7a3766-4df9-4a62-b680-fc04cc352416, group-E7A0B9C7DBA1, 1, (t:0, i:0))
2023-03-27 23:43:57,246 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FOLLOWER: accept ELECTION from 5c7a3766-4df9-4a62-b680-fc04cc352416: our priority 0 <= candidate's priority 1
2023-03-27 23:43:57,246 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:57,246 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 69c31795-da41-43dd-a637-b3015d9175ea: shutdown 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:57,246 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:57,246 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 69c31795-da41-43dd-a637-b3015d9175ea: start 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:57,246 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:57,246 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState was interrupted
2023-03-27 23:43:57,247 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1: receive requestVote(ELECTION, 5c7a3766-4df9-4a62-b680-fc04cc352416, group-E7A0B9C7DBA1, 1, (t:0, i:0))
2023-03-27 23:43:57,247 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FOLLOWER: accept ELECTION from 5c7a3766-4df9-4a62-b680-fc04cc352416: our priority 0 <= candidate's priority 1
2023-03-27 23:43:57,247 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:57,247 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: shutdown 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:57,250 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: start 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState
2023-03-27 23:43:57,250 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState was interrupted
2023-03-27 23:43:57,250 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:57,250 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:57,251 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1 replies to ELECTION vote request: 5c7a3766-4df9-4a62-b680-fc04cc352416<-69c31795-da41-43dd-a637-b3015d9175ea#0:OK-t1. Peer's state: 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1:t1, leader=null, voted=5c7a3766-4df9-4a62-b680-fc04cc352416, raftlog=Memoized:69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,253 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:57,253 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:57,253 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-27 23:43:57,253 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 5c7a3766-4df9-4a62-b680-fc04cc352416<-69c31795-da41-43dd-a637-b3015d9175ea#0:OK-t1
2023-03-27 23:43:57,253 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89 ELECTION round 0: result PASSED
2023-03-27 23:43:57,253 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: shutdown 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89
2023-03-27 23:43:57,253 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:57,253 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-E7A0B9C7DBA1 with new leaderId: 5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:57,253 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1: change Leader from null to 5c7a3766-4df9-4a62-b680-fc04cc352416 at term 1 for becomeLeader, leader elected after 5211ms
2023-03-27 23:43:57,253 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:57,254 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1 replies to ELECTION vote request: 5c7a3766-4df9-4a62-b680-fc04cc352416<-117526ec-9427-41bf-9dbd-c8f743595c9c#0:OK-t1. Peer's state: 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1:t1, leader=null, voted=5c7a3766-4df9-4a62-b680-fc04cc352416, raftlog=Memoized:117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,254 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 964b688c-b4b5-456b-baaf-e7a0b9c7dba1, Nodes: 69c31795-da41-43dd-a637-b3015d9175ea(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)117526ec-9427-41bf-9dbd-c8f743595c9c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)5c7a3766-4df9-4a62-b680-fc04cc352416(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:5c7a3766-4df9-4a62-b680-fc04cc352416, CreationTimestamp2023-03-27T23:43:49.718Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:57,254 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-27 23:43:57,254 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-27 23:43:57,254 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-27 23:43:57,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-27 23:43:57,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-27 23:43:57,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-27 23:43:57,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-27 23:43:57,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-27 23:43:57,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1255)) - Service ReplicationManager transitions to RUNNING.
2023-03-27 23:43:57,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(132)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-27 23:43:57,255 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:57,255 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:57,256 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:57,256 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:57,256 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:57,256 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:57,256 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:57,257 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-27 23:43:57,257 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:57,257 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-27 23:43:57,257 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-27 23:43:57,257 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:57,257 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:57,257 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:57,257 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-27 23:43:57,258 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-27 23:43:57,258 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:57,258 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-27 23:43:57,258 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-27 23:43:57,258 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:57,258 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:57,258 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:57,258 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-27 23:43:57,258 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5c7a3766-4df9-4a62-b680-fc04cc352416: start 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderStateImpl
2023-03-27 23:43:57,259 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:57,260 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-LeaderElection89] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1: set configuration 0: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,260 [5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 5c7a3766-4df9-4a62-b680-fc04cc352416@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-0/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1/current/log_inprogress_0
2023-03-27 23:43:57,268 [69c31795-da41-43dd-a637-b3015d9175ea-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-E7A0B9C7DBA1 with new leaderId: 5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:57,268 [69c31795-da41-43dd-a637-b3015d9175ea-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: change Leader from null to 5c7a3766-4df9-4a62-b680-fc04cc352416 at term 1 for appendEntries, leader elected after 5170ms
2023-03-27 23:43:57,274 [69c31795-da41-43dd-a637-b3015d9175ea-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1: set configuration 0: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,275 [69c31795-da41-43dd-a637-b3015d9175ea-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:57,277 [117526ec-9427-41bf-9dbd-c8f743595c9c-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-E7A0B9C7DBA1 with new leaderId: 5c7a3766-4df9-4a62-b680-fc04cc352416
2023-03-27 23:43:57,277 [117526ec-9427-41bf-9dbd-c8f743595c9c-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1: change Leader from null to 5c7a3766-4df9-4a62-b680-fc04cc352416 at term 1 for appendEntries, leader elected after 5115ms
2023-03-27 23:43:57,278 [117526ec-9427-41bf-9dbd-c8f743595c9c-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1: set configuration 0: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:0|startupRole:FOLLOWER, 5c7a3766-4df9-4a62-b680-fc04cc352416|rpc:10.1.0.32:39339|dataStream:10.1.0.32:39875|priority:1|startupRole:FOLLOWER, 117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,278 [117526ec-9427-41bf-9dbd-c8f743595c9c-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:57,279 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1/current/log_inprogress_0
2023-03-27 23:43:57,279 [69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-E7A0B9C7DBA1-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/964b688c-b4b5-456b-baaf-e7a0b9c7dba1/current/log_inprogress_0
2023-03-27 23:43:57,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:57,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-27 23:43:57,478 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5121147347ns, electionTimeout:5120ms
2023-03-27 23:43:57,478 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 69c31795-da41-43dd-a637-b3015d9175ea: shutdown 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState
2023-03-27 23:43:57,478 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:57,478 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:57,478 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 69c31795-da41-43dd-a637-b3015d9175ea: start 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90
2023-03-27 23:43:57,479 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,479 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90 PRE_VOTE round 0: result PASSED (term=0)
2023-03-27 23:43:57,480 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90 ELECTION round 0: submit vote requests at term 1 for -1: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,480 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90 ELECTION round 0: result PASSED (term=1)
2023-03-27 23:43:57,480 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 69c31795-da41-43dd-a637-b3015d9175ea: shutdown 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90
2023-03-27 23:43:57,480 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:57,480 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-39FCC8AF315C with new leaderId: 69c31795-da41-43dd-a637-b3015d9175ea
2023-03-27 23:43:57,480 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C: change Leader from null to 69c31795-da41-43dd-a637-b3015d9175ea at term 1 for becomeLeader, leader elected after 5136ms
2023-03-27 23:43:57,480 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:57,481 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:57,481 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:57,481 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:57,481 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:57,481 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:57,481 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:57,481 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:57,482 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 69c31795-da41-43dd-a637-b3015d9175ea: start 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderStateImpl
2023-03-27 23:43:57,482 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:57,482 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-LeaderElection90] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C: set configuration 0: peers:[69c31795-da41-43dd-a637-b3015d9175ea|rpc:10.1.0.32:40539|dataStream:10.1.0.32:34781|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,483 [69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 69c31795-da41-43dd-a637-b3015d9175ea@group-39FCC8AF315C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-1/data/ratis/07dee5f9-4a37-447e-ae5a-39fcc8af315c/current/log_inprogress_0
2023-03-27 23:43:57,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:57,712 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-27 23:43:57,712 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Cluster exits safe mode
2023-03-27 23:43:57,712 [Listener at 127.0.0.1/37647] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:43:57,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has 3 sufficientlyReplicated, 0 underReplicated and 0 unhealthy containers
2023-03-27 23:43:57,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(422)) - Datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) has entered maintenance
2023-03-27 23:43:57,823 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:57,823 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) moved to HEALTHY state.
2023-03-27 23:43:57,823 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:43:57,823 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=35bc327f-518e-4ba7-b1e3-903aa5ff57fd to datanode:3fee8600-457c-478d-8bf5-017cc394a56c
2023-03-27 23:43:57,823 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=35bc327f-518e-4ba7-b1e3-903aa5ff57fd to datanode:2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:43:57,823 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=35bc327f-518e-4ba7-b1e3-903aa5ff57fd to datanode:fda26913-bdfb-48f8-b38a-a95200d457c8
2023-03-27 23:43:57,824 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 35bc327f-518e-4ba7-b1e3-903aa5ff57fd, Nodes: 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)fda26913-bdfb-48f8-b38a-a95200d457c8(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-27T23:43:57.823Z[Etc/UTC]].
2023-03-27 23:43:57,824 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0. Excluded 6.
2023-03-27 23:43:57,840 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5119443383ns, electionTimeout:5119ms
2023-03-27 23:43:57,840 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: shutdown 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState
2023-03-27 23:43:57,840 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:57,840 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:57,840 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: start 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91
2023-03-27 23:43:57,841 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,841 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91 PRE_VOTE round 0: result PASSED (term=0)
2023-03-27 23:43:57,842 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91 ELECTION round 0: submit vote requests at term 1 for -1: peers:[117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,842 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91 ELECTION round 0: result PASSED (term=1)
2023-03-27 23:43:57,842 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: shutdown 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91
2023-03-27 23:43:57,842 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:57,842 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-AB61CF327F9C with new leaderId: 117526ec-9427-41bf-9dbd-c8f743595c9c
2023-03-27 23:43:57,843 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C: change Leader from null to 117526ec-9427-41bf-9dbd-c8f743595c9c at term 1 for becomeLeader, leader elected after 5131ms
2023-03-27 23:43:57,843 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:57,843 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:57,843 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:57,843 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:57,843 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:57,843 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:57,843 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:57,844 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:57,844 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 117526ec-9427-41bf-9dbd-c8f743595c9c: start 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderStateImpl
2023-03-27 23:43:57,844 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:57,844 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-LeaderElection91] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C: set configuration 0: peers:[117526ec-9427-41bf-9dbd-c8f743595c9c|rpc:10.1.0.32:44893|dataStream:10.1.0.32:33557|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:57,845 [117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 117526ec-9427-41bf-9dbd-c8f743595c9c@group-AB61CF327F9C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-2/data/ratis/c1cfb39d-45de-41c7-b94b-ab61cf327f9c/current/log_inprogress_0
2023-03-27 23:43:58,303 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5024474195ns, electionTimeout:5024ms
2023-03-27 23:43:58,304 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: shutdown 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:58,304 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:58,304 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:58,304 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: start 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92
2023-03-27 23:43:58,304 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,304 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6
2023-03-27 23:43:58,304 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,305 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,305 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:58,312 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108: receive requestVote(PRE_VOTE, 3d5bec3e-3873-417f-9114-370ff3a7c03a, group-5BEEF9EF3108, 0, (t:0, i:0))
2023-03-27 23:43:58,312 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FOLLOWER: reject PRE_VOTE from 3d5bec3e-3873-417f-9114-370ff3a7c03a: our priority 1 > candidate's priority 0
2023-03-27 23:43:58,312 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108 replies to PRE_VOTE vote request: 3d5bec3e-3873-417f-9114-370ff3a7c03a<-476d332c-e00b-4a08-bd5a-0b3284a7ea0c#0:FAIL-t0. Peer's state: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108:t0, leader=null, voted=, raftlog=Memoized:476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,313 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108: receive requestVote(PRE_VOTE, 3d5bec3e-3873-417f-9114-370ff3a7c03a, group-5BEEF9EF3108, 0, (t:0, i:0))
2023-03-27 23:43:58,313 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FOLLOWER: accept PRE_VOTE from 3d5bec3e-3873-417f-9114-370ff3a7c03a: our priority 0 <= candidate's priority 0
2023-03-27 23:43:58,313 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108 replies to PRE_VOTE vote request: 3d5bec3e-3873-417f-9114-370ff3a7c03a<-4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6#0:OK-t0. Peer's state: 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108:t0, leader=null, voted=, raftlog=Memoized:4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,314 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2023-03-27 23:43:58,314 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 3d5bec3e-3873-417f-9114-370ff3a7c03a<-4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6#0:OK-t0
2023-03-27 23:43:58,314 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 3d5bec3e-3873-417f-9114-370ff3a7c03a<-476d332c-e00b-4a08-bd5a-0b3284a7ea0c#0:FAIL-t0
2023-03-27 23:43:58,314 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92 PRE_VOTE round 0: result REJECTED
2023-03-27 23:43:58,314 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-27 23:43:58,314 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: shutdown 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92
2023-03-27 23:43:58,314 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-LeaderElection92] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: start 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:58,316 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,316 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,366 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5065410758ns, electionTimeout:5065ms
2023-03-27 23:43:58,366 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: shutdown 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:58,366 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:58,366 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:58,366 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: start 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93
2023-03-27 23:43:58,367 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,367 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,367 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6
2023-03-27 23:43:58,367 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,367 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 3d5bec3e-3873-417f-9114-370ff3a7c03a
2023-03-27 23:43:58,377 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: receive requestVote(PRE_VOTE, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c, group-5BEEF9EF3108, 0, (t:0, i:0))
2023-03-27 23:43:58,377 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FOLLOWER: accept PRE_VOTE from 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: our priority 0 <= candidate's priority 1
2023-03-27 23:43:58,377 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108 replies to PRE_VOTE vote request: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c<-3d5bec3e-3873-417f-9114-370ff3a7c03a#0:OK-t0. Peer's state: 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108:t0, leader=null, voted=, raftlog=Memoized:3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,378 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,378 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,379 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108: receive requestVote(PRE_VOTE, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c, group-5BEEF9EF3108, 0, (t:0, i:0))
2023-03-27 23:43:58,379 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FOLLOWER: accept PRE_VOTE from 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: our priority 0 <= candidate's priority 1
2023-03-27 23:43:58,379 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108 replies to PRE_VOTE vote request: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c<-4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6#0:OK-t0. Peer's state: 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108:t0, leader=null, voted=, raftlog=Memoized:4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,379 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-27 23:43:58,379 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c<-3d5bec3e-3873-417f-9114-370ff3a7c03a#0:OK-t0
2023-03-27 23:43:58,379 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93 PRE_VOTE round 0: result PASSED
2023-03-27 23:43:58,380 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93 ELECTION round 0: submit vote requests at term 1 for -1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,382 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,382 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108: receive requestVote(ELECTION, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c, group-5BEEF9EF3108, 1, (t:0, i:0))
2023-03-27 23:43:58,382 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FOLLOWER: accept ELECTION from 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: our priority 0 <= candidate's priority 1
2023-03-27 23:43:58,382 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:58,382 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: shutdown 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:58,382 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,382 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: start 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:58,382 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState was interrupted
2023-03-27 23:43:58,383 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: receive requestVote(ELECTION, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c, group-5BEEF9EF3108, 1, (t:0, i:0))
2023-03-27 23:43:58,383 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FOLLOWER: accept ELECTION from 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: our priority 0 <= candidate's priority 1
2023-03-27 23:43:58,383 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:58,383 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: shutdown 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:58,383 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: start 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState
2023-03-27 23:43:58,383 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState was interrupted
2023-03-27 23:43:58,383 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108 replies to ELECTION vote request: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c<-4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6#0:OK-t1. Peer's state: 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108:t1, leader=null, voted=476d332c-e00b-4a08-bd5a-0b3284a7ea0c, raftlog=Memoized:4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,384 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-27 23:43:58,384 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c<-4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6#0:OK-t1
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93 ELECTION round 0: result PASSED
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: shutdown 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-5BEEF9EF3108 with new leaderId: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108: change Leader from null to 476d332c-e00b-4a08-bd5a-0b3284a7ea0c at term 1 for becomeLeader, leader elected after 5094ms
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:58,384 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108 replies to ELECTION vote request: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c<-3d5bec3e-3873-417f-9114-370ff3a7c03a#0:OK-t1. Peer's state: 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108:t1, leader=null, voted=476d332c-e00b-4a08-bd5a-0b3284a7ea0c, raftlog=Memoized:3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:58,384 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:58,385 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:58,385 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:58,385 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:58,385 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-27 23:43:58,385 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:58,385 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-27 23:43:58,385 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-27 23:43:58,385 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:58,386 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:58,386 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:58,386 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-27 23:43:58,386 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: b5657b85-1b7c-4d62-99bb-5beef9ef3108, Nodes: 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)3d5bec3e-3873-417f-9114-370ff3a7c03a(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)476d332c-e00b-4a08-bd5a-0b3284a7ea0c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:476d332c-e00b-4a08-bd5a-0b3284a7ea0c, CreationTimestamp2023-03-27T23:43:51.328Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:43:58,386 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,387 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,387 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-27 23:43:58,387 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:58,387 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-27 23:43:58,387 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-27 23:43:58,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:43:58,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:58,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:43:58,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-27 23:43:58,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: start 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderStateImpl
2023-03-27 23:43:58,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:58,389 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108/current/log_inprogress_0
2023-03-27 23:43:58,393 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108-LeaderElection93] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-5BEEF9EF3108: set configuration 0: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,395 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-5BEEF9EF3108 with new leaderId: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:58,395 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108: change Leader from null to 476d332c-e00b-4a08-bd5a-0b3284a7ea0c at term 1 for appendEntries, leader elected after 5147ms
2023-03-27 23:43:58,397 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-server-thread3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108: set configuration 0: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,397 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6-server-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:58,399 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-5BEEF9EF3108-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108/current/log_inprogress_0
2023-03-27 23:43:58,402 [3d5bec3e-3873-417f-9114-370ff3a7c03a-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-5BEEF9EF3108 with new leaderId: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:58,402 [3d5bec3e-3873-417f-9114-370ff3a7c03a-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: change Leader from null to 476d332c-e00b-4a08-bd5a-0b3284a7ea0c at term 1 for appendEntries, leader elected after 5133ms
2023-03-27 23:43:58,402 [3d5bec3e-3873-417f-9114-370ff3a7c03a-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108: set configuration 0: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:0|startupRole:FOLLOWER, 3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:0|startupRole:FOLLOWER, 476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,403 [3d5bec3e-3873-417f-9114-370ff3a7c03a-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:58,404 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5198408585ns, electionTimeout:5198ms
2023-03-27 23:43:58,404 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-5BEEF9EF3108-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/b5657b85-1b7c-4d62-99bb-5beef9ef3108/current/log_inprogress_0
2023-03-27 23:43:58,404 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: shutdown 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState
2023-03-27 23:43:58,404 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:58,404 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:58,404 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: start 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94
2023-03-27 23:43:58,406 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,406 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94 PRE_VOTE round 0: result PASSED (term=0)
2023-03-27 23:43:58,407 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94 ELECTION round 0: submit vote requests at term 1 for -1: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,407 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94 ELECTION round 0: result PASSED (term=1)
2023-03-27 23:43:58,407 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: shutdown 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94
2023-03-27 23:43:58,407 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:58,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:58,407 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-ECAF8EF23EFD with new leaderId: 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6
2023-03-27 23:43:58,407 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD: change Leader from null to 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6 at term 1 for becomeLeader, leader elected after 5212ms
2023-03-27 23:43:58,408 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:58,408 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:58,408 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:58,408 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:58,408 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:58,408 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:58,408 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:58,408 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:58,409 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: start 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderStateImpl
2023-03-27 23:43:58,409 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:58,409 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-LeaderElection94] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD: set configuration 0: peers:[4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6|rpc:10.1.0.32:36455|dataStream:10.1.0.32:45739|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,410 [4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6@group-ECAF8EF23EFD-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-3/data/ratis/1d842bc1-3603-4066-a0a1-ecaf8ef23efd/current/log_inprogress_0
2023-03-27 23:43:58,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:43:58,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:58,787 [IPC Server handler 18 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-03-27 23:43:58,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:58,849 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5144445932ns, electionTimeout:5144ms
2023-03-27 23:43:58,849 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: shutdown 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState
2023-03-27 23:43:58,849 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:58,849 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:58,849 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: start 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95
2023-03-27 23:43:58,850 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,850 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95 PRE_VOTE round 0: result PASSED (term=0)
2023-03-27 23:43:58,851 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95 ELECTION round 0: submit vote requests at term 1 for -1: peers:[3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95 ELECTION round 0: result PASSED (term=1)
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: shutdown 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-1C7C2F9DC6C1 with new leaderId: 3d5bec3e-3873-417f-9114-370ff3a7c03a
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1: change Leader from null to 3d5bec3e-3873-417f-9114-370ff3a7c03a at term 1 for becomeLeader, leader elected after 5158ms
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:58,852 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:58,853 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:58,853 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:58,853 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:58,853 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a: start 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderStateImpl
2023-03-27 23:43:58,853 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:58,853 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-LeaderElection95] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1: set configuration 0: peers:[3d5bec3e-3873-417f-9114-370ff3a7c03a|rpc:10.1.0.32:37315|dataStream:10.1.0.32:39907|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,854 [3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 3d5bec3e-3873-417f-9114-370ff3a7c03a@group-1C7C2F9DC6C1-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-4/data/ratis/a8c4edc4-6035-4112-b9ab-1c7c2f9dc6c1/current/log_inprogress_0
2023-03-27 23:43:58,916 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: addNew group-903AA5FF57FD:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER] returns group-903AA5FF57FD:java.util.concurrent.CompletableFuture@29e8066e[Not completed]
2023-03-27 23:43:58,916 [pool-1655-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: new RaftServerImpl for group-903AA5FF57FD:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:58,916 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:58,916 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:58,916 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:58,916 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:58,916 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:58,916 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:58,916 [pool-1655-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD: ConfigurationManager, init=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:58,917 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis] (custom)
2023-03-27 23:43:58,917 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:58,917 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:58,917 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:58,917 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:58,917 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:58,918 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:58,918 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:58,918 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:58,918 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:58,918 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:58,919 [pool-1655-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd does not exist. Creating ...
2023-03-27 23:43:58,920 [pool-1655-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:58,921 [pool-1655-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd has been successfully formatted.
2023-03-27 23:43:58,921 [pool-1655-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-903AA5FF57FD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:58,921 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:58,921 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:58,921 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:58,921 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:58,921 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:58,921 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:58,922 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:58,922 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:58,922 [pool-1655-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd
2023-03-27 23:43:58,922 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:58,922 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:58,922 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:58,923 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:58,923 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:58,923 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:58,923 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:58,923 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:58,924 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:58,924 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:58,927 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:58,927 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:58,927 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:58,927 [pool-1655-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:58,927 [pool-1655-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:58,928 [pool-1655-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD: start as a follower, conf=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,928 [pool-1655-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:58,928 [pool-1655-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: start 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState
2023-03-27 23:43:58,928 [pool-1655-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-903AA5FF57FD,id=2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:43:58,928 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,928 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:58,928 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,928 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:58,928 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:58,928 [pool-1655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:58,929 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=35bc327f-518e-4ba7-b1e3-903aa5ff57fd
2023-03-27 23:43:58,934 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3fee8600-457c-478d-8bf5-017cc394a56c: addNew group-903AA5FF57FD:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER] returns group-903AA5FF57FD:java.util.concurrent.CompletableFuture@e525ffe[Not completed]
2023-03-27 23:43:58,934 [pool-1681-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 3fee8600-457c-478d-8bf5-017cc394a56c: new RaftServerImpl for group-903AA5FF57FD:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:58,934 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:58,934 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:58,934 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:58,934 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:58,934 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:58,934 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:58,934 [pool-1681-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD: ConfigurationManager, init=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:58,935 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis] (custom)
2023-03-27 23:43:58,935 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:58,935 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:58,935 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:58,935 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:58,935 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:58,936 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:58,936 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:58,936 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:58,936 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:58,936 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:58,936 [pool-1681-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd does not exist. Creating ...
2023-03-27 23:43:58,937 [pool-1681-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:58,939 [pool-1681-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd has been successfully formatted.
2023-03-27 23:43:58,939 [pool-1681-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-903AA5FF57FD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:58,939 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:58,939 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:58,939 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:58,939 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:58,939 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:58,939 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:58,940 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:58,941 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:58,942 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:58,945 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:58,945 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:58,945 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:58,945 [pool-1681-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:58,946 [pool-1681-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:58,946 [pool-1681-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD: start as a follower, conf=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,946 [pool-1681-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:58,946 [pool-1681-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3fee8600-457c-478d-8bf5-017cc394a56c: start 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState
2023-03-27 23:43:58,946 [pool-1681-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-903AA5FF57FD,id=3fee8600-457c-478d-8bf5-017cc394a56c
2023-03-27 23:43:58,946 [3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,946 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:58,946 [3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,946 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:58,946 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:58,946 [pool-1681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:58,956 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - fda26913-bdfb-48f8-b38a-a95200d457c8: addNew group-903AA5FF57FD:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER] returns group-903AA5FF57FD:java.util.concurrent.CompletableFuture@dc49d14[Not completed]
2023-03-27 23:43:58,956 [pool-1703-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - fda26913-bdfb-48f8-b38a-a95200d457c8: new RaftServerImpl for group-903AA5FF57FD:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-27 23:43:58,956 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-27 23:43:58,956 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-27 23:43:58,956 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-27 23:43:58,956 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-27 23:43:58,956 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-27 23:43:58,956 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-27 23:43:58,956 [pool-1703-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD: ConfigurationManager, init=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-27 23:43:58,956 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-6/data/ratis] (custom)
2023-03-27 23:43:58,957 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-27 23:43:58,957 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-27 23:43:58,957 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-27 23:43:58,957 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-27 23:43:58,957 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-27 23:43:58,958 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:43:58,958 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-27 23:43:58,958 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-27 23:43:58,958 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-27 23:43:58,958 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-27 23:43:58,958 [pool-1703-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-6/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd does not exist. Creating ...
2023-03-27 23:43:58,959 [pool-1703-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-6/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd/in_use.lock acquired by nodename 15260@fv-az462-845
2023-03-27 23:43:58,960 [pool-1703-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-6/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd has been successfully formatted.
2023-03-27 23:43:58,961 [pool-1703-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-903AA5FF57FD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-27 23:43:58,961 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-27 23:43:58,961 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-27 23:43:58,961 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:58,961 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-27 23:43:58,961 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-6/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-27 23:43:58,962 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-27 23:43:58,963 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-27 23:43:58,964 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:43:58,967 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-27 23:43:58,967 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-27 23:43:58,967 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-27 23:43:58,967 [pool-1703-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:58,967 [pool-1703-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-27 23:43:58,968 [pool-1703-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD: start as a follower, conf=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:58,968 [pool-1703-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-27 23:43:58,968 [pool-1703-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fda26913-bdfb-48f8-b38a-a95200d457c8: start fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState
2023-03-27 23:43:58,968 [pool-1703-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-903AA5FF57FD,id=fda26913-bdfb-48f8-b38a-a95200d457c8
2023-03-27 23:43:58,968 [fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:43:58,968 [fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:43:58,968 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-27 23:43:58,968 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-27 23:43:58,968 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-27 23:43:58,968 [pool-1703-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-27 23:43:58,975 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=35bc327f-518e-4ba7-b1e3-903aa5ff57fd.
2023-03-27 23:43:59,387 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5053547122ns, electionTimeout:5053ms
2023-03-27 23:43:59,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: shutdown 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState
2023-03-27 23:43:59,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:59,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:59,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: start 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96
2023-03-27 23:43:59,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:59,388 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96 PRE_VOTE round 0: result PASSED (term=0)
2023-03-27 23:43:59,389 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96 ELECTION round 0: submit vote requests at term 1 for -1: peers:[476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:59,389 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96 ELECTION round 0: result PASSED (term=1)
2023-03-27 23:43:59,389 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: shutdown 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96
2023-03-27 23:43:59,389 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:59,390 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-65F4DC8ECF0E with new leaderId: 476d332c-e00b-4a08-bd5a-0b3284a7ea0c
2023-03-27 23:43:59,390 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E: change Leader from null to 476d332c-e00b-4a08-bd5a-0b3284a7ea0c at term 1 for becomeLeader, leader elected after 5066ms
2023-03-27 23:43:59,390 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:59,390 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:59,390 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:59,390 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:59,390 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:59,390 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:59,390 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:59,391 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:59,391 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c: start 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderStateImpl
2023-03-27 23:43:59,391 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:59,394 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-LeaderElection96] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E: set configuration 0: peers:[476d332c-e00b-4a08-bd5a-0b3284a7ea0c|rpc:10.1.0.32:44901|dataStream:10.1.0.32:33491|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:59,395 [476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 476d332c-e00b-4a08-bd5a-0b3284a7ea0c@group-65F4DC8ECF0E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-5/data/ratis/0d225c0c-3853-4e9b-81d4-65f4dc8ecf0e/current/log_inprogress_0
2023-03-27 23:43:59,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:43:59,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:43:59,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:43:59,732 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5008447938ns, electionTimeout:5008ms
2023-03-27 23:43:59,732 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 38de582e-58a6-400e-852c-9e1084927a05: shutdown 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState
2023-03-27 23:43:59,732 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:43:59,732 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:43:59,732 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 38de582e-58a6-400e-852c-9e1084927a05: start 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97
2023-03-27 23:43:59,732 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[38de582e-58a6-400e-852c-9e1084927a05|rpc:10.1.0.32:33063|dataStream:10.1.0.32:40501|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:59,733 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97 PRE_VOTE round 0: result PASSED (term=0)
2023-03-27 23:43:59,734 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97 ELECTION round 0: submit vote requests at term 1 for -1: peers:[38de582e-58a6-400e-852c-9e1084927a05|rpc:10.1.0.32:33063|dataStream:10.1.0.32:40501|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:59,734 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97 ELECTION round 0: result PASSED (term=1)
2023-03-27 23:43:59,734 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 38de582e-58a6-400e-852c-9e1084927a05: shutdown 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97
2023-03-27 23:43:59,734 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:43:59,734 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-B3FC760A9277 with new leaderId: 38de582e-58a6-400e-852c-9e1084927a05
2023-03-27 23:43:59,734 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277: change Leader from null to 38de582e-58a6-400e-852c-9e1084927a05 at term 1 for becomeLeader, leader elected after 5022ms
2023-03-27 23:43:59,734 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:43:59,734 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:59,734 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:43:59,735 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:43:59,735 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:43:59,735 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:43:59,735 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:43:59,735 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:43:59,735 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 38de582e-58a6-400e-852c-9e1084927a05: start 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderStateImpl
2023-03-27 23:43:59,735 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:43:59,736 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-LeaderElection97] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277: set configuration 0: peers:[38de582e-58a6-400e-852c-9e1084927a05|rpc:10.1.0.32:33063|dataStream:10.1.0.32:40501|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:43:59,736 [38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 38de582e-58a6-400e-852c-9e1084927a05@group-B3FC760A9277-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c78ba74d-d893-4100-8e6e-4798e738ee0d/datanode-6/data/ratis/4e1a23bf-fbb6-4c74-99b8-b3fc760a9277/current/log_inprogress_0
2023-03-27 23:43:59,822 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:43:59,911 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(356)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-03-27 23:43:59,912 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1546)) - Container Balancer is not running.
2023-03-27 23:43:59,912 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1660)) - Stopping Replication Manager Service.
2023-03-27 23:43:59,912 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(310)) - Stopping Replication Monitor Thread.
2023-03-27 23:43:59,915 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1555)) - Stopping the Datanode Admin Monitor.
2023-03-27 23:43:59,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(880)) - Replication Monitor Thread is stopped
2023-03-27 23:43:59,915 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1562)) - Stopping datanode service RPC server
2023-03-27 23:43:59,915 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-03-27 23:43:59,917 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 38815
2023-03-27 23:43:59,918 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Under Replicated Processor interrupted. Exiting...
2023-03-27 23:43:59,918 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Over Replicated Processor interrupted. Exiting...
2023-03-27 23:43:59,921 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-27 23:43:59,923 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:43:59,924 [EndpointStateMachine task thread for /0.0.0.0:38815 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:38815 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az462-845/10.1.0.32"; destination host is: "0.0.0.0":38815; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy56.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-03-27 23:43:59,981 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-03-27 23:43:59,981 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1570)) - Stopping block service RPC server
2023-03-27 23:43:59,981 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-03-27 23:43:59,983 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 38901
2023-03-27 23:43:59,988 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1577)) - Stopping the StorageContainerLocationProtocol RPC server
2023-03-27 23:43:59,989 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(206)) - Stopping the RPC server for Client Protocol
2023-03-27 23:43:59,988 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-27 23:43:59,989 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:43:59,990 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 39209
2023-03-27 23:43:59,994 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-27 23:43:59,995 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1584)) - Stopping Storage Container Manager HTTP server.
2023-03-27 23:43:59,995 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:43:59,997 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@48ee8da8{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-27 23:43:59,998 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@9869881{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:43:59,998 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:43:59,999 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1fd12ba2{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-27 23:44:00,001 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@124d2d75{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:44:00,005 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1592)) - Stopping SCM LayoutVersionManager Service.
2023-03-27 23:44:00,005 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1600)) - Stopping Block Manager Service.
2023-03-27 23:44:00,006 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-27 23:44:00,006 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-27 23:44:00,006 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1622)) - Stopping SCM Event Queue.
2023-03-27 23:44:00,007 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1633)) - Stopping SCM HA services.
2023-03-27 23:44:00,007 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-03-27 23:44:00,007 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-03-27 23:44:00,007 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-03-27 23:44:00,007 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-03-27 23:44:00,008 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - HddsDatanode metrics system stopped (again)
2023-03-27 23:44:00,008 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-03-27 23:44:00,009 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-03-27 23:44:00,009 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState] INFO  impl.FollowerState (FollowerState.java:lostMajorityHeartbeatsRecently(108)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState: Skipping leader election since it stepped down recently (elapsed = 5118ms < waitTime = 10s)
2023-03-27 23:44:00,009 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-03-27 23:44:00,009 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-27 23:44:00,009 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-03-27 23:44:00,009 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(320)) - Replication Monitor Thread is not running.
2023-03-27 23:44:00,009 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(324)) - Cannot stop Container Balancer because it's not running or stopping
2023-03-27 23:44:00,009 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1651)) - Stopping SCM MetadataStore.
2023-03-27 23:44:00,010 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:44:00,011 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-27 23:44:00,011 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-27 23:44:00,011 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:44:00,011 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:44:00,038 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-27 23:44:00,038 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-27 23:44:00,043 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:44:00,087 [main] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 43 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:44:00,089 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-27 23:44:00,089 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-27 23:44:00,089 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-27 23:44:00,090 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-27 23:44:00,091 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-27 23:44:00,091 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-27 23:44:00,091 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-27 23:44:00,092 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-27 23:44:00,094 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-27 23:44:00,096 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-27 23:44:00,096 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-27 23:44:00,096 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-27 23:44:00,098 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-27 23:44:00,098 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-27 23:44:00,099 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(277)) - Starting Replication Monitor Thread.
2023-03-27 23:44:00,104 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-27 23:44:00,105 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-03-27 23:44:00,105 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 1, healthy pipeline threshold count is 1
2023-03-27 23:44:00,106 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 1, pipeline's with at least one datanode reported threshold count is 1
2023-03-27 23:44:00,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:00,106 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(398)) - SCM start with adminUsers: [runner]
2023-03-27 23:44:00,106 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:44:00,107 [Socket Reader #1 for port 38815] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 38815
2023-03-27 23:44:00,109 [Listener at 0.0.0.0/38815] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:44:00,109 [Socket Reader #1 for port 38901] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 38901
2023-03-27 23:44:00,112 [Listener at 0.0.0.0/38901] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:44:00,113 [Socket Reader #1 for port 39209] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 39209
2023-03-27 23:44:00,141 [Listener at 0.0.0.0/39209] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-27 23:44:00,141 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(415)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-27 23:44:00,141 [Listener at 0.0.0.0/39209] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-27 23:44:00,142 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1449)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:39209
2023-03-27 23:44:00,143 [Listener at 0.0.0.0/39209] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-03-27 23:44:00,146 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-03-27 23:44:00,147 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-03-27 23:44:00,159 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-03-27 23:44:00,159 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-03-27 23:44:00,191 [Listener at 0.0.0.0/39209] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(197)) - RPC server for Client  is listening at /0.0.0.0:39209
2023-03-27 23:44:00,192 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:44:00,199 [IPC Server listener on 39209] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 39209: starting
2023-03-27 23:44:00,209 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1463)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38901
2023-03-27 23:44:00,209 [Listener at 0.0.0.0/39209] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:38901
2023-03-27 23:44:00,209 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:44:00,209 [IPC Server listener on 38901] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 38901: starting
2023-03-27 23:44:00,211 [Listener at 0.0.0.0/39209] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:38815
2023-03-27 23:44:00,211 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:44:00,211 [IPC Server listener on 38815] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 38815: starting
2023-03-27 23:44:00,212 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3a36da5e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:44:00,217 [Listener at 0.0.0.0/39209] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:34629
2023-03-27 23:44:00,217 [Listener at 0.0.0.0/39209] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:44:00,218 [Listener at 0.0.0.0/39209] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:44:00,218 [Listener at 0.0.0.0/39209] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:44:00,219 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:44:00,219 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-27 23:44:00,219 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:44:00,220 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:44:00,220 [Listener at 0.0.0.0/39209] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/ozone-meta/webserver
2023-03-27 23:44:00,220 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34629
2023-03-27 23:44:00,220 [Listener at 0.0.0.0/39209] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:44:00,221 [Listener at 0.0.0.0/39209] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:44:00,221 [Listener at 0.0.0.0/39209] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:44:00,222 [Listener at 0.0.0.0/39209] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-27 23:44:00,222 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@474deb4c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:44:00,222 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2e88ad38{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-27 23:44:00,224 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@64745270{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-27 23:44:00,226 [Listener at 0.0.0.0/39209] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5ce0f50a{HTTP/1.1, (http/1.1)}{0.0.0.0:34629}
2023-03-27 23:44:00,227 [Listener at 0.0.0.0/39209] INFO  server.Server (Server.java:doStart(415)) - Started @187119ms
2023-03-27 23:44:00,227 [Listener at 0.0.0.0/39209] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:44:00,227 [Listener at 0.0.0.0/39209] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:34629
2023-03-27 23:44:00,227 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-27 23:44:00,228 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:44:00,228 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:44:00,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:00,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:00,943 [EndpointStateMachine task thread for /0.0.0.0:38815 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(1010)) - Retrying connect to server: 0.0.0.0/0.0.0.0:38815. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2023-03-27 23:44:00,949 [IPC Server handler 0 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:00,950 [IPC Server handler 1 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode fda26913-bdfb-48f8-b38a-a95200d457c8(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:00,950 [IPC Server handler 2 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 3a4aa664-0d4f-4943-bed7-1a9050fc989f(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:00,950 [IPC Server handler 3 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode b6ec7ff8-4fb1-4237-b084-632f2f252394(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:00,950 [IPC Server handler 4 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 0da438f1-d8bd-4523-91d3-cbc74717487d(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:00,956 [IPC Server handler 5 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:00,956 [IPC Server handler 6 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:00,957 [IPC Server handler 7 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:00,961 [IPC Server handler 8 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/fda26913-bdfb-48f8-b38a-a95200d457c8
2023-03-27 23:44:00,961 [IPC Server handler 8 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : fda26913-bdfb-48f8-b38a-a95200d457c8{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=36627, RATIS=45647, RATIS_ADMIN=45647, RATIS_SERVER=45647, RATIS_DATASTREAM=36631, STANDALONE=35567], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:00,969 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-27 23:44:00,969 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-03-27 23:44:00,974 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-27 23:44:00,982 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:00,987 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:44:01,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:01,228 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 1 of 7 DN Heartbeats.
2023-03-27 23:44:01,228 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-27 23:44:01,228 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:44:01,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:01,515 [IPC Server handler 0 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3a4aa664-0d4f-4943-bed7-1a9050fc989f
2023-03-27 23:44:01,515 [IPC Server handler 0 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 3a4aa664-0d4f-4943-bed7-1a9050fc989f{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=46569, RATIS=39079, RATIS_ADMIN=39079, RATIS_SERVER=39079, RATIS_DATASTREAM=34219, STANDALONE=44631], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:01,518 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-27 23:44:01,518 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-27 23:44:01,518 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 1
2023-03-27 23:44:01,518 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-27 23:44:01,518 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:44:01,527 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:01,528 [IPC Server handler 1 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/b6ec7ff8-4fb1-4237-b084-632f2f252394
2023-03-27 23:44:01,528 [IPC Server handler 1 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : b6ec7ff8-4fb1-4237-b084-632f2f252394{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=39077, RATIS=41001, RATIS_ADMIN=41001, RATIS_SERVER=41001, RATIS_DATASTREAM=34259, STANDALONE=36781], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:01,528 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:01,539 [IPC Server handler 2 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/0da438f1-d8bd-4523-91d3-cbc74717487d
2023-03-27 23:44:01,531 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:44:01,539 [IPC Server handler 2 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 0da438f1-d8bd-4523-91d3-cbc74717487d{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=38235, RATIS=46839, RATIS_ADMIN=46839, RATIS_SERVER=46839, RATIS_DATASTREAM=35639, STANDALONE=43611], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:01,531 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-27 23:44:01,540 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-27 23:44:01,531 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-27 23:44:01,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:01,540 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-27 23:44:01,540 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:01,541 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-27 23:44:01,541 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-27 23:44:01,541 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-27 23:44:01,541 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:01,541 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-27 23:44:01,788 [IPC Server handler 3 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/49220674-b9b6-430a-b99a-f5474fac1494
2023-03-27 23:44:01,788 [IPC Server handler 3 on default port 38815] INFO  node.NodeStateManager (NodeStateManager.java:newNodeStatus(338)) - Updating nodeOperationalState on registration as the datanode has a persisted state of IN_MAINTENANCE and expiry of 0
2023-03-27 23:44:01,788 [IPC Server handler 3 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 49220674-b9b6-430a-b99a-f5474fac1494{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=43069, RATIS=45963, RATIS_ADMIN=45963, RATIS_SERVER=45963, RATIS_DATASTREAM=32953, STANDALONE=43449], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:01,789 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:01,789 [EventQueue-NewNodeForNewNodeHandler] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:continueAdminForNode(267)) - Continue admin for datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:44:01,792 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-03-27 23:44:01,792 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-27 23:44:01,792 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-27 23:44:01,792 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-27 23:44:01,792 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-27 23:44:01,792 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-27 23:44:01,792 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-27 23:44:01,793 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-27 23:44:01,793 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1255)) - Service ReplicationManager transitions to RUNNING.
2023-03-27 23:44:01,793 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(132)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-27 23:44:01,922 [IPC Server handler 4 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:44:01,922 [IPC Server handler 4 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 2829ccc8-889f-48cc-a62b-b3954aa0680c{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=38649, RATIS=35843, RATIS_ADMIN=35843, RATIS_SERVER=35843, RATIS_DATASTREAM=33845, STANDALONE=36853], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:01,922 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:01,941 [IPC Server handler 5 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3fee8600-457c-478d-8bf5-017cc394a56c
2023-03-27 23:44:01,941 [IPC Server handler 5 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 3fee8600-457c-478d-8bf5-017cc394a56c{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=35611, RATIS=37685, RATIS_ADMIN=37685, RATIS_SERVER=37685, RATIS_DATASTREAM=41173, STANDALONE=46071], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:01,941 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:01,942 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0. Excluded 6.
2023-03-27 23:44:02,106 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:44:02,106 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Finalizing its pipelines []
2023-03-27 23:44:02,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:02,228 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-27 23:44:02,229 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Cluster exits safe mode
2023-03-27 23:44:02,229 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-27 23:44:02,233 [Listener at 0.0.0.0/39209] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:44:02,234 [Listener at 0.0.0.0/39209] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 49220674-b9b6-430a-b99a-f5474fac1494: close
2023-03-27 23:44:02,234 [Listener at 0.0.0.0/39209] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 49220674-b9b6-430a-b99a-f5474fac1494: shutdown server GrpcServerProtocolService now
2023-03-27 23:44:02,234 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 49220674-b9b6-430a-b99a-f5474fac1494: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-27 23:44:02,235 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 49220674-b9b6-430a-b99a-f5474fac1494: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-27 23:44:02,235 [grpc-default-executor-2] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 49220674-b9b6-430a-b99a-f5474fac1494: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-27 23:44:02,235 [grpc-default-executor-2] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 49220674-b9b6-430a-b99a-f5474fac1494: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-27 23:44:02,235 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 49220674-b9b6-430a-b99a-f5474fac1494: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-27 23:44:02,235 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-GrpcLogAppender is already stopped
2023-03-27 23:44:02,235 [grpc-default-executor-7] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-GrpcLogAppender is already stopped
2023-03-27 23:44:02,238 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-GrpcLogAppender is already stopped
2023-03-27 23:44:02,238 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-GrpcLogAppender is already stopped
2023-03-27 23:44:02,238 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725->49220674-b9b6-430a-b99a-f5474fac1494-GrpcLogAppender is already stopped
2023-03-27 23:44:02,238 [Listener at 0.0.0.0/39209] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 49220674-b9b6-430a-b99a-f5474fac1494: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:44:02,238 [49220674-b9b6-430a-b99a-f5474fac1494-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xfa805d11, L:/0:0:0:0:0:0:0:0:32953] CLOSE
2023-03-27 23:44:02,238 [49220674-b9b6-430a-b99a-f5474fac1494-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xfa805d11, L:/0:0:0:0:0:0:0:0:32953] INACTIVE
2023-03-27 23:44:02,238 [49220674-b9b6-430a-b99a-f5474fac1494-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xfa805d11, L:/0:0:0:0:0:0:0:0:32953] UNREGISTERED
2023-03-27 23:44:02,249 [JvmPauseMonitor37] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-49220674-b9b6-430a-b99a-f5474fac1494: Stopped
2023-03-27 23:44:02,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:02,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:03,106 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:44:03,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:03,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:03,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:03,930 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5002420946ns, electionTimeout:5002ms
2023-03-27 23:44:03,930 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: shutdown 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState
2023-03-27 23:44:03,930 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-27 23:44:03,930 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:44:03,930 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: start 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98
2023-03-27 23:44:03,931 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:44:03,931 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:44:03,931 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:44:03,932 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD: receive requestVote(PRE_VOTE, 2829ccc8-889f-48cc-a62b-b3954aa0680c, group-903AA5FF57FD, 0, (t:0, i:0))
2023-03-27 23:44:03,932 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(49)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FOLLOWER: accept PRE_VOTE from 2829ccc8-889f-48cc-a62b-b3954aa0680c: our priority 0 <= candidate's priority 1
2023-03-27 23:44:03,932 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD replies to PRE_VOTE vote request: 2829ccc8-889f-48cc-a62b-b3954aa0680c<-3fee8600-457c-478d-8bf5-017cc394a56c#0:OK-t0. Peer's state: 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD:t0, leader=null, voted=, raftlog=Memoized:3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:44:03,933 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for fda26913-bdfb-48f8-b38a-a95200d457c8
2023-03-27 23:44:03,934 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-27 23:44:03,934 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 2829ccc8-889f-48cc-a62b-b3954aa0680c<-3fee8600-457c-478d-8bf5-017cc394a56c#0:OK-t0
2023-03-27 23:44:03,935 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98 PRE_VOTE round 0: result PASSED
2023-03-27 23:44:03,936 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98 ELECTION round 0: submit vote requests at term 1 for -1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:44:03,937 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD: receive requestVote(ELECTION, 2829ccc8-889f-48cc-a62b-b3954aa0680c, group-903AA5FF57FD, 1, (t:0, i:0))
2023-03-27 23:44:03,937 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(49)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FOLLOWER: accept ELECTION from 2829ccc8-889f-48cc-a62b-b3954aa0680c: our priority 0 <= candidate's priority 1
2023-03-27 23:44:03,937 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:44:03,937 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3fee8600-457c-478d-8bf5-017cc394a56c: shutdown 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState
2023-03-27 23:44:03,937 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:44:03,937 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:44:03,938 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD: receive requestVote(PRE_VOTE, 2829ccc8-889f-48cc-a62b-b3954aa0680c, group-903AA5FF57FD, 0, (t:0, i:0))
2023-03-27 23:44:03,938 [grpc-default-executor-9] INFO  impl.VoteContext (VoteContext.java:log(49)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FOLLOWER: accept PRE_VOTE from 2829ccc8-889f-48cc-a62b-b3954aa0680c: our priority 0 <= candidate's priority 1
2023-03-27 23:44:03,938 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD replies to PRE_VOTE vote request: 2829ccc8-889f-48cc-a62b-b3954aa0680c<-fda26913-bdfb-48f8-b38a-a95200d457c8#0:OK-t0. Peer's state: fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD:t0, leader=null, voted=, raftlog=Memoized:fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:44:03,939 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3fee8600-457c-478d-8bf5-017cc394a56c: start 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState
2023-03-27 23:44:03,939 [3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState was interrupted
2023-03-27 23:44:03,939 [3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:44:03,939 [3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:44:03,939 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD: receive requestVote(ELECTION, 2829ccc8-889f-48cc-a62b-b3954aa0680c, group-903AA5FF57FD, 1, (t:0, i:0))
2023-03-27 23:44:03,939 [grpc-default-executor-9] INFO  impl.VoteContext (VoteContext.java:log(49)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FOLLOWER: accept ELECTION from 2829ccc8-889f-48cc-a62b-b3954aa0680c: our priority 0 <= candidate's priority 1
2023-03-27 23:44:03,939 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:44:03,939 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fda26913-bdfb-48f8-b38a-a95200d457c8: shutdown fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState
2023-03-27 23:44:03,939 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fda26913-bdfb-48f8-b38a-a95200d457c8: start fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState
2023-03-27 23:44:03,940 [fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState was interrupted
2023-03-27 23:44:03,940 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD replies to ELECTION vote request: 2829ccc8-889f-48cc-a62b-b3954aa0680c<-3fee8600-457c-478d-8bf5-017cc394a56c#0:OK-t1. Peer's state: 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD:t1, leader=null, voted=2829ccc8-889f-48cc-a62b-b3954aa0680c, raftlog=Memoized:3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:44:03,941 [fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-27 23:44:03,941 [fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-27 23:44:03,941 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-27 23:44:03,941 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 2829ccc8-889f-48cc-a62b-b3954aa0680c<-3fee8600-457c-478d-8bf5-017cc394a56c#0:OK-t1
2023-03-27 23:44:03,941 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98 ELECTION round 0: result PASSED
2023-03-27 23:44:03,941 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: shutdown 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98
2023-03-27 23:44:03,941 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD replies to ELECTION vote request: 2829ccc8-889f-48cc-a62b-b3954aa0680c<-fda26913-bdfb-48f8-b38a-a95200d457c8#0:OK-t1. Peer's state: fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD:t1, leader=null, voted=2829ccc8-889f-48cc-a62b-b3954aa0680c, raftlog=Memoized:fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:44:03,941 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-27 23:44:03,941 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-903AA5FF57FD with new leaderId: 2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:44:03,941 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD: change Leader from null to 2829ccc8-889f-48cc-a62b-b3954aa0680c at term 1 for becomeLeader, leader elected after 5024ms
2023-03-27 23:44:03,942 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-27 23:44:03,942 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:44:03,942 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-27 23:44:03,942 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-27 23:44:03,942 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-27 23:44:03,942 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-27 23:44:03,942 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-27 23:44:03,942 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-27 23:44:03,943 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-27 23:44:03,943 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:44:03,943 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-27 23:44:03,943 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-27 23:44:03,943 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:44:03,943 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:44:03,943 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:44:03,943 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-27 23:44:03,944 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-27 23:44:03,944 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-27 23:44:03,944 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-27 23:44:03,944 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-27 23:44:03,944 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-27 23:44:03,944 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-27 23:44:03,944 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-27 23:44:03,945 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-27 23:44:03,945 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: start 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderStateImpl
2023-03-27 23:44:03,945 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:44:03,946 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 35bc327f-518e-4ba7-b1e3-903aa5ff57fd, Nodes: 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)fda26913-bdfb-48f8-b38a-a95200d457c8(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:2829ccc8-889f-48cc-a62b-b3954aa0680c, CreationTimestamp2023-03-27T23:44:00.090Z[Etc/UTC]] moved to OPEN state
2023-03-27 23:44:03,950 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd/current/log_inprogress_0
2023-03-27 23:44:03,960 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderElection98] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD: set configuration 0: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:44:03,963 [3fee8600-457c-478d-8bf5-017cc394a56c-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-903AA5FF57FD with new leaderId: 2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:44:03,963 [3fee8600-457c-478d-8bf5-017cc394a56c-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD: change Leader from null to 2829ccc8-889f-48cc-a62b-b3954aa0680c at term 1 for appendEntries, leader elected after 5028ms
2023-03-27 23:44:03,971 [fda26913-bdfb-48f8-b38a-a95200d457c8-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-903AA5FF57FD with new leaderId: 2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:44:03,971 [fda26913-bdfb-48f8-b38a-a95200d457c8-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD: change Leader from null to 2829ccc8-889f-48cc-a62b-b3954aa0680c at term 1 for appendEntries, leader elected after 5014ms
2023-03-27 23:44:04,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:04,421 [JvmPauseMonitor54] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-117526ec-9427-41bf-9dbd-c8f743595c9c: Detected pause in JVM or host machine (eg GC): pause of approximately 120351152ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=390ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:44:04,421 [JvmPauseMonitor58] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-38de582e-58a6-400e-852c-9e1084927a05: Detected pause in JVM or host machine (eg GC): pause of approximately 145779076ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=390ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:44:04,421 [JvmPauseMonitor56] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-3d5bec3e-3873-417f-9114-370ff3a7c03a: Detected pause in JVM or host machine (eg GC): pause of approximately 173724272ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=390ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:44:04,422 [JvmPauseMonitor55] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-4ba86ab6-fed9-4bb6-8f8b-120ddf0c96d6: Detected pause in JVM or host machine (eg GC): pause of approximately 173917570ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=390ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:44:04,423 [JvmPauseMonitor52] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-5c7a3766-4df9-4a62-b680-fc04cc352416: Detected pause in JVM or host machine (eg GC): pause of approximately 263889395ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=390ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:44:04,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:04,424 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:44:04,424 [JvmPauseMonitor51] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 325867222ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=390ms
GC pool 'PS Scavenge' had collection(s): count=1 time=54ms
2023-03-27 23:44:04,432 [Listener at 0.0.0.0/39209] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-3/data-0/containers/hdds/688b4844-e085-4513-aaec-821622cea348/DS-645240ef-02cf-4937-861d-fe0dae7d8e31/container.db for volume DS-645240ef-02cf-4937-861d-fe0dae7d8e31
2023-03-27 23:44:04,432 [Listener at 0.0.0.0/39209] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-27 23:44:04,432 [Listener at 0.0.0.0/39209] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-27 23:44:04,432 [fda26913-bdfb-48f8-b38a-a95200d457c8-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD: set configuration 0: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:44:04,433 [fda26913-bdfb-48f8-b38a-a95200d457c8-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:44:04,433 [3fee8600-457c-478d-8bf5-017cc394a56c-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD: set configuration 0: peers:[3fee8600-457c-478d-8bf5-017cc394a56c|rpc:10.1.0.32:37685|dataStream:10.1.0.32:41173|priority:0|startupRole:FOLLOWER, 2829ccc8-889f-48cc-a62b-b3954aa0680c|rpc:10.1.0.32:35843|dataStream:10.1.0.32:33845|priority:1|startupRole:FOLLOWER, fda26913-bdfb-48f8-b38a-a95200d457c8|rpc:10.1.0.32:45647|dataStream:10.1.0.32:36631|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-27 23:44:04,433 [3fee8600-457c-478d-8bf5-017cc394a56c-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-27 23:44:04,435 [fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - fda26913-bdfb-48f8-b38a-a95200d457c8@group-903AA5FF57FD-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-6/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd/current/log_inprogress_0
2023-03-27 23:44:04,436 [Listener at 0.0.0.0/39209] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-27 23:44:04,437 [3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 3fee8600-457c-478d-8bf5-017cc394a56c@group-903AA5FF57FD-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-5/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd/current/log_inprogress_0
2023-03-27 23:44:04,455 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@746bd79f{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-27 23:44:04,456 [Listener at 0.0.0.0/39209] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1f603a21{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:44:04,456 [Listener at 0.0.0.0/39209] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:44:04,458 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@9107c1d{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-27 23:44:04,460 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2d7e5b5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:44:04,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:04,826 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32) moved to stale state. Finalizing its pipelines []
2023-03-27 23:44:05,106 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:44:05,107 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState: change to CANDIDATE, lastRpcElapsedTime:10216876765ns, electionTimeout:5098ms
2023-03-27 23:44:05,107 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: shutdown 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState
2023-03-27 23:44:05,107 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2023-03-27 23:44:05,107 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-27 23:44:05,107 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: start 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-3BACC333D725-LeaderElection99
2023-03-27 23:44:05,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:05,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 4 milliseconds for processing 6 containers.
2023-03-27 23:44:05,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:06,106 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:44:06,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:06,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:06,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:07,106 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-27 23:44:07,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:07,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:07,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:07,830 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(83)) - A dead datanode is detected. 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:44:07,830 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(96)) - Clearing command queue of size 0 for DN 49220674-b9b6-430a-b99a-f5474fac1494(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:44:07,830 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/49220674-b9b6-430a-b99a-f5474fac1494
2023-03-27 23:44:07,863 [Listener at 0.0.0.0/39209] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(356)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-03-27 23:44:07,863 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1546)) - Container Balancer is not running.
2023-03-27 23:44:07,863 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1660)) - Stopping Replication Manager Service.
2023-03-27 23:44:07,863 [Listener at 0.0.0.0/39209] INFO  replication.ReplicationManager (ReplicationManager.java:stop(310)) - Stopping Replication Monitor Thread.
2023-03-27 23:44:07,863 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1555)) - Stopping the Datanode Admin Monitor.
2023-03-27 23:44:07,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(880)) - Replication Monitor Thread is stopped
2023-03-27 23:44:07,863 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1562)) - Stopping datanode service RPC server
2023-03-27 23:44:07,863 [Listener at 0.0.0.0/39209] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-03-27 23:44:07,864 [Listener at 0.0.0.0/39209] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 38815
2023-03-27 23:44:07,867 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Under Replicated Processor interrupted. Exiting...
2023-03-27 23:44:07,869 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Over Replicated Processor interrupted. Exiting...
2023-03-27 23:44:07,876 [IPC Server listener on 38815] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 38815
2023-03-27 23:44:07,876 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:44:07,930 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-03-27 23:44:07,930 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1570)) - Stopping block service RPC server
2023-03-27 23:44:07,930 [Listener at 0.0.0.0/39209] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-03-27 23:44:07,930 [Listener at 0.0.0.0/39209] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 38901
2023-03-27 23:44:07,934 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1577)) - Stopping the StorageContainerLocationProtocol RPC server
2023-03-27 23:44:07,934 [Listener at 0.0.0.0/39209] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(206)) - Stopping the RPC server for Client Protocol
2023-03-27 23:44:07,934 [Listener at 0.0.0.0/39209] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 39209
2023-03-27 23:44:07,934 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:44:07,935 [IPC Server listener on 38901] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 38901
2023-03-27 23:44:07,937 [IPC Server listener on 39209] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 39209
2023-03-27 23:44:07,937 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1584)) - Stopping Storage Container Manager HTTP server.
2023-03-27 23:44:07,937 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:44:07,938 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@64745270{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-27 23:44:07,938 [Listener at 0.0.0.0/39209] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5ce0f50a{HTTP/1.1, (http/1.1)}{0.0.0.0:34629}
2023-03-27 23:44:07,938 [Listener at 0.0.0.0/39209] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:44:07,939 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2e88ad38{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-27 23:44:07,939 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@474deb4c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:44:07,941 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1592)) - Stopping SCM LayoutVersionManager Service.
2023-03-27 23:44:07,941 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1600)) - Stopping Block Manager Service.
2023-03-27 23:44:07,941 [Listener at 0.0.0.0/39209] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-27 23:44:07,942 [Listener at 0.0.0.0/39209] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-27 23:44:07,942 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1622)) - Stopping SCM Event Queue.
2023-03-27 23:44:07,942 [EndpointStateMachine task thread for /0.0.0.0:38815 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:38815 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az462-845/10.1.0.32"; destination host is: "0.0.0.0":38815; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy56.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-03-27 23:44:07,944 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1633)) - Stopping SCM HA services.
2023-03-27 23:44:07,944 [Listener at 0.0.0.0/39209] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-03-27 23:44:07,945 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-03-27 23:44:07,945 [Listener at 0.0.0.0/39209] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-03-27 23:44:07,945 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2023-03-27 23:44:07,946 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-03-27 23:44:07,948 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-03-27 23:44:07,950 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2023-03-27 23:44:07,950 [Listener at 0.0.0.0/39209] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-03-27 23:44:07,950 [Listener at 0.0.0.0/39209] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-03-27 23:44:07,950 [Listener at 0.0.0.0/39209] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-03-27 23:44:07,950 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-03-27 23:44:07,950 [Listener at 0.0.0.0/39209] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-27 23:44:07,950 [Listener at 0.0.0.0/39209] INFO  replication.ReplicationManager (ReplicationManager.java:stop(320)) - Replication Monitor Thread is not running.
2023-03-27 23:44:07,950 [Listener at 0.0.0.0/39209] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(324)) - Cannot stop Container Balancer because it's not running or stopping
2023-03-27 23:44:07,951 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1651)) - Stopping SCM MetadataStore.
2023-03-27 23:44:07,952 [Listener at 0.0.0.0/39209] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:44:07,952 [Listener at 0.0.0.0/39209] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-27 23:44:07,952 [Listener at 0.0.0.0/39209] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-27 23:44:07,952 [Listener at 0.0.0.0/39209] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:44:07,952 [Listener at 0.0.0.0/39209] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-27 23:44:07,996 [Listener at 0.0.0.0/39209] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-27 23:44:07,996 [Listener at 0.0.0.0/39209] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-27 23:44:07,998 [Listener at 0.0.0.0/39209] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-27 23:44:08,045 [Listener at 0.0.0.0/39209] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 46 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-27 23:44:08,046 [Listener at 0.0.0.0/39209] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-27 23:44:08,054 [Listener at 0.0.0.0/39209] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-27 23:44:08,054 [Listener at 0.0.0.0/39209] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-27 23:44:08,054 [Listener at 0.0.0.0/39209] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-27 23:44:08,055 [Listener at 0.0.0.0/39209] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-27 23:44:08,055 [Listener at 0.0.0.0/39209] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-27 23:44:08,055 [Listener at 0.0.0.0/39209] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-27 23:44:08,055 [Listener at 0.0.0.0/39209] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-27 23:44:08,055 [Listener at 0.0.0.0/39209] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-27 23:44:08,057 [Listener at 0.0.0.0/39209] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-27 23:44:08,057 [Listener at 0.0.0.0/39209] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-27 23:44:08,057 [Listener at 0.0.0.0/39209] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-27 23:44:08,059 [Listener at 0.0.0.0/39209] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-27 23:44:08,059 [Listener at 0.0.0.0/39209] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-27 23:44:08,059 [Listener at 0.0.0.0/39209] INFO  replication.ReplicationManager (ReplicationManager.java:start(277)) - Starting Replication Monitor Thread.
2023-03-27 23:44:08,060 [Listener at 0.0.0.0/39209] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-27 23:44:08,060 [Listener at 0.0.0.0/39209] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-03-27 23:44:08,060 [Listener at 0.0.0.0/39209] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 2, healthy pipeline threshold count is 1
2023-03-27 23:44:08,061 [Listener at 0.0.0.0/39209] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2023-03-27 23:44:08,061 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(398)) - SCM start with adminUsers: [runner]
2023-03-27 23:44:08,061 [Listener at 0.0.0.0/39209] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:44:08,062 [Socket Reader #1 for port 38815] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 38815
2023-03-27 23:44:08,062 [Listener at 0.0.0.0/38815] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:44:08,063 [Socket Reader #1 for port 38901] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 38901
2023-03-27 23:44:08,063 [Listener at 0.0.0.0/38901] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-27 23:44:08,064 [Socket Reader #1 for port 39209] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 39209
2023-03-27 23:44:08,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:08,072 [Listener at 0.0.0.0/39209] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-27 23:44:08,072 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(415)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-27 23:44:08,073 [Listener at 0.0.0.0/39209] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-27 23:44:08,073 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1449)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:39209
2023-03-27 23:44:08,074 [Listener at 0.0.0.0/39209] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-03-27 23:44:08,074 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-03-27 23:44:08,075 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-03-27 23:44:08,084 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-03-27 23:44:08,085 [Listener at 0.0.0.0/39209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-03-27 23:44:08,110 [Listener at 0.0.0.0/39209] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(197)) - RPC server for Client  is listening at /0.0.0.0:39209
2023-03-27 23:44:08,111 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:44:08,118 [IPC Server listener on 39209] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 39209: starting
2023-03-27 23:44:08,165 [Listener at 0.0.0.0/39209] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1463)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38901
2023-03-27 23:44:08,165 [Listener at 0.0.0.0/39209] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:38901
2023-03-27 23:44:08,167 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:44:08,171 [IPC Server listener on 38901] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 38901: starting
2023-03-27 23:44:08,184 [Listener at 0.0.0.0/39209] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:38815
2023-03-27 23:44:08,184 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-27 23:44:08,184 [IPC Server listener on 38815] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 38815: starting
2023-03-27 23:44:08,197 [Listener at 0.0.0.0/39209] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:34629
2023-03-27 23:44:08,197 [Listener at 0.0.0.0/39209] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-27 23:44:08,198 [Listener at 0.0.0.0/39209] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-27 23:44:08,198 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@cef23a8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-27 23:44:08,202 [Listener at 0.0.0.0/39209] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-27 23:44:08,203 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-27 23:44:08,203 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-27 23:44:08,203 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-27 23:44:08,203 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-27 23:44:08,204 [Listener at 0.0.0.0/39209] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/ozone-meta/webserver
2023-03-27 23:44:08,204 [Listener at 0.0.0.0/39209] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34629
2023-03-27 23:44:08,204 [Listener at 0.0.0.0/39209] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-27 23:44:08,214 [Listener at 0.0.0.0/39209] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-27 23:44:08,214 [Listener at 0.0.0.0/39209] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-27 23:44:08,215 [Listener at 0.0.0.0/39209] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-27 23:44:08,215 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@a1689e8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-27 23:44:08,216 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@23b3afb4{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-27 23:44:08,217 [Listener at 0.0.0.0/39209] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@487ee2a{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-27 23:44:08,238 [Listener at 0.0.0.0/39209] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@790ea58f{HTTP/1.1, (http/1.1)}{0.0.0.0:34629}
2023-03-27 23:44:08,239 [Listener at 0.0.0.0/39209] INFO  server.Server (Server.java:doStart(415)) - Started @195130ms
2023-03-27 23:44:08,239 [Listener at 0.0.0.0/39209] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-27 23:44:08,239 [Listener at 0.0.0.0/39209] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:34629
2023-03-27 23:44:08,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:08,519 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:08,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:08,947 [EndpointStateMachine task thread for /0.0.0.0:38815 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(1010)) - Retrying connect to server: 0.0.0.0/0.0.0.0:38815. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2023-03-27 23:44:08,962 [IPC Server handler 1 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode fda26913-bdfb-48f8-b38a-a95200d457c8(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:08,962 [IPC Server handler 2 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 3a4aa664-0d4f-4943-bed7-1a9050fc989f(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:08,964 [IPC Server handler 2 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 0da438f1-d8bd-4523-91d3-cbc74717487d(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:08,964 [IPC Server handler 0 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:08,966 [IPC Server handler 1 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode b6ec7ff8-4fb1-4237-b084-632f2f252394(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:08,966 [IPC Server handler 1 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:08,966 [IPC Server handler 6 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:08,967 [IPC Server handler 7 on default port 38815] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode fda26913-bdfb-48f8-b38a-a95200d457c8(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32). Asking datanode to re-register.
2023-03-27 23:44:09,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:09,163 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:09,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:09,514 [IPC Server handler 2 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3a4aa664-0d4f-4943-bed7-1a9050fc989f
2023-03-27 23:44:09,514 [IPC Server handler 2 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 3a4aa664-0d4f-4943-bed7-1a9050fc989f{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=46569, RATIS=39079, RATIS_ADMIN=39079, RATIS_SERVER=39079, RATIS_DATASTREAM=34219, STANDALONE=44631], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:09,519 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-27 23:44:09,519 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-27 23:44:09,521 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-03-27 23:44:09,533 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:09,536 [IPC Server handler 0 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/0da438f1-d8bd-4523-91d3-cbc74717487d
2023-03-27 23:44:09,536 [IPC Server handler 0 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 0da438f1-d8bd-4523-91d3-cbc74717487d{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=38235, RATIS=46839, RATIS_ADMIN=46839, RATIS_SERVER=46839, RATIS_DATASTREAM=35639, STANDALONE=43611], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:09,536 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-27 23:44:09,536 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-27 23:44:09,538 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:09,538 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-03-27 23:44:09,538 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:44:09,538 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:44:09,539 [IPC Server handler 1 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/b6ec7ff8-4fb1-4237-b084-632f2f252394
2023-03-27 23:44:09,539 [IPC Server handler 1 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : b6ec7ff8-4fb1-4237-b084-632f2f252394{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=39077, RATIS=41001, RATIS_ADMIN=41001, RATIS_SERVER=41001, RATIS_DATASTREAM=34259, STANDALONE=36781], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:09,540 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-27 23:44:09,540 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-03-27 23:44:09,541 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-27 23:44:09,545 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-27 23:44:09,545 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-27 23:44:09,541 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-27 23:44:09,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:09,548 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:09,548 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-27 23:44:09,550 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-27 23:44:09,550 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-27 23:44:09,550 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:09,551 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:09,941 [IPC Server handler 6 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3fee8600-457c-478d-8bf5-017cc394a56c
2023-03-27 23:44:09,941 [IPC Server handler 6 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 3fee8600-457c-478d-8bf5-017cc394a56c{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=35611, RATIS=37685, RATIS_ADMIN=37685, RATIS_SERVER=37685, RATIS_DATASTREAM=41173, STANDALONE=46071], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:09,942 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:09,944 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-03-27 23:44:09,944 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-27 23:44:09,944 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 2
2023-03-27 23:44:09,944 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-27 23:44:09,944 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-27 23:44:09,944 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-27 23:44:09,944 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-27 23:44:09,945 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-27 23:44:09,945 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-27 23:44:09,945 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-27 23:44:09,945 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1255)) - Service ReplicationManager transitions to RUNNING.
2023-03-27 23:44:09,945 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(132)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-27 23:44:09,947 [IPC Server handler 7 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:44:09,947 [IPC Server handler 7 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 2829ccc8-889f-48cc-a62b-b3954aa0680c{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=38649, RATIS=35843, RATIS_ADMIN=35843, RATIS_SERVER=35843, RATIS_DATASTREAM=33845, STANDALONE=36853], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:09,947 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:09,963 [IPC Server handler 3 on default port 38815] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/fda26913-bdfb-48f8-b38a-a95200d457c8
2023-03-27 23:44:09,963 [IPC Server handler 3 on default port 38815] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : fda26913-bdfb-48f8-b38a-a95200d457c8{ip: 10.1.0.32, host: fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net, ports: [REPLICATION=36627, RATIS=45647, RATIS_ADMIN=45647, RATIS_SERVER=45647, RATIS_DATASTREAM=36631, STANDALONE=35567], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-27 23:44:09,965 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-27 23:44:09,966 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(160)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0. Excluded 6.
2023-03-27 23:44:10,005 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:10,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:10,368 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:10,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:10,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:10,724 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:11,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:11,084 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:11,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:11,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:12,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(352)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-27 23:44:12,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:12,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:13,076 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-03-27 23:44:13,076 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=1, replicaIndex=0, sourceNodes=[3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)], priority=NORMAL to 3a4aa664-0d4f-4943-bed7-1a9050fc989f(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:44:13,078 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #4 is under replicated. Expected replica count is 3, but found 2.
2023-03-27 23:44:13,078 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=4, replicaIndex=0, sourceNodes=[3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)], priority=NORMAL to b6ec7ff8-4fb1-4237-b084-632f2f252394(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:44:13,087 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #6 is under replicated. Expected replica count is 3, but found 2.
2023-03-27 23:44:13,087 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=6, replicaIndex=0, sourceNodes=[3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)], priority=NORMAL to b6ec7ff8-4fb1-4237-b084-632f2f252394(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)
2023-03-27 23:44:13,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 14 milliseconds for processing 6 containers.
2023-03-27 23:44:13,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:13,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:14,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:14,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:14,516 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 1 from [3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)] using NO_COMPRESSION
2023-03-27 23:44:14,519 [grpc-default-executor-9] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(62)) - Streaming container data (1) to other datanode with compression NO_COMPRESSION
2023-03-27 23:44:14,543 [grpc-default-executor-9] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(111)) - Sent 11776 bytes for container 1
2023-03-27 23:44:14,545 [grpc-default-executor-8] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(218)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-0/data-0/containers/tmp/container-copy/container-1.tar
2023-03-27 23:44:14,548 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 1 is downloaded with size 11776, starting to import.
2023-03-27 23:44:14,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:14,575 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 1 is replicated successfully
2023-03-27 23:44:14,575 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(220)) - Successful DONE replicateContainerCommand: containerId=1, replicaIndex=0, sourceNodes=[3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)], priority=NORMAL, transferred 11776 bytes
2023-03-27 23:44:15,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-27 23:44:15,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:15,540 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 6 from [3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)] using NO_COMPRESSION
2023-03-27 23:44:15,540 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 4 from [3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)] using NO_COMPRESSION
2023-03-27 23:44:15,547 [grpc-default-executor-1] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(62)) - Streaming container data (4) to other datanode with compression NO_COMPRESSION
2023-03-27 23:44:15,548 [grpc-default-executor-9] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(62)) - Streaming container data (6) to other datanode with compression NO_COMPRESSION
2023-03-27 23:44:15,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:15,552 [grpc-default-executor-1] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(111)) - Sent 11776 bytes for container 4
2023-03-27 23:44:15,552 [grpc-default-executor-1] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(218)) - Container 4 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-2/data-0/containers/tmp/container-copy/container-4.tar
2023-03-27 23:44:15,555 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 4 is downloaded with size 11776, starting to import.
2023-03-27 23:44:15,576 [grpc-default-executor-9] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(111)) - Sent 11776 bytes for container 6
2023-03-27 23:44:15,580 [grpc-default-executor-1] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(218)) - Container 6 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-2/data-0/containers/tmp/container-copy/container-6.tar
2023-03-27 23:44:15,582 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 6 is downloaded with size 11776, starting to import.
2023-03-27 23:44:15,595 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 4 is replicated successfully
2023-03-27 23:44:15,595 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(220)) - Successful DONE replicateContainerCommand: containerId=4, replicaIndex=0, sourceNodes=[3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)], priority=NORMAL, transferred 11776 bytes
2023-03-27 23:44:15,597 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 6 is replicated successfully
2023-03-27 23:44:15,597 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(220)) - Successful DONE replicateContainerCommand: containerId=6, replicaIndex=0, sourceNodes=[3fee8600-457c-478d-8bf5-017cc394a56c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32), 2829ccc8-889f-48cc-a62b-b3954aa0680c(fv-az462-845.5dk1zbeb1hiuljg1e1zidnqquc.phxx.internal.cloudapp.net/10.1.0.32)], priority=NORMAL, transferred 11776 bytes
2023-03-27 23:44:16,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:16,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:16,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:17,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:17,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:17,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:18,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-27 23:44:18,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:18,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:19,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:19,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:19,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:20,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:20,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:20,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:21,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-27 23:44:21,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:21,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:22,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:22,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:22,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:23,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:23,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:23,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:24,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-27 23:44:24,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:24,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:25,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:25,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-27 23:44:25,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:26,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:26,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:26,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:27,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-27 23:44:27,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:27,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:28,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:28,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:28,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:29,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:29,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:29,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:30,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-27 23:44:30,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:30,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:31,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:31,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:31,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:31,714 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:32,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:32,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:32,503 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:32,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:32,875 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:33,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:33,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:33,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:33,790 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:34,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:34,180 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:34,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:34,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:34,812 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-27 23:44:35,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:35,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:35,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:36,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:36,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:36,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:37,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:37,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-27 23:44:37,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:38,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-27 23:44:38,358 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(455)) - Shutting down the Mini Ozone Cluster
2023-03-27 23:44:38,368 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(471)) - Stopping the Mini Ozone Cluster
2023-03-27 23:44:38,368 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(553)) - Stopping the OzoneManager
2023-03-27 23:44:38,368 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(2155)) - om1[localhost:0]: Stopping Ozone Manager
2023-03-27 23:44:38,375 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 43801
2023-03-27 23:44:38,385 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-27 23:44:38,386 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-27 23:44:38,386 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-03-27 23:44:38,390 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-03-27 23:44:38,390 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:44:38,390 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-03-27 23:44:38,390 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2023-03-27 23:44:38,390 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-03-27 23:44:38,391 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-03-27 23:44:38,405 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:88)
2023-03-27 23:44:38,405 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 88
2023-03-27 23:44:38,425 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 88
2023-03-27 23:44:38,426 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 88
2023-03-27 23:44:38,426 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-27 23:44:38,426 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(540)) - Stopping OMDoubleBuffer flush thread
2023-03-27 23:44:38,426 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(625)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-03-27 23:44:38,427 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 88
2023-03-27 23:44:38,427 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:44:38,428 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-03-27 23:44:38,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(385)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-27 23:44:38,431 [JvmPauseMonitor33] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-03-27 23:44:38,431 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-27 23:44:38,431 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(549)) - OMDoubleBuffer flush thread is not running.
2023-03-27 23:44:38,431 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-03-27 23:44:38,431 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-03-27 23:44:38,431 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-03-27 23:44:38,432 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-03-27 23:44:38,432 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SnapshotDeletingService
2023-03-27 23:44:38,435 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1d77102{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-27 23:44:38,436 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@457471db{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-27 23:44:38,436 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-27 23:44:38,458 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@63b96d3e{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-27 23:44:38,460 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@e42e98f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-27 23:44:38,472 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(530)) - Stopping the HddsDatanodes
2023-03-27 23:44:38,475 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:44:38,475 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 0da438f1-d8bd-4523-91d3-cbc74717487d: close
2023-03-27 23:44:38,481 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B: shutdown
2023-03-27 23:44:38,481 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E79B029C057B,id=0da438f1-d8bd-4523-91d3-cbc74717487d
2023-03-27 23:44:38,481 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 0da438f1-d8bd-4523-91d3-cbc74717487d: shutdown 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-LeaderStateImpl
2023-03-27 23:44:38,482 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 3a4aa664-0d4f-4943-bed7-1a9050fc989f: Completed APPEND_ENTRIES, lastRequest: 0da438f1-d8bd-4523-91d3-cbc74717487d->3a4aa664-0d4f-4943-bed7-1a9050fc989f#383-t1,previous=(t:1, i:40),leaderCommit=40,initializing? true,entries: size=1, first=(t:1, i:41), METADATAENTRY(c:39)
2023-03-27 23:44:38,483 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->3a4aa664-0d4f-4943-bed7-1a9050fc989f-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:44:38,483 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->3a4aa664-0d4f-4943-bed7-1a9050fc989f: nextIndex: updateUnconditionally 42 -> 41
2023-03-27 23:44:38,483 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 3a4aa664-0d4f-4943-bed7-1a9050fc989f: Completed APPEND_ENTRIES, lastRequest: null
2023-03-27 23:44:38,483 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->3a4aa664-0d4f-4943-bed7-1a9050fc989f-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:44:38,483 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->3a4aa664-0d4f-4943-bed7-1a9050fc989f: nextIndex: updateUnconditionally 41 -> 40
2023-03-27 23:44:38,485 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 0da438f1-d8bd-4523-91d3-cbc74717487d: shutdown server GrpcServerProtocolService now
2023-03-27 23:44:38,485 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(419)) - Attempting to stop container services.
2023-03-27 23:44:38,487 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-PendingRequests: sendNotLeaderResponses
2023-03-27 23:44:38,487 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->b6ec7ff8-4fb1-4237-b084-632f2f252394-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->b6ec7ff8-4fb1-4237-b084-632f2f252394-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-27 23:44:38,488 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - b6ec7ff8-4fb1-4237-b084-632f2f252394: Completed APPEND_ENTRIES, lastRequest: 0da438f1-d8bd-4523-91d3-cbc74717487d->b6ec7ff8-4fb1-4237-b084-632f2f252394#389-t1,previous=(t:1, i:40),leaderCommit=40,initializing? true,entries: size=1, first=(t:1, i:41), METADATAENTRY(c:39)
2023-03-27 23:44:38,488 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - b6ec7ff8-4fb1-4237-b084-632f2f252394: Completed APPEND_ENTRIES, lastRequest: null
2023-03-27 23:44:38,488 [grpc-default-executor-9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->b6ec7ff8-4fb1-4237-b084-632f2f252394-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:44:38,488 [grpc-default-executor-9] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->b6ec7ff8-4fb1-4237-b084-632f2f252394: nextIndex: updateUnconditionally 42 -> 41
2023-03-27 23:44:38,488 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->b6ec7ff8-4fb1-4237-b084-632f2f252394-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:44:38,488 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B->b6ec7ff8-4fb1-4237-b084-632f2f252394: nextIndex: updateUnconditionally 41 -> 40
2023-03-27 23:44:38,491 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 3a4aa664-0d4f-4943-bed7-1a9050fc989f Close channels
2023-03-27 23:44:38,492 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: close
2023-03-27 23:44:38,492 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A: shutdown
2023-03-27 23:44:38,493 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1E8C9C770F7A,id=0da438f1-d8bd-4523-91d3-cbc74717487d
2023-03-27 23:44:38,493 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 0da438f1-d8bd-4523-91d3-cbc74717487d: shutdown 0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-LeaderStateImpl
2023-03-27 23:44:38,493 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-PendingRequests: sendNotLeaderResponses
2023-03-27 23:44:38,495 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-1E8C9C770F7A: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-1/data/ratis/4dc02b46-96cc-4ddb-9d8f-1e8c9c770f7a/sm/snapshot.1_0
2023-03-27 23:44:38,495 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:44:38,496 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: shutdown server GrpcServerProtocolService now
2023-03-27 23:44:38,496 [2829ccc8-889f-48cc-a62b-b3954aa0680c-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD: shutdown
2023-03-27 23:44:38,496 [2829ccc8-889f-48cc-a62b-b3954aa0680c-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-903AA5FF57FD,id=2829ccc8-889f-48cc-a62b-b3954aa0680c
2023-03-27 23:44:38,496 [2829ccc8-889f-48cc-a62b-b3954aa0680c-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c: shutdown 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-LeaderStateImpl
2023-03-27 23:44:38,496 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-1E8C9C770F7A: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-1/data/ratis/4dc02b46-96cc-4ddb-9d8f-1e8c9c770f7a/sm/snapshot.1_0 took: 1 ms
2023-03-27 23:44:38,496 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->3fee8600-457c-478d-8bf5-017cc394a56c-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->3fee8600-457c-478d-8bf5-017cc394a56c-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-27 23:44:38,496 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:44:38,496 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:44:38,497 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A: closes. applyIndex: 0
2023-03-27 23:44:38,497 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 3fee8600-457c-478d-8bf5-017cc394a56c: Completed APPEND_ENTRIES, lastRequest: 2829ccc8-889f-48cc-a62b-b3954aa0680c->3fee8600-457c-478d-8bf5-017cc394a56c#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "3fee8600-457c-478d-8bf5-017cc394a56c"
address: "10.1.0.32:37685"
dataStreamAddress: "10.1.0.32:41173"
clientAddress: "10.1.0.32:37685"
adminAddress: "10.1.0.32:37685"
startupRole: FOLLOWER
,id: "2829ccc8-889f-48cc-a62b-b3954aa0680c"
address: "10.1.0.32:35843"
priority: 1
dataStreamAddress: "10.1.0.32:33845"
clientAddress: "10.1.0.32:35843"
adminAddress: "10.1.0.32:35843"
startupRole: FOLLOWER
,id: "fda26913-bdfb-48f8-b38a-a95200d457c8"
address: "10.1.0.32:45647"
dataStreamAddress: "10.1.0.32:36631"
clientAddress: "10.1.0.32:45647"
adminAddress: "10.1.0.32:45647"
startupRole: FOLLOWER
, old:)
2023-03-27 23:44:38,497 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 3fee8600-457c-478d-8bf5-017cc394a56c: Completed APPEND_ENTRIES, lastRequest: null
2023-03-27 23:44:38,497 [grpc-default-executor-9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->3fee8600-457c-478d-8bf5-017cc394a56c-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:44:38,497 [grpc-default-executor-9] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->3fee8600-457c-478d-8bf5-017cc394a56c: nextIndex: updateUnconditionally 1 -> 0
2023-03-27 23:44:38,497 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->3fee8600-457c-478d-8bf5-017cc394a56c-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:44:38,497 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->3fee8600-457c-478d-8bf5-017cc394a56c: nextIndex: updateUnconditionally 0 -> 0
2023-03-27 23:44:38,498 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->fda26913-bdfb-48f8-b38a-a95200d457c8-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->fda26913-bdfb-48f8-b38a-a95200d457c8-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-27 23:44:38,498 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - fda26913-bdfb-48f8-b38a-a95200d457c8: Completed APPEND_ENTRIES, lastRequest: null
2023-03-27 23:44:38,498 [grpc-default-executor-9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->fda26913-bdfb-48f8-b38a-a95200d457c8-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:44:38,498 [grpc-default-executor-9] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->fda26913-bdfb-48f8-b38a-a95200d457c8: nextIndex: updateUnconditionally 1 -> 0
2023-03-27 23:44:38,498 [2829ccc8-889f-48cc-a62b-b3954aa0680c-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-PendingRequests: sendNotLeaderResponses
2023-03-27 23:44:38,499 [2829ccc8-889f-48cc-a62b-b3954aa0680c-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-StateMachineUpdater: set stopIndex = 0
2023-03-27 23:44:38,499 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:44:38,500 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - fda26913-bdfb-48f8-b38a-a95200d457c8: Completed APPEND_ENTRIES, lastRequest: 2829ccc8-889f-48cc-a62b-b3954aa0680c->fda26913-bdfb-48f8-b38a-a95200d457c8#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "3fee8600-457c-478d-8bf5-017cc394a56c"
address: "10.1.0.32:37685"
dataStreamAddress: "10.1.0.32:41173"
clientAddress: "10.1.0.32:37685"
adminAddress: "10.1.0.32:37685"
startupRole: FOLLOWER
,id: "2829ccc8-889f-48cc-a62b-b3954aa0680c"
address: "10.1.0.32:35843"
priority: 1
dataStreamAddress: "10.1.0.32:33845"
clientAddress: "10.1.0.32:35843"
adminAddress: "10.1.0.32:35843"
startupRole: FOLLOWER
,id: "fda26913-bdfb-48f8-b38a-a95200d457c8"
address: "10.1.0.32:45647"
dataStreamAddress: "10.1.0.32:36631"
clientAddress: "10.1.0.32:45647"
adminAddress: "10.1.0.32:45647"
startupRole: FOLLOWER
, old:)
2023-03-27 23:44:38,503 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - b6ec7ff8-4fb1-4237-b084-632f2f252394 Close channels
2023-03-27 23:44:38,504 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 3fee8600-457c-478d-8bf5-017cc394a56c Close channels
2023-03-27 23:44:38,506 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-StateMachineUpdater: set stopIndex = 41
2023-03-27 23:44:38,506 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-1E8C9C770F7A-SegmentedRaftLogWorker close()
2023-03-27 23:44:38,506 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-903AA5FF57FD: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd/sm/snapshot.1_0
2023-03-27 23:44:38,507 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->fda26913-bdfb-48f8-b38a-a95200d457c8-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-27 23:44:38,507 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD->fda26913-bdfb-48f8-b38a-a95200d457c8: nextIndex: updateUnconditionally 0 -> 0
2023-03-27 23:44:38,507 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-E79B029C057B: Taking a snapshot at:(t:1, i:41) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-1/data/ratis/a2f5aba9-6fca-43ef-ba3d-e79b029c057b/sm/snapshot.1_41
2023-03-27 23:44:38,507 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-903AA5FF57FD: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-4/data/ratis/35bc327f-518e-4ba7-b1e3-903aa5ff57fd/sm/snapshot.1_0 took: 1 ms
2023-03-27 23:44:38,507 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-StateMachineUpdater: Took a snapshot at index 0
2023-03-27 23:44:38,507 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-27 23:44:38,508 [2829ccc8-889f-48cc-a62b-b3954aa0680c-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD: closes. applyIndex: 0
2023-03-27 23:44:38,508 [2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:44:38,508 [2829ccc8-889f-48cc-a62b-b3954aa0680c-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 2829ccc8-889f-48cc-a62b-b3954aa0680c@group-903AA5FF57FD-SegmentedRaftLogWorker close()
2023-03-27 23:44:38,508 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-E79B029C057B: Finished taking a snapshot at:(t:1, i:41) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-688b4844-e085-4513-aaec-821622cea348/datanode-1/data/ratis/a2f5aba9-6fca-43ef-ba3d-e79b029c057b/sm/snapshot.1_41 took: 1 ms
2023-03-27 23:44:38,508 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-StateMachineUpdater: Took a snapshot at index 41
2023-03-27 23:44:38,508 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 41
2023-03-27 23:44:38,509 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 0da438f1-d8bd-4523-91d3-cbc74717487d: shutdown server GrpcServerProtocolService successfully
2023-03-27 23:44:38,509 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B: closes. applyIndex: 41
2023-03-27 23:44:38,509 [0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-27 23:44:38,509 [0da438f1-d8bd-4523-91d3-cbc74717487d-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 0da438f1-d8bd-4523-91d3-cbc74717487d@group-E79B029C057B-SegmentedRaftLogWorker close()
2023-03-27 23:44:38,510 [0da438f1-d8bd-4523-91d3-cbc74717487d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe0401d1b, L:/0:0:0:0:0:0:0:0:35639] CLOSE
2023-03-27 23:44:38,510 [0da438f1-d8bd-4523-91d3-cbc74717487d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe0401d1b, L:/0:0:0:0:0:0:0:0:35639] INACTIVE
2023-03-27 23:44:38,510 [0da438f1-d8bd-4523-91d3-cbc74717487d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe0401d1b, L:/0:0:0:0:0:0:0:0:35639] UNREGISTERED
]]></system-out>
  </testcase>
  <testcase name="testEnteringMaintenanceNodeCompletesAfterSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="14.745"/>
  <testcase name="testDecommissioningNodesCompleteDecommissionOnSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="32.518"/>
</testsuite>