2023-03-20 21:34:19,046 [Mini-Cluster-Provider-Create] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:19,049 [Mini-Cluster-Provider-Create] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:19,049 [Mini-Cluster-Provider-Create] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-20 21:34:19,049 [Mini-Cluster-Provider-Create] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-20 21:34:19,050 [Mini-Cluster-Provider-Create] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:19,050 [Mini-Cluster-Provider-Create] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:19,179 [Mini-Cluster-Provider-Create] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-20 21:34:19,179 [Mini-Cluster-Provider-Create] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-20 21:34:19,188 [Mini-Cluster-Provider-Create] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:19,235 [Mini-Cluster-Provider-Create] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:19,237 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(349)) - upgrade localId to 111677748019200000
2023-03-20 21:34:19,238 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(359)) - upgrade delTxnId to 0
2023-03-20 21:34:19,238 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(376)) - upgrade containerId to 0
2023-03-20 21:34:19,238 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-20 21:34:19,238 [Mini-Cluster-Provider-Create] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-20 21:34:19,239 [Mini-Cluster-Provider-Create] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-20 21:34:19,239 [Mini-Cluster-Provider-Create] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:19,239 [Mini-Cluster-Provider-Create] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2023-03-20 21:34:19,239 [Mini-Cluster-Provider-Create] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-20 21:34:19,239 [Mini-Cluster-Provider-Create] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:19,239 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-20 21:34:19,239 [Mini-Cluster-Provider-Create] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-20 21:34:19,244 [Mini-Cluster-Provider-Create] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-20 21:34:19,244 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-20 21:34:19,244 [Mini-Cluster-Provider-Create] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-20 21:34:19,244 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-20 21:34:19,245 [Mini-Cluster-Provider-Create] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-20 21:34:19,245 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-20 21:34:19,245 [Mini-Cluster-Provider-Create] INFO  replication.ReplicationManager (ReplicationManager.java:start(273)) - Starting Replication Monitor Thread.
2023-03-20 21:34:19,246 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-20 21:34:19,246 [Mini-Cluster-Provider-Create] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2023-03-20 21:34:19,247 [Mini-Cluster-Provider-Create] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2023-03-20 21:34:19,247 [Mini-Cluster-Provider-Create] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-03-20 21:34:19,247 [Mini-Cluster-Provider-Create] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(395)) - SCM start with adminUsers: [runner]
2023-03-20 21:34:19,247 [Mini-Cluster-Provider-Create] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:19,247 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:19,248 [Listener at 0.0.0.0/42601] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:19,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:19,253 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:19,253 [Listener at 0.0.0.0/33765] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:19,260 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:19,263 [Listener at 0.0.0.0/42371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-20 21:34:19,263 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(412)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-20 21:34:19,263 [Listener at 0.0.0.0/42371] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-20 21:34:19,263 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1442)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42371
2023-03-20 21:34:19,269 [Listener at 0.0.0.0/42371] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-03-20 21:34:19,269 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-03-20 21:34:19,269 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-03-20 21:34:19,277 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-03-20 21:34:19,277 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-03-20 21:34:19,297 [Listener at 0.0.0.0/42371] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(194)) - RPC server for Client  is listening at /0.0.0.0:42371
2023-03-20 21:34:19,297 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:19,298 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:19,300 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1456)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33765
2023-03-20 21:34:19,304 [Listener at 0.0.0.0/42371] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:33765
2023-03-20 21:34:19,305 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:19,305 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:19,306 [Listener at 0.0.0.0/42371] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:42601
2023-03-20 21:34:19,306 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:19,306 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:19,322 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:0
2023-03-20 21:34:19,322 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:19,322 [Listener at 0.0.0.0/42371] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:19,323 [Listener at 0.0.0.0/42371] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:19,323 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:19,323 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-20 21:34:19,324 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:19,324 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:19,324 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/webserver
2023-03-20 21:34:19,324 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 38151
2023-03-20 21:34:19,324 [Listener at 0.0.0.0/42371] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:19,324 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@469c38a4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:19,336 [Listener at 0.0.0.0/42371] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:19,336 [Listener at 0.0.0.0/42371] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:19,336 [Listener at 0.0.0.0/42371] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:19,336 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2615db2c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:19,336 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3376857e{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-20 21:34:19,338 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3bf6fa60{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-20 21:34:19,338 [Listener at 0.0.0.0/42371] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@35fc8ce4{HTTP/1.1, (http/1.1)}{0.0.0.0:38151}
2023-03-20 21:34:19,338 [Listener at 0.0.0.0/42371] INFO  server.Server (Server.java:doStart(415)) - Started @360608ms
2023-03-20 21:34:19,338 [Listener at 0.0.0.0/42371] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:19,339 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:38151
2023-03-20 21:34:19,339 [Listener at 0.0.0.0/42371] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:19,340 [Listener at 0.0.0.0/42371] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-03-20 21:34:19,340 [Listener at 0.0.0.0/42371] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2023-03-20 21:34:19,340 [Listener at 0.0.0.0/42371] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-03-20 21:34:19,340 [Listener at 0.0.0.0/42371] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2023-03-20 21:34:19,341 [Listener at 0.0.0.0/42371] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:19,341 [Listener at 0.0.0.0/42371] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2023-03-20 21:34:19,404 [Listener at 0.0.0.0/42371] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 62 ms to scan 2 urls, producing 167 keys and 463 values [using 2 cores]
2023-03-20 21:34:19,404 [Listener at 0.0.0.0/42371] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2023-03-20 21:34:19,404 [Listener at 0.0.0.0/42371] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:19,404 [Listener at 0.0.0.0/42371] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:33765]
2023-03-20 21:34:19,405 [Listener at 0.0.0.0/42371] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:33765]
2023-03-20 21:34:19,412 [Listener at 0.0.0.0/42371] INFO  om.OzoneManager (OzoneManager.java:<init>(620)) - OM start with adminUsers: [runner]
2023-03-20 21:34:19,413 [Listener at 0.0.0.0/42371] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:19,413 [Listener at 0.0.0.0/42371] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2023-03-20 21:34:19,413 [Listener at 0.0.0.0/42371] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2023-03-20 21:34:19,577 [Listener at 0.0.0.0/42371] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(750)) - S3 Multi-Tenancy is disabled
2023-03-20 21:34:19,577 [Listener at 0.0.0.0/42371] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:19,623 [Listener at 0.0.0.0/42371] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4228)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2023-03-20 21:34:19,623 [Listener at 0.0.0.0/42371] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-20 21:34:19,623 [Listener at 0.0.0.0/42371] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(439)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2023-03-20 21:34:19,623 [Listener at 0.0.0.0/42371] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-20 21:34:19,624 [Listener at 0.0.0.0/42371] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(164)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:35067
2023-03-20 21:34:19,624 [Listener at 0.0.0.0/42371] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(636)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 35067 (fallback to raft.grpc.server.port)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 35067 (fallback to raft.grpc.server.port)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 35067 (custom)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:19,626 [Listener at 0.0.0.0/42371] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:19,627 [Listener at 0.0.0.0/42371] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2023-03-20 21:34:19,627 [Listener at 0.0.0.0/42371] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:19,627 [Listener at 0.0.0.0/42371] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:19,627 [Listener at 0.0.0.0/42371] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-20 21:34:19,628 [Listener at 0.0.0.0/42371] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:19,628 [Listener at 0.0.0.0/42371] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/ratis] (custom)
2023-03-20 21:34:19,632 [Listener at 0.0.0.0/42371] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:35067|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@40fcddd7[Not completed]
2023-03-20 21:34:19,632 [Listener at 0.0.0.0/42371] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2107)) - OzoneManager Ratis server initialized at port 35067
2023-03-20 21:34:19,632 [pool-4035-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:35067|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
2023-03-20 21:34:19,632 [Listener at 0.0.0.0/42371] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1134)) - Creating RPC Server
2023-03-20 21:34:19,632 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:localhost:35067|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/ratis] (custom)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:19,633 [pool-4035-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:19,873 [Finalizer] WARN  managed.ManagedRocksObjectUtils (ManagedRocksObjectUtils.java:assertClosed(54)) - RocksIterator is not closed properly
2023-03-20 21:34:19,874 [Finalizer] WARN  managed.ManagedRocksObjectUtils (ManagedRocksObjectUtils.java:assertClosed(54)) - ManagedColumnFamilyOptions is not closed properly
2023-03-20 21:34:19,957 [Listener at 0.0.0.0/42371] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 323 ms to scan 19 urls, producing 68 keys and 4951 values [using 2 cores]
2023-03-20 21:34:19,957 [Listener at 0.0.0.0/42371] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:19,958 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:19,974 [Listener at 127.0.0.1/46711] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2023-03-20 21:34:19,983 [Listener at 127.0.0.1/46711] INFO  om.OzoneManager (OzoneManager.java:start(1564)) - OzoneManager RPC server is listening at localhost/127.0.0.1:46711
2023-03-20 21:34:19,984 [Listener at 127.0.0.1/46711] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(559)) - Starting OzoneManagerRatisServer om1 at port 35067
2023-03-20 21:34:19,984 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2023-03-20 21:34:19,985 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:19,986 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2023-03-20 21:34:19,986 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:19,986 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:19,986 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:19,986 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:19,986 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-03-20 21:34:19,987 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:19,990 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:19,990 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:19,990 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2023-03-20 21:34:19,990 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:19,990 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:19,990 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:localhost:35067|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:19,990 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:19,990 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2023-03-20 21:34:19,991 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-03-20 21:34:19,991 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:19,991 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:19,991 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:19,991 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2023-03-20 21:34:19,991 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2023-03-20 21:34:19,991 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2023-03-20 21:34:19,991 [Listener at 127.0.0.1/46711] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - om1: start RPC server
2023-03-20 21:34:19,992 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - om1: GrpcService started, listening on 35067
2023-03-20 21:34:19,992 [Listener at 127.0.0.1/46711] INFO  om.OzoneManager (OzoneManager.java:start(1580)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2023-03-20 21:34:19,992 [JvmPauseMonitor84] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-om1: Started
2023-03-20 21:34:19,993 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2023-03-20 21:34:19,993 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:19,994 [Listener at 127.0.0.1/46711] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:19,994 [Listener at 127.0.0.1/46711] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:19,995 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:19,995 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2023-03-20 21:34:19,995 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:19,995 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:19,995 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/webserver
2023-03-20 21:34:19,995 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 46617
2023-03-20 21:34:19,995 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:19,996 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:19,996 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:19,997 [Listener at 127.0.0.1/46711] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:19,998 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7ba2fed2{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:19,998 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5ec74c0c{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-20 21:34:20,000 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2af92681{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-20 21:34:20,000 [Listener at 127.0.0.1/46711] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4086fe38{HTTP/1.1, (http/1.1)}{0.0.0.0:46617}
2023-03-20 21:34:20,000 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(415)) - Started @361270ms
2023-03-20 21:34:20,001 [Listener at 127.0.0.1/46711] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:20,001 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of ozoneManager listening at http://0.0.0.0:46617
2023-03-20 21:34:20,001 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:20,001 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:20,006 [Listener at 127.0.0.1/46711] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2051)) - Trash Interval set to 0. Files deleted won't move to trash
2023-03-20 21:34:20,006 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5dde7f11] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:20,018 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:20,018 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:20,018 [Listener at 127.0.0.1/46711] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:20,028 [Listener at 127.0.0.1/46711] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:20,043 [Listener at 127.0.0.1/46711] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:20,090 [Listener at 127.0.0.1/46711] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 45 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:20,091 [Listener at 127.0.0.1/46711] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:20,091 [Listener at 127.0.0.1/46711] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:20,092 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:20,092 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data-0/containers/hdds
2023-03-20 21:34:20,092 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data-0/containers/hdds
2023-03-20 21:34:20,102 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis to VolumeSet
2023-03-20 21:34:20,102 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis
2023-03-20 21:34:20,102 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis
2023-03-20 21:34:20,112 [Thread-6297] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data-0/containers/hdds
2023-03-20 21:34:20,112 [Listener at 127.0.0.1/46711] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:20,113 [Listener at 127.0.0.1/46711] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:20,113 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:20,113 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:20,113 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:20,113 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:20,114 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:20,114 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:20,114 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:20,114 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:20,114 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:20,114 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:20,114 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:20,114 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:20,114 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:20,115 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:20,116 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:20,116 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:20,116 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:20,116 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:20,116 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x702acaaa] REGISTERED
2023-03-20 21:34:20,116 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis] (custom)
2023-03-20 21:34:20,116 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x702acaaa] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:20,116 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x702acaaa, L:/0:0:0:0:0:0:0:0:38853] ACTIVE
2023-03-20 21:34:20,117 [Listener at 127.0.0.1/46711] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:20,120 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:20,120 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:20,120 [Listener at 127.0.0.1/46711] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:20,121 [Listener at 127.0.0.1/46711] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:20,121 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:20,122 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:20,122 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:20,122 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:20,122 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/meta/webserver
2023-03-20 21:34:20,122 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34697
2023-03-20 21:34:20,122 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:20,123 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:20,123 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:20,123 [Listener at 127.0.0.1/46711] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:20,123 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2b90048f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:20,123 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3f9bf0db{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:20,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:20,322 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@67899a75{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/meta/webserver/jetty-0_0_0_0-34697-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-7023648703296099697/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:20,323 [Listener at 127.0.0.1/46711] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6b9f160b{HTTP/1.1, (http/1.1)}{0.0.0.0:34697}
2023-03-20 21:34:20,323 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(415)) - Started @361593ms
2023-03-20 21:34:20,323 [Listener at 127.0.0.1/46711] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:20,324 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34697
2023-03-20 21:34:20,324 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:20,324 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:20,324 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:20,324 [Listener at 127.0.0.1/46711] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:20,334 [Listener at 127.0.0.1/46711] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:20,335 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1a4536e4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:20,338 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/meta/datanode.id
2023-03-20 21:34:20,350 [Listener at 127.0.0.1/46711] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:20,394 [Listener at 127.0.0.1/46711] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:20,395 [Listener at 127.0.0.1/46711] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:20,396 [Listener at 127.0.0.1/46711] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:20,396 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:20,396 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data-0/containers/hdds
2023-03-20 21:34:20,397 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data-0/containers/hdds
2023-03-20 21:34:20,407 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis to VolumeSet
2023-03-20 21:34:20,407 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis
2023-03-20 21:34:20,407 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis
2023-03-20 21:34:20,417 [Thread-6311] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data-0/containers/hdds
2023-03-20 21:34:20,417 [Listener at 127.0.0.1/46711] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:20,418 [Listener at 127.0.0.1/46711] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:20,418 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:20,418 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:20,418 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:20,418 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:20,418 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:20,418 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:20,418 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:20,418 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:20,419 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:20,419 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:20,419 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:20,419 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:20,419 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:20,419 [Listener at 127.0.0.1/46711] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:20,420 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:20,421 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:20,421 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:20,421 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:20,421 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3adaa8a8] REGISTERED
2023-03-20 21:34:20,421 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis] (custom)
2023-03-20 21:34:20,421 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3adaa8a8] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:20,422 [Listener at 127.0.0.1/46711] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:20,422 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3adaa8a8, L:/0:0:0:0:0:0:0:0:40753] ACTIVE
2023-03-20 21:34:20,424 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:20,424 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:20,424 [Listener at 127.0.0.1/46711] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:20,425 [Listener at 127.0.0.1/46711] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:20,425 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:20,425 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:20,425 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:20,425 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:20,426 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/meta/webserver
2023-03-20 21:34:20,426 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 45033
2023-03-20 21:34:20,426 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:20,428 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:20,428 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:20,428 [Listener at 127.0.0.1/46711] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:20,429 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5ad41387{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:20,429 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7cf265eb{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:20,624 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2f71e1a2{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/meta/webserver/jetty-0_0_0_0-45033-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-3950161102876270227/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:20,625 [Listener at 127.0.0.1/46711] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@686b2640{HTTP/1.1, (http/1.1)}{0.0.0.0:45033}
2023-03-20 21:34:20,625 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(415)) - Started @361894ms
2023-03-20 21:34:20,625 [Listener at 127.0.0.1/46711] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:20,626 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45033
2023-03-20 21:34:20,626 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:20,626 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:20,626 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:20,626 [Listener at 127.0.0.1/46711] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:20,636 [Listener at 127.0.0.1/46711] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:20,644 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77c21278] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:20,645 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/meta/datanode.id
2023-03-20 21:34:20,655 [Listener at 127.0.0.1/46711] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:20,700 [Listener at 127.0.0.1/46711] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:20,701 [Listener at 127.0.0.1/46711] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:20,701 [Listener at 127.0.0.1/46711] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:20,702 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:20,702 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data-0/containers/hdds
2023-03-20 21:34:20,702 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data-0/containers/hdds
2023-03-20 21:34:20,712 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis to VolumeSet
2023-03-20 21:34:20,712 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis
2023-03-20 21:34:20,712 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis
2023-03-20 21:34:20,721 [Thread-6325] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data-0/containers/hdds
2023-03-20 21:34:20,721 [Listener at 127.0.0.1/46711] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:20,722 [Listener at 127.0.0.1/46711] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:20,722 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:20,722 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:20,722 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:20,722 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:20,722 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:20,722 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:20,722 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:20,723 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:20,723 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:20,723 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:20,723 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:20,723 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:20,723 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:20,724 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:20,725 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:20,725 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:20,725 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:20,725 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:20,725 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3c2ba2f2] REGISTERED
2023-03-20 21:34:20,725 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis] (custom)
2023-03-20 21:34:20,725 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3c2ba2f2] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:20,725 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3c2ba2f2, L:/0:0:0:0:0:0:0:0:46387] ACTIVE
2023-03-20 21:34:20,726 [Listener at 127.0.0.1/46711] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:20,728 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:20,728 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:20,728 [Listener at 127.0.0.1/46711] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:20,728 [Listener at 127.0.0.1/46711] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:20,729 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:20,729 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:20,729 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:20,729 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:20,729 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/meta/webserver
2023-03-20 21:34:20,730 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 40313
2023-03-20 21:34:20,730 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:20,730 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:20,730 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:20,730 [Listener at 127.0.0.1/46711] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:20,731 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@226dfd5f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:20,731 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@459b94fd{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:20,926 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5a3f5bce{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/meta/webserver/jetty-0_0_0_0-40313-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-8827442559459703644/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:20,927 [Listener at 127.0.0.1/46711] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@11c6e8e{HTTP/1.1, (http/1.1)}{0.0.0.0:40313}
2023-03-20 21:34:20,927 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(415)) - Started @362196ms
2023-03-20 21:34:20,927 [Listener at 127.0.0.1/46711] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:20,928 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:40313
2023-03-20 21:34:20,928 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:20,928 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:20,928 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:20,928 [Listener at 127.0.0.1/46711] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:20,938 [Listener at 127.0.0.1/46711] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:20,948 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2900910c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:20,949 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/meta/datanode.id
2023-03-20 21:34:20,958 [Listener at 127.0.0.1/46711] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:21,005 [Listener at 127.0.0.1/46711] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 46 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:21,006 [Listener at 127.0.0.1/46711] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:21,008 [Listener at 127.0.0.1/46711] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:21,008 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:21,008 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/hdds
2023-03-20 21:34:21,009 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/hdds
2023-03-20 21:34:21,020 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis to VolumeSet
2023-03-20 21:34:21,020 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis
2023-03-20 21:34:21,020 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis
2023-03-20 21:34:21,031 [Thread-6339] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/hdds
2023-03-20 21:34:21,031 [Listener at 127.0.0.1/46711] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:21,032 [Listener at 127.0.0.1/46711] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:21,032 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:21,032 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:21,032 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:21,032 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:21,032 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:21,032 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:21,032 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:21,032 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:21,033 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:21,033 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:21,033 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:21,033 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:21,033 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:21,033 [Listener at 127.0.0.1/46711] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:21,034 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:21,038 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:21,038 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:21,038 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:21,038 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:21,038 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc613c859] REGISTERED
2023-03-20 21:34:21,038 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis] (custom)
2023-03-20 21:34:21,038 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc613c859] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:21,038 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc613c859, L:/0:0:0:0:0:0:0:0:39027] ACTIVE
2023-03-20 21:34:21,039 [Listener at 127.0.0.1/46711] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:21,041 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:21,041 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:21,042 [Listener at 127.0.0.1/46711] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:21,044 [Listener at 127.0.0.1/46711] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:21,045 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:21,045 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:21,045 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:21,045 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:21,045 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/meta/webserver
2023-03-20 21:34:21,045 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 35971
2023-03-20 21:34:21,045 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:21,050 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:21,050 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:21,050 [Listener at 127.0.0.1/46711] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:21,051 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@452dd8cc{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:21,051 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4073e5f1{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:21,088 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1097384945ns, electionTimeout:1097ms
2023-03-20 21:34:21,088 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2023-03-20 21:34:21,088 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:21,088 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:21,088 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection138
2023-03-20 21:34:21,089 [om1@group-C5BA1605619E-LeaderElection138] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection138 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|rpc:localhost:35067|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:21,089 [om1@group-C5BA1605619E-LeaderElection138] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection138 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection138 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:localhost:35067|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection138 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection138
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1457ms
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:21,090 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-20 21:34:21,091 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:21,091 [om1@group-C5BA1605619E-LeaderElection138] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2023-03-20 21:34:21,091 [om1@group-C5BA1605619E-LeaderElection138] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:21,095 [om1@group-C5BA1605619E-LeaderElection138] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:localhost:35067|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:21,099 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2023-03-20 21:34:21,100 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:35067"
startupRole: FOLLOWER
]
2023-03-20 21:34:21,250 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@363d0921{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/meta/webserver/jetty-0_0_0_0-35971-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-1767639838871416411/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:21,252 [Listener at 127.0.0.1/46711] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@43a8e430{HTTP/1.1, (http/1.1)}{0.0.0.0:35971}
2023-03-20 21:34:21,252 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(415)) - Started @362521ms
2023-03-20 21:34:21,252 [Listener at 127.0.0.1/46711] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:21,252 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:35971
2023-03-20 21:34:21,252 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:21,252 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:21,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:21,253 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:21,253 [Listener at 127.0.0.1/46711] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:21,263 [Listener at 127.0.0.1/46711] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:21,263 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@351aa768] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:21,264 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/meta/datanode.id
2023-03-20 21:34:21,281 [Listener at 127.0.0.1/46711] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:21,325 [Listener at 127.0.0.1/46711] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:21,326 [Listener at 127.0.0.1/46711] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:21,328 [Listener at 127.0.0.1/46711] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:21,328 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:21,328 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data-0/containers/hdds
2023-03-20 21:34:21,328 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data-0/containers/hdds
2023-03-20 21:34:21,338 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis to VolumeSet
2023-03-20 21:34:21,338 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis
2023-03-20 21:34:21,338 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis
2023-03-20 21:34:21,348 [Thread-6355] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data-0/containers/hdds
2023-03-20 21:34:21,348 [Listener at 127.0.0.1/46711] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:21,349 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:21,350 [Listener at 127.0.0.1/46711] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:21,350 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:21,350 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:21,350 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:21,350 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:21,351 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis] (custom)
2023-03-20 21:34:21,352 [Listener at 127.0.0.1/46711] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:21,351 [c2f44316-1a3e-468b-9a76-53c43d628173-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdd696339] REGISTERED
2023-03-20 21:34:21,353 [c2f44316-1a3e-468b-9a76-53c43d628173-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdd696339] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:21,353 [c2f44316-1a3e-468b-9a76-53c43d628173-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdd696339, L:/0:0:0:0:0:0:0:0:40549] ACTIVE
2023-03-20 21:34:21,354 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:21,354 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:21,355 [Listener at 127.0.0.1/46711] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:21,355 [Listener at 127.0.0.1/46711] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:21,355 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:21,356 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:21,356 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:21,356 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:21,356 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/meta/webserver
2023-03-20 21:34:21,356 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 42523
2023-03-20 21:34:21,356 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:21,357 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:21,357 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:21,357 [Listener at 127.0.0.1/46711] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:21,357 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@430b31b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:21,357 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@665e141b{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:21,551 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1b700167{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/meta/webserver/jetty-0_0_0_0-42523-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-5780301244887870655/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:21,552 [Listener at 127.0.0.1/46711] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7a6dbc6f{HTTP/1.1, (http/1.1)}{0.0.0.0:42523}
2023-03-20 21:34:21,552 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(415)) - Started @362822ms
2023-03-20 21:34:21,552 [Listener at 127.0.0.1/46711] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:21,553 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:42523
2023-03-20 21:34:21,553 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:21,553 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:21,553 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:21,553 [Listener at 127.0.0.1/46711] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:21,560 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@18783492] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:21,561 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/meta/datanode.id
2023-03-20 21:34:21,563 [Listener at 127.0.0.1/46711] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:21,579 [Listener at 127.0.0.1/46711] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:21,624 [Listener at 127.0.0.1/46711] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:21,625 [Listener at 127.0.0.1/46711] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:21,626 [Listener at 127.0.0.1/46711] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:21,626 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:21,626 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data-0/containers/hdds
2023-03-20 21:34:21,627 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data-0/containers/hdds
2023-03-20 21:34:21,637 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis to VolumeSet
2023-03-20 21:34:21,637 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis
2023-03-20 21:34:21,637 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis
2023-03-20 21:34:21,647 [Thread-6369] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data-0/containers/hdds
2023-03-20 21:34:21,647 [Listener at 127.0.0.1/46711] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:21,648 [Listener at 127.0.0.1/46711] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:21,648 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:21,648 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:21,648 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:21,648 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:21,648 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:21,649 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:21,649 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:21,649 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:21,649 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:21,649 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:21,649 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:21,649 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:21,649 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:21,650 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:21,651 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:21,651 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:21,651 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:21,651 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:21,651 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaac850e0] REGISTERED
2023-03-20 21:34:21,651 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis] (custom)
2023-03-20 21:34:21,651 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaac850e0] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:21,651 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaac850e0, L:/0:0:0:0:0:0:0:0:34323] ACTIVE
2023-03-20 21:34:21,652 [Listener at 127.0.0.1/46711] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:21,654 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:21,654 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:21,654 [Listener at 127.0.0.1/46711] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:21,655 [Listener at 127.0.0.1/46711] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:21,655 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:21,655 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:21,655 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:21,655 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:21,656 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/meta/webserver
2023-03-20 21:34:21,656 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 43817
2023-03-20 21:34:21,656 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:21,656 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:21,657 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:21,657 [Listener at 127.0.0.1/46711] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:21,657 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2fba7d7c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:21,657 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@e975ff4{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:21,850 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5bac76a5{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/meta/webserver/jetty-0_0_0_0-43817-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-5457169095834946009/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:21,852 [Listener at 127.0.0.1/46711] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6b1a4bf{HTTP/1.1, (http/1.1)}{0.0.0.0:43817}
2023-03-20 21:34:21,852 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(415)) - Started @363121ms
2023-03-20 21:34:21,852 [Listener at 127.0.0.1/46711] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:21,852 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:43817
2023-03-20 21:34:21,855 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:21,855 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:21,855 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:21,855 [Listener at 127.0.0.1/46711] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:21,864 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@571a7e53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:21,865 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/meta/datanode.id
2023-03-20 21:34:21,865 [Listener at 127.0.0.1/46711] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:21,881 [Listener at 127.0.0.1/46711] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:21,927 [Listener at 127.0.0.1/46711] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 45 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:21,928 [Listener at 127.0.0.1/46711] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:21,928 [Listener at 127.0.0.1/46711] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:21,929 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:21,929 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data-0/containers/hdds
2023-03-20 21:34:21,929 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data-0/containers/hdds
2023-03-20 21:34:21,939 [Listener at 127.0.0.1/46711] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis to VolumeSet
2023-03-20 21:34:21,939 [Listener at 127.0.0.1/46711] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis
2023-03-20 21:34:21,939 [Listener at 127.0.0.1/46711] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis
2023-03-20 21:34:21,951 [Thread-6383] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data-0/containers/hdds
2023-03-20 21:34:21,951 [Listener at 127.0.0.1/46711] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:21,952 [Listener at 127.0.0.1/46711] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:21,952 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:21,952 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:21,952 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:21,952 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:21,953 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:21,953 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:21,953 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:21,953 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:21,953 [Listener at 127.0.0.1/46711] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:21,953 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:21,953 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:21,953 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:21,953 [Listener at 127.0.0.1/46711] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:21,954 [Listener at 127.0.0.1/46711] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:21,954 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:21,954 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:21,954 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:21,954 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:21,954 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:21,954 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:21,954 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:21,954 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:21,955 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:21,955 [Listener at 127.0.0.1/46711] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:21,955 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:21,955 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:21,955 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:21,955 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:21,955 [ad06446d-1378-4ceb-aafe-e920688dce34-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x08dfe364] REGISTERED
2023-03-20 21:34:21,955 [Listener at 127.0.0.1/46711] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis] (custom)
2023-03-20 21:34:21,955 [ad06446d-1378-4ceb-aafe-e920688dce34-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x08dfe364] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:21,955 [ad06446d-1378-4ceb-aafe-e920688dce34-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x08dfe364, L:/0:0:0:0:0:0:0:0:44401] ACTIVE
2023-03-20 21:34:21,956 [Listener at 127.0.0.1/46711] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:21,958 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:21,958 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:21,958 [Listener at 127.0.0.1/46711] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:21,959 [Listener at 127.0.0.1/46711] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:21,959 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:21,959 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:21,959 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:21,960 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:21,960 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/meta/webserver
2023-03-20 21:34:21,960 [Listener at 127.0.0.1/46711] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 39109
2023-03-20 21:34:21,960 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:21,961 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:21,961 [Listener at 127.0.0.1/46711] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:21,961 [Listener at 127.0.0.1/46711] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:21,961 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@499da35f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:21,961 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7a37a7cc{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:22,156 [Listener at 127.0.0.1/46711] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3afa2d68{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/meta/webserver/jetty-0_0_0_0-39109-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-4428200784446493706/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:22,157 [Listener at 127.0.0.1/46711] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@65606c51{HTTP/1.1, (http/1.1)}{0.0.0.0:39109}
2023-03-20 21:34:22,158 [Listener at 127.0.0.1/46711] INFO  server.Server (Server.java:doStart(415)) - Started @363427ms
2023-03-20 21:34:22,158 [Listener at 127.0.0.1/46711] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:22,158 [Listener at 127.0.0.1/46711] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:39109
2023-03-20 21:34:22,160 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-20 21:34:22,160 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:22,160 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:22,160 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:22,168 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a51813] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:22,169 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/meta/datanode.id
2023-03-20 21:34:22,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:22,362 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-1819e498-3d26-483d-bf35-767a906b0b5e/container.db to cache
2023-03-20 21:34:22,362 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-1819e498-3d26-483d-bf35-767a906b0b5e/container.db for volume DS-1819e498-3d26-483d-bf35-767a906b0b5e
2023-03-20 21:34:22,362 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:22,362 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:22,362 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 45831
2023-03-20 21:34:22,363 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:22,368 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start RPC server
2023-03-20 21:34:22,369 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: GrpcService started, listening on 34483
2023-03-20 21:34:22,369 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c810b0b2-f38c-4bc5-874a-38f1937d7d9e is started using port 34483 for RATIS
2023-03-20 21:34:22,369 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c810b0b2-f38c-4bc5-874a-38f1937d7d9e is started using port 34483 for RATIS_ADMIN
2023-03-20 21:34:22,369 [JvmPauseMonitor85] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-c810b0b2-f38c-4bc5-874a-38f1937d7d9e: Started
2023-03-20 21:34:22,369 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c810b0b2-f38c-4bc5-874a-38f1937d7d9e is started using port 34483 for RATIS_SERVER
2023-03-20 21:34:22,369 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c810b0b2-f38c-4bc5-874a-38f1937d7d9e is started using port 38853 for RATIS_DATASTREAM
2023-03-20 21:34:22,369 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc c810b0b2-f38c-4bc5-874a-38f1937d7d9e is started using port 45741
2023-03-20 21:34:22,370 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:22,670 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-38bfbc49-5fc1-4b6e-8d35-0d6e9fb8d0de/container.db to cache
2023-03-20 21:34:22,670 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-38bfbc49-5fc1-4b6e-8d35-0d6e9fb8d0de/container.db for volume DS-38bfbc49-5fc1-4b6e-8d35-0d6e9fb8d0de
2023-03-20 21:34:22,671 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:22,671 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:22,671 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 39621
2023-03-20 21:34:22,672 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:22,673 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: start RPC server
2023-03-20 21:34:22,673 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: GrpcService started, listening on 36759
2023-03-20 21:34:22,673 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 is started using port 36759 for RATIS
2023-03-20 21:34:22,673 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 is started using port 36759 for RATIS_ADMIN
2023-03-20 21:34:22,673 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 is started using port 36759 for RATIS_SERVER
2023-03-20 21:34:22,673 [JvmPauseMonitor86] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-1226cf83-b1fd-416f-9846-61bdfa3ff6b3: Started
2023-03-20 21:34:22,673 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 is started using port 40753 for RATIS_DATASTREAM
2023-03-20 21:34:22,674 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 is started using port 44947
2023-03-20 21:34:22,674 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:22,978 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-c62bb234-cdf0-440f-a112-1703b1431d87/container.db to cache
2023-03-20 21:34:22,978 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-c62bb234-cdf0-440f-a112-1703b1431d87/container.db for volume DS-c62bb234-cdf0-440f-a112-1703b1431d87
2023-03-20 21:34:22,978 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:22,979 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:22,979 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 46645
2023-03-20 21:34:22,980 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:22,985 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start RPC server
2023-03-20 21:34:22,985 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: GrpcService started, listening on 45703
2023-03-20 21:34:22,985 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ad5f436c-b0db-4b4f-b4fd-dcb016937dbf is started using port 45703 for RATIS
2023-03-20 21:34:22,985 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ad5f436c-b0db-4b4f-b4fd-dcb016937dbf is started using port 45703 for RATIS_ADMIN
2023-03-20 21:34:22,985 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ad5f436c-b0db-4b4f-b4fd-dcb016937dbf is started using port 45703 for RATIS_SERVER
2023-03-20 21:34:22,985 [JvmPauseMonitor87] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: Started
2023-03-20 21:34:22,985 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ad5f436c-b0db-4b4f-b4fd-dcb016937dbf is started using port 46387 for RATIS_DATASTREAM
2023-03-20 21:34:22,985 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc ad5f436c-b0db-4b4f-b4fd-dcb016937dbf is started using port 37991
2023-03-20 21:34:22,986 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:23,160 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-20 21:34:23,160 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:23,160 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:23,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:23,288 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-f4cdd729-a977-4d45-9f7c-1f4b1672453b/container.db to cache
2023-03-20 21:34:23,288 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-f4cdd729-a977-4d45-9f7c-1f4b1672453b/container.db for volume DS-f4cdd729-a977-4d45-9f7c-1f4b1672453b
2023-03-20 21:34:23,289 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:23,289 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:23,289 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 46199
2023-03-20 21:34:23,290 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:23,293 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: start RPC server
2023-03-20 21:34:23,295 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: GrpcService started, listening on 34363
2023-03-20 21:34:23,296 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9ce389bc-6c47-40b9-aa21-f44fc17fd7db is started using port 34363 for RATIS
2023-03-20 21:34:23,296 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9ce389bc-6c47-40b9-aa21-f44fc17fd7db is started using port 34363 for RATIS_ADMIN
2023-03-20 21:34:23,296 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9ce389bc-6c47-40b9-aa21-f44fc17fd7db is started using port 34363 for RATIS_SERVER
2023-03-20 21:34:23,296 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9ce389bc-6c47-40b9-aa21-f44fc17fd7db is started using port 39027 for RATIS_DATASTREAM
2023-03-20 21:34:23,297 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 9ce389bc-6c47-40b9-aa21-f44fc17fd7db is started using port 34777
2023-03-20 21:34:23,297 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:23,297 [JvmPauseMonitor88] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-9ce389bc-6c47-40b9-aa21-f44fc17fd7db: Started
2023-03-20 21:34:23,587 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-fc367b51-928d-4514-887e-fae107276260/container.db to cache
2023-03-20 21:34:23,587 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-fc367b51-928d-4514-887e-fae107276260/container.db for volume DS-fc367b51-928d-4514-887e-fae107276260
2023-03-20 21:34:23,587 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:23,587 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:23,587 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 45549
2023-03-20 21:34:23,588 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:23,590 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - c2f44316-1a3e-468b-9a76-53c43d628173: start RPC server
2023-03-20 21:34:23,590 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - c2f44316-1a3e-468b-9a76-53c43d628173: GrpcService started, listening on 33117
2023-03-20 21:34:23,590 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c2f44316-1a3e-468b-9a76-53c43d628173 is started using port 33117 for RATIS
2023-03-20 21:34:23,590 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c2f44316-1a3e-468b-9a76-53c43d628173 is started using port 33117 for RATIS_ADMIN
2023-03-20 21:34:23,590 [JvmPauseMonitor89] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-c2f44316-1a3e-468b-9a76-53c43d628173: Started
2023-03-20 21:34:23,590 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c2f44316-1a3e-468b-9a76-53c43d628173 is started using port 33117 for RATIS_SERVER
2023-03-20 21:34:23,590 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c2f44316-1a3e-468b-9a76-53c43d628173 is started using port 40549 for RATIS_DATASTREAM
2023-03-20 21:34:23,590 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc c2f44316-1a3e-468b-9a76-53c43d628173 is started using port 40115
2023-03-20 21:34:23,591 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:23,889 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-9531f318-f2fb-4a97-b9d4-81636e8d3eb3/container.db to cache
2023-03-20 21:34:23,890 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-9531f318-f2fb-4a97-b9d4-81636e8d3eb3/container.db for volume DS-9531f318-f2fb-4a97-b9d4-81636e8d3eb3
2023-03-20 21:34:23,890 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:23,890 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:23,892 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 39745
2023-03-20 21:34:23,893 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:23,894 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: start RPC server
2023-03-20 21:34:23,895 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: GrpcService started, listening on 36869
2023-03-20 21:34:23,895 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38 is started using port 36869 for RATIS
2023-03-20 21:34:23,895 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38 is started using port 36869 for RATIS_ADMIN
2023-03-20 21:34:23,895 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38 is started using port 36869 for RATIS_SERVER
2023-03-20 21:34:23,895 [JvmPauseMonitor90] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: Started
2023-03-20 21:34:23,895 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38 is started using port 34323 for RATIS_DATASTREAM
2023-03-20 21:34:23,895 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38 is started using port 35469
2023-03-20 21:34:23,896 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:24,160 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-20 21:34:24,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:24,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:24,193 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-b3a4655f-49ba-4aad-97d8-33192a4797b1/container.db to cache
2023-03-20 21:34:24,194 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-b3a4655f-49ba-4aad-97d8-33192a4797b1/container.db for volume DS-b3a4655f-49ba-4aad-97d8-33192a4797b1
2023-03-20 21:34:24,194 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:24,194 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:24,194 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 44493
2023-03-20 21:34:24,195 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:24,196 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - ad06446d-1378-4ceb-aafe-e920688dce34: start RPC server
2023-03-20 21:34:24,196 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - ad06446d-1378-4ceb-aafe-e920688dce34: GrpcService started, listening on 45443
2023-03-20 21:34:24,197 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ad06446d-1378-4ceb-aafe-e920688dce34 is started using port 45443 for RATIS
2023-03-20 21:34:24,197 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ad06446d-1378-4ceb-aafe-e920688dce34 is started using port 45443 for RATIS_ADMIN
2023-03-20 21:34:24,197 [JvmPauseMonitor91] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-ad06446d-1378-4ceb-aafe-e920688dce34: Started
2023-03-20 21:34:24,197 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ad06446d-1378-4ceb-aafe-e920688dce34 is started using port 45443 for RATIS_SERVER
2023-03-20 21:34:24,197 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ad06446d-1378-4ceb-aafe-e920688dce34 is started using port 44401 for RATIS_DATASTREAM
2023-03-20 21:34:24,197 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc ad06446d-1378-4ceb-aafe-e920688dce34 is started using port 33865
2023-03-20 21:34:24,197 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:24,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:24,335 [IPC Server handler 0 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:24,335 [IPC Server handler 0 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : c810b0b2-f38c-4bc5-874a-38f1937d7d9e{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45831, RATIS=34483, RATIS_ADMIN=34483, RATIS_SERVER=34483, RATIS_DATASTREAM=38853, STANDALONE=45741], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:24,337 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-20 21:34:24,337 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-20 21:34:24,340 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:24,341 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-20 21:34:24,341 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=946b457e-a222-4d6d-be88-c381d26a4e6f to datanode:c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:24,341 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 946b457e-a222-4d6d-be88-c381d26a4e6f, Nodes: c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:24.341Z[Etc/UTC]].
2023-03-20 21:34:24,645 [IPC Server handler 2 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:24,645 [IPC Server handler 2 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 1226cf83-b1fd-416f-9846-61bdfa3ff6b3{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=39621, RATIS=36759, RATIS_ADMIN=36759, RATIS_SERVER=36759, RATIS_DATASTREAM=40753, STANDALONE=44947], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:24,647 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-20 21:34:24,648 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:24,648 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=16659239-5113-4ca3-8976-a2799a78ebf2 to datanode:1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:24,648 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 16659239-5113-4ca3-8976-a2799a78ebf2, Nodes: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:24.648Z[Etc/UTC]].
2023-03-20 21:34:24,949 [IPC Server handler 3 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:24,949 [IPC Server handler 3 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : ad5f436c-b0db-4b4f-b4fd-dcb016937dbf{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=46645, RATIS=45703, RATIS_ADMIN=45703, RATIS_SERVER=45703, RATIS_DATASTREAM=46387, STANDALONE=37991], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:24,949 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:24,950 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-20 21:34:24,950 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-20 21:34:24,950 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-20 21:34:24,950 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-20 21:34:24,950 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:24,950 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=e59ede23-824b-49aa-b4ff-59442e686788 to datanode:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:24,950 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: e59ede23-824b-49aa-b4ff-59442e686788, Nodes: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:24.950Z[Etc/UTC]].
2023-03-20 21:34:24,950 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c to datanode:c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:24,950 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c to datanode:1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:24,950 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c to datanode:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:24,951 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 27a0404e-e3ec-48ab-a304-02d605ba4e5c, Nodes: c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10)ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:24.950Z[Etc/UTC]].
2023-03-20 21:34:24,951 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:25,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 3 of 7 DN Heartbeats.
2023-03-20 21:34:25,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:25,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:25,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:25,264 [IPC Server handler 4 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:25,264 [IPC Server handler 4 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 9ce389bc-6c47-40b9-aa21-f44fc17fd7db{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=46199, RATIS=34363, RATIS_ADMIN=34363, RATIS_SERVER=34363, RATIS_DATASTREAM=39027, STANDALONE=34777], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:25,264 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:25,266 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=402930f6-6fce-4ea8-a53b-50915993717e to datanode:9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:25,266 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 402930f6-6fce-4ea8-a53b-50915993717e, Nodes: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:25.266Z[Etc/UTC]].
2023-03-20 21:34:25,266 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:34:25,561 [IPC Server handler 2 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:25,562 [IPC Server handler 2 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : c2f44316-1a3e-468b-9a76-53c43d628173{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45549, RATIS=33117, RATIS_ADMIN=33117, RATIS_SERVER=33117, RATIS_DATASTREAM=40549, STANDALONE=40115], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:25,562 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:25,562 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=c405d3a8-315a-4fbf-b7da-712cde8ccbf2 to datanode:c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:25,562 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: c405d3a8-315a-4fbf-b7da-712cde8ccbf2, Nodes: c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:25.562Z[Etc/UTC]].
2023-03-20 21:34:25,563 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2023-03-20 21:34:25,866 [IPC Server handler 3 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:25,866 [IPC Server handler 3 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=39745, RATIS=36869, RATIS_ADMIN=36869, RATIS_SERVER=36869, RATIS_DATASTREAM=34323, STANDALONE=35469], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:25,866 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:25,866 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=e5a8d140-d18d-49ef-8d60-f785482b8116 to datanode:6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:25,866 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: e5a8d140-d18d-49ef-8d60-f785482b8116, Nodes: 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:25.866Z[Etc/UTC]].
2023-03-20 21:34:25,867 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff to datanode:c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:25,867 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff to datanode:9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:25,867 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff to datanode:6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:25,867 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: dcaa0c25-9483-47d9-b73e-08f3b6f653ff, Nodes: c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10)9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10)6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:25.867Z[Etc/UTC]].
2023-03-20 21:34:25,867 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:26,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 6 of 7 DN Heartbeats.
2023-03-20 21:34:26,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:26,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:26,172 [IPC Server handler 4 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:26,172 [IPC Server handler 4 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : ad06446d-1378-4ceb-aafe-e920688dce34{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=44493, RATIS=45443, RATIS_ADMIN=45443, RATIS_SERVER=45443, RATIS_DATASTREAM=44401, STANDALONE=33865], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:26,173 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:26,173 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=df6acdd5-290a-4c11-993a-7ecea2ad9ace to datanode:ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:26,173 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: df6acdd5-290a-4c11-993a-7ecea2ad9ace, Nodes: ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:26.173Z[Etc/UTC]].
2023-03-20 21:34:26,173 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:34:26,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:27,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:27,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:27,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:27,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:27,335 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: addNew group-C381D26A4E6F:[c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER] returns group-C381D26A4E6F:java.util.concurrent.CompletableFuture@370fe029[Not completed]
2023-03-20 21:34:27,336 [pool-4050-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: new RaftServerImpl for group-C381D26A4E6F:[c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:27,336 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:27,336 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:27,336 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:27,336 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:27,336 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:27,336 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:27,336 [pool-4050-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F: ConfigurationManager, init=-1: peers:[c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis] (custom)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:27,337 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:27,338 [pool-4050-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/946b457e-a222-4d6d-be88-c381d26a4e6f does not exist. Creating ...
2023-03-20 21:34:27,338 [pool-4050-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/946b457e-a222-4d6d-be88-c381d26a4e6f/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:27,339 [pool-4050-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/946b457e-a222-4d6d-be88-c381d26a4e6f has been successfully formatted.
2023-03-20 21:34:27,339 [pool-4050-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-C381D26A4E6F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:27,339 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:27,340 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:27,340 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,340 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:27,340 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 946b457e-a222-4d6d-be88-c381d26a4e6f, Nodes: c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c810b0b2-f38c-4bc5-874a-38f1937d7d9e, CreationTimestamp2023-03-20T21:34:24.341Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:27,340 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:27,340 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,341 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:27,341 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:27,341 [pool-4050-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/946b457e-a222-4d6d-be88-c381d26a4e6f
2023-03-20 21:34:27,341 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:27,341 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:27,342 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:27,342 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,342 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:27,342 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:27,342 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:27,343 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:27,343 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:27,343 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:27,343 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,346 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:27,346 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:27,346 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:27,346 [pool-4050-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,346 [pool-4050-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,347 [pool-4050-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F: start as a follower, conf=-1: peers:[c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:27,347 [pool-4050-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:27,347 [pool-4050-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState
2023-03-20 21:34:27,347 [pool-4050-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C381D26A4E6F,id=c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:27,347 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:27,347 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:27,347 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:27,347 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:27,347 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:27,347 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:27,347 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=946b457e-a222-4d6d-be88-c381d26a4e6f
2023-03-20 21:34:27,347 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=946b457e-a222-4d6d-be88-c381d26a4e6f.
2023-03-20 21:34:27,347 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: addNew group-02D605BA4E5C:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] returns group-02D605BA4E5C:java.util.concurrent.CompletableFuture@33307210[Not completed]
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: new RaftServerImpl for group-02D605BA4E5C:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: ConfigurationManager, init=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis] (custom)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:27,348 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:27,349 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:27,349 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:27,349 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:27,349 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:27,349 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:27,349 [pool-4050-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c does not exist. Creating ...
2023-03-20 21:34:27,350 [pool-4050-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:27,351 [pool-4050-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c has been successfully formatted.
2023-03-20 21:34:27,351 [pool-4050-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-02D605BA4E5C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:27,352 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,352 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:27,353 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:27,353 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:27,353 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:27,353 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:27,353 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:27,353 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:27,353 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,356 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:27,356 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:27,356 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:27,356 [pool-4050-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,356 [pool-4050-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,356 [pool-4050-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: start as a follower, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:27,356 [pool-4050-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:27,356 [pool-4050-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:27,357 [pool-4050-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-02D605BA4E5C,id=c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:27,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:27,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:27,357 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:27,357 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:27,357 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:27,357 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:27,357 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:27,364 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: addNew group-02D605BA4E5C:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] returns group-02D605BA4E5C:java.util.concurrent.CompletableFuture@3caf63be[Not completed]
2023-03-20 21:34:27,364 [pool-4072-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: new RaftServerImpl for group-02D605BA4E5C:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:27,364 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:27,364 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:27,364 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:27,364 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:27,364 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:27,364 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:27,364 [pool-4072-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: ConfigurationManager, init=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:27,364 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis] (custom)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:27,365 [pool-4072-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c does not exist. Creating ...
2023-03-20 21:34:27,366 [pool-4072-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:27,368 [pool-4072-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c has been successfully formatted.
2023-03-20 21:34:27,368 [pool-4072-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-02D605BA4E5C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:27,368 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:27,369 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:27,370 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:27,370 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,373 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:27,373 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:27,373 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:27,373 [pool-4072-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,373 [pool-4072-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,373 [pool-4072-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: start as a follower, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:27,373 [pool-4072-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:27,373 [pool-4072-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: start 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:27,374 [pool-4072-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-02D605BA4E5C,id=1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:27,374 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:27,374 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:27,374 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:27,375 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:27,375 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:27,375 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:27,380 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: addNew group-02D605BA4E5C:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] returns group-02D605BA4E5C:java.util.concurrent.CompletableFuture@5218d9a7[Not completed]
2023-03-20 21:34:27,380 [pool-4094-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: new RaftServerImpl for group-02D605BA4E5C:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:27,380 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:27,380 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:27,380 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:27,380 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:27,380 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:27,380 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: ConfigurationManager, init=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis] (custom)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:27,381 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:27,382 [pool-4094-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c does not exist. Creating ...
2023-03-20 21:34:27,382 [pool-4094-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:27,383 [pool-4094-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c has been successfully formatted.
2023-03-20 21:34:27,383 [pool-4094-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-02D605BA4E5C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:27,383 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:27,383 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:27,383 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:27,384 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:27,385 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:27,385 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: start as a follower, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-02D605BA4E5C,id=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:27,392 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:27,392 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:27,392 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:27,393 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:27,393 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:27,394 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c.
2023-03-20 21:34:27,645 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: addNew group-A2799A78EBF2:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER] returns group-A2799A78EBF2:java.util.concurrent.CompletableFuture@1d25163[Not completed]
2023-03-20 21:34:27,645 [pool-4072-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: new RaftServerImpl for group-A2799A78EBF2:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:27,645 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:27,645 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:27,645 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:27,645 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:27,645 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:27,645 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: ConfigurationManager, init=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis] (custom)
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:27,646 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:27,647 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:27,647 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:27,647 [pool-4072-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/16659239-5113-4ca3-8976-a2799a78ebf2 does not exist. Creating ...
2023-03-20 21:34:27,647 [pool-4072-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/16659239-5113-4ca3-8976-a2799a78ebf2/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:27,648 [pool-4072-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/16659239-5113-4ca3-8976-a2799a78ebf2 has been successfully formatted.
2023-03-20 21:34:27,648 [pool-4072-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-A2799A78EBF2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:27,648 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,649 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 16659239-5113-4ca3-8976-a2799a78ebf2, Nodes: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1226cf83-b1fd-416f-9846-61bdfa3ff6b3, CreationTimestamp2023-03-20T21:34:24.648Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/16659239-5113-4ca3-8976-a2799a78ebf2
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,649 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:27,649 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:27,650 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:27,650 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,657 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:27,657 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:27,657 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: start as a follower, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: start 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2799A78EBF2,id=1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:27,658 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:27,658 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:27,658 [pool-4072-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:27,659 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=16659239-5113-4ca3-8976-a2799a78ebf2
2023-03-20 21:34:27,659 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=16659239-5113-4ca3-8976-a2799a78ebf2.
2023-03-20 21:34:27,948 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: addNew group-59442E686788:[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:1|startupRole:FOLLOWER] returns group-59442E686788:java.util.concurrent.CompletableFuture@3b23119a[Not completed]
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: new RaftServerImpl for group-59442E686788:[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788: ConfigurationManager, init=-1: peers:[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis] (custom)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:27,949 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:27,950 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:27,950 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:27,950 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:27,950 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:27,950 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:27,950 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:27,950 [pool-4094-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/e59ede23-824b-49aa-b4ff-59442e686788 does not exist. Creating ...
2023-03-20 21:34:27,951 [pool-4094-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/e59ede23-824b-49aa-b4ff-59442e686788/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:27,952 [pool-4094-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/e59ede23-824b-49aa-b4ff-59442e686788 has been successfully formatted.
2023-03-20 21:34:27,952 [pool-4094-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-59442E686788: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:27,952 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:27,952 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:27,952 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:27,953 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: e59ede23-824b-49aa-b4ff-59442e686788, Nodes: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf, CreationTimestamp2023-03-20T21:34:24.950Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:27,953 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/e59ede23-824b-49aa-b4ff-59442e686788
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:27,953 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:27,954 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:27,954 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:27,954 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:27,954 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:27,954 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:27,961 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:27,961 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:27,961 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788: start as a follower, conf=-1: peers:[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59442E686788,id=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:27,962 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:27,962 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:27,962 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:27,963 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=e59ede23-824b-49aa-b4ff-59442e686788
2023-03-20 21:34:27,963 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=e59ede23-824b-49aa-b4ff-59442e686788.
2023-03-20 21:34:28,161 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:28,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:28,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:28,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:28,264 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: addNew group-50915993717E:[9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:1|startupRole:FOLLOWER] returns group-50915993717E:java.util.concurrent.CompletableFuture@4670b085[Not completed]
2023-03-20 21:34:28,265 [pool-4116-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: new RaftServerImpl for group-50915993717E:[9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:28,265 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:28,265 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:28,265 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:28,265 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E: ConfigurationManager, init=-1: peers:[9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis] (custom)
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:28,266 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:28,267 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:28,267 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:28,267 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:28,267 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:28,267 [pool-4116-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/402930f6-6fce-4ea8-a53b-50915993717e does not exist. Creating ...
2023-03-20 21:34:28,268 [pool-4116-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/402930f6-6fce-4ea8-a53b-50915993717e/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:28,269 [pool-4116-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/402930f6-6fce-4ea8-a53b-50915993717e has been successfully formatted.
2023-03-20 21:34:28,269 [pool-4116-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-50915993717E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:28,269 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:28,269 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:28,269 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,269 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:28,269 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 402930f6-6fce-4ea8-a53b-50915993717e, Nodes: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9ce389bc-6c47-40b9-aa21-f44fc17fd7db, CreationTimestamp2023-03-20T21:34:25.266Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:28,269 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:28,269 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:28,269 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/402930f6-6fce-4ea8-a53b-50915993717e
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:28,270 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:28,271 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,278 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:28,278 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:28,278 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:28,278 [pool-4116-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,278 [pool-4116-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,278 [pool-4116-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E: start as a follower, conf=-1: peers:[9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:28,278 [pool-4116-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:28,278 [pool-4116-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: start 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState
2023-03-20 21:34:28,279 [pool-4116-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-50915993717E,id=9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:28,279 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:28,279 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:28,279 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:28,279 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:28,279 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:28,279 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:28,279 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=402930f6-6fce-4ea8-a53b-50915993717e
2023-03-20 21:34:28,279 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=402930f6-6fce-4ea8-a53b-50915993717e.
2023-03-20 21:34:28,279 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: addNew group-08F3B6F653FF:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER] returns group-08F3B6F653FF:java.util.concurrent.CompletableFuture@424f2c93[Not completed]
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: new RaftServerImpl for group-08F3B6F653FF:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: ConfigurationManager, init=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis] (custom)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:28,280 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:28,281 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:28,281 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:28,281 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:28,281 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:28,281 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:28,281 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:28,281 [pool-4116-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff does not exist. Creating ...
2023-03-20 21:34:28,282 [pool-4116-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:28,283 [pool-4116-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff has been successfully formatted.
2023-03-20 21:34:28,283 [pool-4116-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-08F3B6F653FF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:28,283 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:28,283 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:28,283 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,283 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:28,283 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:28,283 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:28,283 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:28,284 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:28,285 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,292 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:28,292 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:28,292 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:28,292 [pool-4116-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,292 [pool-4116-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,292 [pool-4116-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: start as a follower, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:28,293 [pool-4116-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:28,293 [pool-4116-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: start 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:28,293 [pool-4116-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-08F3B6F653FF,id=9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:28,293 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:28,293 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:28,293 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:28,293 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:28,293 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:28,293 [pool-4116-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:28,293 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff
2023-03-20 21:34:28,298 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c2f44316-1a3e-468b-9a76-53c43d628173: addNew group-08F3B6F653FF:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER] returns group-08F3B6F653FF:java.util.concurrent.CompletableFuture@24fd1aa[Not completed]
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - c2f44316-1a3e-468b-9a76-53c43d628173: new RaftServerImpl for group-08F3B6F653FF:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: ConfigurationManager, init=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis] (custom)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:28,299 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:28,300 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:28,300 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:28,300 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:28,300 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:28,300 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:28,300 [pool-4138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff does not exist. Creating ...
2023-03-20 21:34:28,301 [pool-4138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:28,302 [pool-4138-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff has been successfully formatted.
2023-03-20 21:34:28,303 [pool-4138-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-08F3B6F653FF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:28,303 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:28,303 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:28,303 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,303 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:28,303 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:28,303 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,303 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:28,303 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:28,304 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:28,305 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,312 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:28,313 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:28,313 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:28,313 [pool-4138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,313 [pool-4138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,313 [pool-4138-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: start as a follower, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:28,313 [pool-4138-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:28,313 [pool-4138-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c2f44316-1a3e-468b-9a76-53c43d628173: start c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:28,313 [pool-4138-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-08F3B6F653FF,id=c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:28,313 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:28,315 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:28,315 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:28,315 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:28,316 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:28,316 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:28,321 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: addNew group-08F3B6F653FF:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER] returns group-08F3B6F653FF:java.util.concurrent.CompletableFuture@1775241f[Not completed]
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: new RaftServerImpl for group-08F3B6F653FF:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: ConfigurationManager, init=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis] (custom)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:28,322 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:28,371 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:28,371 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:28,371 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:28,371 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:28,371 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:28,371 [pool-4160-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff does not exist. Creating ...
2023-03-20 21:34:28,375 [pool-4160-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:28,377 [pool-4160-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff has been successfully formatted.
2023-03-20 21:34:28,377 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:28,377 [pool-4160-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-08F3B6F653FF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:28,378 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:28,378 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:28,378 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,378 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:28,378 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:28,378 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:28,379 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:28,380 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,383 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:28,383 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:28,383 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:28,383 [pool-4160-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,383 [pool-4160-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,384 [pool-4160-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: start as a follower, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:28,384 [pool-4160-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:28,384 [pool-4160-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: start 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:28,384 [pool-4160-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-08F3B6F653FF,id=6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:28,384 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:28,384 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:28,384 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:28,384 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:28,384 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:28,384 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:28,386 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff.
2023-03-20 21:34:28,561 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c2f44316-1a3e-468b-9a76-53c43d628173: addNew group-712CDE8CCBF2:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER] returns group-712CDE8CCBF2:java.util.concurrent.CompletableFuture@333beb59[Not completed]
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - c2f44316-1a3e-468b-9a76-53c43d628173: new RaftServerImpl for group-712CDE8CCBF2:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2: ConfigurationManager, init=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis] (custom)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:28,562 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:28,563 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:28,563 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:28,563 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:28,563 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:28,563 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:28,563 [pool-4138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/c405d3a8-315a-4fbf-b7da-712cde8ccbf2 does not exist. Creating ...
2023-03-20 21:34:28,564 [pool-4138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/c405d3a8-315a-4fbf-b7da-712cde8ccbf2/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:28,565 [pool-4138-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/c405d3a8-315a-4fbf-b7da-712cde8ccbf2 has been successfully formatted.
2023-03-20 21:34:28,565 [pool-4138-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-712CDE8CCBF2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:28,565 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:28,566 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:28,566 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: c405d3a8-315a-4fbf-b7da-712cde8ccbf2, Nodes: c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c2f44316-1a3e-468b-9a76-53c43d628173, CreationTimestamp2023-03-20T21:34:25.562Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:28,566 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,566 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:28,566 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:28,566 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:28,566 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/c405d3a8-315a-4fbf-b7da-712cde8ccbf2
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:28,567 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:28,568 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2: start as a follower, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c2f44316-1a3e-468b-9a76-53c43d628173: start c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-712CDE8CCBF2,id=c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:28,571 [pool-4138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:28,572 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:28,572 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:28,572 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=c405d3a8-315a-4fbf-b7da-712cde8ccbf2
2023-03-20 21:34:28,572 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=c405d3a8-315a-4fbf-b7da-712cde8ccbf2.
2023-03-20 21:34:28,649 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:28,864 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: addNew group-F785482B8116:[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:1|startupRole:FOLLOWER] returns group-F785482B8116:java.util.concurrent.CompletableFuture@27a2ca06[Not completed]
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: new RaftServerImpl for group-F785482B8116:[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116: ConfigurationManager, init=-1: peers:[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis] (custom)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:28,865 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:28,866 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:28,866 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:28,866 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:28,866 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:28,866 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:28,866 [pool-4160-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/e5a8d140-d18d-49ef-8d60-f785482b8116 does not exist. Creating ...
2023-03-20 21:34:28,867 [pool-4160-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/e5a8d140-d18d-49ef-8d60-f785482b8116/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:28,868 [pool-4160-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/e5a8d140-d18d-49ef-8d60-f785482b8116 has been successfully formatted.
2023-03-20 21:34:28,868 [pool-4160-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-F785482B8116: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:28,868 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:28,868 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:28,868 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,868 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:28,869 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: e5a8d140-d18d-49ef-8d60-f785482b8116, Nodes: 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:6b93f795-e4f1-4cdd-8e17-5fb6627a9a38, CreationTimestamp2023-03-20T21:34:25.866Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:28,869 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/e5a8d140-d18d-49ef-8d60-f785482b8116
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:28,869 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:28,870 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:28,870 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:28,870 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:28,870 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:28,871 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:28,873 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:28,873 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:28,873 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116: start as a follower, conf=-1: peers:[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: start 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState
2023-03-20 21:34:28,874 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F785482B8116,id=6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:28,874 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:28,874 [pool-4160-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:28,875 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=e5a8d140-d18d-49ef-8d60-f785482b8116
2023-03-20 21:34:28,875 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=e5a8d140-d18d-49ef-8d60-f785482b8116.
2023-03-20 21:34:29,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:29,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:29,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:29,167 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ad06446d-1378-4ceb-aafe-e920688dce34: addNew group-7ECEA2AD9ACE:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:1|startupRole:FOLLOWER] returns group-7ECEA2AD9ACE:java.util.concurrent.CompletableFuture@189d49da[Not completed]
2023-03-20 21:34:29,168 [pool-4182-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - ad06446d-1378-4ceb-aafe-e920688dce34: new RaftServerImpl for group-7ECEA2AD9ACE:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:29,168 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:29,168 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:29,168 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:29,168 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:29,168 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:29,168 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:29,168 [pool-4182-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE: ConfigurationManager, init=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis] (custom)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:29,169 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:29,170 [pool-4182-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/df6acdd5-290a-4c11-993a-7ecea2ad9ace does not exist. Creating ...
2023-03-20 21:34:29,170 [pool-4182-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/df6acdd5-290a-4c11-993a-7ecea2ad9ace/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:29,171 [pool-4182-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/df6acdd5-290a-4c11-993a-7ecea2ad9ace has been successfully formatted.
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-7ECEA2AD9ACE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:29,172 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: df6acdd5-290a-4c11-993a-7ecea2ad9ace, Nodes: ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ad06446d-1378-4ceb-aafe-e920688dce34, CreationTimestamp2023-03-20T21:34:26.173Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/df6acdd5-290a-4c11-993a-7ecea2ad9ace
2023-03-20 21:34:29,172 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:29,172 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:29,173 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:29,173 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:29,173 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:29,173 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:29,173 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:29,173 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:29,176 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:29,176 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:29,176 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:29,176 [pool-4182-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:29,176 [pool-4182-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:29,177 [pool-4182-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE: start as a follower, conf=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:29,177 [pool-4182-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:29,177 [pool-4182-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad06446d-1378-4ceb-aafe-e920688dce34: start ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState
2023-03-20 21:34:29,177 [pool-4182-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7ECEA2AD9ACE,id=ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:29,177 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:29,177 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:29,177 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:29,177 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:29,177 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:29,177 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:29,177 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=df6acdd5-290a-4c11-993a-7ecea2ad9ace
2023-03-20 21:34:29,177 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=df6acdd5-290a-4c11-993a-7ecea2ad9ace.
2023-03-20 21:34:29,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:29,372 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:29,566 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:29,868 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:29,953 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:30,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:30,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:30,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:30,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:30,285 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:30,371 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:30,566 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:30,649 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:31,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:31,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:31,162 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:31,172 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:31,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:31,372 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:31,869 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:31,953 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:32,163 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:32,163 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:32,163 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:32,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:32,285 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:32,355 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5008368646ns, electionTimeout:5008ms
2023-03-20 21:34:32,355 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState
2023-03-20 21:34:32,355 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:32,355 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:32,355 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139
2023-03-20 21:34:32,356 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,356 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-C381D26A4E6F with new leaderId: c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F: change Leader from null to c810b0b2-f38c-4bc5-874a-38f1937d7d9e at term 1 for becomeLeader, leader elected after 5020ms
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:32,357 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:32,358 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:32,358 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:32,358 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:32,358 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:32,358 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:32,358 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderStateImpl
2023-03-20 21:34:32,358 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:32,359 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderElection139] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F: set configuration 0: peers:[c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,360 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/946b457e-a222-4d6d-be88-c381d26a4e6f/current/log_inprogress_0
2023-03-20 21:34:32,444 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5087350237ns, electionTimeout:5087ms
2023-03-20 21:34:32,444 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:32,444 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:32,444 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:32,444 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140
2023-03-20 21:34:32,444 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,445 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:32,445 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:32,445 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:32,445 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:32,446 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5053379126ns, electionTimeout:5053ms
2023-03-20 21:34:32,446 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:32,446 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:32,446 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:32,446 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141
2023-03-20 21:34:32,448 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,458 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:32,458 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:32,458 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:32,459 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:32,464 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: receive requestVote(PRE_VOTE, c810b0b2-f38c-4bc5-874a-38f1937d7d9e, group-02D605BA4E5C, 0, (t:0, i:0))
2023-03-20 21:34:32,465 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: receive requestVote(PRE_VOTE, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf, group-02D605BA4E5C, 0, (t:0, i:0))
2023-03-20 21:34:32,465 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FOLLOWER: reject PRE_VOTE from ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: our priority 1 > candidate's priority 0
2023-03-20 21:34:32,465 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C replies to PRE_VOTE vote request: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf<-1226cf83-b1fd-416f-9846-61bdfa3ff6b3#0:FAIL-t0. Peer's state: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C:t0, leader=null, voted=, raftlog=Memoized:1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,465 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:32,465 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf<-1226cf83-b1fd-416f-9846-61bdfa3ff6b3#0:FAIL-t0
2023-03-20 21:34:32,465 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141 PRE_VOTE round 0: result REJECTED
2023-03-20 21:34:32,470 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: receive requestVote(PRE_VOTE, c810b0b2-f38c-4bc5-874a-38f1937d7d9e, group-02D605BA4E5C, 0, (t:0, i:0))
2023-03-20 21:34:32,470 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FOLLOWER: reject PRE_VOTE from c810b0b2-f38c-4bc5-874a-38f1937d7d9e: our priority 1 > candidate's priority 0
2023-03-20 21:34:32,470 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C replies to PRE_VOTE vote request: c810b0b2-f38c-4bc5-874a-38f1937d7d9e<-1226cf83-b1fd-416f-9846-61bdfa3ff6b3#0:FAIL-t0. Peer's state: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C:t0, leader=null, voted=, raftlog=Memoized:1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,471 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:32,471 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c810b0b2-f38c-4bc5-874a-38f1937d7d9e<-1226cf83-b1fd-416f-9846-61bdfa3ff6b3#0:FAIL-t0
2023-03-20 21:34:32,471 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140 PRE_VOTE round 0: result REJECTED
2023-03-20 21:34:32,471 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:34:32,471 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140
2023-03-20 21:34:32,471 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-LeaderElection140] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:32,471 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-CANDIDATE: accept PRE_VOTE from c810b0b2-f38c-4bc5-874a-38f1937d7d9e: our priority 0 <= candidate's priority 0
2023-03-20 21:34:32,471 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C replies to PRE_VOTE vote request: c810b0b2-f38c-4bc5-874a-38f1937d7d9e<-ad5f436c-b0db-4b4f-b4fd-dcb016937dbf#0:OK-t0. Peer's state: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C:t0, leader=null, voted=, raftlog=Memoized:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,471 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: receive requestVote(PRE_VOTE, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf, group-02D605BA4E5C, 0, (t:0, i:0))
2023-03-20 21:34:32,471 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:34:32,471 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141
2023-03-20 21:34:32,473 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-LeaderElection141] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:32,473 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FOLLOWER: accept PRE_VOTE from ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: our priority 0 <= candidate's priority 0
2023-03-20 21:34:32,473 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C replies to PRE_VOTE vote request: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf<-c810b0b2-f38c-4bc5-874a-38f1937d7d9e#0:OK-t0. Peer's state: c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C:t0, leader=null, voted=, raftlog=Memoized:c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,475 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:32,475 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:32,477 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:32,477 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:32,567 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:32,575 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5201212728ns, electionTimeout:5200ms
2023-03-20 21:34:32,575 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: shutdown 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:32,575 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:32,575 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:32,575 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: start 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142
2023-03-20 21:34:32,575 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,576 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:32,578 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:32,578 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:32,578 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:32,582 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: receive requestVote(PRE_VOTE, 1226cf83-b1fd-416f-9846-61bdfa3ff6b3, group-02D605BA4E5C, 0, (t:0, i:0))
2023-03-20 21:34:32,582 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FOLLOWER: accept PRE_VOTE from 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: our priority 0 <= candidate's priority 1
2023-03-20 21:34:32,582 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: receive requestVote(PRE_VOTE, 1226cf83-b1fd-416f-9846-61bdfa3ff6b3, group-02D605BA4E5C, 0, (t:0, i:0))
2023-03-20 21:34:32,582 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C replies to PRE_VOTE vote request: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3<-c810b0b2-f38c-4bc5-874a-38f1937d7d9e#0:OK-t0. Peer's state: c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C:t0, leader=null, voted=, raftlog=Memoized:c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,582 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FOLLOWER: accept PRE_VOTE from 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: our priority 0 <= candidate's priority 1
2023-03-20 21:34:32,582 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C replies to PRE_VOTE vote request: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3<-ad5f436c-b0db-4b4f-b4fd-dcb016937dbf#0:OK-t0. Peer's state: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C:t0, leader=null, voted=, raftlog=Memoized:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,582 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:32,582 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3<-c810b0b2-f38c-4bc5-874a-38f1937d7d9e#0:OK-t0
2023-03-20 21:34:32,582 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142 PRE_VOTE round 0: result PASSED
2023-03-20 21:34:32,584 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142 ELECTION round 0: submit vote requests at term 1 for -1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,584 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: receive requestVote(ELECTION, 1226cf83-b1fd-416f-9846-61bdfa3ff6b3, group-02D605BA4E5C, 1, (t:0, i:0))
2023-03-20 21:34:32,584 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FOLLOWER: accept ELECTION from 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: our priority 0 <= candidate's priority 1
2023-03-20 21:34:32,584 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:32,584 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:32,584 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:32,585 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:32,585 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:32,585 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: receive requestVote(ELECTION, 1226cf83-b1fd-416f-9846-61bdfa3ff6b3, group-02D605BA4E5C, 1, (t:0, i:0))
2023-03-20 21:34:32,585 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FOLLOWER: accept ELECTION from 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: our priority 0 <= candidate's priority 1
2023-03-20 21:34:32,585 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:32,585 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:32,585 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState was interrupted
2023-03-20 21:34:32,588 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:32,588 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:32,588 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:32,588 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState was interrupted
2023-03-20 21:34:32,589 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C replies to ELECTION vote request: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3<-c810b0b2-f38c-4bc5-874a-38f1937d7d9e#0:OK-t1. Peer's state: c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C:t1, leader=null, voted=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, raftlog=Memoized:c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,591 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:32,591 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3<-c810b0b2-f38c-4bc5-874a-38f1937d7d9e#0:OK-t1
2023-03-20 21:34:32,591 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142 ELECTION round 0: result PASSED
2023-03-20 21:34:32,591 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: shutdown 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142
2023-03-20 21:34:32,591 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:32,591 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-02D605BA4E5C with new leaderId: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:32,591 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: change Leader from null to 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 at term 1 for becomeLeader, leader elected after 5226ms
2023-03-20 21:34:32,591 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:32,591 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:32,591 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:32,591 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:32,592 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C replies to ELECTION vote request: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3<-ad5f436c-b0db-4b4f-b4fd-dcb016937dbf#0:OK-t1. Peer's state: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C:t1, leader=null, voted=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, raftlog=Memoized:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,592 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:32,592 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:32,592 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:32,592 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:32,592 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:32,592 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:32,593 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:32,594 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:32,594 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:32,594 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:32,594 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: start 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderStateImpl
2023-03-20 21:34:32,594 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:32,592 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:32,592 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 27a0404e-e3ec-48ab-a304-02d605ba4e5c, Nodes: c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10)ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:1226cf83-b1fd-416f-9846-61bdfa3ff6b3, CreationTimestamp2023-03-20T21:34:24.950Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:32,594 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-20 21:34:32,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-20 21:34:32,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-20 21:34:32,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-20 21:34:32,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-20 21:34:32,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-20 21:34:32,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-20 21:34:32,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-20 21:34:32,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1175)) - Service ReplicationManager transitions to RUNNING.
2023-03-20 21:34:32,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-20 21:34:32,595 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/current/log_inprogress_0
2023-03-20 21:34:32,609 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderElection142] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: set configuration 0: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,611 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-02D605BA4E5C with new leaderId: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:32,611 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: change Leader from null to 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 at term 1 for appendEntries, leader elected after 5262ms
2023-03-20 21:34:32,619 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: set configuration 0: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,619 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:32,619 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-02D605BA4E5C with new leaderId: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:32,620 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: change Leader from null to 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 at term 1 for appendEntries, leader elected after 5233ms
2023-03-20 21:34:32,620 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/current/log_inprogress_0
2023-03-20 21:34:32,623 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: set configuration 0: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,623 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:32,624 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/current/log_inprogress_0
2023-03-20 21:34:32,715 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5057578262ns, electionTimeout:5057ms
2023-03-20 21:34:32,716 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: shutdown 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState
2023-03-20 21:34:32,716 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:32,716 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:32,716 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: start 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143
2023-03-20 21:34:32,716 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,716 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:32,717 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143 ELECTION round 0: submit vote requests at term 1 for -1: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: shutdown 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-A2799A78EBF2 with new leaderId: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: change Leader from null to 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 at term 1 for becomeLeader, leader elected after 5071ms
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: start 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderStateImpl
2023-03-20 21:34:32,718 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:32,720 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderElection143] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: set configuration 0: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,720 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/16659239-5113-4ca3-8976-a2799a78ebf2/current/log_inprogress_0
2023-03-20 21:34:32,967 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5005563242ns, electionTimeout:5005ms
2023-03-20 21:34:32,968 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState
2023-03-20 21:34:32,968 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:32,968 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:32,968 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144
2023-03-20 21:34:32,968 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,968 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:32,969 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,969 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:32,969 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144
2023-03-20 21:34:32,969 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:32,969 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-59442E686788 with new leaderId: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:32,969 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788: change Leader from null to ad5f436c-b0db-4b4f-b4fd-dcb016937dbf at term 1 for becomeLeader, leader elected after 5019ms
2023-03-20 21:34:32,970 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:32,970 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:32,970 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:32,971 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:32,971 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:32,971 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:32,971 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:32,971 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:32,971 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderStateImpl
2023-03-20 21:34:32,971 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:32,977 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderElection144] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788: set configuration 0: peers:[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:32,978 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/e59ede23-824b-49aa-b4ff-59442e686788/current/log_inprogress_0
2023-03-20 21:34:33,163 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:33,163 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Cluster exits safe mode
2023-03-20 21:34:33,163 [Listener at 127.0.0.1/46711] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:33,166 [Listener at 127.0.0.1/46711] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:33,167 [Listener at 127.0.0.1/46711] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:33,167 [Listener at 127.0.0.1/46711] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-20 21:34:33,167 [Listener at 127.0.0.1/46711] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-20 21:34:33,168 [Listener at 127.0.0.1/46711] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:33,168 [Listener at 127.0.0.1/46711] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:33,183 [Listener at 0.0.0.0/34783] INFO  rpc.RpcClient (RpcClient.java:createVolume(476)) - Creating Volume: vol1, with user54411 as owner and space quota set to -1 bytes, counts quota set to -1
2023-03-20 21:34:33,190 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(195)) - created volume:vol1 for user:user54411
2023-03-20 21:34:33,195 [Listener at 0.0.0.0/34783] INFO  rpc.RpcClient (RpcClient.java:createBucket(698)) - Creating Bucket: vol1/bucket1, with bucket layout LEGACY, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2023-03-20 21:34:33,200 [OM StateMachine ApplyTransaction Thread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(263)) - created bucket: bucket1 of layout LEGACY in volume: vol1
2023-03-20 21:34:33,222 [IPC Server handler 3 on default port 33765] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2023-03-20 21:34:33,222 [IPC Server handler 3 on default port 33765] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(237)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-03-20 21:34:33,222 [IPC Server handler 3 on default port 33765] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
2023-03-20 21:34:33,257 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:33,341 [Listener at 127.0.0.1/46711] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-20 21:34:33,341 [Listener at 127.0.0.1/46711] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-20 21:34:33,342 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:33,343 [Listener at 127.0.0.1/46711] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:33,343 [Listener at 127.0.0.1/46711] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:33,346 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5053435172ns, electionTimeout:5053ms
2023-03-20 21:34:33,346 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: shutdown 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:33,346 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:33,347 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5033846896ns, electionTimeout:5031ms
2023-03-20 21:34:33,347 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c2f44316-1a3e-468b-9a76-53c43d628173: shutdown c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:33,347 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:33,356 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:33,356 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c2f44316-1a3e-468b-9a76-53c43d628173: start c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146
2023-03-20 21:34:33,357 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:33,357 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: start 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145
2023-03-20 21:34:33,357 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,363 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,371 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:33,375 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:33,375 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:33,376 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:33,380 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:33,386 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:33,386 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:33,389 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:33,396 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: receive requestVote(PRE_VOTE, c2f44316-1a3e-468b-9a76-53c43d628173, group-08F3B6F653FF, 0, (t:0, i:0))
2023-03-20 21:34:33,396 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FOLLOWER: accept PRE_VOTE from c2f44316-1a3e-468b-9a76-53c43d628173: our priority 0 <= candidate's priority 1
2023-03-20 21:34:33,396 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF replies to PRE_VOTE vote request: c2f44316-1a3e-468b-9a76-53c43d628173<-6b93f795-e4f1-4cdd-8e17-5fb6627a9a38#0:OK-t0. Peer's state: 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF:t0, leader=null, voted=, raftlog=Memoized:6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,396 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: receive requestVote(PRE_VOTE, c2f44316-1a3e-468b-9a76-53c43d628173, group-08F3B6F653FF, 0, (t:0, i:0))
2023-03-20 21:34:33,396 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-CANDIDATE: accept PRE_VOTE from c2f44316-1a3e-468b-9a76-53c43d628173: our priority 0 <= candidate's priority 1
2023-03-20 21:34:33,396 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF replies to PRE_VOTE vote request: c2f44316-1a3e-468b-9a76-53c43d628173<-9ce389bc-6c47-40b9-aa21-f44fc17fd7db#0:OK-t0. Peer's state: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF:t0, leader=null, voted=, raftlog=Memoized:9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,397 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: receive requestVote(PRE_VOTE, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db, group-08F3B6F653FF, 0, (t:0, i:0))
2023-03-20 21:34:33,397 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FOLLOWER: accept PRE_VOTE from 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: our priority 0 <= candidate's priority 0
2023-03-20 21:34:33,397 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF replies to PRE_VOTE vote request: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db<-6b93f795-e4f1-4cdd-8e17-5fb6627a9a38#0:OK-t0. Peer's state: 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF:t0, leader=null, voted=, raftlog=Memoized:6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,398 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: receive requestVote(PRE_VOTE, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db, group-08F3B6F653FF, 0, (t:0, i:0))
2023-03-20 21:34:33,398 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-CANDIDATE: reject PRE_VOTE from 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: our priority 1 > candidate's priority 0
2023-03-20 21:34:33,398 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF replies to PRE_VOTE vote request: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db<-c2f44316-1a3e-468b-9a76-53c43d628173#0:FAIL-t0. Peer's state: c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF:t0, leader=null, voted=, raftlog=Memoized:c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,409 [Listener at 127.0.0.1/46711] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 66 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:33,411 [Listener at 127.0.0.1/46711] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(349)) - upgrade localId to 111677748019200000
2023-03-20 21:34:33,411 [Listener at 127.0.0.1/46711] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(359)) - upgrade delTxnId to 0
2023-03-20 21:34:33,411 [Listener at 127.0.0.1/46711] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(376)) - upgrade containerId to 0
2023-03-20 21:34:33,411 [Listener at 127.0.0.1/46711] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-20 21:34:33,412 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:33,412 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c2f44316-1a3e-468b-9a76-53c43d628173<-6b93f795-e4f1-4cdd-8e17-5fb6627a9a38#0:OK-t0
2023-03-20 21:34:33,412 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2023-03-20 21:34:33,412 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db<-6b93f795-e4f1-4cdd-8e17-5fb6627a9a38#0:OK-t0
2023-03-20 21:34:33,412 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db<-c2f44316-1a3e-468b-9a76-53c43d628173#0:FAIL-t0
2023-03-20 21:34:33,414 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145 PRE_VOTE round 0: result REJECTED
2023-03-20 21:34:33,414 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:34:33,414 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: shutdown 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145
2023-03-20 21:34:33,414 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-LeaderElection145] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: start 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:33,415 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146 PRE_VOTE round 0: result PASSED
2023-03-20 21:34:33,417 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:33,417 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:33,420 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,430 [Listener at 127.0.0.1/46711] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-20 21:34:33,430 [Listener at 127.0.0.1/46711] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-20 21:34:33,430 [Listener at 127.0.0.1/46711] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:33,430 [Listener at 127.0.0.1/46711] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2023-03-20 21:34:33,430 [Listener at 127.0.0.1/46711] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-20 21:34:33,430 [Listener at 127.0.0.1/46711] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:33,430 [Listener at 127.0.0.1/46711] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-20 21:34:33,431 [Listener at 127.0.0.1/46711] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-20 21:34:33,431 [Listener at 127.0.0.1/46711] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-20 21:34:33,433 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: receive requestVote(ELECTION, c2f44316-1a3e-468b-9a76-53c43d628173, group-08F3B6F653FF, 1, (t:0, i:0))
2023-03-20 21:34:33,433 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FOLLOWER: accept ELECTION from c2f44316-1a3e-468b-9a76-53c43d628173: our priority 0 <= candidate's priority 1
2023-03-20 21:34:33,433 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:33,433 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: shutdown 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:33,436 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:33,436 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:33,436 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: start 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:33,436 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState was interrupted
2023-03-20 21:34:33,439 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:33,439 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:33,439 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF replies to ELECTION vote request: c2f44316-1a3e-468b-9a76-53c43d628173<-6b93f795-e4f1-4cdd-8e17-5fb6627a9a38#0:OK-t1. Peer's state: 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF:t1, leader=null, voted=c2f44316-1a3e-468b-9a76-53c43d628173, raftlog=Memoized:6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,442 [Listener at 127.0.0.1/46711] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-20 21:34:33,442 [Listener at 127.0.0.1/46711] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-20 21:34:33,443 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: receive requestVote(ELECTION, c2f44316-1a3e-468b-9a76-53c43d628173, group-08F3B6F653FF, 1, (t:0, i:0))
2023-03-20 21:34:33,443 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FOLLOWER: accept ELECTION from c2f44316-1a3e-468b-9a76-53c43d628173: our priority 0 <= candidate's priority 1
2023-03-20 21:34:33,443 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:33,443 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: shutdown 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:33,444 [Listener at 127.0.0.1/46711] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-20 21:34:33,445 [Listener at 127.0.0.1/46711] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-20 21:34:33,445 [Listener at 127.0.0.1/46711] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-20 21:34:33,445 [Listener at 127.0.0.1/46711] INFO  replication.ReplicationManager (ReplicationManager.java:start(273)) - Starting Replication Monitor Thread.
2023-03-20 21:34:33,448 [Listener at 127.0.0.1/46711] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-20 21:34:33,448 [Listener at 127.0.0.1/46711] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2023-03-20 21:34:33,448 [Listener at 127.0.0.1/46711] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2023-03-20 21:34:33,448 [Listener at 127.0.0.1/46711] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-03-20 21:34:33,449 [Listener at 127.0.0.1/46711] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(395)) - SCM start with adminUsers: [runner]
2023-03-20 21:34:33,449 [Listener at 127.0.0.1/46711] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:33,449 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:33,450 [Listener at 0.0.0.0/44329] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:33,450 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:33,455 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: start 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:33,455 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState was interrupted
2023-03-20 21:34:33,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c2f44316-1a3e-468b-9a76-53c43d628173<-6b93f795-e4f1-4cdd-8e17-5fb6627a9a38#0:OK-t1
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146 ELECTION round 0: result PASSED
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c2f44316-1a3e-468b-9a76-53c43d628173: shutdown c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-08F3B6F653FF with new leaderId: c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: change Leader from null to c2f44316-1a3e-468b-9a76-53c43d628173 at term 1 for becomeLeader, leader elected after 5156ms
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:33,456 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:33,457 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: dcaa0c25-9483-47d9-b73e-08f3b6f653ff, Nodes: c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10)9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10)6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:c2f44316-1a3e-468b-9a76-53c43d628173, CreationTimestamp2023-03-20T21:34:25.867Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:33,459 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:33,459 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:33,459 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:33,459 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:33,459 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:33,459 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:33,459 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:33,459 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:33,460 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF replies to ELECTION vote request: c2f44316-1a3e-468b-9a76-53c43d628173<-9ce389bc-6c47-40b9-aa21-f44fc17fd7db#0:OK-t1. Peer's state: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF:t1, leader=null, voted=c2f44316-1a3e-468b-9a76-53c43d628173, raftlog=Memoized:9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,460 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:33,460 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:33,460 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:33,461 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:33,462 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c2f44316-1a3e-468b-9a76-53c43d628173: start c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderStateImpl
2023-03-20 21:34:33,462 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:33,464 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/current/log_inprogress_0
2023-03-20 21:34:33,470 [Listener at 0.0.0.0/41615] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:33,472 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:33,476 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5197393819ns, electionTimeout:5197ms
2023-03-20 21:34:33,476 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: shutdown 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState
2023-03-20 21:34:33,476 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:33,477 [Listener at 0.0.0.0/46329] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-20 21:34:33,477 [Listener at 0.0.0.0/46329] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(412)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-20 21:34:33,477 [Listener at 0.0.0.0/46329] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-20 21:34:33,477 [Listener at 0.0.0.0/46329] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1442)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:46329
2023-03-20 21:34:33,477 [Listener at 0.0.0.0/46329] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2023-03-20 21:34:33,487 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:33,487 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: start 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147
2023-03-20 21:34:33,488 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-server-thread2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-08F3B6F653FF with new leaderId: c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:33,488 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: change Leader from null to c2f44316-1a3e-468b-9a76-53c43d628173 at term 1 for appendEntries, leader elected after 5165ms
2023-03-20 21:34:33,489 [Listener at 0.0.0.0/46329] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(194)) - RPC server for Client  is listening at /0.0.0.0:46329
2023-03-20 21:34:33,490 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,490 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:33,492 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147 ELECTION round 0: submit vote requests at term 1 for -1: peers:[9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,492 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:33,492 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: shutdown 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147
2023-03-20 21:34:33,492 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:33,492 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-50915993717E with new leaderId: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:33,495 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderElection146] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: set configuration 0: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,495 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: set configuration 0: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,496 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:33,503 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E: change Leader from null to 9ce389bc-6c47-40b9-aa21-f44fc17fd7db at term 1 for becomeLeader, leader elected after 5225ms
2023-03-20 21:34:33,503 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:33,503 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:33,503 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:33,504 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:33,504 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:33,537 [Listener at 0.0.0.0/46329] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1456)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:41615
2023-03-20 21:34:33,541 [Listener at 0.0.0.0/46329] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:41615
2023-03-20 21:34:33,541 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:33,542 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:33,544 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-08F3B6F653FF with new leaderId: c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:33,545 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: change Leader from null to c2f44316-1a3e-468b-9a76-53c43d628173 at term 1 for appendEntries, leader elected after 5263ms
2023-03-20 21:34:33,545 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:33,545 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:33,545 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:33,545 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:33,545 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:33,545 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: start 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderStateImpl
2023-03-20 21:34:33,545 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:33,545 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/current/log_inprogress_0
2023-03-20 21:34:33,553 [Listener at 0.0.0.0/46329] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:44329
2023-03-20 21:34:33,555 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: set configuration 0: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,556 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:33,556 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:33,556 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:33,555 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/402930f6-6fce-4ea8-a53b-50915993717e/current/log_inprogress_0
2023-03-20 21:34:33,564 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@72abea78] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:33,566 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/current/log_inprogress_0
2023-03-20 21:34:33,566 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderElection147] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E: set configuration 0: peers:[9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,567 [Listener at 0.0.0.0/46329] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:0
2023-03-20 21:34:33,567 [Listener at 0.0.0.0/46329] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:33,572 [Listener at 0.0.0.0/46329] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:33,573 [Listener at 0.0.0.0/46329] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:33,573 [Listener at 0.0.0.0/46329] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:33,573 [Listener at 0.0.0.0/46329] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-20 21:34:33,574 [Listener at 0.0.0.0/46329] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:33,574 [Listener at 0.0.0.0/46329] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:33,575 [Listener at 0.0.0.0/46329] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/ozone-meta/webserver
2023-03-20 21:34:33,575 [Listener at 0.0.0.0/46329] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 44517
2023-03-20 21:34:33,575 [Listener at 0.0.0.0/46329] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:33,576 [Listener at 0.0.0.0/46329] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:33,576 [Listener at 0.0.0.0/46329] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:33,576 [Listener at 0.0.0.0/46329] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:33,576 [Listener at 0.0.0.0/46329] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@79e12f04{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:33,576 [Listener at 0.0.0.0/46329] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@61537f13{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-20 21:34:33,578 [Listener at 0.0.0.0/46329] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@708924a2{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-20 21:34:33,579 [Listener at 0.0.0.0/46329] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6469f994{HTTP/1.1, (http/1.1)}{0.0.0.0:44517}
2023-03-20 21:34:33,580 [Listener at 0.0.0.0/46329] INFO  server.Server (Server.java:doStart(415)) - Started @374849ms
2023-03-20 21:34:33,580 [Listener at 0.0.0.0/46329] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:33,580 [Listener at 0.0.0.0/46329] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:44517
2023-03-20 21:34:33,581 [Listener at 0.0.0.0/46329] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:33,584 [Listener at 0.0.0.0/46329] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-03-20 21:34:33,585 [Listener at 0.0.0.0/46329] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2023-03-20 21:34:33,585 [Listener at 0.0.0.0/46329] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-03-20 21:34:33,585 [Listener at 0.0.0.0/46329] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2023-03-20 21:34:33,585 [Listener at 0.0.0.0/46329] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:33,585 [Listener at 0.0.0.0/46329] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2023-03-20 21:34:33,630 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5058831694ns, electionTimeout:5058ms
2023-03-20 21:34:33,630 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c2f44316-1a3e-468b-9a76-53c43d628173: shutdown c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState
2023-03-20 21:34:33,630 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:33,630 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:33,630 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c2f44316-1a3e-468b-9a76-53c43d628173: start c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148
2023-03-20 21:34:33,645 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,645 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:33,647 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,647 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:33,647 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c2f44316-1a3e-468b-9a76-53c43d628173: shutdown c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148
2023-03-20 21:34:33,647 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:33,647 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-712CDE8CCBF2 with new leaderId: c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:33,654 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2: change Leader from null to c2f44316-1a3e-468b-9a76-53c43d628173 at term 1 for becomeLeader, leader elected after 5084ms
2023-03-20 21:34:33,654 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:33,654 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:33,654 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:33,654 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:33,654 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:33,654 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:33,654 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:33,654 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:33,655 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c2f44316-1a3e-468b-9a76-53c43d628173: start c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderStateImpl
2023-03-20 21:34:33,655 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:33,660 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/c405d3a8-315a-4fbf-b7da-712cde8ccbf2/current/log_inprogress_0
2023-03-20 21:34:33,662 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderElection148] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2: set configuration 0: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,749 [Listener at 0.0.0.0/46329] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 162 ms to scan 2 urls, producing 167 keys and 463 values [using 2 cores]
2023-03-20 21:34:33,749 [Listener at 0.0.0.0/46329] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2023-03-20 21:34:33,749 [Listener at 0.0.0.0/46329] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:33,749 [Listener at 0.0.0.0/46329] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:41615]
2023-03-20 21:34:33,750 [Listener at 0.0.0.0/46329] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:41615]
2023-03-20 21:34:33,761 [Listener at 0.0.0.0/46329] INFO  om.OzoneManager (OzoneManager.java:<init>(620)) - OM start with adminUsers: [runner]
2023-03-20 21:34:33,761 [Listener at 0.0.0.0/46329] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:33,762 [Listener at 0.0.0.0/46329] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2023-03-20 21:34:33,762 [Listener at 0.0.0.0/46329] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2023-03-20 21:34:33,943 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5069537653ns, electionTimeout:5069ms
2023-03-20 21:34:33,944 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: shutdown 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState
2023-03-20 21:34:33,944 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:33,949 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:33,949 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: start 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149
2023-03-20 21:34:33,951 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,951 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:33,956 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149 ELECTION round 0: submit vote requests at term 1 for -1: peers:[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:33,956 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:33,956 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: shutdown 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149
2023-03-20 21:34:33,956 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:33,956 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-F785482B8116 with new leaderId: 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:33,957 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116: change Leader from null to 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38 at term 1 for becomeLeader, leader elected after 5090ms
2023-03-20 21:34:33,957 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:33,957 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:33,957 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:33,957 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:33,957 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:33,957 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:33,958 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:33,958 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:33,958 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: start 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderStateImpl
2023-03-20 21:34:33,959 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:33,960 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/e5a8d140-d18d-49ef-8d60-f785482b8116/current/log_inprogress_0
2023-03-20 21:34:33,969 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderElection149] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116: set configuration 0: peers:[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:34,008 [Listener at 0.0.0.0/46329] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(750)) - S3 Multi-Tenancy is disabled
2023-03-20 21:34:34,009 [Listener at 0.0.0.0/46329] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:34,022 [IPC Server handler 1 on default port 42371] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(366)) - Starting Maintenance for node 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10)
2023-03-20 21:34:34,024 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) moved to HEALTHY state.
2023-03-20 21:34:34,026 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:34,026 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:34:34,036 [Listener at 0.0.0.0/46329] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4228)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2023-03-20 21:34:34,036 [Listener at 0.0.0.0/46329] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-20 21:34:34,036 [Listener at 0.0.0.0/46329] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(439)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2023-03-20 21:34:34,037 [Listener at 0.0.0.0/46329] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:34,037 [Listener at 0.0.0.0/46329] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:34,037 [Listener at 0.0.0.0/46329] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-20 21:34:34,037 [Listener at 0.0.0.0/46329] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(164)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:35217
2023-03-20 21:34:34,037 [Listener at 0.0.0.0/46329] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(636)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2023-03-20 21:34:34,037 [Listener at 0.0.0.0/46329] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:34,037 [Listener at 0.0.0.0/46329] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 35217 (fallback to raft.grpc.server.port)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 35217 (fallback to raft.grpc.server.port)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 35217 (custom)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:34,038 [Listener at 0.0.0.0/46329] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:34,039 [Listener at 0.0.0.0/46329] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2023-03-20 21:34:34,039 [Listener at 0.0.0.0/46329] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:34,039 [Listener at 0.0.0.0/46329] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:34,039 [Listener at 0.0.0.0/46329] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-20 21:34:34,039 [Listener at 0.0.0.0/46329] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:34,039 [Listener at 0.0.0.0/46329] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/ozone-meta/ratis] (custom)
2023-03-20 21:34:34,040 [Listener at 0.0.0.0/46329] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:35217|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@6b1bb2a9[Not completed]
2023-03-20 21:34:34,040 [Listener at 0.0.0.0/46329] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2107)) - OzoneManager Ratis server initialized at port 35217
2023-03-20 21:34:34,040 [Listener at 0.0.0.0/46329] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1134)) - Creating RPC Server
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:35217|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:localhost:35217|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/ozone-meta/ratis] (custom)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:34,042 [pool-4307-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:34,232 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5055422597ns, electionTimeout:5055ms
2023-03-20 21:34:34,232 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ad06446d-1378-4ceb-aafe-e920688dce34: shutdown ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState
2023-03-20 21:34:34,232 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:34,232 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:34,232 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad06446d-1378-4ceb-aafe-e920688dce34: start ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150
2023-03-20 21:34:34,238 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:34,238 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:34,240 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:34,240 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:34,240 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - ad06446d-1378-4ceb-aafe-e920688dce34: shutdown ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150
2023-03-20 21:34:34,240 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:34,240 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-7ECEA2AD9ACE with new leaderId: ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:34,240 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE: change Leader from null to ad06446d-1378-4ceb-aafe-e920688dce34 at term 1 for becomeLeader, leader elected after 5071ms
2023-03-20 21:34:34,241 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:34,241 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:34,241 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:34,241 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:34,241 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:34,241 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:34,241 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:34,241 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:34,241 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad06446d-1378-4ceb-aafe-e920688dce34: start ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderStateImpl
2023-03-20 21:34:34,242 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:34,243 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/df6acdd5-290a-4c11-993a-7ecea2ad9ace/current/log_inprogress_0
2023-03-20 21:34:34,254 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(326)) - Waiting for pipelines to close for 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10). There are 2 pipelines
2023-03-20 21:34:34,254 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderElection150] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE: set configuration 0: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:34,254 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:34,255 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10). Finalizing its pipelines [PipelineID=16659239-5113-4ca3-8976-a2799a78ebf2, PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c]
2023-03-20 21:34:34,255 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 16659239-5113-4ca3-8976-a2799a78ebf2, Nodes: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:1226cf83-b1fd-416f-9846-61bdfa3ff6b3, CreationTimestamp2023-03-20T21:34:24.648Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:34:34,255 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=16659239-5113-4ca3-8976-a2799a78ebf2 close command to datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:34,256 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 16659239-5113-4ca3-8976-a2799a78ebf2, Nodes: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:1226cf83-b1fd-416f-9846-61bdfa3ff6b3, CreationTimestamp2023-03-20T21:34:24.648Z[Etc/UTC]] removed.
2023-03-20 21:34:34,257 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #1 closed for pipeline=PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:34,257 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #2 closed for pipeline=PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:34,257 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #3 closed for pipeline=PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:34,257 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #1, current state: CLOSING
2023-03-20 21:34:34,257 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:34,258 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 27a0404e-e3ec-48ab-a304-02d605ba4e5c, Nodes: c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10)ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:1226cf83-b1fd-416f-9846-61bdfa3ff6b3, CreationTimestamp2023-03-20T21:34:24.950Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:34:34,258 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c close command to datanode c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:34,258 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #2, current state: CLOSING
2023-03-20 21:34:34,259 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #3, current state: CLOSING
2023-03-20 21:34:34,259 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c close command to datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:34,259 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c close command to datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:34,259 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 27a0404e-e3ec-48ab-a304-02d605ba4e5c, Nodes: c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10)ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:1226cf83-b1fd-416f-9846-61bdfa3ff6b3, CreationTimestamp2023-03-20T21:34:24.950Z[Etc/UTC]] removed.
2023-03-20 21:34:34,406 [Finalizer] WARN  managed.ManagedRocksObjectUtils (ManagedRocksObjectUtils.java:assertClosed(54)) - RocksIterator is not closed properly
2023-03-20 21:34:34,407 [Finalizer] WARN  managed.ManagedRocksObjectUtils (ManagedRocksObjectUtils.java:assertClosed(54)) - ManagedColumnFamilyOptions is not closed properly
2023-03-20 21:34:34,408 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c is not found
2023-03-20 21:34:34,408 [IPC Server handler 10 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-03-20 21:34:34,410 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=16659239-5113-4ca3-8976-a2799a78ebf2 is not found
2023-03-20 21:34:34,410 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c is not found
2023-03-20 21:34:34,410 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c is not found
2023-03-20 21:34:34,436 [Listener at 0.0.0.0/46329] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 396 ms to scan 19 urls, producing 68 keys and 4951 values [using 2 cores]
2023-03-20 21:34:34,437 [Listener at 0.0.0.0/46329] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:34,437 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:34,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:34,457 [Listener at 127.0.0.1/38731] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2023-03-20 21:34:34,476 [Listener at 127.0.0.1/38731] INFO  om.OzoneManager (OzoneManager.java:start(1564)) - OzoneManager RPC server is listening at localhost/127.0.0.1:38731
2023-03-20 21:34:34,476 [Listener at 127.0.0.1/38731] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(559)) - Starting OzoneManagerRatisServer om1 at port 35217
2023-03-20 21:34:34,476 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2023-03-20 21:34:34,478 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:34,479 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2023-03-20 21:34:34,479 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:34,479 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:34,479 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:34,479 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:34,479 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:34,479 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-20 21:34:34,479 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-03-20 21:34:34,480 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:34,483 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:34,483 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:34,483 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2023-03-20 21:34:34,483 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:34,483 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:34,488 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:localhost:35217|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:34,488 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:34,488 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2023-03-20 21:34:34,492 [om1-impl-thread1] ERROR util.JmxRegister (JmxRegister.java:tryRegister(40)) - Failed to register JMX Bean with name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.ratis.util.JmxRegister.tryRegister(JmxRegister.java:38)
	at org.apache.ratis.util.JmxRegister.register(JmxRegister.java:56)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:353)
	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:344)
	at org.apache.ratis.util.ConcurrentUtils.accept(ConcurrentUtils.java:173)
	at org.apache.ratis.util.ConcurrentUtils.lambda$null$3(ConcurrentUtils.java:165)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:34:34,492 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2023-03-20 21:34:34,493 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:34,493 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2023-03-20 21:34:34,493 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2023-03-20 21:34:34,493 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2023-03-20 21:34:34,493 [Listener at 127.0.0.1/38731] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - om1: start RPC server
2023-03-20 21:34:34,496 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:34,496 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:34,496 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - om1: GrpcService started, listening on 35217
2023-03-20 21:34:34,500 [Listener at 127.0.0.1/38731] INFO  om.OzoneManager (OzoneManager.java:start(1580)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2023-03-20 21:34:34,500 [JvmPauseMonitor92] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-om1: Started
2023-03-20 21:34:34,521 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2023-03-20 21:34:34,521 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:34,522 [Listener at 127.0.0.1/38731] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:34,522 [Listener at 127.0.0.1/38731] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:34,522 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:34,523 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2023-03-20 21:34:34,523 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:34,523 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:34,523 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/ozone-meta/webserver
2023-03-20 21:34:34,523 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 35475
2023-03-20 21:34:34,523 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:34,547 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:34,547 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:34,547 [Listener at 127.0.0.1/38731] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:34,550 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1e7d2104{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:34,550 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@25998747{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-20 21:34:34,552 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@275510ee{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-20 21:34:34,563 [Listener at 127.0.0.1/38731] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@11148c9c{HTTP/1.1, (http/1.1)}{0.0.0.0:35475}
2023-03-20 21:34:34,563 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(415)) - Started @375833ms
2023-03-20 21:34:34,563 [Listener at 127.0.0.1/38731] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:34,564 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of ozoneManager listening at http://0.0.0.0:35475
2023-03-20 21:34:34,566 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:34,567 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:34,570 [Listener at 127.0.0.1/38731] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2051)) - Trash Interval set to 0. Files deleted won't move to trash
2023-03-20 21:34:34,570 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@792e8e23] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:34,599 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:34,599 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:34,599 [Listener at 127.0.0.1/38731] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:34,610 [Listener at 127.0.0.1/38731] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:34,626 [Listener at 127.0.0.1/38731] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:34,673 [Listener at 127.0.0.1/38731] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 46 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:34,674 [Listener at 127.0.0.1/38731] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:34,675 [Listener at 127.0.0.1/38731] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:34,675 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:34,675 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data-0/containers/hdds
2023-03-20 21:34:34,681 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data-0/containers/hdds
2023-03-20 21:34:34,692 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis to VolumeSet
2023-03-20 21:34:34,692 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis
2023-03-20 21:34:34,693 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis
2023-03-20 21:34:34,706 [Thread-6677] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data-0/containers/hdds
2023-03-20 21:34:34,706 [Listener at 127.0.0.1/38731] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:34,708 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:34,714 [Listener at 127.0.0.1/38731] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:34,715 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:34,715 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:34,715 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:34,715 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:34,715 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:34,715 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:34,715 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:34,716 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:34,716 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:34,716 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:34,716 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:34,717 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:34,717 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:34,717 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:34,717 [52a46685-3070-4024-834b-c3445a236f70-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x978a00d6] REGISTERED
2023-03-20 21:34:34,717 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis] (custom)
2023-03-20 21:34:34,717 [52a46685-3070-4024-834b-c3445a236f70-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x978a00d6] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:34,717 [52a46685-3070-4024-834b-c3445a236f70-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x978a00d6, L:/0:0:0:0:0:0:0:0:40357] ACTIVE
2023-03-20 21:34:34,718 [Listener at 127.0.0.1/38731] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:34,720 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:34,720 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:34,721 [Listener at 127.0.0.1/38731] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:34,721 [Listener at 127.0.0.1/38731] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:34,722 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:34,722 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:34,722 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:34,722 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:34,722 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/meta/webserver
2023-03-20 21:34:34,722 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 39031
2023-03-20 21:34:34,722 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:34,723 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:34,723 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:34,723 [Listener at 127.0.0.1/38731] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:34,724 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@79b1fbb3{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:34,724 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@f5f9699{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:34,922 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1a3bf0ab{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/meta/webserver/jetty-0_0_0_0-39031-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6134371280937134523/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:34,924 [Listener at 127.0.0.1/38731] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@634b4130{HTTP/1.1, (http/1.1)}{0.0.0.0:39031}
2023-03-20 21:34:34,924 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(415)) - Started @376193ms
2023-03-20 21:34:34,924 [Listener at 127.0.0.1/38731] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:34,924 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:39031
2023-03-20 21:34:34,925 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:34,925 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:34,925 [Listener at 127.0.0.1/38731] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:34,928 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:34,935 [Listener at 127.0.0.1/38731] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:34,936 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4f1d2fd9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:34,937 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/meta/datanode.id
2023-03-20 21:34:34,976 [Listener at 127.0.0.1/38731] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:35,024 [Listener at 127.0.0.1/38731] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 47 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:35,025 [Listener at 127.0.0.1/38731] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:35,026 [Listener at 127.0.0.1/38731] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:35,026 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:35,026 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data-0/containers/hdds
2023-03-20 21:34:35,026 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data-0/containers/hdds
2023-03-20 21:34:35,037 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis to VolumeSet
2023-03-20 21:34:35,037 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis
2023-03-20 21:34:35,037 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis
2023-03-20 21:34:35,047 [Thread-6691] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data-0/containers/hdds
2023-03-20 21:34:35,047 [Listener at 127.0.0.1/38731] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:35,048 [Listener at 127.0.0.1/38731] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:35,048 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:35,048 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:35,048 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:35,048 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:35,048 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:35,048 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:35,048 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:35,049 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:35,049 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:35,049 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:35,049 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:35,049 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:35,049 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:35,050 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:35,051 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:35,051 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:35,051 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:35,051 [79924adf-68a9-4348-9386-442656259f82-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x92ec2e56] REGISTERED
2023-03-20 21:34:35,051 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:35,051 [79924adf-68a9-4348-9386-442656259f82-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x92ec2e56] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:35,051 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis] (custom)
2023-03-20 21:34:35,051 [79924adf-68a9-4348-9386-442656259f82-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x92ec2e56, L:/0:0:0:0:0:0:0:0:43049] ACTIVE
2023-03-20 21:34:35,052 [Listener at 127.0.0.1/38731] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:35,054 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:35,054 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:35,054 [Listener at 127.0.0.1/38731] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:35,055 [Listener at 127.0.0.1/38731] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:35,055 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:35,055 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:35,056 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:35,056 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:35,056 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/meta/webserver
2023-03-20 21:34:35,056 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 36095
2023-03-20 21:34:35,056 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:35,057 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:35,057 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:35,057 [Listener at 127.0.0.1/38731] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:35,057 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3eeb2867{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:35,057 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2193c8d3{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:35,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:35,256 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@39fbdaaa{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/meta/webserver/jetty-0_0_0_0-36095-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6011982825049316314/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:35,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:35,259 [Listener at 127.0.0.1/38731] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5874d32{HTTP/1.1, (http/1.1)}{0.0.0.0:36095}
2023-03-20 21:34:35,259 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(415)) - Started @376529ms
2023-03-20 21:34:35,259 [Listener at 127.0.0.1/38731] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:35,260 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:36095
2023-03-20 21:34:35,260 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:35,260 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:35,260 [Listener at 127.0.0.1/38731] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:35,264 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:35,268 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c63f470] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:35,269 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/meta/datanode.id
2023-03-20 21:34:35,270 [Listener at 127.0.0.1/38731] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:35,286 [Listener at 127.0.0.1/38731] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:35,332 [Listener at 127.0.0.1/38731] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 45 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:35,333 [Listener at 127.0.0.1/38731] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:35,334 [Listener at 127.0.0.1/38731] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:35,334 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:35,334 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data-0/containers/hdds
2023-03-20 21:34:35,334 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data-0/containers/hdds
2023-03-20 21:34:35,344 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis to VolumeSet
2023-03-20 21:34:35,344 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis
2023-03-20 21:34:35,344 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis
2023-03-20 21:34:35,353 [Thread-6705] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data-0/containers/hdds
2023-03-20 21:34:35,354 [Listener at 127.0.0.1/38731] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:35,355 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:35,356 [Listener at 127.0.0.1/38731] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:35,356 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:35,356 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:35,356 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:35,356 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:35,356 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:35,356 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:35,359 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:35,359 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:35,359 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:35,361 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:35,361 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:35,361 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:35,361 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:35,361 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:35,361 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis] (custom)
2023-03-20 21:34:35,362 [e5cc6624-b71a-402d-a69e-29759be12af7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x40bf178f] REGISTERED
2023-03-20 21:34:35,362 [e5cc6624-b71a-402d-a69e-29759be12af7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x40bf178f] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:35,362 [e5cc6624-b71a-402d-a69e-29759be12af7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x40bf178f, L:/0:0:0:0:0:0:0:0:44975] ACTIVE
2023-03-20 21:34:35,364 [Listener at 127.0.0.1/38731] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:35,366 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:35,366 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:35,366 [Listener at 127.0.0.1/38731] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:35,367 [Listener at 127.0.0.1/38731] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:35,367 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:35,367 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:35,367 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:35,367 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:35,368 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/meta/webserver
2023-03-20 21:34:35,368 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 43139
2023-03-20 21:34:35,368 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:35,369 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:35,369 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:35,369 [Listener at 127.0.0.1/38731] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:35,369 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@185a2fee{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:35,369 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@648d43d5{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:35,386 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: remove    LEADER 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2:t1, leader=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, voted=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, raftlog=Memoized:1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLog:OPENED:c0, conf=0: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-20 21:34:35,386 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: shutdown
2023-03-20 21:34:35,386 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2799A78EBF2,id=1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:35,386 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: shutdown 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-LeaderStateImpl
2023-03-20 21:34:35,386 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-PendingRequests: sendNotLeaderResponses
2023-03-20 21:34:35,387 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:34:35,387 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-A2799A78EBF2: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/16659239-5113-4ca3-8976-a2799a78ebf2/sm/snapshot.1_0
2023-03-20 21:34:35,388 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-A2799A78EBF2: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/16659239-5113-4ca3-8976-a2799a78ebf2/sm/snapshot.1_0 took: 1 ms
2023-03-20 21:34:35,388 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:34:35,388 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:34:35,388 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: closes. applyIndex: 0
2023-03-20 21:34:35,388 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:35,388 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2-SegmentedRaftLogWorker close()
2023-03-20 21:34:35,390 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-A2799A78EBF2: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/16659239-5113-4ca3-8976-a2799a78ebf2
2023-03-20 21:34:35,390 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=16659239-5113-4ca3-8976-a2799a78ebf2 command on datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3.
2023-03-20 21:34:35,392 [IPC Server handler 5 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-03-20 21:34:35,395 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 39.
2023-03-20 21:34:35,395 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 39.
2023-03-20 21:34:35,396 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 1 is closed with bcsId 39.
2023-03-20 21:34:35,396 [IPC Server handler 6 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-03-20 21:34:35,397 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(292)) - Moving container #1 to CLOSED state, datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) reported CLOSED replica.
2023-03-20 21:34:35,397 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c is not found
2023-03-20 21:34:35,397 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 39.
2023-03-20 21:34:35,398 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 39.
2023-03-20 21:34:35,399 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 1 is closed with bcsId 39.
2023-03-20 21:34:35,401 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 39.
2023-03-20 21:34:35,401 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 1 is synced with bcsId 39.
2023-03-20 21:34:35,403 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 1 is closed with bcsId 39.
2023-03-20 21:34:35,404 [IPC Server handler 7 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-03-20 21:34:35,405 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 2 is synced with bcsId 42.
2023-03-20 21:34:35,405 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 2 is synced with bcsId 42.
2023-03-20 21:34:35,406 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 2 is synced with bcsId 42.
2023-03-20 21:34:35,406 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 2 is synced with bcsId 42.
2023-03-20 21:34:35,408 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 2 is closed with bcsId 42.
2023-03-20 21:34:35,409 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 2 is closed with bcsId 42.
2023-03-20 21:34:35,412 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 2 is synced with bcsId 42.
2023-03-20 21:34:35,412 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 2 is synced with bcsId 42.
2023-03-20 21:34:35,413 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(292)) - Moving container #2 to CLOSED state, datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10) reported CLOSED replica.
2023-03-20 21:34:35,413 [IPC Server handler 14 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-03-20 21:34:35,414 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 2 is closed with bcsId 42.
2023-03-20 21:34:35,414 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: remove  FOLLOWER ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C:t1, leader=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, voted=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, raftlog=Memoized:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c47, conf=0: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-20 21:34:35,414 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: shutdown
2023-03-20 21:34:35,414 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-02D605BA4E5C,id=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:35,414 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:35,414 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-StateMachineUpdater: set stopIndex = 47
2023-03-20 21:34:35,414 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-FollowerState was interrupted
2023-03-20 21:34:35,414 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-02D605BA4E5C: Taking a snapshot at:(t:1, i:47) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/sm/snapshot.1_47
2023-03-20 21:34:35,415 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-02D605BA4E5C: Finished taking a snapshot at:(t:1, i:47) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/sm/snapshot.1_47 took: 1 ms
2023-03-20 21:34:35,415 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-StateMachineUpdater: Took a snapshot at index 47
2023-03-20 21:34:35,415 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 47
2023-03-20 21:34:35,416 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: closes. applyIndex: 47
2023-03-20 21:34:35,416 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:35,416 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C-SegmentedRaftLogWorker close()
2023-03-20 21:34:35,418 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 3 is synced with bcsId 35.
2023-03-20 21:34:35,418 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 3 is synced with bcsId 35.
2023-03-20 21:34:35,419 [IPC Server handler 16 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-03-20 21:34:35,420 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-02D605BA4E5C: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:35,420 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c command on datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf.
2023-03-20 21:34:35,420 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: Failed APPEND_ENTRIES request 1226cf83-b1fd-416f-9846-61bdfa3ff6b3->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf#307-t1,previous=(t:1, i:48),leaderCommit=48,initializing? true,entries: size=1, first=(t:1, i:49), STATEMACHINELOGENTRY, 222@client-8181ADD742A2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: group-02D605BA4E5C not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: group-02D605BA4E5C not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-03-20 21:34:35,420 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #3 to QUASI_CLOSED state, datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10) reported QUASI_CLOSED replica.
2023-03-20 21:34:35,420 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 3 is synced with bcsId 35.
2023-03-20 21:34:35,422 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 3 is synced with bcsId 35.
2023-03-20 21:34:35,424 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: group-02D605BA4E5C not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:34:35,424 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: nextIndex: updateUnconditionally 51 -> 49
2023-03-20 21:34:35,425 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 3 is closed with bcsId 35.
2023-03-20 21:34:35,425 [IPC Server handler 0 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-03-20 21:34:35,425 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: remove    LEADER 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C:t1, leader=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, voted=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, raftlog=Memoized:1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c50, conf=0: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-20 21:34:35,425 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: shutdown
2023-03-20 21:34:35,426 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-02D605BA4E5C,id=1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:35,426 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: shutdown 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-LeaderStateImpl
2023-03-20 21:34:35,426 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-PendingRequests: sendNotLeaderResponses
2023-03-20 21:34:35,426 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #3 to CLOSED state, datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) reported CLOSED replica.
2023-03-20 21:34:35,426 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-20 21:34:35,426 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->c810b0b2-f38c-4bc5-874a-38f1937d7d9e-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->c810b0b2-f38c-4bc5-874a-38f1937d7d9e-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-20 21:34:35,425 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 3 is synced with bcsId 35.
2023-03-20 21:34:35,427 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 3 is synced with bcsId 35.
2023-03-20 21:34:35,427 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: Completed APPEND_ENTRIES, lastRequest: 1226cf83-b1fd-416f-9846-61bdfa3ff6b3->c810b0b2-f38c-4bc5-874a-38f1937d7d9e#301-t1,previous=(t:1, i:49),leaderCommit=49,initializing? true,entries: size=1, first=(t:1, i:50), METADATAENTRY(c:49)
2023-03-20 21:34:35,427 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->c810b0b2-f38c-4bc5-874a-38f1937d7d9e-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-20 21:34:35,427 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->c810b0b2-f38c-4bc5-874a-38f1937d7d9e: nextIndex: updateUnconditionally 51 -> 50
2023-03-20 21:34:35,427 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: Completed APPEND_ENTRIES, lastRequest: null
2023-03-20 21:34:35,427 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->c810b0b2-f38c-4bc5-874a-38f1937d7d9e-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-20 21:34:35,427 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->c810b0b2-f38c-4bc5-874a-38f1937d7d9e: nextIndex: updateUnconditionally 50 -> 49
2023-03-20 21:34:35,429 [ContainerOp-27a0404e-e3ec-48ab-a304-02d605ba4e5c-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 3 is closed with bcsId 35.
2023-03-20 21:34:35,432 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-StateMachineUpdater: set stopIndex = 50
2023-03-20 21:34:35,432 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-02D605BA4E5C: Taking a snapshot at:(t:1, i:50) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/sm/snapshot.1_50
2023-03-20 21:34:35,433 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-02D605BA4E5C: Finished taking a snapshot at:(t:1, i:50) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/sm/snapshot.1_50 took: 2 ms
2023-03-20 21:34:35,433 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-StateMachineUpdater: Took a snapshot at index 50
2023-03-20 21:34:35,433 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 50
2023-03-20 21:34:35,434 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: closes. applyIndex: 50
2023-03-20 21:34:35,434 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:35,434 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C-SegmentedRaftLogWorker close()
2023-03-20 21:34:35,437 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:35,437 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c command on datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3.
2023-03-20 21:34:35,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:35,618 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1130123214ns, electionTimeout:1122ms
2023-03-20 21:34:35,618 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2023-03-20 21:34:35,618 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:35,618 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:35,618 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection151
2023-03-20 21:34:35,619 [om1@group-C5BA1605619E-LeaderElection151] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection151 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|rpc:localhost:35217|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:35,619 [om1@group-C5BA1605619E-LeaderElection151] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection151 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:35,620 [om1@group-C5BA1605619E-LeaderElection151] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection151 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:localhost:35217|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection151 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection151
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1578ms
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2023-03-20 21:34:35,621 [om1@group-C5BA1605619E-LeaderElection151] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:35,622 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7b240e75{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/meta/webserver/jetty-0_0_0_0-43139-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-8906491913223952351/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:35,629 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2023-03-20 21:34:35,629 [Listener at 127.0.0.1/38731] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@13236d9d{HTTP/1.1, (http/1.1)}{0.0.0.0:43139}
2023-03-20 21:34:35,630 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(415)) - Started @376899ms
2023-03-20 21:34:35,630 [Listener at 127.0.0.1/38731] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:35,632 [om1@group-C5BA1605619E-LeaderElection151] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:localhost:35217|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:35,633 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:35217"
startupRole: FOLLOWER
]
2023-03-20 21:34:35,633 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:43139
2023-03-20 21:34:35,633 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:35,633 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:35,633 [Listener at 127.0.0.1/38731] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:35,640 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:35,644 [Listener at 127.0.0.1/38731] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:35,648 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5540809c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:35,650 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/meta/datanode.id
2023-03-20 21:34:35,659 [Listener at 127.0.0.1/38731] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:35,706 [Listener at 127.0.0.1/38731] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 47 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:35,708 [Listener at 127.0.0.1/38731] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:35,713 [Listener at 127.0.0.1/38731] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:35,713 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:35,713 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data-0/containers/hdds
2023-03-20 21:34:35,714 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data-0/containers/hdds
2023-03-20 21:34:35,724 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis to VolumeSet
2023-03-20 21:34:35,724 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis
2023-03-20 21:34:35,725 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis
2023-03-20 21:34:35,735 [Thread-6722] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data-0/containers/hdds
2023-03-20 21:34:35,735 [Listener at 127.0.0.1/38731] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:35,736 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:35,737 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:35,737 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:35,737 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:35,737 [Listener at 127.0.0.1/38731] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:35,738 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:35,739 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:35,739 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:35,739 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:35,739 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:35,739 [05384c5d-9495-4201-8a60-c8c72abd74fb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc4ad617e] REGISTERED
2023-03-20 21:34:35,739 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis] (custom)
2023-03-20 21:34:35,739 [05384c5d-9495-4201-8a60-c8c72abd74fb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc4ad617e] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:35,739 [05384c5d-9495-4201-8a60-c8c72abd74fb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc4ad617e, L:/0:0:0:0:0:0:0:0:34701] ACTIVE
2023-03-20 21:34:35,740 [Listener at 127.0.0.1/38731] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:35,741 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:35,742 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:35,743 [Listener at 127.0.0.1/38731] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:35,743 [Listener at 127.0.0.1/38731] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:35,744 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:35,744 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:35,744 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:35,744 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:35,745 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/meta/webserver
2023-03-20 21:34:35,745 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 44719
2023-03-20 21:34:35,745 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:35,746 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:35,746 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:35,746 [Listener at 127.0.0.1/38731] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:35,746 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7d05a6e9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:35,746 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@22908282{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:35,954 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@8249bee{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/meta/webserver/jetty-0_0_0_0-44719-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-3222089308900534441/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:35,956 [Listener at 127.0.0.1/38731] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@d2bec9e{HTTP/1.1, (http/1.1)}{0.0.0.0:44719}
2023-03-20 21:34:35,956 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(415)) - Started @377226ms
2023-03-20 21:34:35,956 [Listener at 127.0.0.1/38731] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:35,957 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:44719
2023-03-20 21:34:35,961 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:35,961 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:35,961 [Listener at 127.0.0.1/38731] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:35,964 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:35,971 [Listener at 127.0.0.1/38731] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:35,972 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2bb295d2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:35,974 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/meta/datanode.id
2023-03-20 21:34:35,987 [Listener at 127.0.0.1/38731] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:36,036 [Listener at 127.0.0.1/38731] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 48 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:36,037 [Listener at 127.0.0.1/38731] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:36,044 [Listener at 127.0.0.1/38731] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:36,044 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:36,044 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data-0/containers/hdds
2023-03-20 21:34:36,044 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data-0/containers/hdds
2023-03-20 21:34:36,054 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis to VolumeSet
2023-03-20 21:34:36,054 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis
2023-03-20 21:34:36,054 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis
2023-03-20 21:34:36,064 [Thread-6736] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data-0/containers/hdds
2023-03-20 21:34:36,064 [Listener at 127.0.0.1/38731] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:36,066 [Listener at 127.0.0.1/38731] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:36,066 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:36,066 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:36,066 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:36,066 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:36,066 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:36,066 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:36,066 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:36,066 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:36,067 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:36,067 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:36,067 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:36,067 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:36,067 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:36,067 [Listener at 127.0.0.1/38731] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:36,068 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:36,069 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:36,069 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:36,069 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:36,069 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:36,069 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis] (custom)
2023-03-20 21:34:36,069 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9d63b4a2] REGISTERED
2023-03-20 21:34:36,069 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9d63b4a2] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:36,069 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9d63b4a2, L:/0:0:0:0:0:0:0:0:37825] ACTIVE
2023-03-20 21:34:36,070 [Listener at 127.0.0.1/38731] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:36,072 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:36,072 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:36,073 [Listener at 127.0.0.1/38731] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:36,076 [Listener at 127.0.0.1/38731] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:36,077 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:36,077 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:36,077 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:36,077 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:36,077 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/meta/webserver
2023-03-20 21:34:36,077 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 41393
2023-03-20 21:34:36,077 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:36,080 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:36,081 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:36,081 [Listener at 127.0.0.1/38731] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:36,081 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5edc8403{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:36,081 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7ceb1ffc{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:36,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:36,259 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10).
2023-03-20 21:34:36,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-20 21:34:36,277 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7dbea411{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/meta/webserver/jetty-0_0_0_0-41393-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-1329478351802912566/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:36,279 [Listener at 127.0.0.1/38731] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3aa7a855{HTTP/1.1, (http/1.1)}{0.0.0.0:41393}
2023-03-20 21:34:36,279 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(415)) - Started @377548ms
2023-03-20 21:34:36,279 [Listener at 127.0.0.1/38731] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:36,280 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41393
2023-03-20 21:34:36,280 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:36,280 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:36,280 [Listener at 127.0.0.1/38731] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:36,286 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:36,291 [Listener at 127.0.0.1/38731] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:36,299 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3258fa3f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:36,300 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/meta/datanode.id
2023-03-20 21:34:36,311 [Listener at 127.0.0.1/38731] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:36,360 [Listener at 127.0.0.1/38731] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 49 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:36,361 [Listener at 127.0.0.1/38731] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:36,362 [Listener at 127.0.0.1/38731] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:36,362 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:36,362 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data-0/containers/hdds
2023-03-20 21:34:36,363 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data-0/containers/hdds
2023-03-20 21:34:36,373 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis to VolumeSet
2023-03-20 21:34:36,373 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis
2023-03-20 21:34:36,373 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis
2023-03-20 21:34:36,385 [Thread-6750] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data-0/containers/hdds
2023-03-20 21:34:36,385 [Listener at 127.0.0.1/38731] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:36,386 [Listener at 127.0.0.1/38731] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:36,386 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:36,386 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:36,386 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:36,386 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:36,386 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:36,386 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:36,386 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:36,386 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:36,387 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:36,387 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:36,387 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:36,387 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:36,387 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:36,388 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:36,389 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:36,389 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:36,389 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:36,389 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:36,389 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis] (custom)
2023-03-20 21:34:36,389 [2325b755-97f4-4680-bb9e-067434f11ceb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd3cfdabb] REGISTERED
2023-03-20 21:34:36,389 [2325b755-97f4-4680-bb9e-067434f11ceb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd3cfdabb] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:36,389 [2325b755-97f4-4680-bb9e-067434f11ceb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd3cfdabb, L:/0:0:0:0:0:0:0:0:34971] ACTIVE
2023-03-20 21:34:36,390 [Listener at 127.0.0.1/38731] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:36,393 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:36,393 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:36,393 [Listener at 127.0.0.1/38731] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:36,396 [Listener at 127.0.0.1/38731] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:36,397 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:36,397 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:36,397 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:36,397 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:36,397 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/meta/webserver
2023-03-20 21:34:36,397 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 44273
2023-03-20 21:34:36,397 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:36,398 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:36,398 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:36,398 [Listener at 127.0.0.1/38731] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:36,399 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@d6a7010{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:36,399 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7f31c148{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:36,408 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: remove  FOLLOWER c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C:t1, leader=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, voted=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, raftlog=Memoized:c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLog:OPENED:c49, conf=0: peers:[1226cf83-b1fd-416f-9846-61bdfa3ff6b3|rpc:10.1.0.10:36759|dataStream:10.1.0.10:40753|priority:1|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:0|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-20 21:34:36,408 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: shutdown
2023-03-20 21:34:36,408 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-02D605BA4E5C,id=c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:36,408 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState
2023-03-20 21:34:36,408 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-StateMachineUpdater: set stopIndex = 49
2023-03-20 21:34:36,408 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-FollowerState was interrupted
2023-03-20 21:34:36,409 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-02D605BA4E5C: Taking a snapshot at:(t:1, i:49) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/sm/snapshot.1_49
2023-03-20 21:34:36,410 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-02D605BA4E5C: Finished taking a snapshot at:(t:1, i:49) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c/sm/snapshot.1_49 took: 1 ms
2023-03-20 21:34:36,410 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-StateMachineUpdater: Took a snapshot at index 49
2023-03-20 21:34:36,410 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 49
2023-03-20 21:34:36,411 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: closes. applyIndex: 49
2023-03-20 21:34:36,411 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:36,411 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C-SegmentedRaftLogWorker close()
2023-03-20 21:34:36,413 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-02D605BA4E5C: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/27a0404e-e3ec-48ab-a304-02d605ba4e5c
2023-03-20 21:34:36,413 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c command on datanode c810b0b2-f38c-4bc5-874a-38f1937d7d9e.
2023-03-20 21:34:36,430 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=27a0404e-e3ec-48ab-a304-02d605ba4e5c is not found
2023-03-20 21:34:36,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:36,645 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@46a18a15{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/meta/webserver/jetty-0_0_0_0-44273-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-1180277399699494377/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:36,647 [Listener at 127.0.0.1/38731] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7defa51a{HTTP/1.1, (http/1.1)}{0.0.0.0:44273}
2023-03-20 21:34:36,647 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(415)) - Started @377916ms
2023-03-20 21:34:36,647 [Listener at 127.0.0.1/38731] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:36,648 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:44273
2023-03-20 21:34:36,648 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:36,648 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:36,648 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:36,648 [Listener at 127.0.0.1/38731] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:36,658 [Listener at 127.0.0.1/38731] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:36,658 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@97648d8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:36,662 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/meta/datanode.id
2023-03-20 21:34:36,674 [Listener at 127.0.0.1/38731] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:36,719 [Listener at 127.0.0.1/38731] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:36,720 [Listener at 127.0.0.1/38731] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:36,721 [Listener at 127.0.0.1/38731] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:36,721 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:36,721 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data-0/containers/hdds
2023-03-20 21:34:36,722 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data-0/containers/hdds
2023-03-20 21:34:36,732 [Listener at 127.0.0.1/38731] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis to VolumeSet
2023-03-20 21:34:36,732 [Listener at 127.0.0.1/38731] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis
2023-03-20 21:34:36,732 [Listener at 127.0.0.1/38731] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis
2023-03-20 21:34:36,741 [Thread-6764] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data-0/containers/hdds
2023-03-20 21:34:36,741 [Listener at 127.0.0.1/38731] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:36,742 [Listener at 127.0.0.1/38731] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:36,742 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:36,743 [Listener at 127.0.0.1/38731] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:36,744 [Listener at 127.0.0.1/38731] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:36,744 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:36,744 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:36,744 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:36,744 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:36,744 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:36,744 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:36,744 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:36,745 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:36,745 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:36,745 [Listener at 127.0.0.1/38731] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:36,745 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:36,745 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:36,745 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:36,745 [a0d6486e-58e7-45ac-85b3-704c8b479dbc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x24f777cd] REGISTERED
2023-03-20 21:34:36,745 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:36,745 [a0d6486e-58e7-45ac-85b3-704c8b479dbc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x24f777cd] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:36,745 [Listener at 127.0.0.1/38731] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis] (custom)
2023-03-20 21:34:36,745 [a0d6486e-58e7-45ac-85b3-704c8b479dbc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x24f777cd, L:/0:0:0:0:0:0:0:0:38747] ACTIVE
2023-03-20 21:34:36,746 [Listener at 127.0.0.1/38731] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:36,748 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:36,748 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:36,748 [Listener at 127.0.0.1/38731] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:36,749 [Listener at 127.0.0.1/38731] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:36,749 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:36,749 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:36,749 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:36,749 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:36,750 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/meta/webserver
2023-03-20 21:34:36,750 [Listener at 127.0.0.1/38731] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34963
2023-03-20 21:34:36,750 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:36,751 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:36,751 [Listener at 127.0.0.1/38731] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:36,751 [Listener at 127.0.0.1/38731] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:36,751 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6a47fa9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:36,751 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7766a61b{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:36,952 [Listener at 127.0.0.1/38731] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@45d7f2de{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/meta/webserver/jetty-0_0_0_0-34963-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-5068731182446476975/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:36,953 [Listener at 127.0.0.1/38731] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4117e99c{HTTP/1.1, (http/1.1)}{0.0.0.0:34963}
2023-03-20 21:34:36,953 [Listener at 127.0.0.1/38731] INFO  server.Server (Server.java:doStart(415)) - Started @378223ms
2023-03-20 21:34:36,953 [Listener at 127.0.0.1/38731] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:36,954 [Listener at 127.0.0.1/38731] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34963
2023-03-20 21:34:36,954 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-20 21:34:36,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:36,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:36,955 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:36,955 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61150d32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:36,956 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/meta/datanode.id
2023-03-20 21:34:36,975 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-53dda7ab-7c78-4c72-952e-1fdf00096eea/container.db to cache
2023-03-20 21:34:36,975 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-53dda7ab-7c78-4c72-952e-1fdf00096eea/container.db for volume DS-53dda7ab-7c78-4c72-952e-1fdf00096eea
2023-03-20 21:34:36,976 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:36,976 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:36,978 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 41215
2023-03-20 21:34:36,980 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 52a46685-3070-4024-834b-c3445a236f70
2023-03-20 21:34:36,985 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 52a46685-3070-4024-834b-c3445a236f70: start RPC server
2023-03-20 21:34:36,986 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 52a46685-3070-4024-834b-c3445a236f70: GrpcService started, listening on 33541
2023-03-20 21:34:36,987 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 52a46685-3070-4024-834b-c3445a236f70 is started using port 33541 for RATIS
2023-03-20 21:34:36,987 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 52a46685-3070-4024-834b-c3445a236f70 is started using port 33541 for RATIS_ADMIN
2023-03-20 21:34:36,987 [JvmPauseMonitor93] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-52a46685-3070-4024-834b-c3445a236f70: Started
2023-03-20 21:34:36,987 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 52a46685-3070-4024-834b-c3445a236f70 is started using port 33541 for RATIS_SERVER
2023-03-20 21:34:36,987 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 52a46685-3070-4024-834b-c3445a236f70 is started using port 40357 for RATIS_DATASTREAM
2023-03-20 21:34:36,988 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 52a46685-3070-4024-834b-c3445a236f70 is started using port 46759
2023-03-20 21:34:36,988 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:37,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #3 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), placeOfBirth=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf, sequenceId=35, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=CLOSED, datanodeDetails=1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10), placeOfBirth=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, sequenceId=35, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=CLOSED, datanodeDetails=c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), placeOfBirth=c810b0b2-f38c-4bc5-874a-38f1937d7d9e, sequenceId=35, keyCount=3, bytesUsed=57}}
2023-03-20 21:34:37,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #3 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), placeOfBirth=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf, sequenceId=35, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=CLOSED, datanodeDetails=1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10), placeOfBirth=1226cf83-b1fd-416f-9846-61bdfa3ff6b3, sequenceId=35, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=CLOSED, datanodeDetails=c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), placeOfBirth=c810b0b2-f38c-4bc5-874a-38f1937d7d9e, sequenceId=35, keyCount=3, bytesUsed=57}}
2023-03-20 21:34:37,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) has 2 sufficientlyReplicated, 1 underReplicated and 1 unhealthy containers
2023-03-20 21:34:37,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:37,260 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10).
2023-03-20 21:34:37,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:34:37,295 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-d450f41f-0e76-4a6b-86a5-3f4f6d74197c/container.db to cache
2023-03-20 21:34:37,295 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-d450f41f-0e76-4a6b-86a5-3f4f6d74197c/container.db for volume DS-d450f41f-0e76-4a6b-86a5-3f4f6d74197c
2023-03-20 21:34:37,295 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:37,295 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:37,296 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 38415
2023-03-20 21:34:37,297 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 79924adf-68a9-4348-9386-442656259f82
2023-03-20 21:34:37,301 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 79924adf-68a9-4348-9386-442656259f82: start RPC server
2023-03-20 21:34:37,301 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 79924adf-68a9-4348-9386-442656259f82: GrpcService started, listening on 42555
2023-03-20 21:34:37,302 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 79924adf-68a9-4348-9386-442656259f82 is started using port 42555 for RATIS
2023-03-20 21:34:37,302 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 79924adf-68a9-4348-9386-442656259f82 is started using port 42555 for RATIS_ADMIN
2023-03-20 21:34:37,302 [JvmPauseMonitor94] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-79924adf-68a9-4348-9386-442656259f82: Started
2023-03-20 21:34:37,302 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 79924adf-68a9-4348-9386-442656259f82 is started using port 42555 for RATIS_SERVER
2023-03-20 21:34:37,302 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 79924adf-68a9-4348-9386-442656259f82 is started using port 43049 for RATIS_DATASTREAM
2023-03-20 21:34:37,302 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 79924adf-68a9-4348-9386-442656259f82 is started using port 42269
2023-03-20 21:34:37,302 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:37,420 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 3 is synced with bcsId 35.
2023-03-20 21:34:37,420 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 3 is synced with bcsId 35.
2023-03-20 21:34:37,422 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(361)) - Container 3 is closed with bcsId 35.
2023-03-20 21:34:37,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:37,675 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-5c7f7fa7-b8b3-4042-a067-622dc6c0684a/container.db to cache
2023-03-20 21:34:37,675 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-5c7f7fa7-b8b3-4042-a067-622dc6c0684a/container.db for volume DS-5c7f7fa7-b8b3-4042-a067-622dc6c0684a
2023-03-20 21:34:37,676 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:37,676 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:37,680 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 33391
2023-03-20 21:34:37,682 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:37,693 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - e5cc6624-b71a-402d-a69e-29759be12af7: start RPC server
2023-03-20 21:34:37,693 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - e5cc6624-b71a-402d-a69e-29759be12af7: GrpcService started, listening on 44593
2023-03-20 21:34:37,694 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis e5cc6624-b71a-402d-a69e-29759be12af7 is started using port 44593 for RATIS
2023-03-20 21:34:37,694 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis e5cc6624-b71a-402d-a69e-29759be12af7 is started using port 44593 for RATIS_ADMIN
2023-03-20 21:34:37,694 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis e5cc6624-b71a-402d-a69e-29759be12af7 is started using port 44593 for RATIS_SERVER
2023-03-20 21:34:37,694 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis e5cc6624-b71a-402d-a69e-29759be12af7 is started using port 44975 for RATIS_DATASTREAM
2023-03-20 21:34:37,694 [JvmPauseMonitor95] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-e5cc6624-b71a-402d-a69e-29759be12af7: Started
2023-03-20 21:34:37,699 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc e5cc6624-b71a-402d-a69e-29759be12af7 is started using port 34529
2023-03-20 21:34:37,704 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:37,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-20 21:34:37,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:37,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:37,998 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-657a43ff-79e7-4c32-82bf-1ca98967c43e/container.db to cache
2023-03-20 21:34:37,998 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-657a43ff-79e7-4c32-82bf-1ca98967c43e/container.db for volume DS-657a43ff-79e7-4c32-82bf-1ca98967c43e
2023-03-20 21:34:37,998 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:38,000 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:38,000 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 39889
2023-03-20 21:34:38,002 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:38,009 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: start RPC server
2023-03-20 21:34:38,009 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: GrpcService started, listening on 41855
2023-03-20 21:34:38,010 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 05384c5d-9495-4201-8a60-c8c72abd74fb is started using port 41855 for RATIS
2023-03-20 21:34:38,010 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 05384c5d-9495-4201-8a60-c8c72abd74fb is started using port 41855 for RATIS_ADMIN
2023-03-20 21:34:38,010 [JvmPauseMonitor96] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-05384c5d-9495-4201-8a60-c8c72abd74fb: Started
2023-03-20 21:34:38,010 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 05384c5d-9495-4201-8a60-c8c72abd74fb is started using port 41855 for RATIS_SERVER
2023-03-20 21:34:38,010 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 05384c5d-9495-4201-8a60-c8c72abd74fb is started using port 34701 for RATIS_DATASTREAM
2023-03-20 21:34:38,010 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 05384c5d-9495-4201-8a60-c8c72abd74fb is started using port 43849
2023-03-20 21:34:38,011 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:38,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) has 3 sufficientlyReplicated, 0 underReplicated and 0 unhealthy containers
2023-03-20 21:34:38,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(422)) - Datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) has entered maintenance
2023-03-20 21:34:38,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:38,247 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) moved to HEALTHY state.
2023-03-20 21:34:38,247 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:38,248 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=2084635c-5d52-438d-811e-183ce2a09169 to datanode:ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:38,248 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=2084635c-5d52-438d-811e-183ce2a09169 to datanode:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:38,248 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=2084635c-5d52-438d-811e-183ce2a09169 to datanode:c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:38,248 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 2084635c-5d52-438d-811e-183ce2a09169, Nodes: ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10)ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10)c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:38.248Z[Etc/UTC]].
2023-03-20 21:34:38,248 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:38,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:34:38,329 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-ccd3fa4a-9b0f-4ce9-95a3-5c5a909c5d17/container.db to cache
2023-03-20 21:34:38,329 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-ccd3fa4a-9b0f-4ce9-95a3-5c5a909c5d17/container.db for volume DS-ccd3fa4a-9b0f-4ce9-95a3-5c5a909c5d17
2023-03-20 21:34:38,329 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:38,329 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:38,330 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 39913
2023-03-20 21:34:38,331 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis a416fcbf-d3db-4cde-9623-07e05d2a4f7f
2023-03-20 21:34:38,333 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: start RPC server
2023-03-20 21:34:38,333 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: GrpcService started, listening on 43949
2023-03-20 21:34:38,333 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis a416fcbf-d3db-4cde-9623-07e05d2a4f7f is started using port 43949 for RATIS
2023-03-20 21:34:38,333 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis a416fcbf-d3db-4cde-9623-07e05d2a4f7f is started using port 43949 for RATIS_ADMIN
2023-03-20 21:34:38,333 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis a416fcbf-d3db-4cde-9623-07e05d2a4f7f is started using port 43949 for RATIS_SERVER
2023-03-20 21:34:38,333 [JvmPauseMonitor97] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-a416fcbf-d3db-4cde-9623-07e05d2a4f7f: Started
2023-03-20 21:34:38,333 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis a416fcbf-d3db-4cde-9623-07e05d2a4f7f is started using port 37825 for RATIS_DATASTREAM
2023-03-20 21:34:38,333 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc a416fcbf-d3db-4cde-9623-07e05d2a4f7f is started using port 38619
2023-03-20 21:34:38,334 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:38,426 [IPC Server handler 0 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-03-20 21:34:38,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:38,686 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-2bf1d7cd-b14c-4e75-bbbd-0dc0c3584029/container.db to cache
2023-03-20 21:34:38,686 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-2bf1d7cd-b14c-4e75-bbbd-0dc0c3584029/container.db for volume DS-2bf1d7cd-b14c-4e75-bbbd-0dc0c3584029
2023-03-20 21:34:38,686 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:38,686 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:38,686 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 35701
2023-03-20 21:34:38,688 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 2325b755-97f4-4680-bb9e-067434f11ceb
2023-03-20 21:34:38,693 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 2325b755-97f4-4680-bb9e-067434f11ceb: start RPC server
2023-03-20 21:34:38,693 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 2325b755-97f4-4680-bb9e-067434f11ceb: GrpcService started, listening on 35621
2023-03-20 21:34:38,696 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 2325b755-97f4-4680-bb9e-067434f11ceb is started using port 35621 for RATIS
2023-03-20 21:34:38,696 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 2325b755-97f4-4680-bb9e-067434f11ceb is started using port 35621 for RATIS_ADMIN
2023-03-20 21:34:38,696 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 2325b755-97f4-4680-bb9e-067434f11ceb is started using port 35621 for RATIS_SERVER
2023-03-20 21:34:38,696 [JvmPauseMonitor98] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-2325b755-97f4-4680-bb9e-067434f11ceb: Started
2023-03-20 21:34:38,696 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 2325b755-97f4-4680-bb9e-067434f11ceb is started using port 34971 for RATIS_DATASTREAM
2023-03-20 21:34:38,697 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 2325b755-97f4-4680-bb9e-067434f11ceb is started using port 41763
2023-03-20 21:34:38,697 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:38,937 [IPC Server handler 5 on default port 44329] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/52a46685-3070-4024-834b-c3445a236f70
2023-03-20 21:34:38,937 [IPC Server handler 5 on default port 44329] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 52a46685-3070-4024-834b-c3445a236f70{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=41215, RATIS=33541, RATIS_ADMIN=33541, RATIS_SERVER=33541, RATIS_DATASTREAM=40357, STANDALONE=46759], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:38,941 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-20 21:34:38,941 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-20 21:34:38,949 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:38,949 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=e910e24a-6d72-480a-9a70-be3927fefb6a to datanode:52a46685-3070-4024-834b-c3445a236f70
2023-03-20 21:34:38,949 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-20 21:34:38,952 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: e910e24a-6d72-480a-9a70-be3927fefb6a, Nodes: 52a46685-3070-4024-834b-c3445a236f70(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:38.949Z[Etc/UTC]].
2023-03-20 21:34:38,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 1 of 7 DN Heartbeats.
2023-03-20 21:34:38,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:38,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:38,988 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-5e73ebfd-eb46-4a01-8377-b0d48cb7aec1/container.db to cache
2023-03-20 21:34:38,988 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data-0/containers/hdds/0e175259-c50f-4ed4-a7b6-aa91f131c8fc/DS-5e73ebfd-eb46-4a01-8377-b0d48cb7aec1/container.db for volume DS-5e73ebfd-eb46-4a01-8377-b0d48cb7aec1
2023-03-20 21:34:38,989 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:38,989 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:38,989 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 45451
2023-03-20 21:34:38,991 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis a0d6486e-58e7-45ac-85b3-704c8b479dbc
2023-03-20 21:34:38,992 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc: start RPC server
2023-03-20 21:34:38,993 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc: GrpcService started, listening on 35909
2023-03-20 21:34:38,993 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis a0d6486e-58e7-45ac-85b3-704c8b479dbc is started using port 35909 for RATIS
2023-03-20 21:34:38,993 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis a0d6486e-58e7-45ac-85b3-704c8b479dbc is started using port 35909 for RATIS_ADMIN
2023-03-20 21:34:38,993 [JvmPauseMonitor99] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-a0d6486e-58e7-45ac-85b3-704c8b479dbc: Started
2023-03-20 21:34:38,993 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis a0d6486e-58e7-45ac-85b3-704c8b479dbc is started using port 35909 for RATIS_SERVER
2023-03-20 21:34:38,993 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis a0d6486e-58e7-45ac-85b3-704c8b479dbc is started using port 38747 for RATIS_DATASTREAM
2023-03-20 21:34:38,994 [EndpointStateMachine task thread for /0.0.0.0:44329 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc a0d6486e-58e7-45ac-85b3-704c8b479dbc is started using port 43207
2023-03-20 21:34:38,994 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:39,247 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:39,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:34:39,276 [IPC Server handler 1 on default port 44329] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/79924adf-68a9-4348-9386-442656259f82
2023-03-20 21:34:39,276 [IPC Server handler 1 on default port 44329] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 79924adf-68a9-4348-9386-442656259f82{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=38415, RATIS=42555, RATIS_ADMIN=42555, RATIS_SERVER=42555, RATIS_DATASTREAM=43049, STANDALONE=42269], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:39,276 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:39,277 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-20 21:34:39,277 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=7974330e-eed0-46af-a7aa-ba594e114897 to datanode:79924adf-68a9-4348-9386-442656259f82
2023-03-20 21:34:39,277 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 7974330e-eed0-46af-a7aa-ba594e114897, Nodes: 79924adf-68a9-4348-9386-442656259f82(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:39.277Z[Etc/UTC]].
2023-03-20 21:34:39,420 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: addNew group-183CE2A09169:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] returns group-183CE2A09169:java.util.concurrent.CompletableFuture@1c72a8a0[Not completed]
2023-03-20 21:34:39,420 [pool-4094-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: new RaftServerImpl for group-183CE2A09169:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: ConfigurationManager, init=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis] (custom)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:39,421 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:39,422 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:39,422 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:39,422 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:39,422 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:39,422 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:39,422 [pool-4094-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/2084635c-5d52-438d-811e-183ce2a09169 does not exist. Creating ...
2023-03-20 21:34:39,424 [pool-4094-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:39,425 [pool-4094-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/2084635c-5d52-438d-811e-183ce2a09169 has been successfully formatted.
2023-03-20 21:34:39,425 [pool-4094-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-183CE2A09169: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:39,425 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:39,425 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:39,425 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:39,425 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:39,425 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:39,425 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/2084635c-5d52-438d-811e-183ce2a09169
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:39,426 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:39,427 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:39,427 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:39,430 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: addNew group-183CE2A09169:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] returns group-183CE2A09169:java.util.concurrent.CompletableFuture@1a64c12e[Not completed]
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: new RaftServerImpl for group-183CE2A09169:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169: ConfigurationManager, init=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis] (custom)
2023-03-20 21:34:39,430 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:39,431 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:39,431 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:39,431 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:39,431 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:39,431 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:39,431 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:39,432 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:39,432 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:39,432 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:39,432 [pool-4050-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/2084635c-5d52-438d-811e-183ce2a09169 does not exist. Creating ...
2023-03-20 21:34:39,438 [pool-4050-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:39,438 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:39,439 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:39,439 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:39,439 [pool-4094-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:39,439 [pool-4094-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:39,439 [pool-4094-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: start as a follower, conf=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:39,439 [pool-4094-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:39,439 [pool-4094-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState
2023-03-20 21:34:39,439 [pool-4050-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/2084635c-5d52-438d-811e-183ce2a09169 has been successfully formatted.
2023-03-20 21:34:39,441 [pool-4094-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-183CE2A09169,id=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:39,441 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:39,441 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:39,441 [pool-4050-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-183CE2A09169: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:39,441 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:39,441 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:39,441 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:39,441 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:39,441 [pool-4094-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:39,442 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:39,442 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:39,442 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:39,442 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:39,442 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:39,442 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/2084635c-5d52-438d-811e-183ce2a09169
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:39,443 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:39,446 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=2084635c-5d52-438d-811e-183ce2a09169
2023-03-20 21:34:39,449 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:39,449 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:39,453 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ad06446d-1378-4ceb-aafe-e920688dce34: addNew group-183CE2A09169:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] returns group-183CE2A09169:java.util.concurrent.CompletableFuture@7e846164[Not completed]
2023-03-20 21:34:39,453 [pool-4182-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - ad06446d-1378-4ceb-aafe-e920688dce34: new RaftServerImpl for group-183CE2A09169:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:39,453 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:39,453 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:39,453 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:39,453 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:39,453 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:39,453 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:39,453 [pool-4182-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: ConfigurationManager, init=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:39,453 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis] (custom)
2023-03-20 21:34:39,454 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:39,454 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:39,454 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:39,454 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:39,454 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:39,454 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:39,455 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:39,455 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:39,455 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:39,455 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:39,455 [pool-4182-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/2084635c-5d52-438d-811e-183ce2a09169 does not exist. Creating ...
2023-03-20 21:34:39,455 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:39,455 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:39,455 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:39,455 [pool-4050-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:39,455 [pool-4182-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:39,456 [pool-4050-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:39,456 [pool-4050-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169: start as a follower, conf=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:39,456 [pool-4050-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:39,456 [pool-4050-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState
2023-03-20 21:34:39,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:39,456 [pool-4182-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/2084635c-5d52-438d-811e-183ce2a09169 has been successfully formatted.
2023-03-20 21:34:39,460 [pool-4182-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-183CE2A09169: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:39,460 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:39,460 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:39,460 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:39,460 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:39,460 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:39,460 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/2084635c-5d52-438d-811e-183ce2a09169
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:39,461 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:39,462 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:39,462 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:39,460 [pool-4050-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-183CE2A09169,id=c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:39,464 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:39,464 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:39,464 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:39,464 [pool-4050-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:39,460 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:39,465 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:39,465 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:39,465 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:39,465 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:39,465 [pool-4182-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:39,465 [pool-4182-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:39,468 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=2084635c-5d52-438d-811e-183ce2a09169
2023-03-20 21:34:39,483 [pool-4182-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: start as a follower, conf=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:39,483 [pool-4182-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:39,483 [pool-4182-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad06446d-1378-4ceb-aafe-e920688dce34: start ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState
2023-03-20 21:34:39,485 [pool-4182-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-183CE2A09169,id=ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:39,485 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:39,485 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:39,485 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:39,485 [pool-4182-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:39,485 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:39,485 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:39,501 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=2084635c-5d52-438d-811e-183ce2a09169.
2023-03-20 21:34:39,509 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=2084635c-5d52-438d-811e-183ce2a09169.
2023-03-20 21:34:39,630 [Listener at 0.0.0.0/34783] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(356)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-03-20 21:34:39,637 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1537)) - Container Balancer is not running.
2023-03-20 21:34:39,637 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1544)) - Stopping Replication Manager Service.
2023-03-20 21:34:39,637 [Listener at 0.0.0.0/34783] INFO  replication.ReplicationManager (ReplicationManager.java:stop(306)) - Stopping Replication Monitor Thread.
2023-03-20 21:34:39,637 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Under Replicated Processor interrupted. Exiting...
2023-03-20 21:34:39,637 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Over Replicated Processor interrupted. Exiting...
2023-03-20 21:34:39,639 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1551)) - Stopping the Datanode Admin Monitor.
2023-03-20 21:34:39,639 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1558)) - Stopping datanode service RPC server
2023-03-20 21:34:39,639 [Listener at 0.0.0.0/34783] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-03-20 21:34:39,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(818)) - Replication Monitor Thread is stopped
2023-03-20 21:34:39,640 [Listener at 0.0.0.0/34783] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42601
2023-03-20 21:34:39,645 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-20 21:34:39,647 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:34:39,648 [IPC Server handler 6 on default port 44329] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:39,648 [IPC Server handler 6 on default port 44329] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : e5cc6624-b71a-402d-a69e-29759be12af7{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=33391, RATIS=44593, RATIS_ADMIN=44593, RATIS_SERVER=44593, RATIS_DATASTREAM=44975, STANDALONE=34529], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:39,649 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:39,649 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=d5324a2d-e604-4092-a161-ac1df4a4bc78 to datanode:e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:39,649 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: d5324a2d-e604-4092-a161-ac1df4a4bc78, Nodes: e5cc6624-b71a-402d-a69e-29759be12af7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:39.649Z[Etc/UTC]].
2023-03-20 21:34:39,650 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-20 21:34:39,651 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-20 21:34:39,651 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-20 21:34:39,651 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-20 21:34:39,651 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:39,651 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=46f08bba-1415-40e8-8a77-d21aa782c062 to datanode:79924adf-68a9-4348-9386-442656259f82
2023-03-20 21:34:39,651 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=46f08bba-1415-40e8-8a77-d21aa782c062 to datanode:52a46685-3070-4024-834b-c3445a236f70
2023-03-20 21:34:39,651 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=46f08bba-1415-40e8-8a77-d21aa782c062 to datanode:e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:39,651 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 46f08bba-1415-40e8-8a77-d21aa782c062, Nodes: 79924adf-68a9-4348-9386-442656259f82(fv-az985-449/10.1.0.10)52a46685-3070-4024-834b-c3445a236f70(fv-az985-449/10.1.0.10)e5cc6624-b71a-402d-a69e-29759be12af7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:39.651Z[Etc/UTC]].
2023-03-20 21:34:39,651 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:39,731 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-03-20 21:34:39,731 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1566)) - Stopping block service RPC server
2023-03-20 21:34:39,732 [Listener at 0.0.0.0/34783] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-03-20 21:34:39,733 [Listener at 0.0.0.0/34783] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 33765
2023-03-20 21:34:39,735 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-20 21:34:39,738 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1573)) - Stopping the StorageContainerLocationProtocol RPC server
2023-03-20 21:34:39,738 [Listener at 0.0.0.0/34783] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(203)) - Stopping the RPC server for Client Protocol
2023-03-20 21:34:39,739 [Listener at 0.0.0.0/34783] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42371
2023-03-20 21:34:39,740 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:34:39,742 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-20 21:34:39,743 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1580)) - Stopping Storage Container Manager HTTP server.
2023-03-20 21:34:39,743 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:34:39,747 [Listener at 0.0.0.0/34783] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3bf6fa60{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-20 21:34:39,747 [Listener at 0.0.0.0/34783] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@35fc8ce4{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:39,747 [Listener at 0.0.0.0/34783] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:39,748 [Listener at 0.0.0.0/34783] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3376857e{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-20 21:34:39,749 [Listener at 0.0.0.0/34783] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2615db2c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:39,750 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1588)) - Stopping SCM LayoutVersionManager Service.
2023-03-20 21:34:39,750 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1596)) - Stopping Block Manager Service.
2023-03-20 21:34:39,750 [Listener at 0.0.0.0/34783] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-20 21:34:39,750 [Listener at 0.0.0.0/34783] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-20 21:34:39,751 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1618)) - Stopping SCM Event Queue.
2023-03-20 21:34:39,755 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1629)) - Stopping SCM HA services.
2023-03-20 21:34:39,755 [Listener at 0.0.0.0/34783] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-03-20 21:34:39,755 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-03-20 21:34:39,755 [Listener at 0.0.0.0/34783] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-03-20 21:34:39,755 [Listener at 0.0.0.0/34783] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2023-03-20 21:34:39,756 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-03-20 21:34:39,761 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-03-20 21:34:39,761 [Listener at 0.0.0.0/34783] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2023-03-20 21:34:39,761 [Listener at 0.0.0.0/34783] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-03-20 21:34:39,761 [Listener at 0.0.0.0/34783] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-03-20 21:34:39,761 [Listener at 0.0.0.0/34783] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-03-20 21:34:39,761 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-03-20 21:34:39,761 [Listener at 0.0.0.0/34783] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-20 21:34:39,761 [Listener at 0.0.0.0/34783] INFO  replication.ReplicationManager (ReplicationManager.java:stop(316)) - Replication Monitor Thread is not running.
2023-03-20 21:34:39,762 [Listener at 0.0.0.0/34783] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-03-20 21:34:39,762 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1647)) - Stopping SCM MetadataStore.
2023-03-20 21:34:39,763 [Listener at 0.0.0.0/34783] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:39,763 [Listener at 0.0.0.0/34783] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-20 21:34:39,763 [Listener at 0.0.0.0/34783] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-20 21:34:39,763 [Listener at 0.0.0.0/34783] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:39,764 [Listener at 0.0.0.0/34783] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:39,814 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:42601 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az985-449/10.1.0.10"; destination host is: "0.0.0.0":42601; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy56.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-03-20 21:34:39,842 [Listener at 0.0.0.0/34783] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-20 21:34:39,842 [Listener at 0.0.0.0/34783] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-20 21:34:39,844 [Listener at 0.0.0.0/34783] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:39,891 [Listener at 0.0.0.0/34783] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 46 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:39,893 [Listener at 0.0.0.0/34783] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-20 21:34:39,893 [Listener at 0.0.0.0/34783] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-20 21:34:39,893 [Listener at 0.0.0.0/34783] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-20 21:34:39,894 [Listener at 0.0.0.0/34783] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:39,894 [Listener at 0.0.0.0/34783] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-20 21:34:39,894 [Listener at 0.0.0.0/34783] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:39,894 [Listener at 0.0.0.0/34783] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-20 21:34:39,895 [Listener at 0.0.0.0/34783] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-20 21:34:39,896 [Listener at 0.0.0.0/34783] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-20 21:34:39,900 [Listener at 0.0.0.0/34783] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-20 21:34:39,900 [Listener at 0.0.0.0/34783] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-20 21:34:39,901 [Listener at 0.0.0.0/34783] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-20 21:34:39,903 [Listener at 0.0.0.0/34783] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-20 21:34:39,903 [Listener at 0.0.0.0/34783] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-20 21:34:39,904 [Listener at 0.0.0.0/34783] INFO  replication.ReplicationManager (ReplicationManager.java:start(273)) - Starting Replication Monitor Thread.
2023-03-20 21:34:39,904 [Listener at 0.0.0.0/34783] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-20 21:34:39,904 [Listener at 0.0.0.0/34783] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-03-20 21:34:39,905 [Listener at 0.0.0.0/34783] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 1, healthy pipeline threshold count is 1
2023-03-20 21:34:39,905 [Listener at 0.0.0.0/34783] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 1, pipeline's with at least one datanode reported threshold count is 1
2023-03-20 21:34:39,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:39,913 [Listener at 0.0.0.0/34783] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(395)) - SCM start with adminUsers: [runner]
2023-03-20 21:34:39,913 [Listener at 0.0.0.0/34783] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:39,913 [Socket Reader #1 for port 42601] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 42601
2023-03-20 21:34:39,919 [Listener at 0.0.0.0/42601] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:39,922 [Socket Reader #1 for port 33765] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 33765
2023-03-20 21:34:39,922 [Listener at 0.0.0.0/33765] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:39,927 [Listener at 0.0.0.0/42371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-20 21:34:39,927 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(412)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-20 21:34:39,928 [Listener at 0.0.0.0/42371] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-20 21:34:39,929 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1442)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42371
2023-03-20 21:34:39,930 [Listener at 0.0.0.0/42371] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-03-20 21:34:39,939 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-03-20 21:34:39,939 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-03-20 21:34:39,941 [Socket Reader #1 for port 42371] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 42371
2023-03-20 21:34:39,952 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-03-20 21:34:39,952 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-03-20 21:34:39,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 3 of 7 DN Heartbeats.
2023-03-20 21:34:39,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:39,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:39,973 [IPC Server handler 1 on default port 44329] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:39,973 [IPC Server handler 1 on default port 44329] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 05384c5d-9495-4201-8a60-c8c72abd74fb{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=39889, RATIS=41855, RATIS_ADMIN=41855, RATIS_SERVER=41855, RATIS_DATASTREAM=34701, STANDALONE=43849], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:39,973 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:39,975 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=12545f98-2564-4b6f-bb8b-5a5c429d75e5 to datanode:05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:39,975 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 12545f98-2564-4b6f-bb8b-5a5c429d75e5, Nodes: 05384c5d-9495-4201-8a60-c8c72abd74fb(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:39.975Z[Etc/UTC]].
2023-03-20 21:34:39,976 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:34:39,981 [Listener at 0.0.0.0/42371] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(194)) - RPC server for Client  is listening at /0.0.0.0:42371
2023-03-20 21:34:39,981 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:39,991 [IPC Server listener on 42371] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 42371: starting
2023-03-20 21:34:39,993 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1456)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33765
2023-03-20 21:34:39,993 [Listener at 0.0.0.0/42371] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:33765
2023-03-20 21:34:39,996 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:40,000 [IPC Server listener on 33765] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 33765: starting
2023-03-20 21:34:40,003 [Listener at 0.0.0.0/42371] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:42601
2023-03-20 21:34:40,003 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:40,003 [IPC Server listener on 42601] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 42601: starting
2023-03-20 21:34:40,019 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2763500e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:40,020 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:38151
2023-03-20 21:34:40,020 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:40,021 [Listener at 0.0.0.0/42371] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:40,022 [Listener at 0.0.0.0/42371] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:40,023 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:40,024 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-20 21:34:40,024 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:40,024 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:40,025 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/webserver
2023-03-20 21:34:40,025 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 38151
2023-03-20 21:34:40,026 [Listener at 0.0.0.0/42371] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:40,028 [Listener at 0.0.0.0/42371] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:40,029 [Listener at 0.0.0.0/42371] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:40,029 [Listener at 0.0.0.0/42371] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:40,029 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@57404a8d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:40,029 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4734a551{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-20 21:34:40,031 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@426753a6{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-20 21:34:40,037 [Listener at 0.0.0.0/42371] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5bee88e3{HTTP/1.1, (http/1.1)}{0.0.0.0:38151}
2023-03-20 21:34:40,037 [Listener at 0.0.0.0/42371] INFO  server.Server (Server.java:doStart(415)) - Started @381307ms
2023-03-20 21:34:40,037 [Listener at 0.0.0.0/42371] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:40,038 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:38151
2023-03-20 21:34:40,038 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-20 21:34:40,038 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:40,038 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:40,302 [IPC Server handler 19 on default port 44329] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a416fcbf-d3db-4cde-9623-07e05d2a4f7f
2023-03-20 21:34:40,302 [IPC Server handler 19 on default port 44329] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : a416fcbf-d3db-4cde-9623-07e05d2a4f7f{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=39913, RATIS=43949, RATIS_ADMIN=43949, RATIS_SERVER=43949, RATIS_DATASTREAM=37825, STANDALONE=38619], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:40,302 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:40,304 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=a42e5b9d-3395-4b3a-97a9-79efad75b4cc to datanode:a416fcbf-d3db-4cde-9623-07e05d2a4f7f
2023-03-20 21:34:40,305 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: a42e5b9d-3395-4b3a-97a9-79efad75b4cc, Nodes: a416fcbf-d3db-4cde-9623-07e05d2a4f7f(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:40.304Z[Etc/UTC]].
2023-03-20 21:34:40,305 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2023-03-20 21:34:40,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:40,659 [IPC Server handler 4 on default port 44329] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/2325b755-97f4-4680-bb9e-067434f11ceb
2023-03-20 21:34:40,659 [IPC Server handler 4 on default port 44329] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 2325b755-97f4-4680-bb9e-067434f11ceb{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=35701, RATIS=35621, RATIS_ADMIN=35621, RATIS_SERVER=35621, RATIS_DATASTREAM=34971, STANDALONE=41763], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:40,659 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:40,660 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d to datanode:2325b755-97f4-4680-bb9e-067434f11ceb
2023-03-20 21:34:40,660 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d, Nodes: 2325b755-97f4-4680-bb9e-067434f11ceb(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:40.660Z[Etc/UTC]].
2023-03-20 21:34:40,660 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=3398bf8a-4c2c-4f6c-985d-312fd93c9006 to datanode:2325b755-97f4-4680-bb9e-067434f11ceb
2023-03-20 21:34:40,660 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=3398bf8a-4c2c-4f6c-985d-312fd93c9006 to datanode:05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:40,660 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=3398bf8a-4c2c-4f6c-985d-312fd93c9006 to datanode:a416fcbf-d3db-4cde-9623-07e05d2a4f7f
2023-03-20 21:34:40,660 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 3398bf8a-4c2c-4f6c-985d-312fd93c9006, Nodes: 2325b755-97f4-4680-bb9e-067434f11ceb(fv-az985-449/10.1.0.10)05384c5d-9495-4201-8a60-c8c72abd74fb(fv-az985-449/10.1.0.10)a416fcbf-d3db-4cde-9623-07e05d2a4f7f(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:40.660Z[Etc/UTC]].
2023-03-20 21:34:40,662 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:40,817 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(1010)) - Retrying connect to server: 0.0.0.0/0.0.0.0:42601. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2023-03-20 21:34:40,821 [IPC Server handler 0 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:40,822 [IPC Server handler 1 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:40,823 [IPC Server handler 1 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:40,823 [IPC Server handler 3 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:40,825 [IPC Server handler 4 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:40,825 [IPC Server handler 4 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:40,826 [IPC Server handler 4 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:40,826 [IPC Server handler 7 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:40,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:40,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 6 of 7 DN Heartbeats.
2023-03-20 21:34:40,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:40,955 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:40,956 [IPC Server handler 3 on default port 44329] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a0d6486e-58e7-45ac-85b3-704c8b479dbc
2023-03-20 21:34:40,956 [IPC Server handler 3 on default port 44329] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : a0d6486e-58e7-45ac-85b3-704c8b479dbc{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45451, RATIS=35909, RATIS_ADMIN=35909, RATIS_SERVER=35909, RATIS_DATASTREAM=38747, STANDALONE=43207], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:40,956 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:40,956 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=d2890860-ad4b-4fae-b8b5-56fd36c5e925 to datanode:a0d6486e-58e7-45ac-85b3-704c8b479dbc
2023-03-20 21:34:40,956 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: d2890860-ad4b-4fae-b8b5-56fd36c5e925, Nodes: a0d6486e-58e7-45ac-85b3-704c8b479dbc(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:40.956Z[Etc/UTC]].
2023-03-20 21:34:40,957 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:34:40,961 [IPC Server handler 8 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:40,961 [IPC Server handler 8 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=39745, RATIS=36869, RATIS_ADMIN=36869, RATIS_SERVER=36869, RATIS_DATASTREAM=34323, STANDALONE=35469], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:40,969 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-20 21:34:40,970 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-20 21:34:40,974 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:40,975 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 1
2023-03-20 21:34:40,976 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-20 21:34:40,978 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:41,038 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 1 of 7 DN Heartbeats.
2023-03-20 21:34:41,039 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:41,039 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:41,433 [IPC Server handler 0 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:41,433 [IPC Server handler 0 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : ad5f436c-b0db-4b4f-b4fd-dcb016937dbf{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=46645, RATIS=45703, RATIS_ADMIN=45703, RATIS_SERVER=45703, RATIS_DATASTREAM=46387, STANDALONE=37991], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:41,433 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:41,435 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-20 21:34:41,435 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-03-20 21:34:41,436 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-20 21:34:41,437 [IPC Server handler 0 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:41,437 [IPC Server handler 0 on default port 42601] INFO  node.NodeStateManager (NodeStateManager.java:newNodeStatus(338)) - Updating nodeOperationalState on registration as the datanode has a persisted state of IN_MAINTENANCE and expiry of 0
2023-03-20 21:34:41,437 [IPC Server handler 0 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 1226cf83-b1fd-416f-9846-61bdfa3ff6b3{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=39621, RATIS=36759, RATIS_ADMIN=36759, RATIS_SERVER=36759, RATIS_DATASTREAM=40753, STANDALONE=44947], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:41,437 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:41,437 [EventQueue-NewNodeForNewNodeHandler] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:continueAdminForNode(267)) - Continue admin for datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10)
2023-03-20 21:34:41,437 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-20 21:34:41,437 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-20 21:34:41,437 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-20 21:34:41,437 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-20 21:34:41,437 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:41,437 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:41,442 [IPC Server handler 3 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:41,442 [IPC Server handler 3 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : c810b0b2-f38c-4bc5-874a-38f1937d7d9e{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45831, RATIS=34483, RATIS_ADMIN=34483, RATIS_SERVER=34483, RATIS_DATASTREAM=38853, STANDALONE=45741], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:41,442 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:41,443 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:41,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:41,461 [IPC Server handler 4 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:41,461 [IPC Server handler 4 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : ad06446d-1378-4ceb-aafe-e920688dce34{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=44493, RATIS=45443, RATIS_ADMIN=45443, RATIS_SERVER=45443, RATIS_DATASTREAM=44401, STANDALONE=33865], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:41,461 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:41,462 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:41,814 [IPC Server handler 7 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:41,814 [IPC Server handler 7 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 9ce389bc-6c47-40b9-aa21-f44fc17fd7db{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=46199, RATIS=34363, RATIS_ADMIN=34363, RATIS_SERVER=34363, RATIS_DATASTREAM=39027, STANDALONE=34777], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:41,814 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:41,818 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:41,824 [IPC Server handler 8 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:41,824 [IPC Server handler 8 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : c2f44316-1a3e-468b-9a76-53c43d628173{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45549, RATIS=33117, RATIS_ADMIN=33117, RATIS_SERVER=33117, RATIS_DATASTREAM=40549, STANDALONE=40115], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:41,825 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:41,825 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1175)) - Service ReplicationManager transitions to RUNNING.
2023-03-20 21:34:41,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-20 21:34:41,905 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:41,905 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10). Finalizing its pipelines []
2023-03-20 21:34:41,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:41,936 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 52a46685-3070-4024-834b-c3445a236f70: addNew group-BE3927FEFB6A:[52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:1|startupRole:FOLLOWER] returns group-BE3927FEFB6A:java.util.concurrent.CompletableFuture@628b8a94[Not completed]
2023-03-20 21:34:41,937 [pool-4321-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 52a46685-3070-4024-834b-c3445a236f70: new RaftServerImpl for group-BE3927FEFB6A:[52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:41,937 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:41,937 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:41,937 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:41,937 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:41,937 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:41,937 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:41,938 [pool-4321-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A: ConfigurationManager, init=-1: peers:[52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:41,938 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis] (custom)
2023-03-20 21:34:41,938 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:41,938 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:41,938 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:41,938 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:41,938 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:41,939 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:41,939 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:41,939 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:41,939 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:41,939 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:41,939 [pool-4321-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/e910e24a-6d72-480a-9a70-be3927fefb6a does not exist. Creating ...
2023-03-20 21:34:41,940 [pool-4321-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/e910e24a-6d72-480a-9a70-be3927fefb6a/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:41,941 [pool-4321-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/e910e24a-6d72-480a-9a70-be3927fefb6a has been successfully formatted.
2023-03-20 21:34:41,941 [pool-4321-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-BE3927FEFB6A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:41,941 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:41,941 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:41,942 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: e910e24a-6d72-480a-9a70-be3927fefb6a, Nodes: 52a46685-3070-4024-834b-c3445a236f70(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:52a46685-3070-4024-834b-c3445a236f70, CreationTimestamp2023-03-20T21:34:38.949Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:41,942 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:41,942 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:41,942 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:41,948 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:41,950 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:41,950 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:41,950 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:41,950 [pool-4321-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/e910e24a-6d72-480a-9a70-be3927fefb6a
2023-03-20 21:34:41,950 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:41,951 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:41,951 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:41,951 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:41,951 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:41,951 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:41,951 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:41,951 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:41,951 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:41,952 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:41,955 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:41,955 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:41,955 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:41,955 [pool-4321-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:41,955 [pool-4321-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:41,955 [pool-4321-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A: start as a follower, conf=-1: peers:[52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:41,955 [pool-4321-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:41,955 [pool-4321-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 52a46685-3070-4024-834b-c3445a236f70: start 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState
2023-03-20 21:34:41,955 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:41,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:41,956 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:41,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:41,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:41,956 [pool-4321-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BE3927FEFB6A,id=52a46685-3070-4024-834b-c3445a236f70
2023-03-20 21:34:41,956 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:41,956 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:41,956 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:41,956 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:41,956 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=e910e24a-6d72-480a-9a70-be3927fefb6a
2023-03-20 21:34:41,956 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=e910e24a-6d72-480a-9a70-be3927fefb6a.
2023-03-20 21:34:41,956 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 52a46685-3070-4024-834b-c3445a236f70: addNew group-D21AA782C062:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER] returns group-D21AA782C062:java.util.concurrent.CompletableFuture@66b4021d[Not completed]
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 52a46685-3070-4024-834b-c3445a236f70: new RaftServerImpl for group-D21AA782C062:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: ConfigurationManager, init=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis] (custom)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:41,957 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:41,958 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:41,958 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:41,958 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:41,958 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:41,958 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:41,958 [pool-4321-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062 does not exist. Creating ...
2023-03-20 21:34:41,959 [pool-4321-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:41,960 [pool-4321-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062 has been successfully formatted.
2023-03-20 21:34:41,960 [pool-4321-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-D21AA782C062: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:41,961 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:41,961 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:41,961 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:41,961 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:41,961 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:41,961 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:41,962 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:41,963 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:41,964 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:41,966 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:41,966 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:41,966 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: start as a follower, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 52a46685-3070-4024-834b-c3445a236f70: start 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState
2023-03-20 21:34:41,967 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D21AA782C062,id=52a46685-3070-4024-834b-c3445a236f70
2023-03-20 21:34:41,967 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:41,967 [pool-4321-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:41,968 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=46f08bba-1415-40e8-8a77-d21aa782c062
2023-03-20 21:34:41,974 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 79924adf-68a9-4348-9386-442656259f82: addNew group-D21AA782C062:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER] returns group-D21AA782C062:java.util.concurrent.CompletableFuture@714cddde[Not completed]
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 79924adf-68a9-4348-9386-442656259f82: new RaftServerImpl for group-D21AA782C062:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062: ConfigurationManager, init=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis] (custom)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:41,975 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:41,976 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:41,976 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:41,976 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:41,976 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:41,976 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:41,976 [pool-4343-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062 does not exist. Creating ...
2023-03-20 21:34:41,977 [pool-4343-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:41,978 [pool-4343-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062 has been successfully formatted.
2023-03-20 21:34:41,978 [pool-4343-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-D21AA782C062: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:41,979 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:41,980 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:41,980 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:41,980 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:41,981 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:41,984 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:41,984 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:41,984 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:41,984 [pool-4343-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:41,984 [pool-4343-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:41,984 [pool-4343-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062: start as a follower, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:41,984 [pool-4343-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:41,984 [pool-4343-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 79924adf-68a9-4348-9386-442656259f82: start 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState
2023-03-20 21:34:41,988 [pool-4343-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D21AA782C062,id=79924adf-68a9-4348-9386-442656259f82
2023-03-20 21:34:41,988 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:41,988 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:41,988 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:41,988 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:41,989 [79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:41,989 [79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:41,998 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - e5cc6624-b71a-402d-a69e-29759be12af7: addNew group-D21AA782C062:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER] returns group-D21AA782C062:java.util.concurrent.CompletableFuture@5d4d57ba[Not completed]
2023-03-20 21:34:41,998 [pool-4365-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - e5cc6624-b71a-402d-a69e-29759be12af7: new RaftServerImpl for group-D21AA782C062:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:41,998 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:41,998 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:41,998 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:41,998 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:41,999 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:41,999 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:42,000 [pool-4365-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062: ConfigurationManager, init=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:42,000 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis] (custom)
2023-03-20 21:34:42,000 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:42,000 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:42,000 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:42,000 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:42,000 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:42,001 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:42,001 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:42,001 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:42,001 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:42,001 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:42,002 [pool-4365-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062 does not exist. Creating ...
2023-03-20 21:34:42,002 [pool-4365-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:42,003 [pool-4365-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062 has been successfully formatted.
2023-03-20 21:34:42,004 [pool-4365-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-D21AA782C062: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:42,004 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:42,004 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:42,004 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,004 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:42,004 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:42,004 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:42,005 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:42,006 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:42,006 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,009 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:42,009 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:42,009 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:42,009 [pool-4365-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,009 [pool-4365-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,009 [pool-4365-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062: start as a follower, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:42,009 [pool-4365-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:42,009 [pool-4365-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5cc6624-b71a-402d-a69e-29759be12af7: start e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState
2023-03-20 21:34:42,016 [pool-4365-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D21AA782C062,id=e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:42,016 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:42,016 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:42,016 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:42,016 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:42,016 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:42,016 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:42,023 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=46f08bba-1415-40e8-8a77-d21aa782c062.
2023-03-20 21:34:42,039 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:42,039 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Cluster exits safe mode
2023-03-20 21:34:42,039 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:42,041 [Listener at 0.0.0.0/42371] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:34:42,041 [Listener at 0.0.0.0/42371] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: close
2023-03-20 21:34:42,041 [Listener at 0.0.0.0/42371] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:42,043 [Listener at 0.0.0.0/42371] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e Close channels
2023-03-20 21:34:42,043 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf Close channels
2023-03-20 21:34:42,044 [grpc-default-executor-4] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-20 21:34:42,268 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 79924adf-68a9-4348-9386-442656259f82: addNew group-BA594E114897:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:1|startupRole:FOLLOWER] returns group-BA594E114897:java.util.concurrent.CompletableFuture@64f47a5[Not completed]
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 79924adf-68a9-4348-9386-442656259f82: new RaftServerImpl for group-BA594E114897:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897: ConfigurationManager, init=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis] (custom)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:42,269 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:42,270 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:42,270 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:42,270 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:42,270 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:42,270 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:42,271 [pool-4343-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/7974330e-eed0-46af-a7aa-ba594e114897 does not exist. Creating ...
2023-03-20 21:34:42,271 [pool-4343-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/7974330e-eed0-46af-a7aa-ba594e114897/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:42,272 [pool-4343-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/7974330e-eed0-46af-a7aa-ba594e114897 has been successfully formatted.
2023-03-20 21:34:42,272 [pool-4343-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-BA594E114897: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:42,273 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:42,273 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:42,273 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,273 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 7974330e-eed0-46af-a7aa-ba594e114897, Nodes: 79924adf-68a9-4348-9386-442656259f82(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:79924adf-68a9-4348-9386-442656259f82, CreationTimestamp2023-03-20T21:34:39.277Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:42,273 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:42,273 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:42,273 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:42,273 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/7974330e-eed0-46af-a7aa-ba594e114897
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:42,274 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:42,275 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:42,275 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,278 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:42,278 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:42,278 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:42,278 [pool-4343-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,278 [pool-4343-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,279 [pool-4343-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897: start as a follower, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:42,279 [pool-4343-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:42,279 [pool-4343-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 79924adf-68a9-4348-9386-442656259f82: start 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState
2023-03-20 21:34:42,279 [pool-4343-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BA594E114897,id=79924adf-68a9-4348-9386-442656259f82
2023-03-20 21:34:42,279 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:42,279 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:42,279 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:42,279 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:42,279 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:42,279 [pool-4343-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:42,279 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=7974330e-eed0-46af-a7aa-ba594e114897
2023-03-20 21:34:42,279 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=7974330e-eed0-46af-a7aa-ba594e114897.
2023-03-20 21:34:42,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:42,647 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - e5cc6624-b71a-402d-a69e-29759be12af7: addNew group-AC1DF4A4BC78:[e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER] returns group-AC1DF4A4BC78:java.util.concurrent.CompletableFuture@54a60309[Not completed]
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - e5cc6624-b71a-402d-a69e-29759be12af7: new RaftServerImpl for group-AC1DF4A4BC78:[e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78: ConfigurationManager, init=-1: peers:[e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis] (custom)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:42,648 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:42,649 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:42,649 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:42,649 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:42,649 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:42,649 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:42,650 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:42,650 [pool-4365-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/d5324a2d-e604-4092-a161-ac1df4a4bc78 does not exist. Creating ...
2023-03-20 21:34:42,650 [pool-4365-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/d5324a2d-e604-4092-a161-ac1df4a4bc78/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:42,651 [pool-4365-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/d5324a2d-e604-4092-a161-ac1df4a4bc78 has been successfully formatted.
2023-03-20 21:34:42,652 [pool-4365-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-AC1DF4A4BC78: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:42,652 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:42,652 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:42,652 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,652 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:42,652 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: d5324a2d-e604-4092-a161-ac1df4a4bc78, Nodes: e5cc6624-b71a-402d-a69e-29759be12af7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e5cc6624-b71a-402d-a69e-29759be12af7, CreationTimestamp2023-03-20T21:34:39.649Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:42,652 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:42,652 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,652 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/d5324a2d-e604-4092-a161-ac1df4a4bc78
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:42,655 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:42,656 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:42,656 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78: start as a follower, conf=-1: peers:[e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5cc6624-b71a-402d-a69e-29759be12af7: start e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AC1DF4A4BC78,id=e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:42,660 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:42,660 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:42,660 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:42,661 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:42,661 [pool-4365-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:42,661 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=d5324a2d-e604-4092-a161-ac1df4a4bc78
2023-03-20 21:34:42,661 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=d5324a2d-e604-4092-a161-ac1df4a4bc78.
2023-03-20 21:34:42,905 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:42,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:42,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:42,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:42,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:42,961 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:42,973 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: addNew group-5A5C429D75E5:[05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER] returns group-5A5C429D75E5:java.util.concurrent.CompletableFuture@3aae15ff[Not completed]
2023-03-20 21:34:42,973 [pool-4387-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: new RaftServerImpl for group-5A5C429D75E5:[05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:42,973 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:42,973 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:42,973 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:42,973 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:42,973 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:42,973 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:42,974 [pool-4387-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5: ConfigurationManager, init=-1: peers:[05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:42,974 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis] (custom)
2023-03-20 21:34:42,974 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:42,974 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:42,974 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:42,974 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:42,974 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:42,975 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:42,975 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:42,975 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:42,975 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:42,975 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:42,976 [pool-4387-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/12545f98-2564-4b6f-bb8b-5a5c429d75e5 does not exist. Creating ...
2023-03-20 21:34:42,976 [pool-4387-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/12545f98-2564-4b6f-bb8b-5a5c429d75e5/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:42,977 [pool-4387-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/12545f98-2564-4b6f-bb8b-5a5c429d75e5 has been successfully formatted.
2023-03-20 21:34:42,977 [pool-4387-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-5A5C429D75E5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:42,978 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 12545f98-2564-4b6f-bb8b-5a5c429d75e5, Nodes: 05384c5d-9495-4201-8a60-c8c72abd74fb(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:05384c5d-9495-4201-8a60-c8c72abd74fb, CreationTimestamp2023-03-20T21:34:39.975Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,978 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/12545f98-2564-4b6f-bb8b-5a5c429d75e5
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:42,978 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:42,979 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,979 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:42,979 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:42,979 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:42,979 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:42,979 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:42,979 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:42,980 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,983 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:42,983 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:42,983 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:42,983 [pool-4387-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,983 [pool-4387-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,983 [pool-4387-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5: start as a follower, conf=-1: peers:[05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:42,983 [pool-4387-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:42,983 [pool-4387-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: start 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState
2023-03-20 21:34:42,984 [pool-4387-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5A5C429D75E5,id=05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:42,984 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:42,984 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:42,984 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:42,984 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:42,984 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:42,984 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:42,986 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=12545f98-2564-4b6f-bb8b-5a5c429d75e5
2023-03-20 21:34:42,986 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=12545f98-2564-4b6f-bb8b-5a5c429d75e5.
2023-03-20 21:34:42,987 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: addNew group-312FD93C9006:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER] returns group-312FD93C9006:java.util.concurrent.CompletableFuture@3e918672[Not completed]
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: new RaftServerImpl for group-312FD93C9006:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006: ConfigurationManager, init=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis] (custom)
2023-03-20 21:34:42,987 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:42,988 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:42,988 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:42,988 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:42,988 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:42,988 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:42,989 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:42,989 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:42,989 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:42,989 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:42,989 [pool-4387-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006 does not exist. Creating ...
2023-03-20 21:34:42,989 [pool-4387-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:42,990 [pool-4387-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006 has been successfully formatted.
2023-03-20 21:34:42,991 [pool-4387-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-312FD93C9006: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:42,991 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:42,991 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:42,991 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,991 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:42,991 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:42,991 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:42,991 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:42,992 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:42,993 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:42,993 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:42,996 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:42,996 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:42,996 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:42,996 [pool-4387-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,996 [pool-4387-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:42,997 [pool-4387-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006: start as a follower, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:42,997 [pool-4387-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:42,997 [pool-4387-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: start 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState
2023-03-20 21:34:42,997 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:42,997 [pool-4387-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-312FD93C9006,id=05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:42,997 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:42,997 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:42,997 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:42,997 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:42,997 [pool-4387-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:42,998 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=3398bf8a-4c2c-4f6c-985d-312fd93c9006
2023-03-20 21:34:43,002 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 2325b755-97f4-4680-bb9e-067434f11ceb: addNew group-312FD93C9006:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER] returns group-312FD93C9006:java.util.concurrent.CompletableFuture@2e0716b8[Not completed]
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 2325b755-97f4-4680-bb9e-067434f11ceb: new RaftServerImpl for group-312FD93C9006:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: ConfigurationManager, init=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis] (custom)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:43,003 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:43,004 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:43,004 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:43,004 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:43,004 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:43,004 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:43,004 [pool-4431-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006 does not exist. Creating ...
2023-03-20 21:34:43,006 [pool-4431-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:43,006 [pool-4431-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006 has been successfully formatted.
2023-03-20 21:34:43,007 [pool-4431-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-312FD93C9006: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:43,007 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:43,007 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:43,007 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,007 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:43,007 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:43,007 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,008 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:43,008 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:43,008 [pool-4431-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006
2023-03-20 21:34:43,008 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:43,009 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:43,009 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,009 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:43,009 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:43,009 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:43,009 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:43,009 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:43,010 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:43,010 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,013 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:43,013 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:43,013 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:43,013 [pool-4431-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,014 [pool-4431-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,014 [pool-4431-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: start as a follower, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:43,014 [pool-4431-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:43,014 [pool-4431-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2325b755-97f4-4680-bb9e-067434f11ceb: start 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState
2023-03-20 21:34:43,014 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:43,014 [pool-4431-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-312FD93C9006,id=2325b755-97f4-4680-bb9e-067434f11ceb
2023-03-20 21:34:43,014 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:43,014 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:43,014 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:43,014 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:43,014 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:43,026 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: addNew group-312FD93C9006:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER] returns group-312FD93C9006:java.util.concurrent.CompletableFuture@407a4dd1[Not completed]
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: new RaftServerImpl for group-312FD93C9006:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: ConfigurationManager, init=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis] (custom)
2023-03-20 21:34:43,027 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:43,028 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:43,028 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:43,028 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:43,028 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:43,028 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:43,029 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:43,029 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:43,029 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:43,029 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:43,029 [pool-4409-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006 does not exist. Creating ...
2023-03-20 21:34:43,029 [pool-4409-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:43,030 [pool-4409-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006 has been successfully formatted.
2023-03-20 21:34:43,030 [pool-4409-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-312FD93C9006: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006
2023-03-20 21:34:43,031 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:43,032 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:43,032 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,032 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:43,032 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:43,032 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:43,032 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:43,032 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:43,032 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:43,033 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: start as a follower, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: start a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState
2023-03-20 21:34:43,036 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-312FD93C9006,id=a416fcbf-d3db-4cde-9623-07e05d2a4f7f
2023-03-20 21:34:43,036 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:43,036 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:43,037 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:43,037 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:43,037 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:43,038 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=3398bf8a-4c2c-4f6c-985d-312fd93c9006.
2023-03-20 21:34:43,299 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: addNew group-79EFAD75B4CC:[a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:1|startupRole:FOLLOWER] returns group-79EFAD75B4CC:java.util.concurrent.CompletableFuture@760608e3[Not completed]
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: new RaftServerImpl for group-79EFAD75B4CC:[a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC: ConfigurationManager, init=-1: peers:[a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis] (custom)
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:43,300 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:43,301 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:43,301 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:43,301 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:43,302 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:43,302 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:43,302 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:43,302 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:43,302 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:43,302 [pool-4409-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/a42e5b9d-3395-4b3a-97a9-79efad75b4cc does not exist. Creating ...
2023-03-20 21:34:43,303 [pool-4409-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/a42e5b9d-3395-4b3a-97a9-79efad75b4cc/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:43,303 [pool-4409-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/a42e5b9d-3395-4b3a-97a9-79efad75b4cc has been successfully formatted.
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-79EFAD75B4CC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,304 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: a42e5b9d-3395-4b3a-97a9-79efad75b4cc, Nodes: a416fcbf-d3db-4cde-9623-07e05d2a4f7f(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a416fcbf-d3db-4cde-9623-07e05d2a4f7f, CreationTimestamp2023-03-20T21:34:40.304Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:43,304 [pool-4409-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/a42e5b9d-3395-4b3a-97a9-79efad75b4cc
2023-03-20 21:34:43,305 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:43,305 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:43,305 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:43,305 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,305 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:43,305 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:43,305 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:43,305 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:43,305 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:43,305 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:43,306 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC: start as a follower, conf=-1: peers:[a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: start a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState
2023-03-20 21:34:43,309 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-79EFAD75B4CC,id=a416fcbf-d3db-4cde-9623-07e05d2a4f7f
2023-03-20 21:34:43,309 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:43,309 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:43,310 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:43,310 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:43,310 [pool-4409-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:43,310 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=a42e5b9d-3395-4b3a-97a9-79efad75b4cc
2023-03-20 21:34:43,310 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=a42e5b9d-3395-4b3a-97a9-79efad75b4cc.
2023-03-20 21:34:43,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:43,652 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:43,658 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 2325b755-97f4-4680-bb9e-067434f11ceb: addNew group-9E114AB0A66D:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:1|startupRole:FOLLOWER] returns group-9E114AB0A66D:java.util.concurrent.CompletableFuture@2d823742[Not completed]
2023-03-20 21:34:43,659 [pool-4431-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 2325b755-97f4-4680-bb9e-067434f11ceb: new RaftServerImpl for group-9E114AB0A66D:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:43,659 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:43,659 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:43,659 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:43,659 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:43,659 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:43,659 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:43,854 [pool-4431-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D: ConfigurationManager, init=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:43,854 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis] (custom)
2023-03-20 21:34:43,854 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:43,855 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:43,855 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:43,855 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:43,855 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:43,856 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:43,856 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:43,856 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:43,856 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:43,856 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:43,856 [pool-4431-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d does not exist. Creating ...
2023-03-20 21:34:43,857 [pool-4431-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:43,858 [JvmPauseMonitor91] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-ad06446d-1378-4ceb-aafe-e920688dce34: Detected pause in JVM or host machine (eg GC): pause of approximately 156696472ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=193ms
2023-03-20 21:34:43,858 [JvmPauseMonitor98] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-2325b755-97f4-4680-bb9e-067434f11ceb: Detected pause in JVM or host machine (eg GC): pause of approximately 158412552ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=193ms
2023-03-20 21:34:43,858 [JvmPauseMonitor95] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-e5cc6624-b71a-402d-a69e-29759be12af7: Detected pause in JVM or host machine (eg GC): pause of approximately 162887001ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=193ms
2023-03-20 21:34:43,858 [JvmPauseMonitor86] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-1226cf83-b1fd-416f-9846-61bdfa3ff6b3: Detected pause in JVM or host machine (eg GC): pause of approximately 180841895ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=193ms
2023-03-20 21:34:43,858 [pool-4431-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d has been successfully formatted.
2023-03-20 21:34:43,859 [pool-4431-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-9E114AB0A66D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:43,859 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:43,859 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:43,859 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,859 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d, Nodes: 2325b755-97f4-4680-bb9e-067434f11ceb(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:2325b755-97f4-4680-bb9e-067434f11ceb, CreationTimestamp2023-03-20T21:34:40.660Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:43,859 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:43,859 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:43,859 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,859 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:43,860 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:43,860 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:43,860 [pool-4431-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d
2023-03-20 21:34:43,860 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:43,865 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:43,865 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,865 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:43,866 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:43,866 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:43,866 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:43,866 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:43,866 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:43,867 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,873 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:43,873 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:43,873 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:43,873 [pool-4431-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,873 [pool-4431-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,873 [pool-4431-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D: start as a follower, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:43,873 [pool-4431-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:43,874 [pool-4431-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2325b755-97f4-4680-bb9e-067434f11ceb: start 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState
2023-03-20 21:34:43,874 [pool-4431-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9E114AB0A66D,id=2325b755-97f4-4680-bb9e-067434f11ceb
2023-03-20 21:34:43,874 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:43,874 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:43,874 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:43,874 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:43,874 [pool-4431-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:43,874 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:43,875 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d
2023-03-20 21:34:43,875 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d.
2023-03-20 21:34:43,905 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:43,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:43,956 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc: addNew group-56FD36C5E925:[a0d6486e-58e7-45ac-85b3-704c8b479dbc|rpc:10.1.0.10:35909|dataStream:10.1.0.10:38747|priority:1|startupRole:FOLLOWER] returns group-56FD36C5E925:java.util.concurrent.CompletableFuture@61013dd9[Not completed]
2023-03-20 21:34:43,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:43,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:43,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc: new RaftServerImpl for group-56FD36C5E925:[a0d6486e-58e7-45ac-85b3-704c8b479dbc|rpc:10.1.0.10:35909|dataStream:10.1.0.10:38747|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925: ConfigurationManager, init=-1: peers:[a0d6486e-58e7-45ac-85b3-704c8b479dbc|rpc:10.1.0.10:35909|dataStream:10.1.0.10:38747|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis] (custom)
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:43,957 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:43,958 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:43,958 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:43,958 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:43,959 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:43,959 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:43,959 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:43,959 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:43,959 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:43,959 [pool-4453-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis/d2890860-ad4b-4fae-b8b5-56fd36c5e925 does not exist. Creating ...
2023-03-20 21:34:43,972 [pool-4453-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis/d2890860-ad4b-4fae-b8b5-56fd36c5e925/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:43,973 [pool-4453-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis/d2890860-ad4b-4fae-b8b5-56fd36c5e925 has been successfully formatted.
2023-03-20 21:34:43,973 [pool-4453-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-56FD36C5E925: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:43,974 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: d2890860-ad4b-4fae-b8b5-56fd36c5e925, Nodes: a0d6486e-58e7-45ac-85b3-704c8b479dbc(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a0d6486e-58e7-45ac-85b3-704c8b479dbc, CreationTimestamp2023-03-20T21:34:40.956Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:43,974 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:43,974 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:43,974 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:43,974 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,974 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:43,974 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis/d2890860-ad4b-4fae-b8b5-56fd36c5e925
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:43,975 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:43,976 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:43,976 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:43,979 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:43,979 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:43,979 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:43,979 [pool-4453-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,979 [pool-4453-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:43,979 [pool-4453-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925: start as a follower, conf=-1: peers:[a0d6486e-58e7-45ac-85b3-704c8b479dbc|rpc:10.1.0.10:35909|dataStream:10.1.0.10:38747|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:43,979 [pool-4453-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:43,979 [pool-4453-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc: start a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState
2023-03-20 21:34:43,980 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:43,980 [pool-4453-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-56FD36C5E925,id=a0d6486e-58e7-45ac-85b3-704c8b479dbc
2023-03-20 21:34:43,980 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:43,980 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:43,980 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:43,980 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:43,980 [pool-4453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:43,980 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=d2890860-ad4b-4fae-b8b5-56fd36c5e925
2023-03-20 21:34:43,980 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=d2890860-ad4b-4fae-b8b5-56fd36c5e925.
2023-03-20 21:34:43,990 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:44,273 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:44,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:44,458 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines []
2023-03-20 21:34:44,469 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5012961434ns, electionTimeout:5004ms
2023-03-20 21:34:44,469 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState
2023-03-20 21:34:44,469 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:44,469 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:44,469 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152
2023-03-20 21:34:44,470 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:44,470 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:44,470 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:44,470 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:44,471 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: receive requestVote(PRE_VOTE, c810b0b2-f38c-4bc5-874a-38f1937d7d9e, group-183CE2A09169, 0, (t:0, i:0))
2023-03-20 21:34:44,471 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FOLLOWER: accept PRE_VOTE from c810b0b2-f38c-4bc5-874a-38f1937d7d9e: our priority 0 <= candidate's priority 1
2023-03-20 21:34:44,471 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169 replies to PRE_VOTE vote request: c810b0b2-f38c-4bc5-874a-38f1937d7d9e<-ad5f436c-b0db-4b4f-b4fd-dcb016937dbf#0:OK-t0. Peer's state: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169:t0, leader=null, voted=, raftlog=Memoized:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:44,471 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:44,471 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c810b0b2-f38c-4bc5-874a-38f1937d7d9e<-ad5f436c-b0db-4b4f-b4fd-dcb016937dbf#0:OK-t0
2023-03-20 21:34:44,471 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152 PRE_VOTE round 0: result PASSED
2023-03-20 21:34:44,475 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: receive requestVote(PRE_VOTE, c810b0b2-f38c-4bc5-874a-38f1937d7d9e, group-183CE2A09169, 0, (t:0, i:0))
2023-03-20 21:34:44,475 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FOLLOWER: accept PRE_VOTE from c810b0b2-f38c-4bc5-874a-38f1937d7d9e: our priority 0 <= candidate's priority 1
2023-03-20 21:34:44,475 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:44,475 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169 replies to PRE_VOTE vote request: c810b0b2-f38c-4bc5-874a-38f1937d7d9e<-ad06446d-1378-4ceb-aafe-e920688dce34#0:OK-t0. Peer's state: ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169:t0, leader=null, voted=, raftlog=Memoized:ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:44,476 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:44,476 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:44,478 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: receive requestVote(ELECTION, c810b0b2-f38c-4bc5-874a-38f1937d7d9e, group-183CE2A09169, 1, (t:0, i:0))
2023-03-20 21:34:44,478 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FOLLOWER: accept ELECTION from c810b0b2-f38c-4bc5-874a-38f1937d7d9e: our priority 0 <= candidate's priority 1
2023-03-20 21:34:44,478 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:44,478 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ad06446d-1378-4ceb-aafe-e920688dce34: shutdown ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState
2023-03-20 21:34:44,478 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad06446d-1378-4ceb-aafe-e920688dce34: start ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState
2023-03-20 21:34:44,478 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState was interrupted
2023-03-20 21:34:44,478 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: receive requestVote(ELECTION, c810b0b2-f38c-4bc5-874a-38f1937d7d9e, group-183CE2A09169, 1, (t:0, i:0))
2023-03-20 21:34:44,478 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FOLLOWER: accept ELECTION from c810b0b2-f38c-4bc5-874a-38f1937d7d9e: our priority 0 <= candidate's priority 1
2023-03-20 21:34:44,478 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:44,478 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState
2023-03-20 21:34:44,479 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState was interrupted
2023-03-20 21:34:44,479 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: start ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState
2023-03-20 21:34:44,479 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:44,479 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:44,479 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:44,480 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169 replies to ELECTION vote request: c810b0b2-f38c-4bc5-874a-38f1937d7d9e<-ad06446d-1378-4ceb-aafe-e920688dce34#0:OK-t1. Peer's state: ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169:t1, leader=null, voted=c810b0b2-f38c-4bc5-874a-38f1937d7d9e, raftlog=Memoized:ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:44,479 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:44,480 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:44,480 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c810b0b2-f38c-4bc5-874a-38f1937d7d9e<-ad06446d-1378-4ceb-aafe-e920688dce34#0:OK-t1
2023-03-20 21:34:44,480 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152 ELECTION round 0: result PASSED
2023-03-20 21:34:44,480 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152
2023-03-20 21:34:44,480 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:44,480 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-183CE2A09169 with new leaderId: c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:44,480 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169: change Leader from null to c810b0b2-f38c-4bc5-874a-38f1937d7d9e at term 1 for becomeLeader, leader elected after 5049ms
2023-03-20 21:34:44,480 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:44,481 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:44,481 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:44,481 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:44,481 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:44,481 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:44,481 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:44,481 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:44,482 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:44,482 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:44,482 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:44,482 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:44,482 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:44,482 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:44,482 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:44,482 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:44,482 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:44,483 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:44,483 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:44,483 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:44,483 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:44,483 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:44,483 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:44,483 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:44,483 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: start c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderStateImpl
2023-03-20 21:34:44,483 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:44,483 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 2084635c-5d52-438d-811e-183ce2a09169, Nodes: ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10)ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10)c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:c810b0b2-f38c-4bc5-874a-38f1937d7d9e, CreationTimestamp2023-03-20T21:34:39.894Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:44,484 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/current/log_inprogress_0
2023-03-20 21:34:44,490 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169 replies to ELECTION vote request: c810b0b2-f38c-4bc5-874a-38f1937d7d9e<-ad5f436c-b0db-4b4f-b4fd-dcb016937dbf#0:OK-t1. Peer's state: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169:t1, leader=null, voted=c810b0b2-f38c-4bc5-874a-38f1937d7d9e, raftlog=Memoized:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:44,490 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderElection152] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169: set configuration 0: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:44,497 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-183CE2A09169 with new leaderId: c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:44,497 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: change Leader from null to c810b0b2-f38c-4bc5-874a-38f1937d7d9e at term 1 for appendEntries, leader elected after 5075ms
2023-03-20 21:34:44,497 [ad06446d-1378-4ceb-aafe-e920688dce34-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-183CE2A09169 with new leaderId: c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:44,497 [ad06446d-1378-4ceb-aafe-e920688dce34-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: change Leader from null to c810b0b2-f38c-4bc5-874a-38f1937d7d9e at term 1 for appendEntries, leader elected after 5043ms
2023-03-20 21:34:44,501 [ad06446d-1378-4ceb-aafe-e920688dce34-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: set configuration 0: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:44,502 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: set configuration 0: peers:[ad06446d-1378-4ceb-aafe-e920688dce34|rpc:10.1.0.10:45443|dataStream:10.1.0.10:44401|priority:0|startupRole:FOLLOWER, c810b0b2-f38c-4bc5-874a-38f1937d7d9e|rpc:10.1.0.10:34483|dataStream:10.1.0.10:38853|priority:1|startupRole:FOLLOWER, ad5f436c-b0db-4b4f-b4fd-dcb016937dbf|rpc:10.1.0.10:45703|dataStream:10.1.0.10:46387|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:44,502 [ad06446d-1378-4ceb-aafe-e920688dce34-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:44,503 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:44,504 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/current/log_inprogress_0
2023-03-20 21:34:44,504 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/current/log_inprogress_0
2023-03-20 21:34:44,652 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:44,860 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:44,905 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:44,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:34:44,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:44,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:44,956 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:44,962 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:44,974 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:44,991 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:45,044 [ForkJoinPool.commonPool-worker-1] WARN  grpc.GrpcUtil (GrpcUtil.java:shutdownManagedChannel(223)) - Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=3288, target=10.1.0.10:45703}}. 
2023-03-20 21:34:45,044 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3@group-02D605BA4E5C->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-GrpcLogAppender is already stopped
2023-03-20 21:34:45,044 [grpc-default-executor-1] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-20 21:34:45,044 [Listener at 0.0.0.0/42371] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:45,045 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3adaa8a8, L:/0:0:0:0:0:0:0:0:40753] CLOSE
2023-03-20 21:34:45,045 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3adaa8a8, L:/0:0:0:0:0:0:0:0:40753] INACTIVE
2023-03-20 21:34:45,045 [1226cf83-b1fd-416f-9846-61bdfa3ff6b3-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3adaa8a8, L:/0:0:0:0:0:0:0:0:40753] UNREGISTERED
2023-03-20 21:34:45,048 [JvmPauseMonitor86] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-1226cf83-b1fd-416f-9846-61bdfa3ff6b3: Stopped
2023-03-20 21:34:45,273 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:45,304 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:45,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:45,859 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:45,905 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:45,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-20 21:34:45,957 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:45,957 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:45,957 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:45,962 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:45,990 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:46,273 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:46,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:46,652 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:46,859 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:46,905 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-20 21:34:46,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:34:46,957 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:46,957 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:46,957 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:46,975 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:46,991 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:47,059 [Listener at 0.0.0.0/42371] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-1/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-38bfbc49-5fc1-4b6e-8d35-0d6e9fb8d0de/container.db for volume DS-38bfbc49-5fc1-4b6e-8d35-0d6e9fb8d0de
2023-03-20 21:34:47,061 [Listener at 0.0.0.0/42371] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:34:47,061 [Listener at 0.0.0.0/42371] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:34:47,065 [Listener at 0.0.0.0/42371] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:34:47,070 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5103362407ns, electionTimeout:5103ms
2023-03-20 21:34:47,070 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 52a46685-3070-4024-834b-c3445a236f70: shutdown 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState
2023-03-20 21:34:47,070 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:47,070 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:47,070 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 52a46685-3070-4024-834b-c3445a236f70: start 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153
2023-03-20 21:34:47,071 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,072 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 79924adf-68a9-4348-9386-442656259f82
2023-03-20 21:34:47,078 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:47,078 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:47,078 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:47,078 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062: receive requestVote(PRE_VOTE, 52a46685-3070-4024-834b-c3445a236f70, group-D21AA782C062, 0, (t:0, i:0))
2023-03-20 21:34:47,078 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FOLLOWER: accept PRE_VOTE from 52a46685-3070-4024-834b-c3445a236f70: our priority 0 <= candidate's priority 0
2023-03-20 21:34:47,079 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062 replies to PRE_VOTE vote request: 52a46685-3070-4024-834b-c3445a236f70<-79924adf-68a9-4348-9386-442656259f82#0:OK-t0. Peer's state: 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062:t0, leader=null, voted=, raftlog=Memoized:79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,085 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2f71e1a2{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:47,085 [Listener at 0.0.0.0/42371] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@686b2640{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:47,085 [Listener at 0.0.0.0/42371] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:47,087 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7cf265eb{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:34:47,088 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5ad41387{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:47,096 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062: receive requestVote(PRE_VOTE, 52a46685-3070-4024-834b-c3445a236f70, group-D21AA782C062, 0, (t:0, i:0))
2023-03-20 21:34:47,097 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FOLLOWER: reject PRE_VOTE from 52a46685-3070-4024-834b-c3445a236f70: our priority 1 > candidate's priority 0
2023-03-20 21:34:47,097 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062 replies to PRE_VOTE vote request: 52a46685-3070-4024-834b-c3445a236f70<-e5cc6624-b71a-402d-a69e-29759be12af7#0:FAIL-t0. Peer's state: e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062:t0, leader=null, voted=, raftlog=Memoized:e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,097 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2023-03-20 21:34:47,097 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 52a46685-3070-4024-834b-c3445a236f70<-79924adf-68a9-4348-9386-442656259f82#0:OK-t0
2023-03-20 21:34:47,097 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 52a46685-3070-4024-834b-c3445a236f70<-e5cc6624-b71a-402d-a69e-29759be12af7#0:FAIL-t0
2023-03-20 21:34:47,097 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153 PRE_VOTE round 0: result REJECTED
2023-03-20 21:34:47,097 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:34:47,097 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 52a46685-3070-4024-834b-c3445a236f70: shutdown 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153
2023-03-20 21:34:47,097 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-LeaderElection153] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 52a46685-3070-4024-834b-c3445a236f70: start 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState
2023-03-20 21:34:47,098 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:47,098 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:47,102 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5146403614ns, electionTimeout:5146ms
2023-03-20 21:34:47,102 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 52a46685-3070-4024-834b-c3445a236f70: shutdown 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState
2023-03-20 21:34:47,102 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:47,102 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:47,102 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 52a46685-3070-4024-834b-c3445a236f70: start 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154
2023-03-20 21:34:47,102 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,102 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:47,104 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154 ELECTION round 0: submit vote requests at term 1 for -1: peers:[52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,104 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:47,104 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 52a46685-3070-4024-834b-c3445a236f70: shutdown 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154
2023-03-20 21:34:47,104 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:47,104 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-BE3927FEFB6A with new leaderId: 52a46685-3070-4024-834b-c3445a236f70
2023-03-20 21:34:47,104 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A: change Leader from null to 52a46685-3070-4024-834b-c3445a236f70 at term 1 for becomeLeader, leader elected after 5166ms
2023-03-20 21:34:47,104 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:47,105 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:47,105 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:47,105 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:47,105 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:47,105 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:47,105 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:47,105 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:47,105 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:47,105 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 52a46685-3070-4024-834b-c3445a236f70: start 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderStateImpl
2023-03-20 21:34:47,106 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:47,107 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/e910e24a-6d72-480a-9a70-be3927fefb6a/current/log_inprogress_0
2023-03-20 21:34:47,108 [52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A-LeaderElection154] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 52a46685-3070-4024-834b-c3445a236f70@group-BE3927FEFB6A: set configuration 0: peers:[52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,114 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5104286498ns, electionTimeout:5097ms
2023-03-20 21:34:47,114 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e5cc6624-b71a-402d-a69e-29759be12af7: shutdown e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState
2023-03-20 21:34:47,114 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:47,114 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:47,114 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5cc6624-b71a-402d-a69e-29759be12af7: start e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155
2023-03-20 21:34:47,114 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,115 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 79924adf-68a9-4348-9386-442656259f82
2023-03-20 21:34:47,115 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:47,115 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:47,115 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 52a46685-3070-4024-834b-c3445a236f70
2023-03-20 21:34:47,119 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062: receive requestVote(PRE_VOTE, e5cc6624-b71a-402d-a69e-29759be12af7, group-D21AA782C062, 0, (t:0, i:0))
2023-03-20 21:34:47,119 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FOLLOWER: accept PRE_VOTE from e5cc6624-b71a-402d-a69e-29759be12af7: our priority 0 <= candidate's priority 1
2023-03-20 21:34:47,119 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062 replies to PRE_VOTE vote request: e5cc6624-b71a-402d-a69e-29759be12af7<-79924adf-68a9-4348-9386-442656259f82#0:OK-t0. Peer's state: 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062:t0, leader=null, voted=, raftlog=Memoized:79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,119 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: receive requestVote(PRE_VOTE, e5cc6624-b71a-402d-a69e-29759be12af7, group-D21AA782C062, 0, (t:0, i:0))
2023-03-20 21:34:47,119 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FOLLOWER: accept PRE_VOTE from e5cc6624-b71a-402d-a69e-29759be12af7: our priority 0 <= candidate's priority 1
2023-03-20 21:34:47,119 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062 replies to PRE_VOTE vote request: e5cc6624-b71a-402d-a69e-29759be12af7<-52a46685-3070-4024-834b-c3445a236f70#0:OK-t0. Peer's state: 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062:t0, leader=null, voted=, raftlog=Memoized:52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,124 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:47,124 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: e5cc6624-b71a-402d-a69e-29759be12af7<-79924adf-68a9-4348-9386-442656259f82#0:OK-t0
2023-03-20 21:34:47,124 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155 PRE_VOTE round 0: result PASSED
2023-03-20 21:34:47,125 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155 ELECTION round 0: submit vote requests at term 1 for -1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,126 [79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:47,126 [79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:47,131 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:47,131 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:47,131 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062: receive requestVote(ELECTION, e5cc6624-b71a-402d-a69e-29759be12af7, group-D21AA782C062, 1, (t:0, i:0))
2023-03-20 21:34:47,131 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FOLLOWER: accept ELECTION from e5cc6624-b71a-402d-a69e-29759be12af7: our priority 0 <= candidate's priority 1
2023-03-20 21:34:47,131 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:47,131 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 79924adf-68a9-4348-9386-442656259f82: shutdown 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState
2023-03-20 21:34:47,131 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 79924adf-68a9-4348-9386-442656259f82: start 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState
2023-03-20 21:34:47,131 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: receive requestVote(ELECTION, e5cc6624-b71a-402d-a69e-29759be12af7, group-D21AA782C062, 1, (t:0, i:0))
2023-03-20 21:34:47,131 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FOLLOWER: accept ELECTION from e5cc6624-b71a-402d-a69e-29759be12af7: our priority 0 <= candidate's priority 1
2023-03-20 21:34:47,131 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:47,131 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 52a46685-3070-4024-834b-c3445a236f70: shutdown 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState
2023-03-20 21:34:47,131 [79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState was interrupted
2023-03-20 21:34:47,134 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 52a46685-3070-4024-834b-c3445a236f70: start 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState
2023-03-20 21:34:47,134 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState was interrupted
2023-03-20 21:34:47,134 [79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:47,134 [79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:47,134 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:47,134 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:47,135 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062 replies to ELECTION vote request: e5cc6624-b71a-402d-a69e-29759be12af7<-79924adf-68a9-4348-9386-442656259f82#0:OK-t1. Peer's state: 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062:t1, leader=null, voted=e5cc6624-b71a-402d-a69e-29759be12af7, raftlog=Memoized:79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,135 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062 replies to ELECTION vote request: e5cc6624-b71a-402d-a69e-29759be12af7<-52a46685-3070-4024-834b-c3445a236f70#0:OK-t1. Peer's state: 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062:t1, leader=null, voted=e5cc6624-b71a-402d-a69e-29759be12af7, raftlog=Memoized:52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,135 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:47,135 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: e5cc6624-b71a-402d-a69e-29759be12af7<-52a46685-3070-4024-834b-c3445a236f70#0:OK-t1
2023-03-20 21:34:47,135 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155 ELECTION round 0: result PASSED
2023-03-20 21:34:47,135 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - e5cc6624-b71a-402d-a69e-29759be12af7: shutdown e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155
2023-03-20 21:34:47,135 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:47,135 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-D21AA782C062 with new leaderId: e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:47,136 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062: change Leader from null to e5cc6624-b71a-402d-a69e-29759be12af7 at term 1 for becomeLeader, leader elected after 5135ms
2023-03-20 21:34:47,136 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:47,136 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:47,136 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:47,136 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 46f08bba-1415-40e8-8a77-d21aa782c062, Nodes: 79924adf-68a9-4348-9386-442656259f82(fv-az985-449/10.1.0.10)52a46685-3070-4024-834b-c3445a236f70(fv-az985-449/10.1.0.10)e5cc6624-b71a-402d-a69e-29759be12af7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:e5cc6624-b71a-402d-a69e-29759be12af7, CreationTimestamp2023-03-20T21:34:39.651Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:47,136 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1175)) - Service ReplicationManager transitions to RUNNING.
2023-03-20 21:34:47,137 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-20 21:34:47,137 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:47,137 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:47,137 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:47,137 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:47,137 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:47,138 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:47,138 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:47,138 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:47,138 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:47,138 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:47,138 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:47,138 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:47,138 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5cc6624-b71a-402d-a69e-29759be12af7: start e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderStateImpl
2023-03-20 21:34:47,139 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:47,140 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062/current/log_inprogress_0
2023-03-20 21:34:47,152 [e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062-LeaderElection155] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-D21AA782C062: set configuration 0: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,156 [79924adf-68a9-4348-9386-442656259f82-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-D21AA782C062 with new leaderId: e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:47,156 [79924adf-68a9-4348-9386-442656259f82-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062: change Leader from null to e5cc6624-b71a-402d-a69e-29759be12af7 at term 1 for appendEntries, leader elected after 5180ms
2023-03-20 21:34:47,157 [52a46685-3070-4024-834b-c3445a236f70-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-D21AA782C062 with new leaderId: e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:47,157 [52a46685-3070-4024-834b-c3445a236f70-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: change Leader from null to e5cc6624-b71a-402d-a69e-29759be12af7 at term 1 for appendEntries, leader elected after 5199ms
2023-03-20 21:34:47,160 [79924adf-68a9-4348-9386-442656259f82-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062: set configuration 0: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,160 [79924adf-68a9-4348-9386-442656259f82-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:47,161 [52a46685-3070-4024-834b-c3445a236f70-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062: set configuration 0: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:0|startupRole:FOLLOWER, e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER, 52a46685-3070-4024-834b-c3445a236f70|rpc:10.1.0.10:33541|dataStream:10.1.0.10:40357|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,161 [52a46685-3070-4024-834b-c3445a236f70-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:47,161 [79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 79924adf-68a9-4348-9386-442656259f82@group-D21AA782C062-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062/current/log_inprogress_0
2023-03-20 21:34:47,164 [52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 52a46685-3070-4024-834b-c3445a236f70@group-D21AA782C062-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-0/data/ratis/46f08bba-1415-40e8-8a77-d21aa782c062/current/log_inprogress_0
2023-03-20 21:34:47,297 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5018361087ns, electionTimeout:5018ms
2023-03-20 21:34:47,297 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 79924adf-68a9-4348-9386-442656259f82: shutdown 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState
2023-03-20 21:34:47,297 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:47,297 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:47,297 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 79924adf-68a9-4348-9386-442656259f82: start 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156
2023-03-20 21:34:47,298 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,298 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:47,299 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156 ELECTION round 0: submit vote requests at term 1 for -1: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,299 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:47,299 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 79924adf-68a9-4348-9386-442656259f82: shutdown 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156
2023-03-20 21:34:47,299 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:47,299 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-BA594E114897 with new leaderId: 79924adf-68a9-4348-9386-442656259f82
2023-03-20 21:34:47,299 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897: change Leader from null to 79924adf-68a9-4348-9386-442656259f82 at term 1 for becomeLeader, leader elected after 5029ms
2023-03-20 21:34:47,299 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:47,300 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:47,300 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:47,300 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:47,300 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:47,300 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:47,300 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:47,300 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:47,300 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 79924adf-68a9-4348-9386-442656259f82: start 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderStateImpl
2023-03-20 21:34:47,300 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:47,301 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-LeaderElection156] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897: set configuration 0: peers:[79924adf-68a9-4348-9386-442656259f82|rpc:10.1.0.10:42555|dataStream:10.1.0.10:43049|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,301 [79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 79924adf-68a9-4348-9386-442656259f82@group-BA594E114897-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-1/data/ratis/7974330e-eed0-46af-a7aa-ba594e114897/current/log_inprogress_0
2023-03-20 21:34:47,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:47,465 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 1226cf83-b1fd-416f-9846-61bdfa3ff6b3(fv-az985-449/10.1.0.10)
2023-03-20 21:34:47,465 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/1226cf83-b1fd-416f-9846-61bdfa3ff6b3
2023-03-20 21:34:47,489 [Listener at 0.0.0.0/42371] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(356)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-03-20 21:34:47,490 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1537)) - Container Balancer is not running.
2023-03-20 21:34:47,490 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1544)) - Stopping Replication Manager Service.
2023-03-20 21:34:47,490 [Listener at 0.0.0.0/42371] INFO  replication.ReplicationManager (ReplicationManager.java:stop(306)) - Stopping Replication Monitor Thread.
2023-03-20 21:34:47,490 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1551)) - Stopping the Datanode Admin Monitor.
2023-03-20 21:34:47,490 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Under Replicated Processor interrupted. Exiting...
2023-03-20 21:34:47,490 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1558)) - Stopping datanode service RPC server
2023-03-20 21:34:47,490 [Listener at 0.0.0.0/42371] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-03-20 21:34:47,490 [Listener at 0.0.0.0/42371] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42601
2023-03-20 21:34:47,490 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Over Replicated Processor interrupted. Exiting...
2023-03-20 21:34:47,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(818)) - Replication Monitor Thread is stopped
2023-03-20 21:34:47,493 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:34:47,494 [IPC Server listener on 42601] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 42601
2023-03-20 21:34:47,565 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-03-20 21:34:47,565 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1566)) - Stopping block service RPC server
2023-03-20 21:34:47,565 [Listener at 0.0.0.0/42371] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-03-20 21:34:47,565 [Listener at 0.0.0.0/42371] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 33765
2023-03-20 21:34:47,568 [IPC Server listener on 33765] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 33765
2023-03-20 21:34:47,568 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1573)) - Stopping the StorageContainerLocationProtocol RPC server
2023-03-20 21:34:47,569 [Listener at 0.0.0.0/42371] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(203)) - Stopping the RPC server for Client Protocol
2023-03-20 21:34:47,569 [Listener at 0.0.0.0/42371] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42371
2023-03-20 21:34:47,569 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:34:47,571 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:34:47,571 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1580)) - Stopping Storage Container Manager HTTP server.
2023-03-20 21:34:47,571 [IPC Server listener on 42371] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 42371
2023-03-20 21:34:47,573 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@426753a6{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-20 21:34:47,574 [Listener at 0.0.0.0/42371] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5bee88e3{HTTP/1.1, (http/1.1)}{0.0.0.0:38151}
2023-03-20 21:34:47,574 [Listener at 0.0.0.0/42371] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:47,574 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4734a551{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-20 21:34:47,574 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@57404a8d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:47,575 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1588)) - Stopping SCM LayoutVersionManager Service.
2023-03-20 21:34:47,575 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1596)) - Stopping Block Manager Service.
2023-03-20 21:34:47,575 [Listener at 0.0.0.0/42371] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-20 21:34:47,575 [Listener at 0.0.0.0/42371] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-20 21:34:47,575 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1618)) - Stopping SCM Event Queue.
2023-03-20 21:34:47,578 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1629)) - Stopping SCM HA services.
2023-03-20 21:34:47,578 [Listener at 0.0.0.0/42371] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-03-20 21:34:47,579 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-03-20 21:34:47,579 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-03-20 21:34:47,579 [Listener at 0.0.0.0/42371] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-03-20 21:34:47,579 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2023-03-20 21:34:47,584 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-03-20 21:34:47,584 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2023-03-20 21:34:47,584 [Listener at 0.0.0.0/42371] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-03-20 21:34:47,584 [Listener at 0.0.0.0/42371] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-03-20 21:34:47,584 [Listener at 0.0.0.0/42371] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-03-20 21:34:47,584 [Listener at 0.0.0.0/42371] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-20 21:34:47,584 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-03-20 21:34:47,585 [Listener at 0.0.0.0/42371] INFO  replication.ReplicationManager (ReplicationManager.java:stop(316)) - Replication Monitor Thread is not running.
2023-03-20 21:34:47,585 [Listener at 0.0.0.0/42371] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-03-20 21:34:47,585 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1647)) - Stopping SCM MetadataStore.
2023-03-20 21:34:47,586 [Listener at 0.0.0.0/42371] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:47,586 [Listener at 0.0.0.0/42371] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-20 21:34:47,586 [Listener at 0.0.0.0/42371] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-20 21:34:47,587 [Listener at 0.0.0.0/42371] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:47,587 [Listener at 0.0.0.0/42371] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:47,609 [Listener at 0.0.0.0/42371] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-20 21:34:47,609 [Listener at 0.0.0.0/42371] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-20 21:34:47,611 [Listener at 0.0.0.0/42371] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:47,666 [Listener at 0.0.0.0/42371] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 47 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:47,668 [Listener at 0.0.0.0/42371] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-20 21:34:47,668 [Listener at 0.0.0.0/42371] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-20 21:34:47,668 [Listener at 0.0.0.0/42371] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-20 21:34:47,669 [Listener at 0.0.0.0/42371] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:47,669 [Listener at 0.0.0.0/42371] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-20 21:34:47,669 [Listener at 0.0.0.0/42371] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:47,669 [Listener at 0.0.0.0/42371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-20 21:34:47,670 [Listener at 0.0.0.0/42371] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-20 21:34:47,670 [Listener at 0.0.0.0/42371] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-20 21:34:47,670 [Listener at 0.0.0.0/42371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-20 21:34:47,670 [Listener at 0.0.0.0/42371] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-20 21:34:47,670 [Listener at 0.0.0.0/42371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-20 21:34:47,672 [Listener at 0.0.0.0/42371] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-20 21:34:47,672 [Listener at 0.0.0.0/42371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-20 21:34:47,672 [Listener at 0.0.0.0/42371] INFO  replication.ReplicationManager (ReplicationManager.java:start(273)) - Starting Replication Monitor Thread.
2023-03-20 21:34:47,678 [Listener at 0.0.0.0/42371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-20 21:34:47,681 [Listener at 0.0.0.0/42371] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-03-20 21:34:47,681 [Listener at 0.0.0.0/42371] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 2, healthy pipeline threshold count is 1
2023-03-20 21:34:47,682 [Listener at 0.0.0.0/42371] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2023-03-20 21:34:47,682 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(395)) - SCM start with adminUsers: [runner]
2023-03-20 21:34:47,682 [Listener at 0.0.0.0/42371] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:47,683 [Socket Reader #1 for port 42601] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 42601
2023-03-20 21:34:47,683 [Listener at 0.0.0.0/42601] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:47,683 [Socket Reader #1 for port 33765] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 33765
2023-03-20 21:34:47,684 [Listener at 0.0.0.0/33765] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:47,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:47,684 [Socket Reader #1 for port 42371] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 42371
2023-03-20 21:34:47,689 [Listener at 0.0.0.0/42371] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-20 21:34:47,689 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(412)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-20 21:34:47,689 [Listener at 0.0.0.0/42371] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-20 21:34:47,689 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1442)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42371
2023-03-20 21:34:47,691 [Listener at 0.0.0.0/42371] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-03-20 21:34:47,700 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-03-20 21:34:47,700 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-03-20 21:34:47,711 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-03-20 21:34:47,711 [Listener at 0.0.0.0/42371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-03-20 21:34:47,736 [Listener at 0.0.0.0/42371] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(194)) - RPC server for Client  is listening at /0.0.0.0:42371
2023-03-20 21:34:47,737 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:47,737 [IPC Server listener on 42371] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 42371: starting
2023-03-20 21:34:47,740 [Listener at 0.0.0.0/42371] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1456)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33765
2023-03-20 21:34:47,740 [Listener at 0.0.0.0/42371] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:33765
2023-03-20 21:34:47,740 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:47,740 [IPC Server listener on 33765] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 33765: starting
2023-03-20 21:34:47,750 [Listener at 0.0.0.0/42371] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:42601
2023-03-20 21:34:47,753 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5093017042ns, electionTimeout:5090ms
2023-03-20 21:34:47,753 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e5cc6624-b71a-402d-a69e-29759be12af7: shutdown e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState
2023-03-20 21:34:47,753 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:47,754 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:47,754 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:47,754 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5cc6624-b71a-402d-a69e-29759be12af7: start e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157
2023-03-20 21:34:47,754 [IPC Server listener on 42601] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 42601: starting
2023-03-20 21:34:47,759 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@20ee12d8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:47,759 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:38151
2023-03-20 21:34:47,761 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:47,765 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,765 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:47,765 [Listener at 0.0.0.0/42371] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:47,766 [Listener at 0.0.0.0/42371] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:47,766 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157 ELECTION round 0: submit vote requests at term 1 for -1: peers:[e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,766 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:47,766 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - e5cc6624-b71a-402d-a69e-29759be12af7: shutdown e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157
2023-03-20 21:34:47,766 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:47,766 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:47,766 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-AC1DF4A4BC78 with new leaderId: e5cc6624-b71a-402d-a69e-29759be12af7
2023-03-20 21:34:47,767 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-20 21:34:47,767 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:47,767 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:47,767 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78: change Leader from null to e5cc6624-b71a-402d-a69e-29759be12af7 at term 1 for becomeLeader, leader elected after 5117ms
2023-03-20 21:34:47,767 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:47,768 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:47,768 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/ozone-meta/webserver
2023-03-20 21:34:47,768 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:47,768 [Listener at 0.0.0.0/42371] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 38151
2023-03-20 21:34:47,768 [Listener at 0.0.0.0/42371] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:47,768 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:47,768 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:47,768 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:47,768 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:47,768 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:47,768 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e5cc6624-b71a-402d-a69e-29759be12af7: start e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderStateImpl
2023-03-20 21:34:47,768 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:47,769 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-LeaderElection157] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78: set configuration 0: peers:[e5cc6624-b71a-402d-a69e-29759be12af7|rpc:10.1.0.10:44593|dataStream:10.1.0.10:44975|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:47,769 [e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - e5cc6624-b71a-402d-a69e-29759be12af7@group-AC1DF4A4BC78-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-2/data/ratis/d5324a2d-e604-4092-a161-ac1df4a4bc78/current/log_inprogress_0
2023-03-20 21:34:47,770 [Listener at 0.0.0.0/42371] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:47,770 [Listener at 0.0.0.0/42371] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:47,776 [Listener at 0.0.0.0/42371] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:47,776 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@58d85a00{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:47,776 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5c26ab0a{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-20 21:34:47,778 [Listener at 0.0.0.0/42371] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4f283b8f{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-20 21:34:47,780 [Listener at 0.0.0.0/42371] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6a275836{HTTP/1.1, (http/1.1)}{0.0.0.0:38151}
2023-03-20 21:34:47,780 [Listener at 0.0.0.0/42371] INFO  server.Server (Server.java:doStart(415)) - Started @389049ms
2023-03-20 21:34:47,780 [Listener at 0.0.0.0/42371] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:47,781 [Listener at 0.0.0.0/42371] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:38151
2023-03-20 21:34:47,855 [EndpointStateMachine task thread for /0.0.0.0:42601 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:42601 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az985-449/10.1.0.10"; destination host is: "0.0.0.0":42601; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy56.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-03-20 21:34:47,872 [IPC Server handler 0 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:47,957 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-20 21:34:47,957 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Cluster exits safe mode
2023-03-20 21:34:47,957 [Listener at 127.0.0.1/38731] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:47,959 [Listener at 127.0.0.1/38731] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:47,963 [Listener at 127.0.0.1/38731] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:47,963 [Listener at 127.0.0.1/38731] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-20 21:34:47,963 [Listener at 127.0.0.1/38731] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-20 21:34:47,963 [Listener at 127.0.0.1/38731] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:47,963 [Listener at 127.0.0.1/38731] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:47,964 [IPC Server handler 1 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:48,054 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5040358753ns, electionTimeout:5040ms
2023-03-20 21:34:48,054 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2325b755-97f4-4680-bb9e-067434f11ceb: shutdown 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState
2023-03-20 21:34:48,054 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:48,054 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:48,054 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2325b755-97f4-4680-bb9e-067434f11ceb: start 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158
2023-03-20 21:34:48,055 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,056 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:48,056 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5072967680ns, electionTimeout:5072ms
2023-03-20 21:34:48,056 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: shutdown 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState
2023-03-20 21:34:48,056 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:48,057 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5020399682ns, electionTimeout:5020ms
2023-03-20 21:34:48,057 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: shutdown a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState
2023-03-20 21:34:48,057 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:48,059 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:48,059 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:48,059 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: start 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159
2023-03-20 21:34:48,059 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:48,059 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: start a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160
2023-03-20 21:34:48,059 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:48,061 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for a416fcbf-d3db-4cde-9623-07e05d2a4f7f
2023-03-20 21:34:48,061 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006: receive requestVote(PRE_VOTE, 2325b755-97f4-4680-bb9e-067434f11ceb, group-312FD93C9006, 0, (t:0, i:0))
2023-03-20 21:34:48,061 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FOLLOWER: reject PRE_VOTE from 2325b755-97f4-4680-bb9e-067434f11ceb: our priority 1 > candidate's priority 0
2023-03-20 21:34:48,061 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006 replies to PRE_VOTE vote request: 2325b755-97f4-4680-bb9e-067434f11ceb<-05384c5d-9495-4201-8a60-c8c72abd74fb#0:FAIL-t0. Peer's state: 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006:t0, leader=null, voted=, raftlog=Memoized:05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,065 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: receive requestVote(PRE_VOTE, 2325b755-97f4-4680-bb9e-067434f11ceb, group-312FD93C9006, 0, (t:0, i:0))
2023-03-20 21:34:48,066 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:48,066 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 2325b755-97f4-4680-bb9e-067434f11ceb<-05384c5d-9495-4201-8a60-c8c72abd74fb#0:FAIL-t0
2023-03-20 21:34:48,066 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158 PRE_VOTE round 0: result REJECTED
2023-03-20 21:34:48,066 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:34:48,066 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 2325b755-97f4-4680-bb9e-067434f11ceb: shutdown 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158
2023-03-20 21:34:48,066 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-LeaderElection158] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2325b755-97f4-4680-bb9e-067434f11ceb: start 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState
2023-03-20 21:34:48,066 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,066 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:48,066 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-CANDIDATE: accept PRE_VOTE from 2325b755-97f4-4680-bb9e-067434f11ceb: our priority 0 <= candidate's priority 0
2023-03-20 21:34:48,066 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006 replies to PRE_VOTE vote request: 2325b755-97f4-4680-bb9e-067434f11ceb<-a416fcbf-d3db-4cde-9623-07e05d2a4f7f#0:OK-t0. Peer's state: a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006:t0, leader=null, voted=, raftlog=Memoized:a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,068 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,068 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159 ELECTION round 0: submit vote requests at term 1 for -1: peers:[05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,068 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:48,068 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:48,068 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:48,069 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: shutdown 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159
2023-03-20 21:34:48,069 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:48,069 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-5A5C429D75E5 with new leaderId: 05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:48,070 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5: change Leader from null to 05384c5d-9495-4201-8a60-c8c72abd74fb at term 1 for becomeLeader, leader elected after 5094ms
2023-03-20 21:34:48,070 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:48,070 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:48,070 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:48,070 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:48,070 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:48,070 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:48,070 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:48,070 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:48,071 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: start 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderStateImpl
2023-03-20 21:34:48,071 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:48,071 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-LeaderElection159] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5: set configuration 0: peers:[05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,072 [Listener at 127.0.0.1/38731] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-20 21:34:48,072 [Listener at 127.0.0.1/38731] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-20 21:34:48,076 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:48,076 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:48,076 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:48,077 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-5A5C429D75E5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/12545f98-2564-4b6f-bb8b-5a5c429d75e5/current/log_inprogress_0
2023-03-20 21:34:48,082 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:48,082 [Listener at 127.0.0.1/38731] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:48,082 [Listener at 127.0.0.1/38731] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:48,087 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006: receive requestVote(PRE_VOTE, a416fcbf-d3db-4cde-9623-07e05d2a4f7f, group-312FD93C9006, 0, (t:0, i:0))
2023-03-20 21:34:48,087 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FOLLOWER: reject PRE_VOTE from a416fcbf-d3db-4cde-9623-07e05d2a4f7f: our priority 1 > candidate's priority 0
2023-03-20 21:34:48,087 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006 replies to PRE_VOTE vote request: a416fcbf-d3db-4cde-9623-07e05d2a4f7f<-05384c5d-9495-4201-8a60-c8c72abd74fb#0:FAIL-t0. Peer's state: 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006:t0, leader=null, voted=, raftlog=Memoized:05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,087 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:48,087 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: a416fcbf-d3db-4cde-9623-07e05d2a4f7f<-05384c5d-9495-4201-8a60-c8c72abd74fb#0:FAIL-t0
2023-03-20 21:34:48,087 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160 PRE_VOTE round 0: result REJECTED
2023-03-20 21:34:48,087 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:34:48,087 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: shutdown a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160
2023-03-20 21:34:48,087 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: start a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState
2023-03-20 21:34:48,088 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-LeaderElection160-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 2325b755-97f4-4680-bb9e-067434f11ceb
2023-03-20 21:34:48,091 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:48,091 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:48,093 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: receive requestVote(PRE_VOTE, a416fcbf-d3db-4cde-9623-07e05d2a4f7f, group-312FD93C9006, 0, (t:0, i:0))
2023-03-20 21:34:48,093 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FOLLOWER: accept PRE_VOTE from a416fcbf-d3db-4cde-9623-07e05d2a4f7f: our priority 0 <= candidate's priority 0
2023-03-20 21:34:48,093 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006 replies to PRE_VOTE vote request: a416fcbf-d3db-4cde-9623-07e05d2a4f7f<-2325b755-97f4-4680-bb9e-067434f11ceb#0:OK-t0. Peer's state: 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006:t0, leader=null, voted=, raftlog=Memoized:2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,121 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5124442591ns, electionTimeout:5124ms
2023-03-20 21:34:48,121 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: shutdown 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState
2023-03-20 21:34:48,121 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:48,121 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:48,121 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: start 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161
2023-03-20 21:34:48,122 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,122 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 2325b755-97f4-4680-bb9e-067434f11ceb
2023-03-20 21:34:48,126 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: receive requestVote(PRE_VOTE, 05384c5d-9495-4201-8a60-c8c72abd74fb, group-312FD93C9006, 0, (t:0, i:0))
2023-03-20 21:34:48,126 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FOLLOWER: accept PRE_VOTE from 05384c5d-9495-4201-8a60-c8c72abd74fb: our priority 0 <= candidate's priority 1
2023-03-20 21:34:48,126 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006 replies to PRE_VOTE vote request: 05384c5d-9495-4201-8a60-c8c72abd74fb<-2325b755-97f4-4680-bb9e-067434f11ceb#0:OK-t0. Peer's state: 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006:t0, leader=null, voted=, raftlog=Memoized:2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,127 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:48,127 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:48,127 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:48,127 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 05384c5d-9495-4201-8a60-c8c72abd74fb<-2325b755-97f4-4680-bb9e-067434f11ceb#0:OK-t0
2023-03-20 21:34:48,127 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161 PRE_VOTE round 0: result PASSED
2023-03-20 21:34:48,127 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for a416fcbf-d3db-4cde-9623-07e05d2a4f7f
2023-03-20 21:34:48,128 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161 ELECTION round 0: submit vote requests at term 1 for -1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,129 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: receive requestVote(ELECTION, 05384c5d-9495-4201-8a60-c8c72abd74fb, group-312FD93C9006, 1, (t:0, i:0))
2023-03-20 21:34:48,129 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FOLLOWER: accept ELECTION from 05384c5d-9495-4201-8a60-c8c72abd74fb: our priority 0 <= candidate's priority 1
2023-03-20 21:34:48,129 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:48,129 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2325b755-97f4-4680-bb9e-067434f11ceb: shutdown 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState
2023-03-20 21:34:48,133 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:48,133 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:48,135 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2325b755-97f4-4680-bb9e-067434f11ceb: start 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState
2023-03-20 21:34:48,135 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState was interrupted
2023-03-20 21:34:48,142 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: receive requestVote(PRE_VOTE, 05384c5d-9495-4201-8a60-c8c72abd74fb, group-312FD93C9006, 0, (t:0, i:0))
2023-03-20 21:34:48,143 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FOLLOWER: accept PRE_VOTE from 05384c5d-9495-4201-8a60-c8c72abd74fb: our priority 0 <= candidate's priority 1
2023-03-20 21:34:48,143 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006 replies to PRE_VOTE vote request: 05384c5d-9495-4201-8a60-c8c72abd74fb<-a416fcbf-d3db-4cde-9623-07e05d2a4f7f#0:OK-t0. Peer's state: a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006:t0, leader=null, voted=, raftlog=Memoized:a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,143 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: receive requestVote(ELECTION, 05384c5d-9495-4201-8a60-c8c72abd74fb, group-312FD93C9006, 1, (t:0, i:0))
2023-03-20 21:34:48,143 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FOLLOWER: accept ELECTION from 05384c5d-9495-4201-8a60-c8c72abd74fb: our priority 0 <= candidate's priority 1
2023-03-20 21:34:48,143 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:48,143 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: shutdown a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState
2023-03-20 21:34:48,143 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: start a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState
2023-03-20 21:34:48,143 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState was interrupted
2023-03-20 21:34:48,143 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:48,144 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:48,144 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006 replies to ELECTION vote request: 05384c5d-9495-4201-8a60-c8c72abd74fb<-2325b755-97f4-4680-bb9e-067434f11ceb#0:OK-t1. Peer's state: 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006:t1, leader=null, voted=05384c5d-9495-4201-8a60-c8c72abd74fb, raftlog=Memoized:2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,144 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:48,144 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-20 21:34:48,144 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 05384c5d-9495-4201-8a60-c8c72abd74fb<-2325b755-97f4-4680-bb9e-067434f11ceb#0:OK-t1
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161 ELECTION round 0: result PASSED
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: shutdown 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-312FD93C9006 with new leaderId: 05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006: change Leader from null to 05384c5d-9495-4201-8a60-c8c72abd74fb at term 1 for becomeLeader, leader elected after 5157ms
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:48,145 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:48,146 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:48,146 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:48,146 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:48,146 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:48,146 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:48,146 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:48,146 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:48,146 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 05384c5d-9495-4201-8a60-c8c72abd74fb: start 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderStateImpl
2023-03-20 21:34:48,147 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:48,144 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006 replies to ELECTION vote request: 05384c5d-9495-4201-8a60-c8c72abd74fb<-a416fcbf-d3db-4cde-9623-07e05d2a4f7f#0:OK-t1. Peer's state: a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006:t1, leader=null, voted=05384c5d-9495-4201-8a60-c8c72abd74fb, raftlog=Memoized:a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,148 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:48,148 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 3398bf8a-4c2c-4f6c-985d-312fd93c9006, Nodes: 2325b755-97f4-4680-bb9e-067434f11ceb(fv-az985-449/10.1.0.10)05384c5d-9495-4201-8a60-c8c72abd74fb(fv-az985-449/10.1.0.10)a416fcbf-d3db-4cde-9623-07e05d2a4f7f(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:05384c5d-9495-4201-8a60-c8c72abd74fb, CreationTimestamp2023-03-20T21:34:40.660Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:48,149 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-3/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006/current/log_inprogress_0
2023-03-20 21:34:48,149 [05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006-LeaderElection161] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 05384c5d-9495-4201-8a60-c8c72abd74fb@group-312FD93C9006: set configuration 0: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,151 [Listener at 127.0.0.1/38731] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 68 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:48,156 [Listener at 127.0.0.1/38731] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(349)) - upgrade localId to 111677748019200000
2023-03-20 21:34:48,156 [Listener at 127.0.0.1/38731] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(359)) - upgrade delTxnId to 0
2023-03-20 21:34:48,156 [Listener at 127.0.0.1/38731] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(376)) - upgrade containerId to 0
2023-03-20 21:34:48,156 [Listener at 127.0.0.1/38731] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-20 21:34:48,160 [2325b755-97f4-4680-bb9e-067434f11ceb-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-312FD93C9006 with new leaderId: 05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:48,160 [2325b755-97f4-4680-bb9e-067434f11ceb-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: change Leader from null to 05384c5d-9495-4201-8a60-c8c72abd74fb at term 1 for appendEntries, leader elected after 5156ms
2023-03-20 21:34:48,160 [2325b755-97f4-4680-bb9e-067434f11ceb-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006: set configuration 0: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,160 [2325b755-97f4-4680-bb9e-067434f11ceb-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:48,162 [2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-312FD93C9006-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006/current/log_inprogress_0
2023-03-20 21:34:48,163 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-312FD93C9006 with new leaderId: 05384c5d-9495-4201-8a60-c8c72abd74fb
2023-03-20 21:34:48,163 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: change Leader from null to 05384c5d-9495-4201-8a60-c8c72abd74fb at term 1 for appendEntries, leader elected after 5135ms
2023-03-20 21:34:48,164 [Listener at 127.0.0.1/38731] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-20 21:34:48,164 [Listener at 127.0.0.1/38731] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-20 21:34:48,165 [Listener at 127.0.0.1/38731] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-20 21:34:48,167 [Listener at 127.0.0.1/38731] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-20 21:34:48,168 [Listener at 127.0.0.1/38731] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-20 21:34:48,173 [Listener at 127.0.0.1/38731] INFO  replication.ReplicationManager (ReplicationManager.java:start(273)) - Starting Replication Monitor Thread.
2023-03-20 21:34:48,175 [Listener at 127.0.0.1/38731] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-20 21:34:48,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:48,175 [Listener at 127.0.0.1/38731] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2023-03-20 21:34:48,175 [Listener at 127.0.0.1/38731] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2023-03-20 21:34:48,175 [Listener at 127.0.0.1/38731] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-03-20 21:34:48,175 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006: set configuration 0: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:0|startupRole:FOLLOWER, 05384c5d-9495-4201-8a60-c8c72abd74fb|rpc:10.1.0.10:41855|dataStream:10.1.0.10:34701|priority:1|startupRole:FOLLOWER, a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,176 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:48,176 [Listener at 127.0.0.1/38731] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(395)) - SCM start with adminUsers: [runner]
2023-03-20 21:34:48,176 [Listener at 127.0.0.1/38731] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:48,176 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:48,177 [Listener at 0.0.0.0/42017] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:48,178 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:48,182 [Listener at 0.0.0.0/36331] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:48,182 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:48,186 [Listener at 0.0.0.0/45115] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-20 21:34:48,186 [Listener at 0.0.0.0/45115] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(412)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-20 21:34:48,186 [Listener at 0.0.0.0/45115] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-20 21:34:48,186 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-312FD93C9006-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/3398bf8a-4c2c-4f6c-985d-312fd93c9006/current/log_inprogress_0
2023-03-20 21:34:48,187 [Listener at 0.0.0.0/45115] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1442)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:45115
2023-03-20 21:34:48,187 [Listener at 0.0.0.0/45115] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2023-03-20 21:34:48,198 [Listener at 0.0.0.0/45115] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(194)) - RPC server for Client  is listening at /0.0.0.0:45115
2023-03-20 21:34:48,198 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:48,198 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:48,202 [Listener at 0.0.0.0/45115] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1456)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:36331
2023-03-20 21:34:48,202 [Listener at 0.0.0.0/45115] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:36331
2023-03-20 21:34:48,204 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:48,204 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:48,206 [Listener at 0.0.0.0/45115] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:42017
2023-03-20 21:34:48,206 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:48,206 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:48,216 [Listener at 0.0.0.0/45115] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:0
2023-03-20 21:34:48,216 [Listener at 0.0.0.0/45115] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:48,217 [Listener at 0.0.0.0/45115] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:48,217 [Listener at 0.0.0.0/45115] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:48,218 [Listener at 0.0.0.0/45115] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:48,218 [Listener at 0.0.0.0/45115] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-20 21:34:48,218 [Listener at 0.0.0.0/45115] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:48,218 [Listener at 0.0.0.0/45115] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:48,219 [Listener at 0.0.0.0/45115] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/ozone-meta/webserver
2023-03-20 21:34:48,219 [Listener at 0.0.0.0/45115] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 42827
2023-03-20 21:34:48,219 [Listener at 0.0.0.0/45115] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:48,220 [Listener at 0.0.0.0/45115] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:48,220 [Listener at 0.0.0.0/45115] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:48,220 [Listener at 0.0.0.0/45115] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:48,220 [Listener at 0.0.0.0/45115] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6f09703a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:48,221 [Listener at 0.0.0.0/45115] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@b1fbab1{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-20 21:34:48,222 [Listener at 0.0.0.0/45115] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3fc26a88{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-20 21:34:48,222 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@47efb1f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:48,225 [Listener at 0.0.0.0/45115] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4fbfea92{HTTP/1.1, (http/1.1)}{0.0.0.0:42827}
2023-03-20 21:34:48,225 [Listener at 0.0.0.0/45115] INFO  server.Server (Server.java:doStart(415)) - Started @389494ms
2023-03-20 21:34:48,225 [Listener at 0.0.0.0/45115] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:48,225 [Listener at 0.0.0.0/45115] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:42827
2023-03-20 21:34:48,225 [Listener at 0.0.0.0/45115] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:48,227 [Listener at 0.0.0.0/45115] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-03-20 21:34:48,227 [Listener at 0.0.0.0/45115] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2023-03-20 21:34:48,227 [Listener at 0.0.0.0/45115] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-03-20 21:34:48,227 [Listener at 0.0.0.0/45115] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2023-03-20 21:34:48,227 [Listener at 0.0.0.0/45115] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:48,228 [Listener at 0.0.0.0/45115] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2023-03-20 21:34:48,296 [Listener at 0.0.0.0/45115] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 66 ms to scan 2 urls, producing 167 keys and 463 values [using 2 cores]
2023-03-20 21:34:48,296 [Listener at 0.0.0.0/45115] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2023-03-20 21:34:48,296 [Listener at 0.0.0.0/45115] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:48,296 [Listener at 0.0.0.0/45115] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:36331]
2023-03-20 21:34:48,297 [Listener at 0.0.0.0/45115] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:36331]
2023-03-20 21:34:48,306 [Listener at 0.0.0.0/45115] INFO  om.OzoneManager (OzoneManager.java:<init>(620)) - OM start with adminUsers: [runner]
2023-03-20 21:34:48,307 [Listener at 0.0.0.0/45115] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:48,307 [Listener at 0.0.0.0/45115] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2023-03-20 21:34:48,307 [Listener at 0.0.0.0/45115] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2023-03-20 21:34:48,433 [IPC Server handler 3 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:48,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:48,463 [IPC Server handler 2 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:48,464 [Listener at 0.0.0.0/45115] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(750)) - S3 Multi-Tenancy is disabled
2023-03-20 21:34:48,464 [Listener at 0.0.0.0/45115] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-20 21:34:48,477 [Listener at 0.0.0.0/45115] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4228)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2023-03-20 21:34:48,478 [Listener at 0.0.0.0/45115] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-20 21:34:48,478 [Listener at 0.0.0.0/45115] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(439)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2023-03-20 21:34:48,478 [Listener at 0.0.0.0/45115] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:48,478 [Listener at 0.0.0.0/45115] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:48,478 [Listener at 0.0.0.0/45115] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-20 21:34:48,478 [Listener at 0.0.0.0/45115] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(164)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:39605
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(636)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2023-03-20 21:34:48,479 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5169394284ns, electionTimeout:5169ms
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:48,479 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: shutdown a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 39605 (fallback to raft.grpc.server.port)
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:48,479 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 39605 (fallback to raft.grpc.server.port)
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:48,479 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:48,479 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: start a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 39605 (custom)
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-03-20 21:34:48,479 [Listener at 0.0.0.0/45115] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:48,480 [Listener at 0.0.0.0/45115] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:48,480 [Listener at 0.0.0.0/45115] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:48,480 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,480 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:48,481 [IPC Server handler 4 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:48,481 [Listener at 0.0.0.0/45115] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2023-03-20 21:34:48,481 [Listener at 0.0.0.0/45115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:48,481 [Listener at 0.0.0.0/45115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:48,481 [Listener at 0.0.0.0/45115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-20 21:34:48,481 [Listener at 0.0.0.0/45115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:48,481 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,481 [Listener at 0.0.0.0/45115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/ozone-meta/ratis] (custom)
2023-03-20 21:34:48,481 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:48,481 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: shutdown a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162
2023-03-20 21:34:48,481 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-79EFAD75B4CC with new leaderId: a416fcbf-d3db-4cde-9623-07e05d2a4f7f
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC: change Leader from null to a416fcbf-d3db-4cde-9623-07e05d2a4f7f at term 1 for becomeLeader, leader elected after 5180ms
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:48,482 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f: start a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderStateImpl
2023-03-20 21:34:48,483 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:48,483 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-LeaderElection162] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC: set configuration 0: peers:[a416fcbf-d3db-4cde-9623-07e05d2a4f7f|rpc:10.1.0.10:43949|dataStream:10.1.0.10:37825|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:48,483 [Listener at 0.0.0.0/45115] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:39605|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@21b5f8bd[Not completed]
2023-03-20 21:34:48,483 [Listener at 0.0.0.0/45115] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2107)) - OzoneManager Ratis server initialized at port 39605
2023-03-20 21:34:48,483 [Listener at 0.0.0.0/45115] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1134)) - Creating RPC Server
2023-03-20 21:34:48,483 [a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - a416fcbf-d3db-4cde-9623-07e05d2a4f7f@group-79EFAD75B4CC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-4/data/ratis/a42e5b9d-3395-4b3a-97a9-79efad75b4cc/current/log_inprogress_0
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:39605|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:localhost:39605|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/ozone-meta/ratis] (custom)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2023-03-20 21:34:48,486 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:48,487 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:48,489 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:48,489 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:48,489 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:48,489 [pool-4617-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:49,330 [Finalizer] WARN  managed.ManagedRocksObjectUtils (ManagedRocksObjectUtils.java:assertClosed(54)) - RocksIterator is not closed properly
2023-03-20 21:34:49,331 [Finalizer] WARN  managed.ManagedRocksObjectUtils (ManagedRocksObjectUtils.java:assertClosed(54)) - ManagedColumnFamilyOptions is not closed properly
2023-03-20 21:34:49,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:49,337 [JvmPauseMonitor89] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-c2f44316-1a3e-468b-9a76-53c43d628173: Detected pause in JVM or host machine (eg GC): pause of approximately 195109348ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,337 [JvmPauseMonitor96] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-05384c5d-9495-4201-8a60-c8c72abd74fb: Detected pause in JVM or host machine (eg GC): pause of approximately 317260351ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,337 [JvmPauseMonitor92] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 333265868ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,337 [JvmPauseMonitor84] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 338754105ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,337 [JvmPauseMonitor99] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-a0d6486e-58e7-45ac-85b3-704c8b479dbc: Detected pause in JVM or host machine (eg GC): pause of approximately 341651072ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,337 [JvmPauseMonitor93] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-52a46685-3070-4024-834b-c3445a236f70: Detected pause in JVM or host machine (eg GC): pause of approximately 345835324ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,337 [JvmPauseMonitor87] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: Detected pause in JVM or host machine (eg GC): pause of approximately 345910024ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,337 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] WARN  impl.FollowerState (FollowerState.java:run(130)) - Unexpected long sleep: sleep 5005ms but took extra 352648646ns (> threshold = 300ms)
2023-03-20 21:34:49,337 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:49,338 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:49,338 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] WARN  impl.FollowerState (FollowerState.java:run(130)) - Unexpected long sleep: sleep 5101ms but took extra 362467633ns (> threshold = 300ms)
2023-03-20 21:34:49,338 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:49,338 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:49,338 [JvmPauseMonitor85] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-c810b0b2-f38c-4bc5-874a-38f1937d7d9e: Detected pause in JVM or host machine (eg GC): pause of approximately 428921873ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,338 [JvmPauseMonitor90] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: Detected pause in JVM or host machine (eg GC): pause of approximately 430543555ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,338 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] WARN  impl.FollowerState (FollowerState.java:run(130)) - Unexpected long sleep: sleep 5026ms but took extra 454917334ns (> threshold = 300ms)
2023-03-20 21:34:49,339 [JvmPauseMonitor88] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-9ce389bc-6c47-40b9-aa21-f44fc17fd7db: Detected pause in JVM or host machine (eg GC): pause of approximately 466009749ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,339 [JvmPauseMonitor98] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-2325b755-97f4-4680-bb9e-067434f11ceb: Detected pause in JVM or host machine (eg GC): pause of approximately 466074549ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,339 [JvmPauseMonitor95] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-e5cc6624-b71a-402d-a69e-29759be12af7: Detected pause in JVM or host machine (eg GC): pause of approximately 479671993ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,339 [JvmPauseMonitor91] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-ad06446d-1378-4ceb-aafe-e920688dce34: Detected pause in JVM or host machine (eg GC): pause of approximately 480827780ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,339 [JvmPauseMonitor94] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-79924adf-68a9-4348-9386-442656259f82: Detected pause in JVM or host machine (eg GC): pause of approximately 482227164ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,339 [JvmPauseMonitor97] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-a416fcbf-d3db-4cde-9623-07e05d2a4f7f: Detected pause in JVM or host machine (eg GC): pause of approximately 484265441ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=494ms
GC pool 'PS Scavenge' had collection(s): count=1 time=150ms
2023-03-20 21:34:49,340 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] WARN  impl.FollowerState (FollowerState.java:run(130)) - Unexpected long sleep: sleep 5169ms but took extra 540467214ns (> threshold = 300ms)
2023-03-20 21:34:49,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:49,357 [IPC Server handler 3 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:34:49,357 [IPC Server handler 3 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=39745, RATIS=36869, RATIS_ADMIN=36869, RATIS_SERVER=36869, RATIS_DATASTREAM=34323, STANDALONE=35469], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:49,358 [IPC Server handler 2 on default port 42601] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10). Asking datanode to re-register.
2023-03-20 21:34:49,358 [IPC Server handler 4 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:49,358 [IPC Server handler 4 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 9ce389bc-6c47-40b9-aa21-f44fc17fd7db{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=46199, RATIS=34363, RATIS_ADMIN=34363, RATIS_SERVER=34363, RATIS_DATASTREAM=39027, STANDALONE=34777], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:49,364 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-20 21:34:49,364 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-20 21:34:49,364 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-03-20 21:34:49,367 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-20 21:34:49,367 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-03-20 21:34:49,367 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-20 21:34:49,385 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:49,385 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:49,426 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:49,426 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:49,440 [IPC Server handler 1 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:49,441 [IPC Server handler 1 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : ad5f436c-b0db-4b4f-b4fd-dcb016937dbf{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=46645, RATIS=45703, RATIS_ADMIN=45703, RATIS_SERVER=45703, RATIS_DATASTREAM=46387, STANDALONE=37991], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:49,441 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:49,447 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-20 21:34:49,447 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-20 21:34:49,447 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-20 21:34:49,448 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-20 21:34:49,448 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-03-20 21:34:49,448 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 2
2023-03-20 21:34:49,448 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:49,451 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:49,451 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-20 21:34:49,451 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-20 21:34:49,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:49,482 [IPC Server handler 0 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:34:49,482 [IPC Server handler 0 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : ad06446d-1378-4ceb-aafe-e920688dce34{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=44493, RATIS=45443, RATIS_ADMIN=45443, RATIS_SERVER=45443, RATIS_DATASTREAM=44401, STANDALONE=33865], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:49,483 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:49,483 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:49,484 [IPC Server handler 19 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:34:49,484 [IPC Server handler 19 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : c810b0b2-f38c-4bc5-874a-38f1937d7d9e{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45831, RATIS=34483, RATIS_ADMIN=34483, RATIS_SERVER=34483, RATIS_DATASTREAM=38853, STANDALONE=45741], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:49,484 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-20 21:34:49,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1175)) - Service ReplicationManager transitions to RUNNING.
2023-03-20 21:34:49,485 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-20 21:34:49,535 [Listener at 0.0.0.0/45115] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 1051 ms to scan 19 urls, producing 68 keys and 4951 values [using 2 cores]
2023-03-20 21:34:49,536 [Listener at 0.0.0.0/45115] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-20 21:34:49,536 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-20 21:34:49,554 [Listener at 127.0.0.1/40507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2023-03-20 21:34:49,564 [Listener at 127.0.0.1/40507] INFO  om.OzoneManager (OzoneManager.java:start(1564)) - OzoneManager RPC server is listening at localhost/127.0.0.1:40507
2023-03-20 21:34:49,564 [Listener at 127.0.0.1/40507] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(559)) - Starting OzoneManagerRatisServer om1 at port 39605
2023-03-20 21:34:49,564 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2023-03-20 21:34:49,566 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:49,567 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2023-03-20 21:34:49,567 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:49,567 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:49,567 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:49,567 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:49,567 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:49,567 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-20 21:34:49,567 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:49,568 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-03-20 21:34:49,569 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:49,571 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:49,571 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:49,571 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2023-03-20 21:34:49,571 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:49,572 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:49,572 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:localhost:39605|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:49,572 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:49,572 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2023-03-20 21:34:49,572 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:49,572 [om1-impl-thread1] ERROR util.JmxRegister (JmxRegister.java:tryRegister(40)) - Failed to register JMX Bean with name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.ratis.util.JmxRegister.tryRegister(JmxRegister.java:38)
	at org.apache.ratis.util.JmxRegister.register(JmxRegister.java:56)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:353)
	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:344)
	at org.apache.ratis.util.ConcurrentUtils.accept(ConcurrentUtils.java:173)
	at org.apache.ratis.util.ConcurrentUtils.lambda$null$3(ConcurrentUtils.java:165)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:34:49,572 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:49,572 [om1-impl-thread1] ERROR util.JmxRegister (JmxRegister.java:tryRegister(40)) - Failed to register JMX Bean with name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.ratis.util.JmxRegister.tryRegister(JmxRegister.java:38)
	at org.apache.ratis.util.JmxRegister.register(JmxRegister.java:56)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:353)
	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:344)
	at org.apache.ratis.util.ConcurrentUtils.accept(ConcurrentUtils.java:173)
	at org.apache.ratis.util.ConcurrentUtils.lambda$null$3(ConcurrentUtils.java:165)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:34:49,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:49,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2023-03-20 21:34:49,573 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2023-03-20 21:34:49,573 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2023-03-20 21:34:49,573 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - om1: start RPC server
2023-03-20 21:34:49,573 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - om1: GrpcService started, listening on 39605
2023-03-20 21:34:49,574 [Listener at 127.0.0.1/40507] INFO  om.OzoneManager (OzoneManager.java:start(1580)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2023-03-20 21:34:49,574 [JvmPauseMonitor100] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-om1: Started
2023-03-20 21:34:49,579 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2023-03-20 21:34:49,579 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:49,580 [Listener at 127.0.0.1/40507] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:49,580 [Listener at 127.0.0.1/40507] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:49,580 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:49,581 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2023-03-20 21:34:49,581 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:49,581 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:49,581 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/ozone-meta/webserver
2023-03-20 21:34:49,581 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 44495
2023-03-20 21:34:49,581 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:49,582 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:49,582 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:49,582 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:49,583 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2356f6ac{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:49,583 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3b472901{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-20 21:34:49,584 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@673f7fb2{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-20 21:34:49,587 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@57e39b3c{HTTP/1.1, (http/1.1)}{0.0.0.0:44495}
2023-03-20 21:34:49,587 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(415)) - Started @390856ms
2023-03-20 21:34:49,587 [Listener at 127.0.0.1/40507] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:49,587 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of ozoneManager listening at http://0.0.0.0:44495
2023-03-20 21:34:49,587 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-20 21:34:49,588 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-20 21:34:49,589 [Listener at 127.0.0.1/40507] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2051)) - Trash Interval set to 0. Files deleted won't move to trash
2023-03-20 21:34:49,589 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5c5bdccb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:49,603 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:49,603 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:49,603 [Listener at 127.0.0.1/40507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:49,614 [Listener at 127.0.0.1/40507] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:49,631 [Listener at 127.0.0.1/40507] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:49,686 [Listener at 127.0.0.1/40507] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 54 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:49,687 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:49,688 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:49,688 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:49,688 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data-0/containers/hdds
2023-03-20 21:34:49,688 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data-0/containers/hdds
2023-03-20 21:34:49,700 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis to VolumeSet
2023-03-20 21:34:49,700 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis
2023-03-20 21:34:49,700 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis
2023-03-20 21:34:49,727 [Thread-7253] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data-0/containers/hdds
2023-03-20 21:34:49,727 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:49,729 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:49,729 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:49,729 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:49,729 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:49,729 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:49,729 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:49,729 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:49,729 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:49,730 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:49,730 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:49,730 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:49,730 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:49,731 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:49,731 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:49,732 [Listener at 127.0.0.1/40507] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:49,732 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:49,732 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:49,732 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:49,732 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:49,732 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:49,732 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:49,732 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:49,733 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:49,733 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:49,733 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:49,735 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:49,735 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:49,735 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:49,735 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:49,735 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis] (custom)
2023-03-20 21:34:49,736 [3b791506-899f-4927-929a-007385ffa693-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa4029890] REGISTERED
2023-03-20 21:34:49,736 [3b791506-899f-4927-929a-007385ffa693-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa4029890] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:49,736 [3b791506-899f-4927-929a-007385ffa693-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa4029890, L:/0:0:0:0:0:0:0:0:39527] ACTIVE
2023-03-20 21:34:49,737 [Listener at 127.0.0.1/40507] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:49,739 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:49,739 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:49,739 [Listener at 127.0.0.1/40507] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:49,740 [Listener at 127.0.0.1/40507] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:49,741 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:49,741 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:49,741 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:49,741 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:49,741 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/meta/webserver
2023-03-20 21:34:49,741 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 35857
2023-03-20 21:34:49,741 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:49,746 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:49,746 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:49,746 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:49,747 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3f7dde3c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:49,747 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6d640db8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:49,947 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2ef8ff59{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/meta/webserver/jetty-0_0_0_0-35857-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-7758934154288396397/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:49,950 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6abdc8d1{HTTP/1.1, (http/1.1)}{0.0.0.0:35857}
2023-03-20 21:34:49,950 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(415)) - Started @391219ms
2023-03-20 21:34:49,950 [Listener at 127.0.0.1/40507] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:49,950 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:35857
2023-03-20 21:34:49,950 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:49,950 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:49,951 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:49,951 [Listener at 127.0.0.1/40507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:49,961 [Listener at 127.0.0.1/40507] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:49,964 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d3f3d43] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:49,967 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/meta/datanode.id
2023-03-20 21:34:49,978 [Listener at 127.0.0.1/40507] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:50,025 [Listener at 127.0.0.1/40507] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 46 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:50,027 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:50,028 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:50,028 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:50,028 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data-0/containers/hdds
2023-03-20 21:34:50,028 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data-0/containers/hdds
2023-03-20 21:34:50,038 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data/ratis to VolumeSet
2023-03-20 21:34:50,038 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data/ratis
2023-03-20 21:34:50,038 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data/ratis
2023-03-20 21:34:50,051 [Thread-7267] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data-0/containers/hdds
2023-03-20 21:34:50,051 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:50,052 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:50,052 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:50,052 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:50,052 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:50,053 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:50,054 [Listener at 127.0.0.1/40507] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:50,054 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:50,054 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:50,054 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:50,054 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:50,054 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:50,054 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:50,055 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:50,055 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:50,055 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:50,055 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:50,055 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:50,055 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:50,055 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:50,055 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:50,055 [73dcf697-4659-4759-9fac-94f9a54bb6a2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe1ffbdcc] REGISTERED
2023-03-20 21:34:50,055 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data/ratis] (custom)
2023-03-20 21:34:50,055 [73dcf697-4659-4759-9fac-94f9a54bb6a2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe1ffbdcc] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:50,055 [73dcf697-4659-4759-9fac-94f9a54bb6a2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe1ffbdcc, L:/0:0:0:0:0:0:0:0:34585] ACTIVE
2023-03-20 21:34:50,056 [Listener at 127.0.0.1/40507] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:50,058 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:50,058 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:50,059 [Listener at 127.0.0.1/40507] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:50,059 [Listener at 127.0.0.1/40507] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:50,060 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:50,060 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:50,060 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:50,060 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:50,060 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/meta/webserver
2023-03-20 21:34:50,061 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 43309
2023-03-20 21:34:50,061 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:50,061 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:50,061 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:50,062 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:50,062 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4057ea39{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:50,062 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@72c9cc18{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:50,261 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5498c10b{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/meta/webserver/jetty-0_0_0_0-43309-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-1206954508145201442/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:50,263 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3faa7ee4{HTTP/1.1, (http/1.1)}{0.0.0.0:43309}
2023-03-20 21:34:50,264 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(415)) - Started @391533ms
2023-03-20 21:34:50,264 [Listener at 127.0.0.1/40507] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:50,264 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:43309
2023-03-20 21:34:50,264 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:50,264 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:50,264 [Listener at 127.0.0.1/40507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:50,265 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:50,274 [Listener at 127.0.0.1/40507] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:50,275 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b19728e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:50,278 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/meta/datanode.id
2023-03-20 21:34:50,290 [Listener at 127.0.0.1/40507] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:50,335 [Listener at 127.0.0.1/40507] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 45 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:50,336 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:50,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:50,337 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:50,337 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:50,337 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data-0/containers/hdds
2023-03-20 21:34:50,338 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data-0/containers/hdds
2023-03-20 21:34:50,340 [IPC Server handler 17 on default port 42601] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:50,340 [IPC Server handler 17 on default port 42601] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : c2f44316-1a3e-468b-9a76-53c43d628173{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45549, RATIS=33117, RATIS_ADMIN=33117, RATIS_SERVER=33117, RATIS_DATASTREAM=40549, STANDALONE=40115], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:50,340 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:50,340 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:50,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:50,352 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis to VolumeSet
2023-03-20 21:34:50,352 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis
2023-03-20 21:34:50,352 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis
2023-03-20 21:34:50,361 [Thread-7283] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data-0/containers/hdds
2023-03-20 21:34:50,362 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:50,363 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:50,364 [Listener at 127.0.0.1/40507] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:50,364 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:50,364 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:50,365 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:50,365 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:50,365 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:50,365 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:50,365 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:50,365 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:50,365 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:50,365 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:50,371 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:50,371 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:50,371 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:50,372 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:50,372 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis] (custom)
2023-03-20 21:34:50,372 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xead6c73f] REGISTERED
2023-03-20 21:34:50,372 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xead6c73f] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:50,372 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xead6c73f, L:/0:0:0:0:0:0:0:0:45553] ACTIVE
2023-03-20 21:34:50,373 [Listener at 127.0.0.1/40507] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:50,375 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:50,375 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:50,375 [Listener at 127.0.0.1/40507] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:50,376 [Listener at 127.0.0.1/40507] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:50,377 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:50,377 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:50,377 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:50,377 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:50,377 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/meta/webserver
2023-03-20 21:34:50,377 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 38869
2023-03-20 21:34:50,377 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:50,380 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:50,380 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:50,380 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:50,381 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@62612b8b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:50,381 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7aeacd61{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:50,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:50,577 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2e54d2c3{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/meta/webserver/jetty-0_0_0_0-38869-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-8575909350671552463/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:50,579 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2a362226{HTTP/1.1, (http/1.1)}{0.0.0.0:38869}
2023-03-20 21:34:50,579 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(415)) - Started @391849ms
2023-03-20 21:34:50,579 [Listener at 127.0.0.1/40507] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:50,580 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38869
2023-03-20 21:34:50,580 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:50,580 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:50,580 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:50,580 [Listener at 127.0.0.1/40507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:50,590 [Listener at 127.0.0.1/40507] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:50,591 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6be166b4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:50,593 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/meta/datanode.id
2023-03-20 21:34:50,607 [Listener at 127.0.0.1/40507] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:50,652 [Listener at 127.0.0.1/40507] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 45 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:50,653 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:50,656 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:50,657 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:50,657 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data-0/containers/hdds
2023-03-20 21:34:50,657 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data-0/containers/hdds
2023-03-20 21:34:50,675 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data/ratis to VolumeSet
2023-03-20 21:34:50,675 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data/ratis
2023-03-20 21:34:50,675 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data/ratis
2023-03-20 21:34:50,687 [Thread-7297] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data-0/containers/hdds
2023-03-20 21:34:50,687 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:50,688 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:50,689 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:50,689 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:50,689 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:50,689 [Listener at 127.0.0.1/40507] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:50,690 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:50,694 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:50,694 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:50,694 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:50,694 [00867d28-7830-4d3d-a4c5-0b9d063e06a7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x68bb225f] REGISTERED
2023-03-20 21:34:50,694 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:50,695 [00867d28-7830-4d3d-a4c5-0b9d063e06a7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x68bb225f] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:50,695 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data/ratis] (custom)
2023-03-20 21:34:50,695 [00867d28-7830-4d3d-a4c5-0b9d063e06a7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x68bb225f, L:/0:0:0:0:0:0:0:0:39523] ACTIVE
2023-03-20 21:34:50,697 [Listener at 127.0.0.1/40507] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:50,698 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:50,698 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:50,699 [Listener at 127.0.0.1/40507] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:50,699 [Listener at 127.0.0.1/40507] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:50,700 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:50,700 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:50,700 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:50,700 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:50,700 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1128509391ns, electionTimeout:1128ms
2023-03-20 21:34:50,701 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2023-03-20 21:34:50,701 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:50,701 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/meta/webserver
2023-03-20 21:34:50,701 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:50,701 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection163
2023-03-20 21:34:50,701 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 41051
2023-03-20 21:34:50,701 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:50,701 [om1@group-C5BA1605619E-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection163 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|rpc:localhost:39605|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:50,701 [om1@group-C5BA1605619E-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection163 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:50,702 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:50,702 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:50,702 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection163 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:localhost:39605|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection163 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection163
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 2216ms
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:50,703 [om1@group-C5BA1605619E-LeaderElection163] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2023-03-20 21:34:50,704 [om1@group-C5BA1605619E-LeaderElection163] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:50,704 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7bf9e2d1{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:50,704 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@26f80307{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:50,714 [om1@group-C5BA1605619E-LeaderElection163] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:localhost:39605|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:50,721 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2023-03-20 21:34:50,722 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:39605"
startupRole: FOLLOWER
]
2023-03-20 21:34:50,909 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@615da025{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/meta/webserver/jetty-0_0_0_0-41051-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-9055138052857773554/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:50,912 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6c1202f6{HTTP/1.1, (http/1.1)}{0.0.0.0:41051}
2023-03-20 21:34:50,912 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(415)) - Started @392181ms
2023-03-20 21:34:50,912 [Listener at 127.0.0.1/40507] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:50,913 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41051
2023-03-20 21:34:50,913 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:50,914 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:50,914 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:50,914 [Listener at 127.0.0.1/40507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:50,924 [Listener at 127.0.0.1/40507] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:50,924 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26f21a26] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:50,926 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/meta/datanode.id
2023-03-20 21:34:50,938 [Listener at 127.0.0.1/40507] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:50,982 [Listener at 127.0.0.1/40507] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:50,983 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:50,984 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:50,984 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:50,984 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data-0/containers/hdds
2023-03-20 21:34:50,984 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data-0/containers/hdds
2023-03-20 21:34:50,994 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data/ratis to VolumeSet
2023-03-20 21:34:50,994 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data/ratis
2023-03-20 21:34:50,994 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data/ratis
2023-03-20 21:34:51,003 [Thread-7313] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data-0/containers/hdds
2023-03-20 21:34:51,004 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:51,005 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:51,006 [Listener at 127.0.0.1/40507] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:51,006 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:51,006 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:51,006 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:51,006 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:51,006 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:51,006 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:51,007 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:51,007 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:51,007 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:51,007 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:51,007 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:51,007 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:51,007 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:51,007 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:51,007 [044bfaef-c902-47be-95bf-0f9e32226746-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb5c03eb0] REGISTERED
2023-03-20 21:34:51,007 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data/ratis] (custom)
2023-03-20 21:34:51,007 [044bfaef-c902-47be-95bf-0f9e32226746-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb5c03eb0] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:51,008 [044bfaef-c902-47be-95bf-0f9e32226746-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb5c03eb0, L:/0:0:0:0:0:0:0:0:43085] ACTIVE
2023-03-20 21:34:51,008 [Listener at 127.0.0.1/40507] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:51,010 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:51,010 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:51,011 [Listener at 127.0.0.1/40507] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:51,011 [Listener at 127.0.0.1/40507] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:51,012 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:51,012 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:51,012 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:51,012 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:51,012 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/meta/webserver
2023-03-20 21:34:51,012 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 43235
2023-03-20 21:34:51,012 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:51,017 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:51,017 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:51,017 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:51,018 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5fa9911e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:51,018 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7d43721c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:51,214 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@d7e1596{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/meta/webserver/jetty-0_0_0_0-43235-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6251120224954372031/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:51,218 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5b9dcf1e{HTTP/1.1, (http/1.1)}{0.0.0.0:43235}
2023-03-20 21:34:51,218 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(415)) - Started @392487ms
2023-03-20 21:34:51,218 [Listener at 127.0.0.1/40507] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:51,219 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:43235
2023-03-20 21:34:51,219 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:51,219 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:51,219 [Listener at 127.0.0.1/40507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:51,224 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:51,271 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d611938] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:51,275 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/meta/datanode.id
2023-03-20 21:34:51,275 [Listener at 127.0.0.1/40507] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:51,289 [Listener at 127.0.0.1/40507] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:51,335 [Listener at 127.0.0.1/40507] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 45 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:51,336 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:51,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:51,340 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:51,341 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:51,341 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data-0/containers/hdds
2023-03-20 21:34:51,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:51,346 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data-0/containers/hdds
2023-03-20 21:34:51,357 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis to VolumeSet
2023-03-20 21:34:51,357 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis
2023-03-20 21:34:51,357 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis
2023-03-20 21:34:51,370 [Thread-7327] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data-0/containers/hdds
2023-03-20 21:34:51,370 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:51,371 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:51,372 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:51,372 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:51,372 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:51,372 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:51,373 [Listener at 127.0.0.1/40507] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:51,373 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:51,373 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:51,373 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:51,373 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:51,373 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:51,373 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:51,373 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:51,374 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:51,374 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:51,374 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:51,374 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:51,374 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:51,374 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:51,374 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:51,374 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x2588f006] REGISTERED
2023-03-20 21:34:51,374 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis] (custom)
2023-03-20 21:34:51,375 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x2588f006] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:51,375 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x2588f006, L:/0:0:0:0:0:0:0:0:42991] ACTIVE
2023-03-20 21:34:51,375 [Listener at 127.0.0.1/40507] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:51,377 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:51,377 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:51,385 [Listener at 127.0.0.1/40507] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:51,385 [Listener at 127.0.0.1/40507] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:51,389 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:51,389 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:51,389 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:51,389 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:51,389 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/meta/webserver
2023-03-20 21:34:51,389 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 39333
2023-03-20 21:34:51,389 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:51,390 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:51,391 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:51,391 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:51,391 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4cd6743e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:51,391 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7068a22e{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:51,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:51,596 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4a4033af{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/meta/webserver/jetty-0_0_0_0-39333-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-7683999625577923879/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:51,598 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@65b4487d{HTTP/1.1, (http/1.1)}{0.0.0.0:39333}
2023-03-20 21:34:51,598 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(415)) - Started @392868ms
2023-03-20 21:34:51,598 [Listener at 127.0.0.1/40507] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:51,599 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:39333
2023-03-20 21:34:51,600 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:51,600 [Listener at 127.0.0.1/40507] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-20 21:34:51,600 [Listener at 127.0.0.1/40507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-20 21:34:51,604 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:51,611 [Listener at 127.0.0.1/40507] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(249)) - HddsDatanodeService host:fv-az985-449 ip:10.1.0.10
2023-03-20 21:34:51,615 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4c76e9fe] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:51,615 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/meta/datanode.id
2023-03-20 21:34:51,626 [Listener at 127.0.0.1/40507] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-20 21:34:51,673 [Listener at 127.0.0.1/40507] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 46 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-20 21:34:51,674 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-20 21:34:51,675 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:<init>(130)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-20 21:34:51,675 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data-0/containers/hdds to VolumeSet
2023-03-20 21:34:51,675 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data-0/containers/hdds
2023-03-20 21:34:51,676 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data-0/containers/hdds
2023-03-20 21:34:51,686 [Listener at 127.0.0.1/40507] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(175)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data/ratis to VolumeSet
2023-03-20 21:34:51,686 [Listener at 127.0.0.1/40507] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data/ratis
2023-03-20 21:34:51,686 [Listener at 127.0.0.1/40507] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data/ratis
2023-03-20 21:34:51,695 [Thread-7341] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data-0/containers/hdds
2023-03-20 21:34:51,695 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-20 21:34:51,696 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-20 21:34:51,696 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:51,696 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-20 21:34:51,696 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-20 21:34:51,696 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-20 21:34:51,697 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-20 21:34:51,697 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-20 21:34:51,697 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-20 21:34:51,697 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:51,697 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-20 21:34:51,697 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-20 21:34:51,697 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-20 21:34:51,697 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-20 21:34:51,697 [Listener at 127.0.0.1/40507] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-20 21:34:51,698 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-20 21:34:51,699 [Listener at 127.0.0.1/40507] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-20 21:34:51,699 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-20 21:34:51,699 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-20 21:34:51,699 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:51,699 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:51,699 [Listener at 127.0.0.1/40507] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data/ratis] (custom)
2023-03-20 21:34:51,699 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0c6062a0] REGISTERED
2023-03-20 21:34:51,699 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0c6062a0] BIND: 0.0.0.0/0.0.0.0:0
2023-03-20 21:34:51,699 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0c6062a0, L:/0:0:0:0:0:0:0:0:43725] ACTIVE
2023-03-20 21:34:51,700 [Listener at 127.0.0.1/40507] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-20 21:34:51,702 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-20 21:34:51,702 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-20 21:34:51,702 [Listener at 127.0.0.1/40507] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-20 21:34:51,702 [Listener at 127.0.0.1/40507] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-20 21:34:51,703 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-20 21:34:51,703 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-20 21:34:51,703 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 21:34:51,703 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 21:34:51,704 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/meta/webserver
2023-03-20 21:34:51,704 [Listener at 127.0.0.1/40507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 38743
2023-03-20 21:34:51,704 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-20 21:34:51,704 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-20 21:34:51,704 [Listener at 127.0.0.1/40507] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-20 21:34:51,705 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-20 21:34:51,705 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@64afa40b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-20 21:34:51,705 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@635931a5{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-20 21:34:51,913 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@52087735{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/meta/webserver/jetty-0_0_0_0-38743-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-1956924023029976648/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:51,918 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2e505d50{HTTP/1.1, (http/1.1)}{0.0.0.0:38743}
2023-03-20 21:34:51,918 [Listener at 127.0.0.1/40507] INFO  server.Server (Server.java:doStart(415)) - Started @393187ms
2023-03-20 21:34:51,918 [Listener at 127.0.0.1/40507] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-20 21:34:51,919 [Listener at 127.0.0.1/40507] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38743
2023-03-20 21:34:51,919 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-20 21:34:51,919 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-20 21:34:51,919 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:51,919 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:51,928 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@295acadd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-20 21:34:51,929 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/meta/datanode.id
2023-03-20 21:34:52,031 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-2e14535f-64a8-4d5a-ade5-c4984d433ed3/container.db to cache
2023-03-20 21:34:52,032 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-2e14535f-64a8-4d5a-ade5-c4984d433ed3/container.db for volume DS-2e14535f-64a8-4d5a-ade5-c4984d433ed3
2023-03-20 21:34:52,032 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:52,032 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:52,032 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 45597
2023-03-20 21:34:52,035 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:34:52,037 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 3b791506-899f-4927-929a-007385ffa693: start RPC server
2023-03-20 21:34:52,037 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 3b791506-899f-4927-929a-007385ffa693: GrpcService started, listening on 39897
2023-03-20 21:34:52,037 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 3b791506-899f-4927-929a-007385ffa693 is started using port 39897 for RATIS
2023-03-20 21:34:52,037 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 3b791506-899f-4927-929a-007385ffa693 is started using port 39897 for RATIS_ADMIN
2023-03-20 21:34:52,037 [JvmPauseMonitor101] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-3b791506-899f-4927-929a-007385ffa693: Started
2023-03-20 21:34:52,037 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 3b791506-899f-4927-929a-007385ffa693 is started using port 39897 for RATIS_SERVER
2023-03-20 21:34:52,037 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 3b791506-899f-4927-929a-007385ffa693 is started using port 39527 for RATIS_DATASTREAM
2023-03-20 21:34:52,038 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 3b791506-899f-4927-929a-007385ffa693 is started using port 37373
2023-03-20 21:34:52,038 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:52,307 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-f849356c-d112-4ce6-8660-a8a9b3372e5b/container.db to cache
2023-03-20 21:34:52,307 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-f849356c-d112-4ce6-8660-a8a9b3372e5b/container.db for volume DS-f849356c-d112-4ce6-8660-a8a9b3372e5b
2023-03-20 21:34:52,308 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:52,308 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:52,308 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 33321
2023-03-20 21:34:52,310 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 73dcf697-4659-4759-9fac-94f9a54bb6a2
2023-03-20 21:34:52,314 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 73dcf697-4659-4759-9fac-94f9a54bb6a2: start RPC server
2023-03-20 21:34:52,314 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 73dcf697-4659-4759-9fac-94f9a54bb6a2: GrpcService started, listening on 35611
2023-03-20 21:34:52,314 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 73dcf697-4659-4759-9fac-94f9a54bb6a2 is started using port 35611 for RATIS
2023-03-20 21:34:52,314 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 73dcf697-4659-4759-9fac-94f9a54bb6a2 is started using port 35611 for RATIS_ADMIN
2023-03-20 21:34:52,314 [JvmPauseMonitor102] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-73dcf697-4659-4759-9fac-94f9a54bb6a2: Started
2023-03-20 21:34:52,314 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 73dcf697-4659-4759-9fac-94f9a54bb6a2 is started using port 35611 for RATIS_SERVER
2023-03-20 21:34:52,315 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 73dcf697-4659-4759-9fac-94f9a54bb6a2 is started using port 34585 for RATIS_DATASTREAM
2023-03-20 21:34:52,315 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 73dcf697-4659-4759-9fac-94f9a54bb6a2 is started using port 32807
2023-03-20 21:34:52,316 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:52,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:52,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:52,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:52,619 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-e5945372-bece-43b4-bdec-3de9ba0c1773/container.db to cache
2023-03-20 21:34:52,619 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-e5945372-bece-43b4-bdec-3de9ba0c1773/container.db for volume DS-e5945372-bece-43b4-bdec-3de9ba0c1773
2023-03-20 21:34:52,619 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:52,619 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:52,619 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 45235
2023-03-20 21:34:52,622 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:34:52,624 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: start RPC server
2023-03-20 21:34:52,624 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: GrpcService started, listening on 45377
2023-03-20 21:34:52,624 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9d2a4ecd-2086-4135-bf3e-5d16e44246f0 is started using port 45377 for RATIS
2023-03-20 21:34:52,625 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9d2a4ecd-2086-4135-bf3e-5d16e44246f0 is started using port 45377 for RATIS_ADMIN
2023-03-20 21:34:52,625 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9d2a4ecd-2086-4135-bf3e-5d16e44246f0 is started using port 45377 for RATIS_SERVER
2023-03-20 21:34:52,625 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9d2a4ecd-2086-4135-bf3e-5d16e44246f0 is started using port 45553 for RATIS_DATASTREAM
2023-03-20 21:34:52,625 [JvmPauseMonitor103] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-9d2a4ecd-2086-4135-bf3e-5d16e44246f0: Started
2023-03-20 21:34:52,627 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 9d2a4ecd-2086-4135-bf3e-5d16e44246f0 is started using port 38887
2023-03-20 21:34:52,628 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:52,920 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-20 21:34:52,920 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:52,920 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:52,949 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-252d4021-a620-48b0-abba-8cbcb4c3d0eb/container.db to cache
2023-03-20 21:34:52,949 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-252d4021-a620-48b0-abba-8cbcb4c3d0eb/container.db for volume DS-252d4021-a620-48b0-abba-8cbcb4c3d0eb
2023-03-20 21:34:52,950 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:52,950 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:52,950 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 42899
2023-03-20 21:34:52,952 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 00867d28-7830-4d3d-a4c5-0b9d063e06a7
2023-03-20 21:34:52,955 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 00867d28-7830-4d3d-a4c5-0b9d063e06a7: start RPC server
2023-03-20 21:34:52,955 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 00867d28-7830-4d3d-a4c5-0b9d063e06a7: GrpcService started, listening on 46797
2023-03-20 21:34:52,955 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 00867d28-7830-4d3d-a4c5-0b9d063e06a7 is started using port 46797 for RATIS
2023-03-20 21:34:52,955 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 00867d28-7830-4d3d-a4c5-0b9d063e06a7 is started using port 46797 for RATIS_ADMIN
2023-03-20 21:34:52,955 [JvmPauseMonitor104] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-00867d28-7830-4d3d-a4c5-0b9d063e06a7: Started
2023-03-20 21:34:52,955 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 00867d28-7830-4d3d-a4c5-0b9d063e06a7 is started using port 46797 for RATIS_SERVER
2023-03-20 21:34:52,955 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 00867d28-7830-4d3d-a4c5-0b9d063e06a7 is started using port 39523 for RATIS_DATASTREAM
2023-03-20 21:34:52,956 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 00867d28-7830-4d3d-a4c5-0b9d063e06a7 is started using port 32967
2023-03-20 21:34:52,962 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:53,298 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-6a65693e-c212-4da9-8209-7347a08c7dfb/container.db to cache
2023-03-20 21:34:53,298 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-6a65693e-c212-4da9-8209-7347a08c7dfb/container.db for volume DS-6a65693e-c212-4da9-8209-7347a08c7dfb
2023-03-20 21:34:53,298 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:53,298 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:53,299 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 45707
2023-03-20 21:34:53,301 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 044bfaef-c902-47be-95bf-0f9e32226746
2023-03-20 21:34:53,303 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 044bfaef-c902-47be-95bf-0f9e32226746: start RPC server
2023-03-20 21:34:53,304 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 044bfaef-c902-47be-95bf-0f9e32226746: GrpcService started, listening on 40849
2023-03-20 21:34:53,304 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 044bfaef-c902-47be-95bf-0f9e32226746 is started using port 40849 for RATIS
2023-03-20 21:34:53,304 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 044bfaef-c902-47be-95bf-0f9e32226746 is started using port 40849 for RATIS_ADMIN
2023-03-20 21:34:53,304 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 044bfaef-c902-47be-95bf-0f9e32226746 is started using port 40849 for RATIS_SERVER
2023-03-20 21:34:53,304 [JvmPauseMonitor105] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-044bfaef-c902-47be-95bf-0f9e32226746: Started
2023-03-20 21:34:53,304 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 044bfaef-c902-47be-95bf-0f9e32226746 is started using port 43085 for RATIS_DATASTREAM
2023-03-20 21:34:53,306 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 044bfaef-c902-47be-95bf-0f9e32226746 is started using port 37513
2023-03-20 21:34:53,306 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:53,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:53,352 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-03-20 21:34:53,352 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=1, replicaIndex=0, sourceNodes=[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL to 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10)
2023-03-20 21:34:53,352 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2023-03-20 21:34:53,352 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=2, replicaIndex=0, sourceNodes=[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL to 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)
2023-03-20 21:34:53,352 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2023-03-20 21:34:53,352 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=3, replicaIndex=0, sourceNodes=[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL to 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10)
2023-03-20 21:34:53,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-20 21:34:53,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:53,640 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-2cdea61d-5909-4d43-b1b1-7703cc320be8/container.db to cache
2023-03-20 21:34:53,640 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-2cdea61d-5909-4d43-b1b1-7703cc320be8/container.db for volume DS-2cdea61d-5909-4d43-b1b1-7703cc320be8
2023-03-20 21:34:53,641 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:53,641 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:53,641 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 43575
2023-03-20 21:34:53,648 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:34:53,658 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: start RPC server
2023-03-20 21:34:53,658 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: GrpcService started, listening on 42673
2023-03-20 21:34:53,663 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290 is started using port 42673 for RATIS
2023-03-20 21:34:53,663 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290 is started using port 42673 for RATIS_ADMIN
2023-03-20 21:34:53,663 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290 is started using port 42673 for RATIS_SERVER
2023-03-20 21:34:53,663 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290 is started using port 42991 for RATIS_DATASTREAM
2023-03-20 21:34:53,663 [JvmPauseMonitor106] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: Started
2023-03-20 21:34:53,664 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290 is started using port 39513
2023-03-20 21:34:53,665 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:53,920 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-20 21:34:53,920 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:53,920 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:53,954 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-22a0dfc8-6941-416a-a056-4855a2d6bff9/container.db to cache
2023-03-20 21:34:53,954 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(350)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-22a0dfc8-6941-416a-a056-4855a2d6bff9/container.db for volume DS-22a0dfc8-6941-416a-a056-4855a2d6bff9
2023-03-20 21:34:53,955 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-20 21:34:53,955 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-20 21:34:53,956 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 45361
2023-03-20 21:34:53,956 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis aa2150a1-a93c-4d22-b89f-1d3c6aa7832d
2023-03-20 21:34:53,956 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: start RPC server
2023-03-20 21:34:53,957 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: GrpcService started, listening on 34025
2023-03-20 21:34:53,957 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis aa2150a1-a93c-4d22-b89f-1d3c6aa7832d is started using port 34025 for RATIS
2023-03-20 21:34:53,957 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis aa2150a1-a93c-4d22-b89f-1d3c6aa7832d is started using port 34025 for RATIS_ADMIN
2023-03-20 21:34:53,957 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis aa2150a1-a93c-4d22-b89f-1d3c6aa7832d is started using port 34025 for RATIS_SERVER
2023-03-20 21:34:53,957 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis aa2150a1-a93c-4d22-b89f-1d3c6aa7832d is started using port 43725 for RATIS_DATASTREAM
2023-03-20 21:34:53,957 [JvmPauseMonitor107] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: Started
2023-03-20 21:34:53,957 [EndpointStateMachine task thread for /0.0.0.0:42017 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc aa2150a1-a93c-4d22-b89f-1d3c6aa7832d is started using port 42835
2023-03-20 21:34:53,958 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:34:53,965 [IPC Server handler 19 on default port 42017] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:34:53,965 [IPC Server handler 19 on default port 42017] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 3b791506-899f-4927-929a-007385ffa693{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45597, RATIS=39897, RATIS_ADMIN=39897, RATIS_SERVER=39897, RATIS_DATASTREAM=39527, STANDALONE=37373], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:53,976 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-20 21:34:53,976 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-20 21:34:53,977 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:53,979 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=7676672b-f26c-4de6-85a4-0f06956c75ec to datanode:3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:34:53,979 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 7676672b-f26c-4de6-85a4-0f06956c75ec, Nodes: 3b791506-899f-4927-929a-007385ffa693(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:53.979Z[Etc/UTC]].
2023-03-20 21:34:53,983 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-20 21:34:54,276 [IPC Server handler 18 on default port 42017] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/73dcf697-4659-4759-9fac-94f9a54bb6a2
2023-03-20 21:34:54,276 [IPC Server handler 18 on default port 42017] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 73dcf697-4659-4759-9fac-94f9a54bb6a2{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=33321, RATIS=35611, RATIS_ADMIN=35611, RATIS_SERVER=35611, RATIS_DATASTREAM=34585, STANDALONE=32807], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:54,277 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:54,277 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-20 21:34:54,279 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=6b03a966-17e8-4e27-8dd6-fd49e628281d to datanode:73dcf697-4659-4759-9fac-94f9a54bb6a2
2023-03-20 21:34:54,279 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 6b03a966-17e8-4e27-8dd6-fd49e628281d, Nodes: 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:54.279Z[Etc/UTC]].
2023-03-20 21:34:54,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:54,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-20 21:34:54,378 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState: change to CANDIDATE, lastRpcElapsedTime:10398188885ns, electionTimeout:5040ms
2023-03-20 21:34:54,378 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc: shutdown a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState
2023-03-20 21:34:54,378 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:54,378 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:54,378 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc: start a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164
2023-03-20 21:34:54,379 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a0d6486e-58e7-45ac-85b3-704c8b479dbc|rpc:10.1.0.10:35909|dataStream:10.1.0.10:38747|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:54,379 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:54,380 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a0d6486e-58e7-45ac-85b3-704c8b479dbc|rpc:10.1.0.10:35909|dataStream:10.1.0.10:38747|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:54,380 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:54,380 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc: shutdown a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164
2023-03-20 21:34:54,380 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:54,380 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-56FD36C5E925 with new leaderId: a0d6486e-58e7-45ac-85b3-704c8b479dbc
2023-03-20 21:34:54,380 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925: change Leader from null to a0d6486e-58e7-45ac-85b3-704c8b479dbc at term 1 for becomeLeader, leader elected after 10422ms
2023-03-20 21:34:54,380 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:54,380 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:54,381 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:54,381 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:54,381 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:54,381 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:54,381 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:54,381 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:54,381 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc: start a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderStateImpl
2023-03-20 21:34:54,381 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:54,382 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-LeaderElection164] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925: set configuration 0: peers:[a0d6486e-58e7-45ac-85b3-704c8b479dbc|rpc:10.1.0.10:35909|dataStream:10.1.0.10:38747|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:54,382 [a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - a0d6486e-58e7-45ac-85b3-704c8b479dbc@group-56FD36C5E925-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-6/data/ratis/d2890860-ad4b-4fae-b8b5-56fd36c5e925/current/log_inprogress_0
2023-03-20 21:34:54,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:54,503 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:10629337739ns, electionTimeout:5165ms
2023-03-20 21:34:54,503 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2325b755-97f4-4680-bb9e-067434f11ceb: shutdown 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState
2023-03-20 21:34:54,503 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:34:54,503 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:54,503 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2325b755-97f4-4680-bb9e-067434f11ceb: start 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165
2023-03-20 21:34:54,504 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:54,504 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:34:54,505 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165 ELECTION round 0: submit vote requests at term 1 for -1: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:54,505 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:34:54,505 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 2325b755-97f4-4680-bb9e-067434f11ceb: shutdown 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165
2023-03-20 21:34:54,505 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:34:54,505 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-9E114AB0A66D with new leaderId: 2325b755-97f4-4680-bb9e-067434f11ceb
2023-03-20 21:34:54,505 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D: change Leader from null to 2325b755-97f4-4680-bb9e-067434f11ceb at term 1 for becomeLeader, leader elected after 10650ms
2023-03-20 21:34:54,505 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2325b755-97f4-4680-bb9e-067434f11ceb: start 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderStateImpl
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:34:54,506 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-LeaderElection165] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D: set configuration 0: peers:[2325b755-97f4-4680-bb9e-067434f11ceb|rpc:10.1.0.10:35621|dataStream:10.1.0.10:34971|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:54,507 [2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 2325b755-97f4-4680-bb9e-067434f11ceb@group-9E114AB0A66D-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-0e175259-c50f-4ed4-a7b6-aa91f131c8fc/datanode-5/data/ratis/2a3c50ea-0bfe-4ce8-9652-9e114ab0a66d/current/log_inprogress_0
2023-03-20 21:34:54,592 [IPC Server handler 17 on default port 42017] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:34:54,593 [IPC Server handler 17 on default port 42017] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 9d2a4ecd-2086-4135-bf3e-5d16e44246f0{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45235, RATIS=45377, RATIS_ADMIN=45377, RATIS_SERVER=45377, RATIS_DATASTREAM=45553, STANDALONE=38887], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:54,595 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-20 21:34:54,595 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-20 21:34:54,595 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-20 21:34:54,595 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-20 21:34:54,597 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:54,598 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=ef3b8ebd-9c2c-493c-8e29-759350b1dafb to datanode:9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:34:54,598 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: ef3b8ebd-9c2c-493c-8e29-759350b1dafb, Nodes: 9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:54.598Z[Etc/UTC]].
2023-03-20 21:34:54,598 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec to datanode:73dcf697-4659-4759-9fac-94f9a54bb6a2
2023-03-20 21:34:54,598 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec to datanode:3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:34:54,598 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec to datanode:9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:34:54,598 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: f3aa6e2d-4ee0-422f-8d86-16f0494636ec, Nodes: 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10)3b791506-899f-4927-929a-007385ffa693(fv-az985-449/10.1.0.10)9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:54.598Z[Etc/UTC]].
2023-03-20 21:34:54,598 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:54,599 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:54,599 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:54,920 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - Waiting for nodes to be ready. Got 3 of 7 DN Heartbeats.
2023-03-20 21:34:54,920 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(225)) - Waiting for cluster to exit safe mode
2023-03-20 21:34:54,920 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - SCM became leader
2023-03-20 21:34:54,931 [IPC Server handler 19 on default port 42017] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/00867d28-7830-4d3d-a4c5-0b9d063e06a7
2023-03-20 21:34:54,931 [IPC Server handler 19 on default port 42017] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 00867d28-7830-4d3d-a4c5-0b9d063e06a7{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=42899, RATIS=46797, RATIS_ADMIN=46797, RATIS_SERVER=46797, RATIS_DATASTREAM=39523, STANDALONE=32967], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:54,932 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:54,934 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=12679b56-4620-40d1-a69e-471ee388a400 to datanode:00867d28-7830-4d3d-a4c5-0b9d063e06a7
2023-03-20 21:34:54,934 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 12679b56-4620-40d1-a69e-471ee388a400, Nodes: 00867d28-7830-4d3d-a4c5-0b9d063e06a7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:54.934Z[Etc/UTC]].
2023-03-20 21:34:54,934 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:34:55,271 [IPC Server handler 18 on default port 42017] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/044bfaef-c902-47be-95bf-0f9e32226746
2023-03-20 21:34:55,271 [IPC Server handler 18 on default port 42017] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 044bfaef-c902-47be-95bf-0f9e32226746{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45707, RATIS=40849, RATIS_ADMIN=40849, RATIS_SERVER=40849, RATIS_DATASTREAM=43085, STANDALONE=37513], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:55,271 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:55,271 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=ed7691cd-5074-4d34-98b8-c2b03a89663d to datanode:044bfaef-c902-47be-95bf-0f9e32226746
2023-03-20 21:34:55,272 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: ed7691cd-5074-4d34-98b8-c2b03a89663d, Nodes: 044bfaef-c902-47be-95bf-0f9e32226746(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:55.271Z[Etc/UTC]].
2023-03-20 21:34:55,272 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2023-03-20 21:34:55,339 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 3 from [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)] using NO_COMPRESSION
2023-03-20 21:34:55,340 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 1 from [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)] using NO_COMPRESSION
2023-03-20 21:34:55,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:55,343 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 2 from [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)] using NO_COMPRESSION
2023-03-20 21:34:55,352 [grpc-default-executor-0] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(62)) - Streaming container data (3) to other datanode with compression NO_COMPRESSION
2023-03-20 21:34:55,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:34:55,356 [grpc-default-executor-3] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(62)) - Streaming container data (2) to other datanode with compression NO_COMPRESSION
2023-03-20 21:34:55,356 [grpc-default-executor-1] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(62)) - Streaming container data (1) to other datanode with compression NO_COMPRESSION
2023-03-20 21:34:55,383 [grpc-default-executor-1] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(111)) - Sent 12800 bytes for container 1
2023-03-20 21:34:55,385 [grpc-default-executor-3] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(111)) - Sent 12800 bytes for container 2
2023-03-20 21:34:55,385 [grpc-default-executor-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(111)) - Sent 11776 bytes for container 3
2023-03-20 21:34:55,385 [grpc-default-executor-4] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(218)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data-0/containers/tmp/container-copy/container-2.tar
2023-03-20 21:34:55,387 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 2 is downloaded with size 12800, starting to import.
2023-03-20 21:34:55,390 [grpc-default-executor-4] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(218)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/tmp/container-copy/container-3.tar
2023-03-20 21:34:55,390 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 3 is downloaded with size 11776, starting to import.
2023-03-20 21:34:55,392 [grpc-default-executor-1] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(218)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/tmp/container-copy/container-1.tar
2023-03-20 21:34:55,392 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 1 is downloaded with size 12800, starting to import.
2023-03-20 21:34:55,420 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 3 is replicated successfully
2023-03-20 21:34:55,420 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(220)) - Successful DONE replicateContainerCommand: containerId=3, replicaIndex=0, sourceNodes=[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL, transferred 11776 bytes
2023-03-20 21:34:55,427 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 1 is replicated successfully
2023-03-20 21:34:55,427 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(220)) - Successful DONE replicateContainerCommand: containerId=1, replicaIndex=0, sourceNodes=[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL, transferred 12800 bytes
2023-03-20 21:34:55,429 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 2 is replicated successfully
2023-03-20 21:34:55,429 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(220)) - Successful DONE replicateContainerCommand: containerId=2, replicaIndex=0, sourceNodes=[ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL, transferred 12800 bytes
2023-03-20 21:34:55,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:55,549 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(455)) - Shutting down the Mini Ozone Cluster
2023-03-20 21:34:55,551 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(471)) - Stopping the Mini Ozone Cluster
2023-03-20 21:34:55,551 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(553)) - Stopping the OzoneManager
2023-03-20 21:34:55,551 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(2166)) - om1[localhost:0]: Stopping Ozone Manager
2023-03-20 21:34:55,553 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 46711
2023-03-20 21:34:55,556 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(455)) - Shutting down the Mini Ozone Cluster
2023-03-20 21:34:55,556 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(471)) - Stopping the Mini Ozone Cluster
2023-03-20 21:34:55,556 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(553)) - Stopping the OzoneManager
2023-03-20 21:34:55,556 [Listener at 127.0.0.1/40507] INFO  om.OzoneManager (OzoneManager.java:stop(2166)) - om1[localhost:0]: Stopping Ozone Manager
2023-03-20 21:34:55,556 [Listener at 127.0.0.1/40507] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 40507
2023-03-20 21:34:55,557 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-20 21:34:55,558 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:34:55,559 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-03-20 21:34:55,559 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:55,559 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-03-20 21:34:55,559 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-03-20 21:34:55,559 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-03-20 21:34:55,560 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:55,560 [om1-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-03-20 21:34:55,571 [om1-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 84
2023-03-20 21:34:55,571 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:84)
2023-03-20 21:34:55,573 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:34:55,573 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-20 21:34:55,573 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-03-20 21:34:55,573 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:55,573 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-03-20 21:34:55,574 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-03-20 21:34:55,574 [om1-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-03-20 21:34:55,574 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:55,574 [om1-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:34:55,574 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:0)
2023-03-20 21:34:55,584 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:34:55,584 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:34:55,584 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-20 21:34:55,584 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(540)) - Stopping OMDoubleBuffer flush thread
2023-03-20 21:34:55,584 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(625)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-03-20 21:34:55,586 [om1-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 0
2023-03-20 21:34:55,586 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:55,586 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-03-20 21:34:55,587 [JvmPauseMonitor100] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-03-20 21:34:55,587 [Listener at 127.0.0.1/40507] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-20 21:34:55,587 [Listener at 127.0.0.1/40507] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(549)) - OMDoubleBuffer flush thread is not running.
2023-03-20 21:34:55,587 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-03-20 21:34:55,587 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-03-20 21:34:55,587 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-03-20 21:34:55,587 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-03-20 21:34:55,587 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SnapshotDeletingService
2023-03-20 21:34:55,588 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@673f7fb2{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-20 21:34:55,588 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@57e39b3c{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:55,588 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:55,588 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3b472901{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-20 21:34:55,588 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2356f6ac{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:55,593 [Listener at 127.0.0.1/40507] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(530)) - Stopping the HddsDatanodes
2023-03-20 21:34:55,594 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:34:55,595 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 73dcf697-4659-4759-9fac-94f9a54bb6a2: close
2023-03-20 21:34:55,595 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 73dcf697-4659-4759-9fac-94f9a54bb6a2: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:55,595 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 73dcf697-4659-4759-9fac-94f9a54bb6a2: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:55,595 [73dcf697-4659-4759-9fac-94f9a54bb6a2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe1ffbdcc, L:/0:0:0:0:0:0:0:0:34585] CLOSE
2023-03-20 21:34:55,595 [73dcf697-4659-4759-9fac-94f9a54bb6a2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe1ffbdcc, L:/0:0:0:0:0:0:0:0:34585] INACTIVE
2023-03-20 21:34:55,595 [73dcf697-4659-4759-9fac-94f9a54bb6a2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe1ffbdcc, L:/0:0:0:0:0:0:0:0:34585] UNREGISTERED
2023-03-20 21:34:55,596 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:34:55,596 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 044bfaef-c902-47be-95bf-0f9e32226746: close
2023-03-20 21:34:55,596 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 044bfaef-c902-47be-95bf-0f9e32226746: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:55,596 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 044bfaef-c902-47be-95bf-0f9e32226746: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:55,596 [044bfaef-c902-47be-95bf-0f9e32226746-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb5c03eb0, L:/0:0:0:0:0:0:0:0:43085] CLOSE
2023-03-20 21:34:55,596 [044bfaef-c902-47be-95bf-0f9e32226746-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb5c03eb0, L:/0:0:0:0:0:0:0:0:43085] INACTIVE
2023-03-20 21:34:55,596 [044bfaef-c902-47be-95bf-0f9e32226746-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb5c03eb0, L:/0:0:0:0:0:0:0:0:43085] UNREGISTERED
2023-03-20 21:34:55,599 [JvmPauseMonitor102] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-73dcf697-4659-4759-9fac-94f9a54bb6a2: Stopped
2023-03-20 21:34:55,603 [JvmPauseMonitor105] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-044bfaef-c902-47be-95bf-0f9e32226746: Stopped
2023-03-20 21:34:55,605 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 84
2023-03-20 21:34:55,605 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 84
2023-03-20 21:34:55,606 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-20 21:34:55,606 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(540)) - Stopping OMDoubleBuffer flush thread
2023-03-20 21:34:55,606 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(625)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-03-20 21:34:55,608 [om1-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 84
2023-03-20 21:34:55,608 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:55,609 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-03-20 21:34:55,609 [JvmPauseMonitor84] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-03-20 21:34:55,609 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-20 21:34:55,609 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(549)) - OMDoubleBuffer flush thread is not running.
2023-03-20 21:34:55,609 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-03-20 21:34:55,609 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-03-20 21:34:55,609 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-03-20 21:34:55,610 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-03-20 21:34:55,610 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SnapshotDeletingService
2023-03-20 21:34:55,614 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2af92681{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-20 21:34:55,615 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4086fe38{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:55,615 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:55,616 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5ec74c0c{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-20 21:34:55,618 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7ba2fed2{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:55,619 [IPC Server handler 13 on default port 42017] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:34:55,619 [IPC Server handler 13 on default port 42017] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=43575, RATIS=42673, RATIS_ADMIN=42673, RATIS_SERVER=42673, RATIS_DATASTREAM=42991, STANDALONE=39513], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:55,619 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:55,620 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=d4b1331b-98d7-4407-82d1-c18179e38b46 to datanode:1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:34:55,620 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: d4b1331b-98d7-4407-82d1-c18179e38b46, Nodes: 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:55.620Z[Etc/UTC]].
2023-03-20 21:34:55,620 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1 to datanode:1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:34:55,620 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1 to datanode:044bfaef-c902-47be-95bf-0f9e32226746
2023-03-20 21:34:55,620 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1 to datanode:00867d28-7830-4d3d-a4c5-0b9d063e06a7
2023-03-20 21:34:55,621 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1, Nodes: 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290(fv-az985-449/10.1.0.10)044bfaef-c902-47be-95bf-0f9e32226746(fv-az985-449/10.1.0.10)00867d28-7830-4d3d-a4c5-0b9d063e06a7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:55.620Z[Etc/UTC]].
2023-03-20 21:34:55,621 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-20 21:34:55,629 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(530)) - Stopping the HddsDatanodes
2023-03-20 21:34:55,630 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:34:55,631 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - c2f44316-1a3e-468b-9a76-53c43d628173: close
2023-03-20 21:34:55,631 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2: shutdown
2023-03-20 21:34:55,631 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - c2f44316-1a3e-468b-9a76-53c43d628173: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:55,631 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-712CDE8CCBF2,id=c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:55,631 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c2f44316-1a3e-468b-9a76-53c43d628173: shutdown c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-LeaderStateImpl
2023-03-20 21:34:55,631 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-PendingRequests: sendNotLeaderResponses
2023-03-20 21:34:55,631 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: shutdown
2023-03-20 21:34:55,631 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:34:55,632 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-712CDE8CCBF2: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/c405d3a8-315a-4fbf-b7da-712cde8ccbf2/sm/snapshot.1_0
2023-03-20 21:34:55,632 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-08F3B6F653FF,id=c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:55,632 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c2f44316-1a3e-468b-9a76-53c43d628173: shutdown c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-LeaderStateImpl
2023-03-20 21:34:55,632 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-20 21:34:55,632 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->9ce389bc-6c47-40b9-aa21-f44fc17fd7db-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->9ce389bc-6c47-40b9-aa21-f44fc17fd7db-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-20 21:34:55,632 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-712CDE8CCBF2: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/c405d3a8-315a-4fbf-b7da-712cde8ccbf2/sm/snapshot.1_0 took: 1 ms
2023-03-20 21:34:55,632 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: Completed APPEND_ENTRIES, lastRequest: c2f44316-1a3e-468b-9a76-53c43d628173->6b93f795-e4f1-4cdd-8e17-5fb6627a9a38#106-t1,previous=(t:1, i:34),leaderCommit=34,initializing? true,entries: size=1, first=(t:1, i:35), METADATAENTRY(c:34)
2023-03-20 21:34:55,633 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: Completed APPEND_ENTRIES, lastRequest: c2f44316-1a3e-468b-9a76-53c43d628173->9ce389bc-6c47-40b9-aa21-f44fc17fd7db#100-t1,previous=(t:1, i:34),leaderCommit=34,initializing? true,entries: size=1, first=(t:1, i:35), METADATAENTRY(c:34)
2023-03-20 21:34:55,633 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:34:55,633 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:34:55,633 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: Completed APPEND_ENTRIES, lastRequest: null
2023-03-20 21:34:55,633 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-PendingRequests: sendNotLeaderResponses
2023-03-20 21:34:55,633 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: Completed APPEND_ENTRIES, lastRequest: null
2023-03-20 21:34:55,633 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->9ce389bc-6c47-40b9-aa21-f44fc17fd7db-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-20 21:34:55,633 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->9ce389bc-6c47-40b9-aa21-f44fc17fd7db: nextIndex: updateUnconditionally 36 -> 35
2023-03-20 21:34:55,633 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-20 21:34:55,634 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: nextIndex: updateUnconditionally 36 -> 35
2023-03-20 21:34:55,634 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->9ce389bc-6c47-40b9-aa21-f44fc17fd7db-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-20 21:34:55,634 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->9ce389bc-6c47-40b9-aa21-f44fc17fd7db: nextIndex: updateUnconditionally 35 -> 34
2023-03-20 21:34:55,634 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-20 21:34:55,634 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF->6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: nextIndex: updateUnconditionally 35 -> 34
2023-03-20 21:34:55,634 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2: closes. applyIndex: 0
2023-03-20 21:34:55,634 [c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:55,636 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-712CDE8CCBF2-SegmentedRaftLogWorker close()
2023-03-20 21:34:55,638 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38 Close channels
2023-03-20 21:34:55,639 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-StateMachineUpdater: set stopIndex = 35
2023-03-20 21:34:55,639 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-08F3B6F653FF: Taking a snapshot at:(t:1, i:35) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/sm/snapshot.1_35
2023-03-20 21:34:55,640 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-08F3B6F653FF: Finished taking a snapshot at:(t:1, i:35) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/sm/snapshot.1_35 took: 1 ms
2023-03-20 21:34:55,641 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-StateMachineUpdater: Took a snapshot at index 35
2023-03-20 21:34:55,641 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 35
2023-03-20 21:34:55,642 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db Close channels
2023-03-20 21:34:55,642 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - c2f44316-1a3e-468b-9a76-53c43d628173: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:55,643 [c2f44316-1a3e-468b-9a76-53c43d628173-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdd696339, L:/0:0:0:0:0:0:0:0:40549] CLOSE
2023-03-20 21:34:55,643 [c2f44316-1a3e-468b-9a76-53c43d628173-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdd696339, L:/0:0:0:0:0:0:0:0:40549] INACTIVE
2023-03-20 21:34:55,643 [c2f44316-1a3e-468b-9a76-53c43d628173-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdd696339, L:/0:0:0:0:0:0:0:0:40549] UNREGISTERED
2023-03-20 21:34:55,644 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF: closes. applyIndex: 35
2023-03-20 21:34:55,644 [c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:55,645 [c2f44316-1a3e-468b-9a76-53c43d628173-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c2f44316-1a3e-468b-9a76-53c43d628173@group-08F3B6F653FF-SegmentedRaftLogWorker close()
2023-03-20 21:34:55,647 [JvmPauseMonitor89] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-c2f44316-1a3e-468b-9a76-53c43d628173: Stopped
2023-03-20 21:34:55,931 [IPC Server handler 19 on default port 42017] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/aa2150a1-a93c-4d22-b89f-1d3c6aa7832d
2023-03-20 21:34:55,931 [IPC Server handler 19 on default port 42017] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : aa2150a1-a93c-4d22-b89f-1d3c6aa7832d{ip: 10.1.0.10, host: fv-az985-449, ports: [REPLICATION=45361, RATIS=34025, RATIS_ADMIN=34025, RATIS_SERVER=34025, RATIS_DATASTREAM=43725, STANDALONE=42835], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-20 21:34:55,934 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-20 21:34:55,934 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=2160d91c-69ee-41f2-9c3a-c7aebff4b3d5 to datanode:aa2150a1-a93c-4d22-b89f-1d3c6aa7832d
2023-03-20 21:34:55,934 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 2160d91c-69ee-41f2-9c3a-c7aebff4b3d5, Nodes: aa2150a1-a93c-4d22-b89f-1d3c6aa7832d(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:55.934Z[Etc/UTC]].
2023-03-20 21:34:55,934 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:34:56,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:56,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:34:56,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:56,965 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3b791506-899f-4927-929a-007385ffa693: addNew group-0F06956C75EC:[3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER] returns group-0F06956C75EC:java.util.concurrent.CompletableFuture@75b0de34[Not completed]
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 3b791506-899f-4927-929a-007385ffa693: new RaftServerImpl for group-0F06956C75EC:[3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC: ConfigurationManager, init=-1: peers:[3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis] (custom)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:56,966 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:56,968 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:56,968 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:56,968 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:56,968 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:56,968 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:56,968 [pool-4631-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/7676672b-f26c-4de6-85a4-0f06956c75ec does not exist. Creating ...
2023-03-20 21:34:56,969 [pool-4631-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/7676672b-f26c-4de6-85a4-0f06956c75ec/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:56,970 [pool-4631-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/7676672b-f26c-4de6-85a4-0f06956c75ec has been successfully formatted.
2023-03-20 21:34:56,970 [pool-4631-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-0F06956C75EC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:56,970 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:56,971 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:56,971 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:56,971 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:56,971 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:56,971 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 7676672b-f26c-4de6-85a4-0f06956c75ec, Nodes: 3b791506-899f-4927-929a-007385ffa693(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3b791506-899f-4927-929a-007385ffa693, CreationTimestamp2023-03-20T21:34:53.979Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:56,971 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/7676672b-f26c-4de6-85a4-0f06956c75ec
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:56,976 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:56,976 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:56,977 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:56,977 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:56,980 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:56,980 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:56,980 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:56,980 [pool-4631-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:56,980 [pool-4631-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:56,980 [pool-4631-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC: start as a follower, conf=-1: peers:[3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:56,980 [pool-4631-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:56,980 [pool-4631-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState
2023-03-20 21:34:56,981 [pool-4631-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F06956C75EC,id=3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:34:56,981 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:56,981 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:56,981 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:56,981 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:56,981 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:56,981 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:56,981 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=7676672b-f26c-4de6-85a4-0f06956c75ec
2023-03-20 21:34:56,981 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=7676672b-f26c-4de6-85a4-0f06956c75ec.
2023-03-20 21:34:56,982 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3b791506-899f-4927-929a-007385ffa693: addNew group-16F0494636EC:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER] returns group-16F0494636EC:java.util.concurrent.CompletableFuture@718f445a[Not completed]
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 3b791506-899f-4927-929a-007385ffa693: new RaftServerImpl for group-16F0494636EC:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: ConfigurationManager, init=-1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis] (custom)
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:56,982 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:56,983 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:56,983 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:56,984 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:56,984 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:56,984 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:56,984 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:56,984 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:56,984 [pool-4631-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/f3aa6e2d-4ee0-422f-8d86-16f0494636ec does not exist. Creating ...
2023-03-20 21:34:56,985 [pool-4631-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/f3aa6e2d-4ee0-422f-8d86-16f0494636ec/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:56,986 [pool-4631-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/f3aa6e2d-4ee0-422f-8d86-16f0494636ec has been successfully formatted.
2023-03-20 21:34:56,986 [pool-4631-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-16F0494636EC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:56,986 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:56,986 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:56,986 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/f3aa6e2d-4ee0-422f-8d86-16f0494636ec
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:56,987 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:56,988 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:56,988 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:56,988 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:56,988 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:56,988 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:56,989 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:56,989 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:56,992 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:56,992 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:56,992 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:56,992 [pool-4631-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:56,992 [pool-4631-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:56,992 [pool-4631-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: start as a follower, conf=-1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:56,992 [pool-4631-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:56,993 [pool-4631-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:34:56,993 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:56,993 [pool-4631-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-16F0494636EC,id=3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:34:56,993 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:56,993 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:56,993 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:56,993 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:56,993 [pool-4631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:56,993 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec
2023-03-20 21:34:57,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:57,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-20 21:34:57,367 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=6b03a966-17e8-4e27-8dd6-fd49e628281d, PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec]
2023-03-20 21:34:57,368 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 6b03a966-17e8-4e27-8dd6-fd49e628281d, Nodes: 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:54.279Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:34:57,368 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: f3aa6e2d-4ee0-422f-8d86-16f0494636ec, Nodes: 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10)3b791506-899f-4927-929a-007385ffa693(fv-az985-449/10.1.0.10)9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:54.598Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:34:57,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:57,593 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: addNew group-759350B1DAFB:[9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:1|startupRole:FOLLOWER] returns group-759350B1DAFB:java.util.concurrent.CompletableFuture@680ec4c3[Not completed]
2023-03-20 21:34:57,593 [pool-4675-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: new RaftServerImpl for group-759350B1DAFB:[9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB: ConfigurationManager, init=-1: peers:[9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis] (custom)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:57,594 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:57,595 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:57,595 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:57,596 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:57,596 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:57,596 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:57,596 [pool-4675-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis/ef3b8ebd-9c2c-493c-8e29-759350b1dafb does not exist. Creating ...
2023-03-20 21:34:57,598 [pool-4675-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis/ef3b8ebd-9c2c-493c-8e29-759350b1dafb/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:57,599 [pool-4675-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis/ef3b8ebd-9c2c-493c-8e29-759350b1dafb has been successfully formatted.
2023-03-20 21:34:57,599 [pool-4675-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-759350B1DAFB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:57,599 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:57,599 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:57,599 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:57,599 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:57,599 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:57,599 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: ef3b8ebd-9c2c-493c-8e29-759350b1dafb, Nodes: 9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9d2a4ecd-2086-4135-bf3e-5d16e44246f0, CreationTimestamp2023-03-20T21:34:54.598Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:57,599 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:57,599 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis/ef3b8ebd-9c2c-493c-8e29-759350b1dafb
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:57,600 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:57,601 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:57,602 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:57,606 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:57,606 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:57,606 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:57,607 [pool-4675-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:57,607 [pool-4675-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:57,625 [pool-4675-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB: start as a follower, conf=-1: peers:[9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:57,630 [pool-4675-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:57,630 [pool-4675-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: start 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-FollowerState
2023-03-20 21:34:57,627 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-1/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-f849356c-d112-4ce6-8660-a8a9b3372e5b/container.db for volume DS-f849356c-d112-4ce6-8660-a8a9b3372e5b
2023-03-20 21:34:57,630 [pool-4675-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-759350B1DAFB,id=9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:34:57,630 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:57,630 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:57,630 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:57,630 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-4/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-6a65693e-c212-4da9-8209-7347a08c7dfb/container.db for volume DS-6a65693e-c212-4da9-8209-7347a08c7dfb
2023-03-20 21:34:57,630 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:34:57,630 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:57,631 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:34:57,632 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:34:57,632 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:34:57,637 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:57,637 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:34:57,637 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:57,637 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=ef3b8ebd-9c2c-493c-8e29-759350b1dafb
2023-03-20 21:34:57,637 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=ef3b8ebd-9c2c-493c-8e29-759350b1dafb.
2023-03-20 21:34:57,637 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: addNew group-16F0494636EC:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER] returns group-16F0494636EC:java.util.concurrent.CompletableFuture@6c314d1a[Not completed]
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: new RaftServerImpl for group-16F0494636EC:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC: ConfigurationManager, init=-1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis] (custom)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:57,649 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:57,650 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:57,651 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:57,651 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:57,651 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:57,651 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:57,651 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:57,652 [pool-4675-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis/f3aa6e2d-4ee0-422f-8d86-16f0494636ec does not exist. Creating ...
2023-03-20 21:34:57,653 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-4/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-fc367b51-928d-4514-887e-fae107276260/container.db for volume DS-fc367b51-928d-4514-887e-fae107276260
2023-03-20 21:34:57,653 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:34:57,655 [pool-4675-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis/f3aa6e2d-4ee0-422f-8d86-16f0494636ec/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:57,655 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:34:57,656 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:34:57,657 [pool-4675-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis/f3aa6e2d-4ee0-422f-8d86-16f0494636ec has been successfully formatted.
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-16F0494636EC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data/ratis/f3aa6e2d-4ee0-422f-8d86-16f0494636ec
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:57,658 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:57,659 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:57,659 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:57,659 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:57,659 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:57,660 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@d7e1596{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:57,660 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:57,660 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:57,661 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5b9dcf1e{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:57,661 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:57,661 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7d43721c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:34:57,661 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5fa9911e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:57,663 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:57,663 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:57,663 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:57,663 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:34:57,663 [pool-4675-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:57,664 [pool-4675-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:57,664 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 00867d28-7830-4d3d-a4c5-0b9d063e06a7: close
2023-03-20 21:34:57,664 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 00867d28-7830-4d3d-a4c5-0b9d063e06a7: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:57,664 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 00867d28-7830-4d3d-a4c5-0b9d063e06a7: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:57,664 [00867d28-7830-4d3d-a4c5-0b9d063e06a7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x68bb225f, L:/0:0:0:0:0:0:0:0:39523] CLOSE
2023-03-20 21:34:57,664 [pool-4675-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC: start as a follower, conf=-1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:57,668 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:34:57,668 [pool-4675-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:57,668 [pool-4675-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: start 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-FollowerState
2023-03-20 21:34:57,664 [00867d28-7830-4d3d-a4c5-0b9d063e06a7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x68bb225f, L:/0:0:0:0:0:0:0:0:39523] INACTIVE
2023-03-20 21:34:57,670 [00867d28-7830-4d3d-a4c5-0b9d063e06a7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x68bb225f, L:/0:0:0:0:0:0:0:0:39523] UNREGISTERED
2023-03-20 21:34:57,672 [pool-4675-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-16F0494636EC,id=9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:34:57,672 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:57,672 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:57,672 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:57,672 [pool-4675-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:57,673 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:57,673 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:57,689 [JvmPauseMonitor104] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-00867d28-7830-4d3d-a4c5-0b9d063e06a7: Stopped
2023-03-20 21:34:57,689 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec
2023-03-20 21:34:57,694 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1b700167{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:57,696 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5498c10b{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:57,728 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3faa7ee4{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:57,728 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@7a6dbc6f{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:57,728 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:57,729 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:57,735 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@72c9cc18{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:34:57,735 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@665e141b{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:34:57,737 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4057ea39{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:57,737 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@430b31b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:57,740 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:34:57,741 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:34:57,741 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: close
2023-03-20 21:34:57,742 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC: shutdown
2023-03-20 21:34:57,742 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-16F0494636EC,id=9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:34:57,742 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: shutdown 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-FollowerState
2023-03-20 21:34:57,743 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: close
2023-03-20 21:34:57,745 [Command processor thread] WARN  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$1(110)) - Add group failed for 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10)
java.io.InterruptedIOException: retry policy=RequestTypeDependentRetryPolicy{WRITE->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@1bf40509, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->org.apache.ratis.retry.ExponentialBackoffRetry@1bf40509}), WATCH->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@1bf40509, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->NoRetry})}
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:125)
	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:106)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:102)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:642)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:34:57,751 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:57,752 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:57,752 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xead6c73f, L:/0:0:0:0:0:0:0:0:45553] CLOSE
2023-03-20 21:34:57,752 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB: shutdown
2023-03-20 21:34:57,752 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xead6c73f, L:/0:0:0:0:0:0:0:0:45553] INACTIVE
2023-03-20 21:34:57,752 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xead6c73f, L:/0:0:0:0:0:0:0:0:45553] UNREGISTERED
2023-03-20 21:34:57,752 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-759350B1DAFB,id=9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:34:57,752 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0: shutdown 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-FollowerState
2023-03-20 21:34:57,755 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: shutdown
2023-03-20 21:34:57,755 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-08F3B6F653FF,id=9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:57,755 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: shutdown 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:57,758 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:57,759 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-StateMachineUpdater: set stopIndex = -1
2023-03-20 21:34:57,759 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-FollowerState was interrupted
2023-03-20 21:34:57,776 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E: shutdown
2023-03-20 21:34:57,776 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-50915993717E,id=9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:57,776 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: shutdown 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-LeaderStateImpl
2023-03-20 21:34:57,776 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-PendingRequests: sendNotLeaderResponses
2023-03-20 21:34:57,776 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:34:57,770 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-08F3B6F653FF: Taking a snapshot at:(t:1, i:35) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/sm/snapshot.1_35
2023-03-20 21:34:57,777 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-50915993717E: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/402930f6-6fce-4ea8-a53b-50915993717e/sm/snapshot.1_0
2023-03-20 21:34:57,770 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-FollowerState was interrupted
2023-03-20 21:34:57,770 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-FollowerState was interrupted
2023-03-20 21:34:57,770 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-StateMachineUpdater: set stopIndex = -1
2023-03-20 21:34:57,777 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB: closes. applyIndex: -1
2023-03-20 21:34:57,770 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-StateMachineUpdater: set stopIndex = 35
2023-03-20 21:34:57,778 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-50915993717E: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/402930f6-6fce-4ea8-a53b-50915993717e/sm/snapshot.1_0 took: 2 ms
2023-03-20 21:34:57,778 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-08F3B6F653FF: Finished taking a snapshot at:(t:1, i:35) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/sm/snapshot.1_35 took: 9 ms
2023-03-20 21:34:57,779 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:34:57,779 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:34:57,779 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-StateMachineUpdater: Took a snapshot at index 35
2023-03-20 21:34:57,779 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 35
2023-03-20 21:34:57,779 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E: closes. applyIndex: 0
2023-03-20 21:34:57,780 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:57,780 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC: closes. applyIndex: -1
2023-03-20 21:34:57,780 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:57,780 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:57,781 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-16F0494636EC-SegmentedRaftLogWorker close()
2023-03-20 21:34:57,781 [9d2a4ecd-2086-4135-bf3e-5d16e44246f0-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0@group-759350B1DAFB-SegmentedRaftLogWorker close()
2023-03-20 21:34:57,782 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - c2f44316-1a3e-468b-9a76-53c43d628173 Close channels
2023-03-20 21:34:57,784 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38 Close channels
2023-03-20 21:34:57,784 [JvmPauseMonitor103] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-9d2a4ecd-2086-4135-bf3e-5d16e44246f0: Stopped
2023-03-20 21:34:57,785 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:57,785 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc613c859, L:/0:0:0:0:0:0:0:0:39027] CLOSE
2023-03-20 21:34:57,785 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc613c859, L:/0:0:0:0:0:0:0:0:39027] INACTIVE
2023-03-20 21:34:57,785 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc613c859, L:/0:0:0:0:0:0:0:0:39027] UNREGISTERED
2023-03-20 21:34:57,786 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF: closes. applyIndex: 35
2023-03-20 21:34:57,787 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-50915993717E-SegmentedRaftLogWorker close()
2023-03-20 21:34:57,787 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:57,788 [9ce389bc-6c47-40b9-aa21-f44fc17fd7db-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db@group-08F3B6F653FF-SegmentedRaftLogWorker close()
2023-03-20 21:34:57,792 [JvmPauseMonitor88] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-9ce389bc-6c47-40b9-aa21-f44fc17fd7db: Stopped
2023-03-20 21:34:58,011 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:58,310 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 044bfaef-c902-47be-95bf-0f9e32226746(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1, PipelineID=ed7691cd-5074-4d34-98b8-c2b03a89663d]
2023-03-20 21:34:58,310 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1, Nodes: 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290(fv-az985-449/10.1.0.10)044bfaef-c902-47be-95bf-0f9e32226746(fv-az985-449/10.1.0.10)00867d28-7830-4d3d-a4c5-0b9d063e06a7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:55.620Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:34:58,310 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: ed7691cd-5074-4d34-98b8-c2b03a89663d, Nodes: 044bfaef-c902-47be-95bf-0f9e32226746(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:55.271Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:34:58,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:58,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:34:58,410 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=c405d3a8-315a-4fbf-b7da-712cde8ccbf2, PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff]
2023-03-20 21:34:58,411 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: c405d3a8-315a-4fbf-b7da-712cde8ccbf2, Nodes: c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:c2f44316-1a3e-468b-9a76-53c43d628173, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:34:58,411 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #4 closed for pipeline=PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff
2023-03-20 21:34:58,411 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #5 closed for pipeline=PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff
2023-03-20 21:34:58,411 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #4, current state: CLOSING
2023-03-20 21:34:58,414 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #6 closed for pipeline=PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff
2023-03-20 21:34:58,414 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: dcaa0c25-9483-47d9-b73e-08f3b6f653ff, Nodes: c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10)9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10)6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:c2f44316-1a3e-468b-9a76-53c43d628173, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:34:58,415 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #5, current state: CLOSING
2023-03-20 21:34:58,415 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #6, current state: CLOSING
2023-03-20 21:34:58,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:58,616 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: addNew group-C18179E38B46:[1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290|rpc:10.1.0.10:42673|dataStream:10.1.0.10:42991|priority:1|startupRole:FOLLOWER] returns group-C18179E38B46:java.util.concurrent.CompletableFuture@2fd30cec[Not completed]
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: new RaftServerImpl for group-C18179E38B46:[1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290|rpc:10.1.0.10:42673|dataStream:10.1.0.10:42991|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46: ConfigurationManager, init=-1: peers:[1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290|rpc:10.1.0.10:42673|dataStream:10.1.0.10:42991|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis] (custom)
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:58,617 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:58,618 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:58,618 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:58,618 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:58,619 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:58,619 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:58,619 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:58,619 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:58,619 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:58,619 [pool-4741-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis/d4b1331b-98d7-4407-82d1-c18179e38b46 does not exist. Creating ...
2023-03-20 21:34:58,621 [pool-4741-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis/d4b1331b-98d7-4407-82d1-c18179e38b46/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:58,622 [pool-4741-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis/d4b1331b-98d7-4407-82d1-c18179e38b46 has been successfully formatted.
2023-03-20 21:34:58,622 [pool-4741-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-C18179E38B46: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:58,622 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:58,622 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:58,623 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:58,623 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:58,623 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: d4b1331b-98d7-4407-82d1-c18179e38b46, Nodes: 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290, CreationTimestamp2023-03-20T21:34:55.620Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:58,623 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:58,623 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:58,623 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:58,623 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis/d4b1331b-98d7-4407-82d1-c18179e38b46
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:58,624 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:58,625 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:58,625 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:58,628 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:58,628 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:58,628 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:58,628 [pool-4741-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:58,628 [pool-4741-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:58,628 [pool-4741-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46: start as a follower, conf=-1: peers:[1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290|rpc:10.1.0.10:42673|dataStream:10.1.0.10:42991|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:58,628 [pool-4741-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:58,629 [pool-4741-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: start 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-FollowerState
2023-03-20 21:34:58,629 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:58,629 [pool-4741-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C18179E38B46,id=1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:34:58,629 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:58,629 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:58,629 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:58,629 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:58,629 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:58,629 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=d4b1331b-98d7-4407-82d1-c18179e38b46
2023-03-20 21:34:58,629 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=d4b1331b-98d7-4407-82d1-c18179e38b46.
2023-03-20 21:34:58,630 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: addNew group-6C6EC40B5BF1:[1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290|rpc:10.1.0.10:42673|dataStream:10.1.0.10:42991|priority:0|startupRole:FOLLOWER, 00867d28-7830-4d3d-a4c5-0b9d063e06a7|rpc:10.1.0.10:46797|dataStream:10.1.0.10:39523|priority:1|startupRole:FOLLOWER, 044bfaef-c902-47be-95bf-0f9e32226746|rpc:10.1.0.10:40849|dataStream:10.1.0.10:43085|priority:0|startupRole:FOLLOWER] returns group-6C6EC40B5BF1:java.util.concurrent.CompletableFuture@2bec8dce[Not completed]
2023-03-20 21:34:58,631 [pool-4741-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: new RaftServerImpl for group-6C6EC40B5BF1:[1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290|rpc:10.1.0.10:42673|dataStream:10.1.0.10:42991|priority:0|startupRole:FOLLOWER, 00867d28-7830-4d3d-a4c5-0b9d063e06a7|rpc:10.1.0.10:46797|dataStream:10.1.0.10:39523|priority:1|startupRole:FOLLOWER, 044bfaef-c902-47be-95bf-0f9e32226746|rpc:10.1.0.10:40849|dataStream:10.1.0.10:43085|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:58,631 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:58,631 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:58,631 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:58,631 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:58,631 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:58,631 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:58,632 [pool-4741-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1: ConfigurationManager, init=-1: peers:[1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290|rpc:10.1.0.10:42673|dataStream:10.1.0.10:42991|priority:0|startupRole:FOLLOWER, 00867d28-7830-4d3d-a4c5-0b9d063e06a7|rpc:10.1.0.10:46797|dataStream:10.1.0.10:39523|priority:1|startupRole:FOLLOWER, 044bfaef-c902-47be-95bf-0f9e32226746|rpc:10.1.0.10:40849|dataStream:10.1.0.10:43085|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:58,632 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis] (custom)
2023-03-20 21:34:58,632 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:58,632 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:58,632 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:58,632 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:58,632 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:58,633 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:58,633 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:58,633 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:58,633 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:58,633 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:58,633 [pool-4741-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis/29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1 does not exist. Creating ...
2023-03-20 21:34:58,634 [pool-4741-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis/29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:58,634 [pool-4741-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis/29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1 has been successfully formatted.
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-6C6EC40B5BF1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:58,635 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:58,635 [pool-4741-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data/ratis/29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1
2023-03-20 21:34:58,636 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:58,636 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:58,636 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:58,636 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:58,636 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:58,636 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:58,636 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:58,636 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:58,637 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:58,637 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:58,640 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:58,640 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:58,640 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1: start as a follower, conf=-1: peers:[1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290|rpc:10.1.0.10:42673|dataStream:10.1.0.10:42991|priority:0|startupRole:FOLLOWER, 00867d28-7830-4d3d-a4c5-0b9d063e06a7|rpc:10.1.0.10:46797|dataStream:10.1.0.10:39523|priority:1|startupRole:FOLLOWER, 044bfaef-c902-47be-95bf-0f9e32226746|rpc:10.1.0.10:40849|dataStream:10.1.0.10:43085|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: start 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-FollowerState
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6C6EC40B5BF1,id=1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:34:58,641 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:58,641 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:58,641 [pool-4741-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:58,642 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1
2023-03-20 21:34:58,929 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: addNew group-C7AEBFF4B3D5:[aa2150a1-a93c-4d22-b89f-1d3c6aa7832d|rpc:10.1.0.10:34025|dataStream:10.1.0.10:43725|priority:1|startupRole:FOLLOWER] returns group-C7AEBFF4B3D5:java.util.concurrent.CompletableFuture@44d5cf2d[Not completed]
2023-03-20 21:34:58,929 [pool-4763-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: new RaftServerImpl for group-C7AEBFF4B3D5:[aa2150a1-a93c-4d22-b89f-1d3c6aa7832d|rpc:10.1.0.10:34025|dataStream:10.1.0.10:43725|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-20 21:34:58,929 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-20 21:34:58,929 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-20 21:34:58,929 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-20 21:34:58,929 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-20 21:34:58,930 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-20 21:34:58,930 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-20 21:34:58,930 [pool-4763-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5: ConfigurationManager, init=-1: peers:[aa2150a1-a93c-4d22-b89f-1d3c6aa7832d|rpc:10.1.0.10:34025|dataStream:10.1.0.10:43725|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-20 21:34:58,930 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data/ratis] (custom)
2023-03-20 21:34:58,930 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-20 21:34:58,930 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-20 21:34:58,930 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-20 21:34:58,930 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-20 21:34:58,930 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-03-20 21:34:58,931 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-20 21:34:58,931 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-20 21:34:58,931 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-20 21:34:58,931 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-20 21:34:58,931 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-20 21:34:58,931 [pool-4763-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data/ratis/2160d91c-69ee-41f2-9c3a-c7aebff4b3d5 does not exist. Creating ...
2023-03-20 21:34:58,932 [pool-4763-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data/ratis/2160d91c-69ee-41f2-9c3a-c7aebff4b3d5/in_use.lock acquired by nodename 14916@fv-az985-449
2023-03-20 21:34:58,933 [pool-4763-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data/ratis/2160d91c-69ee-41f2-9c3a-c7aebff4b3d5 has been successfully formatted.
2023-03-20 21:34:58,933 [pool-4763-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-C7AEBFF4B3D5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-20 21:34:58,933 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-20 21:34:58,933 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-20 21:34:58,934 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:58,934 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 2160d91c-69ee-41f2-9c3a-c7aebff4b3d5, Nodes: aa2150a1-a93c-4d22-b89f-1d3c6aa7832d(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:aa2150a1-a93c-4d22-b89f-1d3c6aa7832d, CreationTimestamp2023-03-20T21:34:55.934Z[Etc/UTC]] moved to OPEN state
2023-03-20 21:34:58,934 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:34:58,934 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-20 21:34:58,934 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-20 21:34:58,934 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data/ratis/2160d91c-69ee-41f2-9c3a-c7aebff4b3d5
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-20 21:34:58,935 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-20 21:34:58,936 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-20 21:34:58,936 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-20 21:34:58,939 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-20 21:34:58,939 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-20 21:34:58,939 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-20 21:34:58,939 [pool-4763-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:58,939 [pool-4763-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-20 21:34:58,940 [pool-4763-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5: start as a follower, conf=-1: peers:[aa2150a1-a93c-4d22-b89f-1d3c6aa7832d|rpc:10.1.0.10:34025|dataStream:10.1.0.10:43725|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:58,940 [pool-4763-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-20 21:34:58,940 [pool-4763-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: start aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-FollowerState
2023-03-20 21:34:58,940 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:34:58,940 [pool-4763-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C7AEBFF4B3D5,id=aa2150a1-a93c-4d22-b89f-1d3c6aa7832d
2023-03-20 21:34:58,940 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:34:58,940 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-20 21:34:58,940 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-20 21:34:58,940 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-20 21:34:58,940 [pool-4763-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-20 21:34:58,941 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=2160d91c-69ee-41f2-9c3a-c7aebff4b3d5
2023-03-20 21:34:58,941 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=2160d91c-69ee-41f2-9c3a-c7aebff4b3d5.
2023-03-20 21:34:59,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10).
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10).
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10).
2023-03-20 21:34:59,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:34:59,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:34:59,679 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5334084004ns, electionTimeout:5150ms
2023-03-20 21:34:59,679 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: shutdown 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:59,679 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2023-03-20 21:34:59,679 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:34:59,679 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: start 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166
2023-03-20 21:34:59,684 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: change Leader from c2f44316-1a3e-468b-9a76-53c43d628173 to null at term 1 for PRE_VOTE
2023-03-20 21:34:59,684 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166 PRE_VOTE round 0: submit vote requests at term 1 for 0: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:34:59,688 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:34:59,697 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:34:59,697 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:34:59,707 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:34:59,707 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:34:59,707 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:34:59,707 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:34:59,707 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166 PRE_VOTE round 0: result REJECTED
2023-03-20 21:34:59,707 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2023-03-20 21:34:59,707 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: shutdown 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166
2023-03-20 21:34:59,707 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-LeaderElection166] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: start 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState
2023-03-20 21:34:59,715 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-3/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-252d4021-a620-48b0-abba-8cbcb4c3d0eb/container.db for volume DS-252d4021-a620-48b0-abba-8cbcb4c3d0eb
2023-03-20 21:34:59,715 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:34:59,716 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:34:59,721 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:34:59,732 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@615da025{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:59,739 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6c1202f6{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:59,739 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:59,740 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@26f80307{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:34:59,740 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7bf9e2d1{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:59,742 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:34:59,749 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: close
2023-03-20 21:34:59,750 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5: shutdown
2023-03-20 21:34:59,750 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C7AEBFF4B3D5,id=aa2150a1-a93c-4d22-b89f-1d3c6aa7832d
2023-03-20 21:34:59,750 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: shutdown aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-FollowerState
2023-03-20 21:34:59,750 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-StateMachineUpdater: set stopIndex = -1
2023-03-20 21:34:59,750 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-FollowerState was interrupted
2023-03-20 21:34:59,750 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5: closes. applyIndex: -1
2023-03-20 21:34:59,750 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:59,750 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d@group-C7AEBFF4B3D5-SegmentedRaftLogWorker close()
2023-03-20 21:34:59,753 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:59,754 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:59,754 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0c6062a0, L:/0:0:0:0:0:0:0:0:43725] CLOSE
2023-03-20 21:34:59,755 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0c6062a0, L:/0:0:0:0:0:0:0:0:43725] INACTIVE
2023-03-20 21:34:59,755 [aa2150a1-a93c-4d22-b89f-1d3c6aa7832d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0c6062a0, L:/0:0:0:0:0:0:0:0:43725] UNREGISTERED
2023-03-20 21:34:59,767 [JvmPauseMonitor107] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-aa2150a1-a93c-4d22-b89f-1d3c6aa7832d: Stopped
2023-03-20 21:34:59,810 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-3/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-f4cdd729-a977-4d45-9f7c-1f4b1672453b/container.db for volume DS-f4cdd729-a977-4d45-9f7c-1f4b1672453b
2023-03-20 21:34:59,812 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:34:59,812 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:34:59,814 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-2/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-e5945372-bece-43b4-bdec-3de9ba0c1773/container.db for volume DS-e5945372-bece-43b4-bdec-3de9ba0c1773
2023-03-20 21:34:59,816 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:34:59,816 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:34:59,816 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:34:59,829 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:34:59,838 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@363d0921{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:59,839 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@43a8e430{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:59,839 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:59,841 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4073e5f1{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:34:59,843 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@452dd8cc{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:59,848 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2e54d2c3{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:34:59,849 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:34:59,849 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: close
2023-03-20 21:34:59,849 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788: shutdown
2023-03-20 21:34:59,849 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-59442E686788,id=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:59,849 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-LeaderStateImpl
2023-03-20 21:34:59,849 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-PendingRequests: sendNotLeaderResponses
2023-03-20 21:34:59,850 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:34:59,850 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-59442E686788: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/e59ede23-824b-49aa-b4ff-59442e686788/sm/snapshot.1_0
2023-03-20 21:34:59,850 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@2a362226{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:34:59,850 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:34:59,850 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown server GrpcServerProtocolService now
2023-03-20 21:34:59,851 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-20 21:34:59,851 [grpc-default-executor-2] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: installSnapshot onError, lastRequest: c810b0b2-f38c-4bc5-874a-38f1937d7d9e->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "ad06446d-1378-4ceb-aafe-e920688dce34"
address: "10.1.0.10:45443"
dataStreamAddress: "10.1.0.10:44401"
clientAddress: "10.1.0.10:45443"
adminAddress: "10.1.0.10:45443"
startupRole: FOLLOWER
,id: "c810b0b2-f38c-4bc5-874a-38f1937d7d9e"
address: "10.1.0.10:34483"
priority: 1
dataStreamAddress: "10.1.0.10:38853"
clientAddress: "10.1.0.10:34483"
adminAddress: "10.1.0.10:34483"
startupRole: FOLLOWER
,id: "ad5f436c-b0db-4b4f-b4fd-dcb016937dbf"
address: "10.1.0.10:45703"
dataStreamAddress: "10.1.0.10:46387"
clientAddress: "10.1.0.10:45703"
adminAddress: "10.1.0.10:45703"
startupRole: FOLLOWER
, old:): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-20 21:34:59,858 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-20 21:34:59,859 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: shutdown
2023-03-20 21:34:59,859 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-20 21:34:59,859 [grpc-default-executor-0] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-GrpcLogAppender: Leader has not got in touch with Follower c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(c0,m0,n1, attendVote=true, lastRpcSendTime=345, lastRpcResponseTime=344) yet, just keep nextIndex unchanged and retry.
2023-03-20 21:34:59,859 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-59442E686788: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/e59ede23-824b-49aa-b4ff-59442e686788/sm/snapshot.1_0 took: 10 ms
2023-03-20 21:34:59,859 [grpc-default-executor-1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-GrpcLogAppender: Leader has not got in touch with Follower c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(c0,m0,n1, attendVote=true, lastRpcSendTime=345, lastRpcResponseTime=345) yet, just keep nextIndex unchanged and retry.
2023-03-20 21:34:59,859 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:34:59,859 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:34:59,860 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788: closes. applyIndex: 0
2023-03-20 21:34:59,860 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:59,858 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 Close channels
2023-03-20 21:34:59,860 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-59442E686788-SegmentedRaftLogWorker close()
2023-03-20 21:34:59,860 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-183CE2A09169,id=ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:34:59,860 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState
2023-03-20 21:34:59,860 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-FollowerState was interrupted
2023-03-20 21:34:59,861 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-183CE2A09169: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/sm/snapshot.1_0
2023-03-20 21:34:59,861 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:34:59,868 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7aeacd61{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:34:59,868 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@62612b8b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:34:59,868 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e Close channels
2023-03-20 21:34:59,875 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:34:59,875 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3c2ba2f2, L:/0:0:0:0:0:0:0:0:46387] CLOSE
2023-03-20 21:34:59,875 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3c2ba2f2, L:/0:0:0:0:0:0:0:0:46387] INACTIVE
2023-03-20 21:34:59,875 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3c2ba2f2, L:/0:0:0:0:0:0:0:0:46387] UNREGISTERED
2023-03-20 21:34:59,876 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-183CE2A09169: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/sm/snapshot.1_0 took: 15 ms
2023-03-20 21:34:59,876 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:34:59,876 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:34:59,876 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169: closes. applyIndex: 0
2023-03-20 21:34:59,876 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:34:59,876 [ad5f436c-b0db-4b4f-b4fd-dcb016937dbf-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf@group-183CE2A09169-SegmentedRaftLogWorker close()
2023-03-20 21:34:59,913 [JvmPauseMonitor87] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-ad5f436c-b0db-4b4f-b4fd-dcb016937dbf: Stopped
2023-03-20 21:35:00,005 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:00,012 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 00867d28-7830-4d3d-a4c5-0b9d063e06a7(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1, PipelineID=12679b56-4620-40d1-a69e-471ee388a400]
2023-03-20 21:35:00,013 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 12679b56-4620-40d1-a69e-471ee388a400, Nodes: 00867d28-7830-4d3d-a4c5-0b9d063e06a7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-20T21:34:54.934Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:35:00,316 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10)
2023-03-20 21:35:00,316 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=6b03a966-17e8-4e27-8dd6-fd49e628281d close command to datanode 73dcf697-4659-4759-9fac-94f9a54bb6a2
2023-03-20 21:35:00,318 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 6b03a966-17e8-4e27-8dd6-fd49e628281d, Nodes: 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:, CreationTimestamp2023-03-20T21:34:54.279Z[Etc/UTC]] removed.
2023-03-20 21:35:00,318 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec close command to datanode 73dcf697-4659-4759-9fac-94f9a54bb6a2
2023-03-20 21:35:00,318 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec close command to datanode 3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:35:00,318 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec close command to datanode 9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:35:00,318 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: f3aa6e2d-4ee0-422f-8d86-16f0494636ec, Nodes: 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10)3b791506-899f-4927-929a-007385ffa693(fv-az985-449/10.1.0.10)9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:, CreationTimestamp2023-03-20T21:34:54.598Z[Etc/UTC]] removed.
2023-03-20 21:35:00,318 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/73dcf697-4659-4759-9fac-94f9a54bb6a2
2023-03-20 21:35:00,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10).
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10).
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10).
2023-03-20 21:35:00,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:35:00,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:00,513 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff, PipelineID=402930f6-6fce-4ea8-a53b-50915993717e]
2023-03-20 21:35:00,513 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 402930f6-6fce-4ea8-a53b-50915993717e, Nodes: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:9ce389bc-6c47-40b9-aa21-f44fc17fd7db, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:35:00,635 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:00,718 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=ef3b8ebd-9c2c-493c-8e29-759350b1dafb]
2023-03-20 21:35:00,718 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: ef3b8ebd-9c2c-493c-8e29-759350b1dafb, Nodes: 9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:9d2a4ecd-2086-4135-bf3e-5d16e44246f0, CreationTimestamp2023-03-20T21:34:54.598Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:35:01,319 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 044bfaef-c902-47be-95bf-0f9e32226746(fv-az985-449/10.1.0.10)
2023-03-20 21:35:01,319 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1 close command to datanode 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:35:01,319 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1 close command to datanode 044bfaef-c902-47be-95bf-0f9e32226746
2023-03-20 21:35:01,319 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1 close command to datanode 00867d28-7830-4d3d-a4c5-0b9d063e06a7
2023-03-20 21:35:01,319 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1, Nodes: 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290(fv-az985-449/10.1.0.10)044bfaef-c902-47be-95bf-0f9e32226746(fv-az985-449/10.1.0.10)00867d28-7830-4d3d-a4c5-0b9d063e06a7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:, CreationTimestamp2023-03-20T21:34:55.620Z[Etc/UTC]] removed.
2023-03-20 21:35:01,319 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=ed7691cd-5074-4d34-98b8-c2b03a89663d close command to datanode 044bfaef-c902-47be-95bf-0f9e32226746
2023-03-20 21:35:01,319 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: ed7691cd-5074-4d34-98b8-c2b03a89663d, Nodes: 044bfaef-c902-47be-95bf-0f9e32226746(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:, CreationTimestamp2023-03-20T21:34:55.271Z[Etc/UTC]] removed.
2023-03-20 21:35:01,319 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/044bfaef-c902-47be-95bf-0f9e32226746
2023-03-20 21:35:01,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10).
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10).
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10).
2023-03-20 21:35:01,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:35:01,432 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10)
2023-03-20 21:35:01,433 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=c405d3a8-315a-4fbf-b7da-712cde8ccbf2 close command to datanode c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:35:01,443 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: c405d3a8-315a-4fbf-b7da-712cde8ccbf2, Nodes: c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:c2f44316-1a3e-468b-9a76-53c43d628173, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] removed.
2023-03-20 21:35:01,443 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff close command to datanode c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:35:01,443 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff close command to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:35:01,443 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff close command to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:35:01,443 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: dcaa0c25-9483-47d9-b73e-08f3b6f653ff, Nodes: c2f44316-1a3e-468b-9a76-53c43d628173(fv-az985-449/10.1.0.10)9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10)6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:c2f44316-1a3e-468b-9a76-53c43d628173, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] removed.
2023-03-20 21:35:01,444 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/c2f44316-1a3e-468b-9a76-53c43d628173
2023-03-20 21:35:01,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:01,794 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-6/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-22a0dfc8-6941-416a-a056-4855a2d6bff9/container.db for volume DS-22a0dfc8-6941-416a-a056-4855a2d6bff9
2023-03-20 21:35:01,794 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:35:01,794 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:35:01,799 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:35:01,810 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@52087735{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:35:01,810 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@2e505d50{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:35:01,810 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:35:01,810 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@635931a5{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:35:01,810 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@64afa40b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:35:01,812 [Command processor thread] WARN  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$1(110)) - Add group failed for 044bfaef-c902-47be-95bf-0f9e32226746(fv-az985-449/10.1.0.10)
java.io.InterruptedIOException: retry policy=RequestTypeDependentRetryPolicy{WRITE->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@1a28f476, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->org.apache.ratis.retry.ExponentialBackoffRetry@1a28f476}), WATCH->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@1a28f476, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->NoRetry})}
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:125)
	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:106)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:102)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:642)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:01,818 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:35:01,819 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: close
2023-03-20 21:35:01,819 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1: shutdown
2023-03-20 21:35:01,819 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: shutdown server GrpcServerProtocolService now
2023-03-20 21:35:01,819 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6C6EC40B5BF1,id=1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:35:01,819 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: shutdown 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-FollowerState
2023-03-20 21:35:01,819 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-StateMachineUpdater: set stopIndex = -1
2023-03-20 21:35:01,819 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-FollowerState was interrupted
2023-03-20 21:35:01,819 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:35:01,819 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1: closes. applyIndex: -1
2023-03-20 21:35:01,820 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x2588f006, L:/0:0:0:0:0:0:0:0:42991] CLOSE
2023-03-20 21:35:01,820 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x2588f006, L:/0:0:0:0:0:0:0:0:42991] INACTIVE
2023-03-20 21:35:01,820 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x2588f006, L:/0:0:0:0:0:0:0:0:42991] UNREGISTERED
2023-03-20 21:35:01,820 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:35:01,820 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-6C6EC40B5BF1-SegmentedRaftLogWorker close()
2023-03-20 21:35:01,825 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46: shutdown
2023-03-20 21:35:01,825 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C18179E38B46,id=1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:35:01,825 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: shutdown 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-FollowerState
2023-03-20 21:35:01,825 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-FollowerState was interrupted
2023-03-20 21:35:01,826 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-StateMachineUpdater: set stopIndex = -1
2023-03-20 21:35:01,826 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46: closes. applyIndex: -1
2023-03-20 21:35:01,828 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:35:01,828 [1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290@group-C18179E38B46-SegmentedRaftLogWorker close()
2023-03-20 21:35:01,834 [JvmPauseMonitor106] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290: Stopped
2023-03-20 21:35:01,934 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode aa2150a1-a93c-4d22-b89f-1d3c6aa7832d(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=2160d91c-69ee-41f2-9c3a-c7aebff4b3d5]
2023-03-20 21:35:01,934 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 2160d91c-69ee-41f2-9c3a-c7aebff4b3d5, Nodes: aa2150a1-a93c-4d22-b89f-1d3c6aa7832d(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:aa2150a1-a93c-4d22-b89f-1d3c6aa7832d, CreationTimestamp2023-03-20T21:34:55.934Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:35:01,937 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-2/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-c62bb234-cdf0-440f-a112-1703b1431d87/container.db for volume DS-c62bb234-cdf0-440f-a112-1703b1431d87
2023-03-20 21:35:01,938 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:35:01,938 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:35:01,941 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:35:01,956 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5a3f5bce{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:35:01,957 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@11c6e8e{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:35:01,957 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:35:01,957 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@459b94fd{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:35:01,957 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@226dfd5f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:35:01,961 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:35:01,961 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: close
2023-03-20 21:35:01,961 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F: shutdown
2023-03-20 21:35:01,962 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C381D26A4E6F,id=c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:35:01,962 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-LeaderStateImpl
2023-03-20 21:35:01,962 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-PendingRequests: sendNotLeaderResponses
2023-03-20 21:35:01,962 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:35:01,962 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-C381D26A4E6F: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/946b457e-a222-4d6d-be88-c381d26a4e6f/sm/snapshot.1_0
2023-03-20 21:35:01,962 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown server GrpcServerProtocolService now
2023-03-20 21:35:01,962 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169: shutdown
2023-03-20 21:35:01,962 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-183CE2A09169,id=c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:35:01,962 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-LeaderStateImpl
2023-03-20 21:35:01,965 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 1226cf83-b1fd-416f-9846-61bdfa3ff6b3 Close channels
2023-03-20 21:35:01,966 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - ad06446d-1378-4ceb-aafe-e920688dce34 Close channels
2023-03-20 21:35:01,966 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-C381D26A4E6F: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/946b457e-a222-4d6d-be88-c381d26a4e6f/sm/snapshot.1_0 took: 4 ms
2023-03-20 21:35:01,967 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:35:01,967 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:35:01,967 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F: closes. applyIndex: 0
2023-03-20 21:35:01,967 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:35:01,967 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-C381D26A4E6F-SegmentedRaftLogWorker close()
2023-03-20 21:35:01,969 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad06446d-1378-4ceb-aafe-e920688dce34-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad06446d-1378-4ceb-aafe-e920688dce34-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-20 21:35:01,969 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - ad06446d-1378-4ceb-aafe-e920688dce34: Completed APPEND_ENTRIES, lastRequest: c810b0b2-f38c-4bc5-874a-38f1937d7d9e->ad06446d-1378-4ceb-aafe-e920688dce34#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "ad06446d-1378-4ceb-aafe-e920688dce34"
address: "10.1.0.10:45443"
dataStreamAddress: "10.1.0.10:44401"
clientAddress: "10.1.0.10:45443"
adminAddress: "10.1.0.10:45443"
startupRole: FOLLOWER
,id: "c810b0b2-f38c-4bc5-874a-38f1937d7d9e"
address: "10.1.0.10:34483"
priority: 1
dataStreamAddress: "10.1.0.10:38853"
clientAddress: "10.1.0.10:34483"
adminAddress: "10.1.0.10:34483"
startupRole: FOLLOWER
,id: "ad5f436c-b0db-4b4f-b4fd-dcb016937dbf"
address: "10.1.0.10:45703"
dataStreamAddress: "10.1.0.10:46387"
clientAddress: "10.1.0.10:45703"
adminAddress: "10.1.0.10:45703"
startupRole: FOLLOWER
, old:)
2023-03-20 21:35:01,970 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - ad06446d-1378-4ceb-aafe-e920688dce34: Completed APPEND_ENTRIES, lastRequest: null
2023-03-20 21:35:01,973 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad06446d-1378-4ceb-aafe-e920688dce34-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-20 21:35:01,974 [grpc-default-executor-4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad06446d-1378-4ceb-aafe-e920688dce34-GrpcLogAppender: Failed to getClient for ad06446d-1378-4ceb-aafe-e920688dce34
org.apache.ratis.protocol.exceptions.AlreadyClosedException: c810b0b2-f38c-4bc5-874a-38f1937d7d9e is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:432)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:465)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:01,974 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-PendingRequests: sendNotLeaderResponses
2023-03-20 21:35:01,974 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad06446d-1378-4ceb-aafe-e920688dce34-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-20 21:35:01,974 [grpc-default-executor-1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169->ad06446d-1378-4ceb-aafe-e920688dce34-GrpcLogAppender: Failed to getClient for ad06446d-1378-4ceb-aafe-e920688dce34
org.apache.ratis.protocol.exceptions.AlreadyClosedException: c810b0b2-f38c-4bc5-874a-38f1937d7d9e is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:01,975 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - ad5f436c-b0db-4b4f-b4fd-dcb016937dbf Close channels
2023-03-20 21:35:01,976 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:35:01,976 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x702acaaa, L:/0:0:0:0:0:0:0:0:38853] CLOSE
2023-03-20 21:35:01,976 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x702acaaa, L:/0:0:0:0:0:0:0:0:38853] INACTIVE
2023-03-20 21:35:01,976 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x702acaaa, L:/0:0:0:0:0:0:0:0:38853] UNREGISTERED
2023-03-20 21:35:01,976 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-183CE2A09169: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/sm/snapshot.1_0
2023-03-20 21:35:01,976 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:35:01,977 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-183CE2A09169: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/sm/snapshot.1_0 took: 0 ms
2023-03-20 21:35:01,977 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:35:01,977 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:35:01,977 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169: closes. applyIndex: 0
2023-03-20 21:35:01,978 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:35:01,978 [c810b0b2-f38c-4bc5-874a-38f1937d7d9e-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c810b0b2-f38c-4bc5-874a-38f1937d7d9e@group-183CE2A09169-SegmentedRaftLogWorker close()
2023-03-20 21:35:01,979 [JvmPauseMonitor85] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-c810b0b2-f38c-4bc5-874a-38f1937d7d9e: Stopped
2023-03-20 21:35:02,005 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:02,005 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:02,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5037342146ns, electionTimeout:5037ms
2023-03-20 21:35:02,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:02,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:02,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:02,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167
2023-03-20 21:35:02,031 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:02,031 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5050514888ns, electionTimeout:5050ms
2023-03-20 21:35:02,031 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState
2023-03-20 21:35:02,031 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:02,031 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:02,031 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168
2023-03-20 21:35:02,031 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 73dcf697-4659-4759-9fac-94f9a54bb6a2
2023-03-20 21:35:02,032 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:02,032 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168 PRE_VOTE round 0: result PASSED (term=0)
2023-03-20 21:35:02,032 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:02,032 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:02,032 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:35:02,033 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168 ELECTION round 0: submit vote requests at term 1 for -1: peers:[3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:02,033 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168 ELECTION round 0: result PASSED (term=1)
2023-03-20 21:35:02,033 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168
2023-03-20 21:35:02,033 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-20 21:35:02,033 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-0F06956C75EC with new leaderId: 3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:35:02,033 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC: change Leader from null to 3b791506-899f-4927-929a-007385ffa693 at term 1 for becomeLeader, leader elected after 5066ms
2023-03-20 21:35:02,033 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-20 21:35:02,033 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:35:02,034 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-20 21:35:02,034 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:02,034 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-20 21:35:02,034 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:02,034 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-20 21:35:02,034 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-20 21:35:02,034 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-20 21:35:02,034 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-20 21:35:02,034 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderStateImpl
2023-03-20 21:35:02,035 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-20 21:35:02,036 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/7676672b-f26c-4de6-85a4-0f06956c75ec/current/log_inprogress_0
2023-03-20 21:35:02,038 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:02,041 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderElection168] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC: set configuration 0: peers:[3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:02,044 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:02,044 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:02,044 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:02,044 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:02,044 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:02,044 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:02,044 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167
2023-03-20 21:35:02,045 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection167] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:02,046 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:02,046 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:02,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:02,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:02,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:02,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:02,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:02,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:02,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:02,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:35:02,434 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=e59ede23-824b-49aa-b4ff-59442e686788, PipelineID=2084635c-5d52-438d-811e-183ce2a09169]
2023-03-20 21:35:02,434 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: e59ede23-824b-49aa-b4ff-59442e686788, Nodes: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:35:02,434 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 2084635c-5d52-438d-811e-183ce2a09169, Nodes: ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10)ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10)c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:c810b0b2-f38c-4bc5-874a-38f1937d7d9e, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:35:02,442 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff is not found
2023-03-20 21:35:02,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:02,935 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 00867d28-7830-4d3d-a4c5-0b9d063e06a7(fv-az985-449/10.1.0.10)
2023-03-20 21:35:02,935 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=12679b56-4620-40d1-a69e-471ee388a400 close command to datanode 00867d28-7830-4d3d-a4c5-0b9d063e06a7
2023-03-20 21:35:02,935 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 12679b56-4620-40d1-a69e-471ee388a400, Nodes: 00867d28-7830-4d3d-a4c5-0b9d063e06a7(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:, CreationTimestamp2023-03-20T21:34:54.934Z[Etc/UTC]] removed.
2023-03-20 21:35:02,935 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/00867d28-7830-4d3d-a4c5-0b9d063e06a7
2023-03-20 21:35:03,034 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:03,034 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:03,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:03,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:03,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #4 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:03,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:03,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:03,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10).
2023-03-20 21:35:03,356 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10).
2023-03-20 21:35:03,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-20 21:35:03,435 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10)
2023-03-20 21:35:03,435 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=402930f6-6fce-4ea8-a53b-50915993717e close command to datanode 9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:35:03,435 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 402930f6-6fce-4ea8-a53b-50915993717e, Nodes: 9ce389bc-6c47-40b9-aa21-f44fc17fd7db(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:9ce389bc-6c47-40b9-aa21-f44fc17fd7db, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] removed.
2023-03-20 21:35:03,435 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/9ce389bc-6c47-40b9-aa21-f44fc17fd7db
2023-03-20 21:35:03,442 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: remove  FOLLOWER 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF:t1, leader=null, voted=c2f44316-1a3e-468b-9a76-53c43d628173, raftlog=Memoized:6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLog:OPENED:c35, conf=0: peers:[c2f44316-1a3e-468b-9a76-53c43d628173|rpc:10.1.0.10:33117|dataStream:10.1.0.10:40549|priority:1|startupRole:FOLLOWER, 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38|rpc:10.1.0.10:36869|dataStream:10.1.0.10:34323|priority:0|startupRole:FOLLOWER, 9ce389bc-6c47-40b9-aa21-f44fc17fd7db|rpc:10.1.0.10:34363|dataStream:10.1.0.10:39027|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-20 21:35:03,442 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: shutdown
2023-03-20 21:35:03,442 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-08F3B6F653FF,id=6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:35:03,442 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: shutdown 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState
2023-03-20 21:35:03,442 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-StateMachineUpdater: set stopIndex = 35
2023-03-20 21:35:03,442 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-FollowerState was interrupted
2023-03-20 21:35:03,444 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff is not found
2023-03-20 21:35:03,444 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-08F3B6F653FF: Taking a snapshot at:(t:1, i:35) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/sm/snapshot.1_35
2023-03-20 21:35:03,446 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-08F3B6F653FF: Finished taking a snapshot at:(t:1, i:35) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff/sm/snapshot.1_35 took: 2 ms
2023-03-20 21:35:03,446 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-StateMachineUpdater: Took a snapshot at index 35
2023-03-20 21:35:03,446 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 35
2023-03-20 21:35:03,447 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: closes. applyIndex: 35
2023-03-20 21:35:03,448 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:35:03,448 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF-SegmentedRaftLogWorker close()
2023-03-20 21:35:03,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:03,462 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 25.
2023-03-20 21:35:03,462 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 4 is synced with bcsId 25.
2023-03-20 21:35:03,463 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 5 is synced with bcsId 30.
2023-03-20 21:35:03,463 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 5 is synced with bcsId 30.
2023-03-20 21:35:03,464 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #4 to QUASI_CLOSED state, datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10) reported QUASI_CLOSED replica.
2023-03-20 21:35:03,464 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-20 21:35:03,464 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(446)) - Container 6 is synced with bcsId 34.
2023-03-20 21:35:03,465 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #5 to QUASI_CLOSED state, datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10) reported QUASI_CLOSED replica.
2023-03-20 21:35:03,466 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #6 to QUASI_CLOSED state, datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10) reported QUASI_CLOSED replica.
2023-03-20 21:35:03,466 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-08F3B6F653FF: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/dcaa0c25-9483-47d9-b73e-08f3b6f653ff
2023-03-20 21:35:03,466 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=dcaa0c25-9483-47d9-b73e-08f3b6f653ff command on datanode 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38.
2023-03-20 21:35:03,735 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10)
2023-03-20 21:35:03,736 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=ef3b8ebd-9c2c-493c-8e29-759350b1dafb close command to datanode 9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:35:03,736 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: ef3b8ebd-9c2c-493c-8e29-759350b1dafb, Nodes: 9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:9d2a4ecd-2086-4135-bf3e-5d16e44246f0, CreationTimestamp2023-03-20T21:34:54.598Z[Etc/UTC]] removed.
2023-03-20 21:35:03,736 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/9d2a4ecd-2086-4135-bf3e-5d16e44246f0
2023-03-20 21:35:03,838 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-5/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-2cdea61d-5909-4d43-b1b1-7703cc320be8/container.db for volume DS-2cdea61d-5909-4d43-b1b1-7703cc320be8
2023-03-20 21:35:03,838 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:35:03,838 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:35:03,842 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:35:03,852 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4a4033af{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:35:03,854 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@65b4487d{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:35:03,854 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:35:03,854 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7068a22e{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:35:03,854 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4cd6743e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:35:03,984 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-0/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-1819e498-3d26-483d-bf35-767a906b0b5e/container.db for volume DS-1819e498-3d26-483d-bf35-767a906b0b5e
2023-03-20 21:35:03,985 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:35:03,985 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:35:03,987 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:35:03,997 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@67899a75{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:35:03,997 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6b9f160b{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:35:03,997 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:35:03,997 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3f9bf0db{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:35:03,998 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2b90048f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:35:04,001 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:35:04,002 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - ad06446d-1378-4ceb-aafe-e920688dce34: close
2023-03-20 21:35:04,003 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE: shutdown
2023-03-20 21:35:04,003 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7ECEA2AD9ACE,id=ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:35:04,003 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - ad06446d-1378-4ceb-aafe-e920688dce34: shutdown ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-LeaderStateImpl
2023-03-20 21:35:04,003 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-PendingRequests: sendNotLeaderResponses
2023-03-20 21:35:04,003 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:35:04,003 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-7ECEA2AD9ACE: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/df6acdd5-290a-4c11-993a-7ecea2ad9ace/sm/snapshot.1_0
2023-03-20 21:35:04,003 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - ad06446d-1378-4ceb-aafe-e920688dce34: shutdown server GrpcServerProtocolService now
2023-03-20 21:35:04,003 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: shutdown
2023-03-20 21:35:04,004 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-183CE2A09169,id=ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:35:04,004 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ad06446d-1378-4ceb-aafe-e920688dce34: shutdown ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState
2023-03-20 21:35:04,005 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-7ECEA2AD9ACE: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/df6acdd5-290a-4c11-993a-7ecea2ad9ace/sm/snapshot.1_0 took: 2 ms
2023-03-20 21:35:04,005 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - ad06446d-1378-4ceb-aafe-e920688dce34: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:35:04,005 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:35:04,006 [ad06446d-1378-4ceb-aafe-e920688dce34-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x08dfe364, L:/0:0:0:0:0:0:0:0:44401] CLOSE
2023-03-20 21:35:04,006 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-183CE2A09169: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/sm/snapshot.1_0
2023-03-20 21:35:04,006 [ad06446d-1378-4ceb-aafe-e920688dce34-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x08dfe364, L:/0:0:0:0:0:0:0:0:44401] INACTIVE
2023-03-20 21:35:04,006 [ad06446d-1378-4ceb-aafe-e920688dce34-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x08dfe364, L:/0:0:0:0:0:0:0:0:44401] UNREGISTERED
2023-03-20 21:35:04,006 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-183CE2A09169: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data/ratis/2084635c-5d52-438d-811e-183ce2a09169/sm/snapshot.1_0 took: 1 ms
2023-03-20 21:35:04,005 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-FollowerState was interrupted
2023-03-20 21:35:04,006 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:35:04,006 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:35:04,005 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:35:04,006 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:35:04,007 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169: closes. applyIndex: 0
2023-03-20 21:35:04,007 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE: closes. applyIndex: 0
2023-03-20 21:35:04,007 [ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:35:04,007 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-7ECEA2AD9ACE-SegmentedRaftLogWorker close()
2023-03-20 21:35:04,009 [ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:35:04,009 [ad06446d-1378-4ceb-aafe-e920688dce34-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ad06446d-1378-4ceb-aafe-e920688dce34@group-183CE2A09169-SegmentedRaftLogWorker close()
2023-03-20 21:35:04,016 [JvmPauseMonitor91] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-ad06446d-1378-4ceb-aafe-e920688dce34: Stopped
2023-03-20 21:35:04,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=1, replicaIndex=0, sourceNodes=[c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL to 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=3, replicaIndex=0, sourceNodes=[c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL to 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #4 is under replicated. Expected replica count is 3, but found 1.
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=4, replicaIndex=0, sourceNodes=[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)], priority=NORMAL to c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=4, replicaIndex=0, sourceNodes=[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)], priority=NORMAL to ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10)
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #5 is under replicated. Expected replica count is 3, but found 1.
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=5, replicaIndex=0, sourceNodes=[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)], priority=NORMAL to c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=5, replicaIndex=0, sourceNodes=[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)], priority=NORMAL to ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10)
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #6 is under replicated. Expected replica count is 3, but found 1.
2023-03-20 21:35:04,357 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=6, replicaIndex=0, sourceNodes=[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)], priority=NORMAL to c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)
2023-03-20 21:35:04,358 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=6, replicaIndex=0, sourceNodes=[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)], priority=NORMAL to ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10)
2023-03-20 21:35:04,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-20 21:35:04,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:04,536 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=946b457e-a222-4d6d-be88-c381d26a4e6f, PipelineID=2084635c-5d52-438d-811e-183ce2a09169]
2023-03-20 21:35:04,536 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 946b457e-a222-4d6d-be88-c381d26a4e6f, Nodes: c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:c810b0b2-f38c-4bc5-874a-38f1937d7d9e, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:35:04,636 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=d4b1331b-98d7-4407-82d1-c18179e38b46]
2023-03-20 21:35:04,636 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: d4b1331b-98d7-4407-82d1-c18179e38b46, Nodes: 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290, CreationTimestamp2023-03-20T21:34:55.620Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:35:04,936 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. aa2150a1-a93c-4d22-b89f-1d3c6aa7832d(fv-az985-449/10.1.0.10)
2023-03-20 21:35:04,937 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=2160d91c-69ee-41f2-9c3a-c7aebff4b3d5 close command to datanode aa2150a1-a93c-4d22-b89f-1d3c6aa7832d
2023-03-20 21:35:04,937 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 2160d91c-69ee-41f2-9c3a-c7aebff4b3d5, Nodes: aa2150a1-a93c-4d22-b89f-1d3c6aa7832d(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:aa2150a1-a93c-4d22-b89f-1d3c6aa7832d, CreationTimestamp2023-03-20T21:34:55.934Z[Etc/UTC]] removed.
2023-03-20 21:35:04,937 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/aa2150a1-a93c-4d22-b89f-1d3c6aa7832d
2023-03-20 21:35:05,033 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:05,034 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:05,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:05,358 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2228)) - Cannot replicate container #1, no healthy datanodes with replica found.
2023-03-20 21:35:05,358 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2228)) - Cannot replicate container #3, no healthy datanodes with replica found.
2023-03-20 21:35:05,358 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:05,358 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:05,358 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:05,358 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:05,359 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:05,359 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:05,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-20 21:35:05,436 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10)
2023-03-20 21:35:05,436 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=e59ede23-824b-49aa-b4ff-59442e686788 close command to datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:35:05,437 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: e59ede23-824b-49aa-b4ff-59442e686788, Nodes: ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:ad5f436c-b0db-4b4f-b4fd-dcb016937dbf, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] removed.
2023-03-20 21:35:05,437 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=2084635c-5d52-438d-811e-183ce2a09169 close command to datanode ad06446d-1378-4ceb-aafe-e920688dce34
2023-03-20 21:35:05,437 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=2084635c-5d52-438d-811e-183ce2a09169 close command to datanode ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:35:05,437 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=2084635c-5d52-438d-811e-183ce2a09169 close command to datanode c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:35:05,437 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 2084635c-5d52-438d-811e-183ce2a09169, Nodes: ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10)ad5f436c-b0db-4b4f-b4fd-dcb016937dbf(fv-az985-449/10.1.0.10)c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:c810b0b2-f38c-4bc5-874a-38f1937d7d9e, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] removed.
2023-03-20 21:35:05,437 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/ad5f436c-b0db-4b4f-b4fd-dcb016937dbf
2023-03-20 21:35:05,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:05,466 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 1 from [c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)] using NO_COMPRESSION
2023-03-20 21:35:05,468 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 3 from [c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)] using NO_COMPRESSION
2023-03-20 21:35:05,470 [grpc-default-executor-1] ERROR replication.GrpcReplicationClient (GrpcReplicationClient.java:onError(201)) - Download of container 1 was unsuccessful
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:535)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:487)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.drainPendingCallbacks(DelayedClientCall.java:507)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$1DrainListenerRunnable.runInContext(DelayedClientCall.java:296)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: /10.1.0.10:45831
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.newConnectException0(Errors.java:155)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.handleConnectErrno(Errors.java:128)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Socket.finishConnect(Socket.java:321)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:710)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:687)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:567)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:477)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:385)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:05,470 [ContainerReplicationThread-1] ERROR replication.SimpleContainerDownloader (SimpleContainerDownloader.java:logError(97)) - Error on replicating container: 1 from c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
	at org.apache.hadoop.ozone.container.replication.SimpleContainerDownloader.getContainerDataFromReplicas(SimpleContainerDownloader.java:80)
	at org.apache.hadoop.ozone.container.replication.DownloadAndImportReplicator.replicate(DownloadAndImportReplicator.java:81)
	at org.apache.hadoop.ozone.container.replication.MeasuredReplicator.replicate(MeasuredReplicator.java:83)
	at org.apache.hadoop.ozone.container.replication.ReplicationTask.runTask(ReplicationTask.java:122)
	at org.apache.hadoop.ozone.container.replication.ReplicationSupervisor$TaskRunner.run(ReplicationSupervisor.java:215)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:535)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:487)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.drainPendingCallbacks(DelayedClientCall.java:507)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$1DrainListenerRunnable.runInContext(DelayedClientCall.java:296)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	... 3 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: /10.1.0.10:45831
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.newConnectException0(Errors.java:155)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.handleConnectErrno(Errors.java:128)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Socket.finishConnect(Socket.java:321)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:710)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:687)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:567)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:477)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:385)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:05,471 [ContainerReplicationThread-1] ERROR replication.SimpleContainerDownloader (SimpleContainerDownloader.java:getContainerDataFromReplicas(90)) - Container 1 could not be downloaded from any datanode
2023-03-20 21:35:05,471 [ContainerReplicationThread-1] WARN  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(217)) - Failed FAILED replicateContainerCommand: containerId=1, replicaIndex=0, sourceNodes=[c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL
2023-03-20 21:35:05,477 [grpc-default-executor-1] ERROR replication.GrpcReplicationClient (GrpcReplicationClient.java:onError(201)) - Download of container 3 was unsuccessful
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:535)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:487)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:432)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:465)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: /10.1.0.10:45831
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.newConnectException0(Errors.java:155)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.handleConnectErrno(Errors.java:128)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Socket.finishConnect(Socket.java:321)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:710)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:687)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:567)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:477)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:385)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:05,478 [ContainerReplicationThread-2] ERROR replication.SimpleContainerDownloader (SimpleContainerDownloader.java:logError(97)) - Error on replicating container: 3 from c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
	at org.apache.hadoop.ozone.container.replication.SimpleContainerDownloader.getContainerDataFromReplicas(SimpleContainerDownloader.java:80)
	at org.apache.hadoop.ozone.container.replication.DownloadAndImportReplicator.replicate(DownloadAndImportReplicator.java:81)
	at org.apache.hadoop.ozone.container.replication.MeasuredReplicator.replicate(MeasuredReplicator.java:83)
	at org.apache.hadoop.ozone.container.replication.ReplicationTask.runTask(ReplicationTask.java:122)
	at org.apache.hadoop.ozone.container.replication.ReplicationSupervisor$TaskRunner.run(ReplicationSupervisor.java:215)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:535)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:487)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:432)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:465)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	... 3 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: /10.1.0.10:45831
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.newConnectException0(Errors.java:155)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.handleConnectErrno(Errors.java:128)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Socket.finishConnect(Socket.java:321)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:710)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:687)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:567)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:477)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:385)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:05,478 [ContainerReplicationThread-2] ERROR replication.SimpleContainerDownloader (SimpleContainerDownloader.java:getContainerDataFromReplicas(90)) - Container 3 could not be downloaded from any datanode
2023-03-20 21:35:05,478 [ContainerReplicationThread-2] WARN  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(217)) - Failed FAILED replicateContainerCommand: containerId=3, replicaIndex=0, sourceNodes=[c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)], priority=NORMAL
2023-03-20 21:35:06,022 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-6/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-b3a4655f-49ba-4aad-97d8-33192a4797b1/container.db for volume DS-b3a4655f-49ba-4aad-97d8-33192a4797b1
2023-03-20 21:35:06,023 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:35:06,023 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:35:06,025 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:35:06,037 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3afa2d68{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:35:06,038 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@65606c51{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:35:06,038 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:35:06,038 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7a37a7cc{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:35:06,038 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@499da35f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:35:06,041 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:35:06,041 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: close
2023-03-20 21:35:06,041 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: shutdown server GrpcServerProtocolService now
2023-03-20 21:35:06,041 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116: shutdown
2023-03-20 21:35:06,041 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F785482B8116,id=6b93f795-e4f1-4cdd-8e17-5fb6627a9a38
2023-03-20 21:35:06,041 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: shutdown 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-LeaderStateImpl
2023-03-20 21:35:06,041 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-PendingRequests: sendNotLeaderResponses
2023-03-20 21:35:06,041 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:35:06,042 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-F785482B8116: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/e5a8d140-d18d-49ef-8d60-f785482b8116/sm/snapshot.1_0
2023-03-20 21:35:06,043 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-F785482B8116: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data/ratis/e5a8d140-d18d-49ef-8d60-f785482b8116/sm/snapshot.1_0 took: 1 ms
2023-03-20 21:35:06,043 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:35:06,043 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:35:06,043 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116: closes. applyIndex: 0
2023-03-20 21:35:06,043 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - c2f44316-1a3e-468b-9a76-53c43d628173 Close channels
2023-03-20 21:35:06,043 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:35:06,044 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 9ce389bc-6c47-40b9-aa21-f44fc17fd7db Close channels
2023-03-20 21:35:06,044 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:35:06,044 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaac850e0, L:/0:0:0:0:0:0:0:0:34323] CLOSE
2023-03-20 21:35:06,045 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaac850e0, L:/0:0:0:0:0:0:0:0:34323] INACTIVE
2023-03-20 21:35:06,045 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 6b93f795-e4f1-4cdd-8e17-5fb6627a9a38@group-F785482B8116-SegmentedRaftLogWorker close()
2023-03-20 21:35:06,045 [6b93f795-e4f1-4cdd-8e17-5fb6627a9a38-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaac850e0, L:/0:0:0:0:0:0:0:0:34323] UNREGISTERED
2023-03-20 21:35:06,048 [JvmPauseMonitor90] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-6b93f795-e4f1-4cdd-8e17-5fb6627a9a38: Stopped
2023-03-20 21:35:06,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:06,359 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2228)) - Cannot replicate container #1, no healthy datanodes with replica found.
2023-03-20 21:35:06,359 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2023-03-20 21:35:06,359 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId=2, replicaIndex=0, sourceNodes=[6b93f795-e4f1-4cdd-8e17-5fb6627a9a38(fv-az985-449/10.1.0.10)], priority=NORMAL to ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10)
2023-03-20 21:35:06,359 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2228)) - Cannot replicate container #3, no healthy datanodes with replica found.
2023-03-20 21:35:06,360 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:06,360 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:06,360 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:06,360 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:06,364 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:06,364 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:06,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 6 milliseconds for processing 6 containers.
2023-03-20 21:35:06,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:06,538 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=df6acdd5-290a-4c11-993a-7ecea2ad9ace]
2023-03-20 21:35:06,538 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: df6acdd5-290a-4c11-993a-7ecea2ad9ace, Nodes: ad06446d-1378-4ceb-aafe-e920688dce34(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:ad06446d-1378-4ceb-aafe-e920688dce34, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:35:07,034 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:07,034 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:07,204 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5159552155ns, electionTimeout:5158ms
2023-03-20 21:35:07,204 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:07,204 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:07,204 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:07,204 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:07,205 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:07,206 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169
2023-03-20 21:35:07,206 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection169] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:07,206 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:07,206 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:07,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:07,365 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2228)) - Cannot replicate container #1, no healthy datanodes with replica found.
2023-03-20 21:35:07,365 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:07,365 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:07,365 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2228)) - Cannot replicate container #3, no healthy datanodes with replica found.
2023-03-20 21:35:07,365 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:07,365 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:07,366 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:07,366 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:07,366 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-03-20 21:35:07,366 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2233)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2196)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1126)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:498)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:363)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:813)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:35:07,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-20 21:35:07,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:07,538 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10)
2023-03-20 21:35:07,538 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=946b457e-a222-4d6d-be88-c381d26a4e6f close command to datanode c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:35:07,539 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 946b457e-a222-4d6d-be88-c381d26a4e6f, Nodes: c810b0b2-f38c-4bc5-874a-38f1937d7d9e(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:c810b0b2-f38c-4bc5-874a-38f1937d7d9e, CreationTimestamp2023-03-20T21:34:47.669Z[Etc/UTC]] removed.
2023-03-20 21:35:07,539 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/c810b0b2-f38c-4bc5-874a-38f1937d7d9e
2023-03-20 21:35:07,638 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290(fv-az985-449/10.1.0.10)
2023-03-20 21:35:07,638 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=d4b1331b-98d7-4407-82d1-c18179e38b46 close command to datanode 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:35:07,639 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: d4b1331b-98d7-4407-82d1-c18179e38b46, Nodes: 1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290, CreationTimestamp2023-03-20T21:34:55.620Z[Etc/UTC]] removed.
2023-03-20 21:35:07,639 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290
2023-03-20 21:35:08,034 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:08,034 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:08,075 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5cc8e710-5a27-4b0f-b5de-2474723ab95d/datanode-5/data-0/containers/hdds/5cc8e710-5a27-4b0f-b5de-2474723ab95d/DS-9531f318-f2fb-4a97-b9d4-81636e8d3eb3/container.db for volume DS-9531f318-f2fb-4a97-b9d4-81636e8d3eb3
2023-03-20 21:35:08,076 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:35:08,076 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:35:08,081 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:35:08,093 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5bac76a5{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:35:08,093 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6b1a4bf{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:35:08,093 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:35:08,093 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@e975ff4{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:35:08,093 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2fba7d7c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:35:08,095 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(545)) - Stopping the StorageContainerManager
2023-03-20 21:35:08,095 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1537)) - Container Balancer is not running.
2023-03-20 21:35:08,095 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1544)) - Stopping Replication Manager Service.
2023-03-20 21:35:08,095 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(306)) - Stopping Replication Monitor Thread.
2023-03-20 21:35:08,095 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Over Replicated Processor interrupted. Exiting...
2023-03-20 21:35:08,095 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(146)) - Under Replicated Processor interrupted. Exiting...
2023-03-20 21:35:08,096 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1551)) - Stopping the Datanode Admin Monitor.
2023-03-20 21:35:08,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(818)) - Replication Monitor Thread is stopped
2023-03-20 21:35:08,097 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1558)) - Stopping datanode service RPC server
2023-03-20 21:35:08,097 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-03-20 21:35:08,097 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42601
2023-03-20 21:35:08,099 [IPC Server listener on 42601] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 42601
2023-03-20 21:35:08,099 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:35:08,139 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-03-20 21:35:08,139 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1566)) - Stopping block service RPC server
2023-03-20 21:35:08,139 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-03-20 21:35:08,140 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 33765
2023-03-20 21:35:08,141 [IPC Server listener on 33765] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 33765
2023-03-20 21:35:08,142 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1573)) - Stopping the StorageContainerLocationProtocol RPC server
2023-03-20 21:35:08,142 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:35:08,142 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(203)) - Stopping the RPC server for Client Protocol
2023-03-20 21:35:08,143 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42371
2023-03-20 21:35:08,143 [IPC Server listener on 42371] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 42371
2023-03-20 21:35:08,144 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1580)) - Stopping Storage Container Manager HTTP server.
2023-03-20 21:35:08,144 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-20 21:35:08,147 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4f283b8f{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-20 21:35:08,147 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6a275836{HTTP/1.1, (http/1.1)}{0.0.0.0:38151}
2023-03-20 21:35:08,147 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:35:08,147 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5c26ab0a{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-20 21:35:08,147 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@58d85a00{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:35:08,147 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1588)) - Stopping SCM LayoutVersionManager Service.
2023-03-20 21:35:08,147 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1596)) - Stopping Block Manager Service.
2023-03-20 21:35:08,147 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-20 21:35:08,148 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-20 21:35:08,148 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1618)) - Stopping SCM Event Queue.
2023-03-20 21:35:08,150 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1629)) - Stopping SCM HA services.
2023-03-20 21:35:08,150 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-03-20 21:35:08,150 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-03-20 21:35:08,150 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-03-20 21:35:08,150 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-03-20 21:35:08,151 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2023-03-20 21:35:08,155 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-03-20 21:35:08,158 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2023-03-20 21:35:08,158 [Mini-Cluster-Provider-Reap] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-03-20 21:35:08,158 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-03-20 21:35:08,158 [Mini-Cluster-Provider-Reap] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-03-20 21:35:08,158 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-20 21:35:08,158 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-03-20 21:35:08,158 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(316)) - Replication Monitor Thread is not running.
2023-03-20 21:35:08,158 [Mini-Cluster-Provider-Reap] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-03-20 21:35:08,158 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1647)) - Stopping SCM MetadataStore.
2023-03-20 21:35:08,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:08,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:09,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:09,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:10,034 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:10,035 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:10,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:10,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:11,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:11,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:12,035 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:12,035 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:12,271 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5065462706ns, electionTimeout:5065ms
2023-03-20 21:35:12,271 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:12,271 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:12,271 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:12,271 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170
2023-03-20 21:35:12,272 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:12,272 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:12,272 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:12,272 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:12,272 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:12,273 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:12,273 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:12,273 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:12,273 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:12,273 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:12,273 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170
2023-03-20 21:35:12,273 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection170] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:12,273 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:12,273 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:12,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:12,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:13,035 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:13,035 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:13,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:13,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:14,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:14,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:15,035 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:15,035 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:15,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:15,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:16,035 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:16,036 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:16,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:16,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:17,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:17,411 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5138455812ns, electionTimeout:5138ms
2023-03-20 21:35:17,411 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:17,412 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:17,412 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:17,412 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171
2023-03-20 21:35:17,413 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:17,414 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:17,414 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:17,414 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:17,414 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:17,414 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:17,414 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:17,414 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:17,415 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:17,415 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:17,415 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171
2023-03-20 21:35:17,415 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection171] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:17,415 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:17,415 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:17,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:18,036 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:18,036 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:18,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:18,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:19,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:19,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:20,036 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:20,036 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:20,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:20,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:21,036 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:21,036 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:21,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:21,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:22,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:22,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:22,573 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5158519394ns, electionTimeout:5158ms
2023-03-20 21:35:22,573 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:22,573 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:22,574 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:22,574 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172
2023-03-20 21:35:22,574 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:22,574 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:22,574 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:22,574 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection172] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:22,575 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:23,036 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:23,036 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:23,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:23,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:24,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:24,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:25,036 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:25,036 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:25,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:25,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:26,036 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:26,036 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:26,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:26,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:27,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:27,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:27,640 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5065485452ns, electionTimeout:5065ms
2023-03-20 21:35:27,640 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:27,641 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:27,641 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:27,641 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173
2023-03-20 21:35:27,641 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:27,641 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:27,641 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:27,641 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection173] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:27,642 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:28,036 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:28,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:28,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:28,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:29,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:29,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:30,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:30,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:30,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:30,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:31,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:31,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:31,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:31,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:35:32,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:32,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:32,810 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5168434007ns, electionTimeout:5168ms
2023-03-20 21:35:32,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:32,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:32,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:32,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174
2023-03-20 21:35:32,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174
2023-03-20 21:35:32,813 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection174] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:32,814 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:32,814 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:33,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:33,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:33,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:33,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:34,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:34,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:34,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:34,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:35,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:35,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:36,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:36,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:36,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:36,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:36,988 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:35:37,303 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:35:37,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:37,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:37,704 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:35:37,879 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5065425758ns, electionTimeout:5065ms
2023-03-20 21:35:37,879 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:37,879 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:37,879 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:37,879 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175
2023-03-20 21:35:37,879 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175
2023-03-20 21:35:37,880 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection175] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:37,881 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:37,881 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:38,011 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:35:38,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:38,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:38,334 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:35:38,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:38,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:38,697 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:35:38,994 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:35:39,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:39,038 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:39,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:39,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:40,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:40,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:41,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:41,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:41,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:41,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:42,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:42,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:42,925 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5044498294ns, electionTimeout:5044ms
2023-03-20 21:35:42,925 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:42,925 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:42,925 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:42,925 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176
2023-03-20 21:35:42,925 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176
2023-03-20 21:35:42,926 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection176] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:42,928 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:42,928 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:43,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:43,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:43,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:43,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:44,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:44,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:44,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:44,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:45,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:45,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:46,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:46,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:46,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:46,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:47,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:47,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:47,979 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5052705357ns, electionTimeout:5051ms
2023-03-20 21:35:47,979 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:47,979 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:47,979 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:47,979 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177
2023-03-20 21:35:47,980 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:47,980 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:47,980 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:47,980 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:47,980 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:47,980 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:47,981 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:47,981 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:47,981 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:47,981 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:47,981 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177
2023-03-20 21:35:47,981 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection177] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:47,981 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:47,981 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:48,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:48,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:48,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:48,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:49,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:49,037 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:49,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:49,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:50,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:50,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:51,037 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:51,038 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:51,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:51,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:52,038 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:52,039 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:35:52,039 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:52,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:52,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:53,067 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5086336784ns, electionTimeout:5086ms
2023-03-20 21:35:53,067 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:53,067 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:53,067 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:53,067 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:53,068 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:53,069 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178
2023-03-20 21:35:53,069 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection178] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:53,069 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:53,069 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:53,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:53,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:54,038 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:54,038 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:54,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:54,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:55,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:55,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:56,038 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:56,038 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:56,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:56,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:57,038 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:57,038 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:57,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:57,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:58,112 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5043468876ns, electionTimeout:5043ms
2023-03-20 21:35:58,112 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:58,112 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:35:58,112 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:35:58,112 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179 PRE_VOTE round 0: result REJECTED
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:35:58,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179
2023-03-20 21:35:58,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection179] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:35:58,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:35:58,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:35:58,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:58,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:35:59,038 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:35:59,038 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:35:59,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:35:59,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:00,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:00,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:01,038 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:01,039 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:01,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:01,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:02,039 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:02,039 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:02,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:02,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:03,177 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5063376744ns, electionTimeout:5063ms
2023-03-20 21:36:03,177 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:03,177 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:03,177 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:03,177 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180
2023-03-20 21:36:03,177 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:03,178 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:03,178 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:03,178 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:03,178 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:03,178 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:03,178 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:03,178 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:03,178 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:03,179 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:03,179 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180
2023-03-20 21:36:03,179 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection180] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:03,179 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:03,179 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:03,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:03,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:04,039 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:04,040 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:04,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:04,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:05,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:05,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:06,040 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:06,040 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:06,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:06,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:07,040 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:07,040 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:07,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:07,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:08,266 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5087351400ns, electionTimeout:5087ms
2023-03-20 21:36:08,266 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:08,266 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:08,266 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:08,266 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181
2023-03-20 21:36:08,267 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:08,267 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:08,267 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:08,267 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:08,267 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:08,267 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:08,267 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:08,267 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:08,268 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:08,268 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:08,268 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181
2023-03-20 21:36:08,268 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection181] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:08,268 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:08,268 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:08,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:08,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:09,040 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:09,041 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:09,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:09,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:10,041 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:10,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:10,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:10,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:11,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:11,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:12,041 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:12,041 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:12,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:12,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:13,334 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5066384817ns, electionTimeout:5066ms
2023-03-20 21:36:13,334 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:13,334 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:13,334 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:13,334 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:13,335 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:13,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182
2023-03-20 21:36:13,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection182] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:13,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:13,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:13,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:13,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:14,041 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:14,041 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:14,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:14,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:15,042 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:15,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:15,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:15,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:16,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:16,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:17,042 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:17,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:17,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:17,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:18,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:18,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:18,530 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5194393281ns, electionTimeout:5194ms
2023-03-20 21:36:18,530 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:18,530 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:18,530 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:18,530 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183
2023-03-20 21:36:18,531 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection183] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:18,532 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:18,532 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:19,042 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:19,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:19,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:19,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:20,042 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:20,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:20,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:20,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:21,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:21,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:22,042 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:22,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:22,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:22,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:23,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:23,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:23,578 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5046388163ns, electionTimeout:5046ms
2023-03-20 21:36:23,578 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:23,578 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:23,578 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:23,578 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184
2023-03-20 21:36:23,578 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:23,579 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:23,579 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:23,579 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:23,580 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:24,042 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:24,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:24,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:24,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:25,042 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:25,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:25,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:25,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:26,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:26,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:27,042 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:27,042 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:27,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:27,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:28,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:28,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:28,683 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5103344466ns, electionTimeout:5103ms
2023-03-20 21:36:28,683 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:28,683 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:28,684 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:28,684 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185
2023-03-20 21:36:28,684 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185
2023-03-20 21:36:28,685 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection185] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:28,686 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:28,686 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:29,043 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:29,043 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:29,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:29,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:30,043 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:30,043 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:30,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:30,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:31,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:31,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:32,043 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:32,043 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:32,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:32,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:33,043 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:33,044 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:33,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:33,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:33,715 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5029709527ns, electionTimeout:5029ms
2023-03-20 21:36:33,715 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:33,715 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:33,715 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:33,715 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186
2023-03-20 21:36:33,715 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186
2023-03-20 21:36:33,716 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:33,717 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:33,717 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:34,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:34,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:35,044 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:35,044 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:35,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:35,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:36,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:36,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:36,993 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:36:37,044 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:37,044 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:37,304 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:36:37,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:37,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:37,706 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:36:38,012 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:36:38,044 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:38,044 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:38,337 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:36:38,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:38,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:38,700 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:36:38,914 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5197415530ns, electionTimeout:5197ms
2023-03-20 21:36:38,914 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:38,914 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:38,914 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:38,914 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187
2023-03-20 21:36:38,914 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:38,915 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:38,916 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:38,996 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:36:39,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:39,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:40,044 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:40,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:40,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:40,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:40,957 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:36:41,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:41,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:42,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:42,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:42,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:42,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:43,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:43,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:43,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:43,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:44,010 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5094347660ns, electionTimeout:5094ms
2023-03-20 21:36:44,010 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:44,010 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:44,010 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:44,010 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188
2023-03-20 21:36:44,010 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188
2023-03-20 21:36:44,011 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection188] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:44,013 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:44,013 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:44,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:44,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:45,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:45,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:45,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:45,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:46,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:46,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:47,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:47,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:47,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:47,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:48,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:48,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:48,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:48,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:49,013 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5001580005ns, electionTimeout:5000ms
2023-03-20 21:36:49,013 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:49,013 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:49,013 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:49,013 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189
2023-03-20 21:36:49,013 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189
2023-03-20 21:36:49,014 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:49,016 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:49,016 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:49,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:49,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:50,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:50,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:50,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:50,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:51,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:51,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:51,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:51,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:52,041 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:36:52,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:52,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:53,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:53,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:53,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:53,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:54,048 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5033622099ns, electionTimeout:5032ms
2023-03-20 21:36:54,048 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:54,048 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:54,048 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:54,048 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190
2023-03-20 21:36:54,049 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:54,049 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:54,049 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:54,049 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:54,049 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:54,049 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:54,049 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:54,049 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:54,050 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:54,050 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:54,050 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190
2023-03-20 21:36:54,050 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection190] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:54,050 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:54,050 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:54,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:54,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:55,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:55,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:55,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:55,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:56,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:56,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:56,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:56,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:57,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:57,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:58,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:36:58,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:36:58,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:58,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:36:59,183 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5133366395ns, electionTimeout:5133ms
2023-03-20 21:36:59,183 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:59,183 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:36:59,183 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:36:59,183 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191 PRE_VOTE round 0: result REJECTED
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:36:59,184 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191
2023-03-20 21:36:59,185 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection191] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:36:59,185 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:36:59,185 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:36:59,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:36:59,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:00,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:00,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:00,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:00,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:01,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:01,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:01,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:01,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:02,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:02,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:03,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:03,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:03,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:03,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:04,235 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5050377697ns, electionTimeout:5050ms
2023-03-20 21:37:04,235 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:04,235 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:04,235 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:04,235 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192
2023-03-20 21:37:04,235 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:04,236 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:04,237 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:04,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:04,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:05,045 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:05,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:05,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:05,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:37:06,046 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:06,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:06,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:06,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:07,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:07,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:08,046 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:08,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:08,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:08,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:09,046 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:09,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:09,321 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5084380770ns, electionTimeout:5084ms
2023-03-20 21:37:09,321 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:09,321 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:09,321 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:09,321 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193
2023-03-20 21:37:09,321 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection193] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:09,322 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:09,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:09,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:10,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:10,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:11,046 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:11,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:11,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:11,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:12,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:12,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:13,046 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:13,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:13,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:13,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:14,046 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:14,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:14,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5013333589ns, electionTimeout:5013ms
2023-03-20 21:37:14,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:14,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:14,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:14,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194
2023-03-20 21:37:14,336 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection194] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:14,337 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:14,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:14,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:37:15,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:15,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:16,046 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:16,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:16,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:16,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:17,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:17,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:18,047 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:18,047 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:18,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:18,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:19,047 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:19,047 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:19,362 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5024368693ns, electionTimeout:5024ms
2023-03-20 21:37:19,362 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:19,362 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:19,362 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:19,362 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195
2023-03-20 21:37:19,362 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:19,362 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:19,362 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection195] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:19,363 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:19,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:19,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:20,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:20,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:21,047 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:21,047 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:21,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:21,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:22,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:22,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:23,048 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:23,048 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:23,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:23,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:24,049 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:24,049 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:24,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:24,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5110435734ns, electionTimeout:5110ms
2023-03-20 21:37:24,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:24,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:24,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:24,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196
2023-03-20 21:37:24,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:24,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:24,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection196] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:24,475 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:24,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:37:25,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:25,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:26,049 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:26,049 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:26,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:26,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:27,049 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:27,049 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:27,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:27,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:28,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:28,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:29,049 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:29,049 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:29,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:29,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:29,630 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5155420656ns, electionTimeout:5155ms
2023-03-20 21:37:29,631 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:29,631 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:29,631 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:29,631 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197
2023-03-20 21:37:29,631 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:29,631 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:29,631 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:29,631 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection197] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:29,632 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:30,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:30,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:31,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:31,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:31,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:31,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:32,049 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:32,049 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:32,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:32,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:33,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:33,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:34,049 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:34,049 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:34,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:34,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:34,739 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5107317550ns, electionTimeout:5107ms
2023-03-20 21:37:34,739 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:34,740 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:34,740 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:34,740 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198
2023-03-20 21:37:34,740 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198
2023-03-20 21:37:34,741 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection198] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:34,742 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:34,742 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:35,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:35,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:36,049 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:36,049 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:36,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:36,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:36,993 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:37:37,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:37,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:37,305 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:37:37,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:37,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:37,706 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:37:38,013 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:37:38,337 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:37:38,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:38,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:38,700 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:37:38,996 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:37:39,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:39,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:39,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:39,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:39,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5064642438ns, electionTimeout:5064ms
2023-03-20 21:37:39,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:39,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:39,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:39,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199
2023-03-20 21:37:39,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection199] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:39,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:39,808 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:40,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:40,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:41,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:41,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:41,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:41,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:42,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:42,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:42,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:42,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:43,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:43,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:44,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:44,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:44,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:44,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:44,817 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5009344203ns, electionTimeout:5009ms
2023-03-20 21:37:44,817 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:44,817 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:44,817 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:44,817 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200
2023-03-20 21:37:44,817 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection200] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:44,818 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:45,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:45,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:45,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:45,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:46,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:46,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:47,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:47,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:47,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:47,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:48,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:48,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:49,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:49,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:49,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:49,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:49,860 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5041334298ns, electionTimeout:5041ms
2023-03-20 21:37:49,860 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:49,860 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:49,860 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:49,860 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201
2023-03-20 21:37:49,860 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:49,863 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:49,864 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:49,864 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:49,864 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:49,864 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:49,864 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:49,864 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:49,864 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:49,865 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:49,865 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201
2023-03-20 21:37:49,865 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection201] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:49,865 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:49,865 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:50,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:50,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:50,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:50,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:51,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:51,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:52,041 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:37:52,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:52,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:52,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:52,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:53,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:53,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:54,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:54,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:54,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:54,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:54,885 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5020385464ns, electionTimeout:5020ms
2023-03-20 21:37:54,885 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:54,885 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:54,885 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:54,885 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202
2023-03-20 21:37:54,886 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:54,886 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:54,886 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:54,886 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection202] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:54,889 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:55,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:55,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:55,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:55,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:56,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:56,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:57,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:57,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:57,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:57,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:58,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:58,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:59,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:37:59,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:37:59,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:37:59,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:37:59,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5041462950ns, electionTimeout:5041ms
2023-03-20 21:37:59,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:59,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:37:59,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:37:59,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203
2023-03-20 21:37:59,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:37:59,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:59,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203 PRE_VOTE round 0: result REJECTED
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection203] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:37:59,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:00,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:00,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:00,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:00,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:01,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:01,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:02,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:02,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:02,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:02,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:03,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:03,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:04,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:04,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:04,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:04,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:05,002 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5070357300ns, electionTimeout:5070ms
2023-03-20 21:38:05,003 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:05,003 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:05,003 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:05,003 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204
2023-03-20 21:38:05,003 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:05,003 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:05,003 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection204] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:05,004 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:05,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:05,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:05,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:05,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:06,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:06,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:07,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:07,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:07,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:07,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:08,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:08,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:08,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:08,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:09,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:09,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:10,028 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5024352460ns, electionTimeout:5024ms
2023-03-20 21:38:10,028 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:10,029 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:10,029 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:10,029 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205
2023-03-20 21:38:10,029 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:10,029 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:10,029 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:10,029 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection205] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:10,030 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:10,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:10,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:10,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:10,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:11,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:11,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:12,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:12,050 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:12,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:12,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:13,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:13,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:13,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:13,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:14,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:14,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:15,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:15,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:15,129 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5099425897ns, electionTimeout:5099ms
2023-03-20 21:38:15,129 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:15,129 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:15,130 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:15,130 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206
2023-03-20 21:38:15,130 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:15,130 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:15,130 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:15,132 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:15,132 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:15,132 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:15,132 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:15,132 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:15,132 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:15,132 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:15,132 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206
2023-03-20 21:38:15,132 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection206] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:15,133 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:15,133 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:15,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:15,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:16,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:16,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:17,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:17,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:17,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:17,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:18,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:18,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:18,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:18,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:19,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:19,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:20,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:20,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:20,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5047387953ns, electionTimeout:5047ms
2023-03-20 21:38:20,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:20,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:20,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:20,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207
2023-03-20 21:38:20,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection207] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:20,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:20,182 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:20,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:20,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:21,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:21,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:22,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:22,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:22,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:22,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:23,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:23,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:23,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:23,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:24,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:24,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:25,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:25,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:25,353 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5171325506ns, electionTimeout:5171ms
2023-03-20 21:38:25,353 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:25,353 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:25,353 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:25,353 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208
2023-03-20 21:38:25,353 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection208] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:25,354 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:25,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:25,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:26,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:26,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:26,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:26,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:27,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:27,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:28,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:28,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:28,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:28,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:29,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:29,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:38:30,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:30,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:30,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:30,473 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5118378373ns, electionTimeout:5118ms
2023-03-20 21:38:30,473 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:30,473 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:30,473 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:30,473 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209
2023-03-20 21:38:30,473 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:30,473 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:30,473 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:30,474 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:30,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:31,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:31,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:31,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:31,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:32,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:32,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:33,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:33,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:33,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:33,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:34,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:34,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:35,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:35,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:35,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:35,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:35,668 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5193359422ns, electionTimeout:5193ms
2023-03-20 21:38:35,668 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:35,668 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:35,668 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:35,668 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210
2023-03-20 21:38:35,668 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:35,668 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:35,668 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:35,669 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:35,670 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:36,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:36,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:36,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:36,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:36,993 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:38:37,305 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:38:37,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:37,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:37,706 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:38:38,013 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:38:38,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:38,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:38,337 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:38:38,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:38,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:38,700 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:38:38,996 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:38:39,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:39,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:40,050 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:40,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:40,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:40,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:40,725 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5055384799ns, electionTimeout:5055ms
2023-03-20 21:38:40,725 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:40,725 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:40,725 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:40,725 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211
2023-03-20 21:38:40,725 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211
2023-03-20 21:38:40,726 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection211] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:40,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:40,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:40,958 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:38:41,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:41,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:41,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:41,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:42,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:42,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:43,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:43,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:43,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:43,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:44,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:44,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:44,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:44,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:45,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:45,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:45,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5084510154ns, electionTimeout:5084ms
2023-03-20 21:38:45,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:45,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:45,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:45,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212
2023-03-20 21:38:45,811 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212
2023-03-20 21:38:45,820 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection212] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:45,826 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:45,826 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:46,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:46,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:46,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:46,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:47,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:47,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:48,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:48,051 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:48,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:48,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:49,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:49,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:49,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:49,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:50,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:50,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:50,934 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113276887ns, electionTimeout:5107ms
2023-03-20 21:38:50,934 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:50,934 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:50,934 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:50,934 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213
2023-03-20 21:38:50,934 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:50,934 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:50,934 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:50,935 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:51,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:51,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:51,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:51,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:52,042 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:38:52,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:52,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:53,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:53,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:53,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:53,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:54,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:54,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:54,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:54,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:55,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:55,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:56,054 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:56,054 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:56,112 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5177385256ns, electionTimeout:5177ms
2023-03-20 21:38:56,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:56,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:38:56,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:38:56,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214
2023-03-20 21:38:56,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:38:56,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:56,113 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214 PRE_VOTE round 0: result REJECTED
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection214] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:38:56,114 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:38:56,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:56,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:57,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:57,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:58,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:58,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:58,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:58,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:38:59,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:38:59,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:38:59,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:38:59,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:00,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:00,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:01,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:01,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:01,293 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5179332796ns, electionTimeout:5179ms
2023-03-20 21:39:01,293 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:01,293 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:01,294 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:01,294 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215
2023-03-20 21:39:01,294 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:01,294 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:01,294 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:01,294 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:01,295 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:01,295 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:01,295 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:01,295 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:01,295 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:01,295 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:01,295 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215
2023-03-20 21:39:01,295 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection215] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:01,296 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:01,296 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:01,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:01,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:02,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:02,053 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:02,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:02,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:03,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:03,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:04,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:04,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:04,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:04,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:05,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:05,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:06,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:06,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:06,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:06,396 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5101366626ns, electionTimeout:5100ms
2023-03-20 21:39:06,396 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:06,396 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:06,396 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:06,397 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216
2023-03-20 21:39:06,397 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:06,397 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:06,397 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:06,397 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:06,398 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:06,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:07,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:07,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:07,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:07,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:08,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:08,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:09,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:09,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:09,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:09,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:10,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:10,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:11,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:11,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:11,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:11,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:11,550 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5152419104ns, electionTimeout:5152ms
2023-03-20 21:39:11,550 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:11,550 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:11,550 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:11,550 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217
2023-03-20 21:39:11,551 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:11,551 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:11,551 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:11,551 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:11,551 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:11,551 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:11,552 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:11,552 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:11,552 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:11,552 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:11,552 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217
2023-03-20 21:39:11,552 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection217] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:11,552 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:11,552 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:12,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:12,053 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:12,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:12,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:13,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:13,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:14,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:14,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:14,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:14,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:15,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:15,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:16,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:16,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:16,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:16,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:16,712 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5160461584ns, electionTimeout:5160ms
2023-03-20 21:39:16,712 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:16,712 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:16,712 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:16,712 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218
2023-03-20 21:39:16,713 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:16,713 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:16,713 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:16,713 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:16,713 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:16,713 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:16,713 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:16,714 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:16,714 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:16,714 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:16,714 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218
2023-03-20 21:39:16,714 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection218] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:16,714 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:16,714 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:17,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:17,053 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:17,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:17,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:18,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:18,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:19,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:19,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:19,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:19,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:20,052 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:20,052 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:20,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:20,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:21,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:21,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:21,831 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5117391033ns, electionTimeout:5117ms
2023-03-20 21:39:21,831 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:21,831 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:21,831 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:21,831 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219
2023-03-20 21:39:21,832 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:21,832 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:21,832 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:21,832 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:21,833 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:22,053 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:22,053 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:22,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:22,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:23,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:23,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:24,053 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:24,053 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:24,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:24,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:25,053 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:25,053 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:25,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:25,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:26,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:26,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:26,868 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5035357328ns, electionTimeout:5035ms
2023-03-20 21:39:26,868 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:26,868 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:26,868 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:26,869 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220
2023-03-20 21:39:26,869 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:26,869 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:26,869 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:26,869 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection220] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:26,870 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:27,054 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:27,054 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:27,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:27,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:28,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:28,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:29,054 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:29,054 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:29,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:29,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:30,054 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:30,054 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:30,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:30,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:31,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:31,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:39:31,906 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5036399834ns, electionTimeout:5036ms
2023-03-20 21:39:31,906 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:31,906 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:31,906 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:31,906 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221
2023-03-20 21:39:31,907 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:31,907 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:31,907 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:31,907 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:31,907 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:31,907 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:31,908 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:31,908 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:31,908 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:31,908 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:31,908 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221
2023-03-20 21:39:31,908 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection221] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:31,908 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:31,908 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:32,054 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:32,054 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:32,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:32,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:33,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:33,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:34,055 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:34,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:34,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:34,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:35,055 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:35,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:35,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:35,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:36,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:36,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:36,930 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5022414417ns, electionTimeout:5022ms
2023-03-20 21:39:36,930 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:36,930 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:36,930 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:36,930 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222
2023-03-20 21:39:36,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:36,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:36,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:36,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:36,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:36,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:36,931 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:36,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:36,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:36,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:36,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222
2023-03-20 21:39:36,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:36,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:36,932 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:36,994 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:39:37,054 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:37,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:37,305 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:39:37,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:37,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:37,707 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:39:38,013 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:39:38,337 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:39:38,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:38,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:38,700 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:39:38,996 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:39:39,055 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:39,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:39,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:39,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:40,055 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:40,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:40,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:40,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:41,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:41,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:42,019 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5087345477ns, electionTimeout:5087ms
2023-03-20 21:39:42,019 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:42,019 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:42,019 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:42,019 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223
2023-03-20 21:39:42,020 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:42,020 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:42,020 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:42,020 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:42,020 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:42,020 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:42,020 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:42,020 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:42,020 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:42,021 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:42,021 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223
2023-03-20 21:39:42,021 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:42,021 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:42,021 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:42,055 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:42,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:42,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:42,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:43,055 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:43,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:43,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:43,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:44,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:44,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:39:45,055 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:45,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:45,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:45,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:46,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:46,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:47,033 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5012420297ns, electionTimeout:5012ms
2023-03-20 21:39:47,033 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:47,033 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:47,033 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:47,033 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224
2023-03-20 21:39:47,034 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:47,034 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:47,034 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:47,034 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:47,034 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:47,034 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:47,034 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:47,034 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:47,035 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:47,035 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:47,035 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224
2023-03-20 21:39:47,035 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection224] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:47,035 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:47,035 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:47,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:47,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:47,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:47,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:48,055 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:48,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:48,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:48,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:49,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:49,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:50,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:50,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:50,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:50,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:51,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:51,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:52,042 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:39:52,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:52,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:52,062 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5027559367ns, electionTimeout:5027ms
2023-03-20 21:39:52,062 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:52,062 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:52,062 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:52,062 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225
2023-03-20 21:39:52,063 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:52,063 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:52,063 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:52,063 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:52,063 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:52,063 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:52,064 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:52,064 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:52,064 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:52,064 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:52,064 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225
2023-03-20 21:39:52,064 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection225] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:52,072 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:52,072 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:52,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:52,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:53,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:53,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:53,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:53,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:54,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:54,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:55,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:55,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:55,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:55,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:56,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:56,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:57,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:57,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:57,158 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5094693262ns, electionTimeout:5086ms
2023-03-20 21:39:57,159 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:57,159 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:39:57,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(720)) - pipeline Action CLOSE on pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec.Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 300185ms
2023-03-20 21:39:57,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:39:57,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226
2023-03-20 21:39:57,180 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226 PRE_VOTE round 0: result REJECTED
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226
2023-03-20 21:39:57,181 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection226] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:39:57,182 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:39:57,182 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:39:57,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:57,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:58,057 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:39:58,057 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:39:58,058 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(83)) - Received pipeline action CLOSE for PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec from datanode 3b791506-899f-4927-929a-007385ffa693. Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 300185ms
2023-03-20 21:39:58,058 [EventQueue-PipelineActionsForPipelineActionHandler] WARN  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(94)) - Pipeline action CLOSE received for unknown pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec, firing close pipeline event.
2023-03-20 21:39:58,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:58,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:39:59,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:39:59,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:00,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:00,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:00,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:00,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:40:01,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:01,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:01,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:01,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:02,373 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5191385863ns, electionTimeout:5191ms
2023-03-20 21:40:02,373 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:02,373 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:40:02,373 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(720)) - pipeline Action CLOSE on pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec.Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 305390ms
2023-03-20 21:40:02,373 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:40:02,373 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227
2023-03-20 21:40:02,373 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:40:02,374 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:02,374 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:02,374 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227 PRE_VOTE round 0: result REJECTED
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:02,375 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:02,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:02,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:03,056 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(83)) - Received pipeline action CLOSE for PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec from datanode 3b791506-899f-4927-929a-007385ffa693. Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 305390ms
2023-03-20 21:40:03,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:03,056 [EventQueue-PipelineActionsForPipelineActionHandler] WARN  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(94)) - Pipeline action CLOSE received for unknown pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec, firing close pipeline event.
2023-03-20 21:40:03,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:03,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:03,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:04,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:04,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:05,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:05,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:05,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:05,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:06,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:06,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:06,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:06,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:07,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:07,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:07,560 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5184358971ns, electionTimeout:5184ms
2023-03-20 21:40:07,560 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:07,560 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:40:07,560 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(720)) - pipeline Action CLOSE on pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec.Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 310577ms
2023-03-20 21:40:07,560 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:40:07,560 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228
2023-03-20 21:40:07,560 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:40:07,560 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:07,561 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:07,561 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:07,562 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:07,562 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:40:07,562 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:07,562 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:07,562 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228 PRE_VOTE round 0: result REJECTED
2023-03-20 21:40:07,563 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:40:07,563 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228
2023-03-20 21:40:07,563 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection228] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:07,563 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:07,563 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:08,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:08,056 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(83)) - Received pipeline action CLOSE for PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec from datanode 3b791506-899f-4927-929a-007385ffa693. Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 310577ms
2023-03-20 21:40:08,057 [EventQueue-PipelineActionsForPipelineActionHandler] WARN  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(94)) - Pipeline action CLOSE received for unknown pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec, firing close pipeline event.
2023-03-20 21:40:08,057 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:08,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:08,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:09,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:09,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:10,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:10,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:10,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:10,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:11,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:11,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:11,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:11,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:12,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:12,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:12,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5163907773ns, electionTimeout:5163ms
2023-03-20 21:40:12,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:12,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:40:12,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(720)) - pipeline Action CLOSE on pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec.Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 315744ms
2023-03-20 21:40:12,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:40:12,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229
2023-03-20 21:40:12,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:40:12,727 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229 PRE_VOTE round 0: result REJECTED
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:12,728 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:13,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:13,056 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(83)) - Received pipeline action CLOSE for PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec from datanode 3b791506-899f-4927-929a-007385ffa693. Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 315744ms
2023-03-20 21:40:13,056 [EventQueue-PipelineActionsForPipelineActionHandler] WARN  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(94)) - Pipeline action CLOSE received for unknown pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec, firing close pipeline event.
2023-03-20 21:40:13,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:13,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:13,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:14,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:14,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:15,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:15,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:15,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:15,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:15,577 [Command processor thread] WARN  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$1(110)) - Add group failed for 73dcf697-4659-4759-9fac-94f9a54bb6a2(fv-az985-449/10.1.0.10)
org.apache.ratis.protocol.exceptions.RaftRetryFailureException: Failed GroupManagementRequest:client-760ECADFFE13->73dcf697-4659-4759-9fac-94f9a54bb6a2@group-16F0494636EC, cid=522, seq=0, RW, null, Add:group-16F0494636EC:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER] for 23 attempts with RequestTypeDependentRetryPolicy{WRITE->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@681529bb, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->org.apache.ratis.retry.ExponentialBackoffRetry@681529bb}), WATCH->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@681529bb, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->NoRetry})}
	at org.apache.ratis.client.impl.RaftClientImpl.noMoreRetries(RaftClientImpl.java:307)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:119)
	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:106)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:102)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:642)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:99)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:223)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:170)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:98)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:134)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:99)
	... 15 more
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:271)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:252)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:165)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:507)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:172)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:221)
	... 19 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: /10.1.0.10:35611
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.newConnectException0(Errors.java:155)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.handleConnectErrno(Errors.java:128)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Socket.finishConnect(Socket.java:321)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:710)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:687)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:567)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:477)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:385)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:40:16,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:16,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:16,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:16,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:17,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:17,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:17,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5077392159ns, electionTimeout:5077ms
2023-03-20 21:40:17,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:17,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:40:17,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(720)) - pipeline Action CLOSE on pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec.Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 320823ms
2023-03-20 21:40:17,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:40:17,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230
2023-03-20 21:40:17,806 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230 PRE_VOTE round 0: result REJECTED
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:17,807 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:17,808 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:18,056 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(83)) - Received pipeline action CLOSE for PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec from datanode 3b791506-899f-4927-929a-007385ffa693. Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 320823ms
2023-03-20 21:40:18,057 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:18,057 [EventQueue-PipelineActionsForPipelineActionHandler] WARN  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(94)) - Pipeline action CLOSE received for unknown pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec, firing close pipeline event.
2023-03-20 21:40:18,057 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:18,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:18,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:19,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:19,057 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:19,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:19,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:20,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:20,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:21,057 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:21,058 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:21,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:21,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:22,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:22,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:22,975 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5167362674ns, electionTimeout:5167ms
2023-03-20 21:40:22,975 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:22,975 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:40:22,975 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(720)) - pipeline Action CLOSE on pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec.Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 325992ms
2023-03-20 21:40:22,975 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:40:22,975 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231
2023-03-20 21:40:22,975 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231 PRE_VOTE round 0: result REJECTED
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231
2023-03-20 21:40:22,976 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection231] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:22,977 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:22,977 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:23,057 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:23,057 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(83)) - Received pipeline action CLOSE for PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec from datanode 3b791506-899f-4927-929a-007385ffa693. Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 325992ms
2023-03-20 21:40:23,057 [EventQueue-PipelineActionsForPipelineActionHandler] WARN  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(94)) - Pipeline action CLOSE received for unknown pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec, firing close pipeline event.
2023-03-20 21:40:23,057 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:23,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:23,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:24,057 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:24,058 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:24,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:24,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:25,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:25,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:26,057 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:26,057 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:26,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:26,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:27,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:27,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:28,057 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:28,057 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:28,093 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5116442067ns, electionTimeout:5116ms
2023-03-20 21:40:28,093 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:28,093 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-20 21:40:28,093 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(720)) - pipeline Action CLOSE on pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec.Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 331110ms
2023-03-20 21:40:28,093 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-20 21:40:28,093 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232
2023-03-20 21:40:28,093 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[73dcf697-4659-4759-9fac-94f9a54bb6a2|rpc:10.1.0.10:35611|dataStream:10.1.0.10:34585|priority:0|startupRole:FOLLOWER, 3b791506-899f-4927-929a-007385ffa693|rpc:10.1.0.10:39897|dataStream:10.1.0.10:39527|priority:1|startupRole:FOLLOWER, 9d2a4ecd-2086-4135-bf3e-5d16e44246f0|rpc:10.1.0.10:45377|dataStream:10.1.0.10:45553|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232 PRE_VOTE round 0: result REJECTED
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232
2023-03-20 21:40:28,094 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-LeaderElection232] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3b791506-899f-4927-929a-007385ffa693: start 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:28,095 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-20 21:40:28,095 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-20 21:40:28,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:28,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:29,057 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:29,058 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(83)) - Received pipeline action CLOSE for PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec from datanode 3b791506-899f-4927-929a-007385ffa693. Reason : 3b791506-899f-4927-929a-007385ffa693 is in candidate state for 331110ms
2023-03-20 21:40:29,058 [EventQueue-PipelineActionsForPipelineActionHandler] WARN  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(94)) - Pipeline action CLOSE received for unknown pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec, firing close pipeline event.
2023-03-20 21:40:29,058 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:29,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:29,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:30,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:30,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:31,060 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec is not found
2023-03-20 21:40:31,060 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-20 21:40:31,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:31,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:31,824 [Command processor thread] WARN  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$1(110)) - Add group failed for 00867d28-7830-4d3d-a4c5-0b9d063e06a7(fv-az985-449/10.1.0.10)
org.apache.ratis.protocol.exceptions.RaftRetryFailureException: Failed GroupManagementRequest:client-A4F5FE82906C->00867d28-7830-4d3d-a4c5-0b9d063e06a7@group-6C6EC40B5BF1, cid=526, seq=0, RW, null, Add:group-6C6EC40B5BF1:[1bf5ab73-9bc2-4a2b-ba36-40cddbfe2290|rpc:10.1.0.10:42673|dataStream:10.1.0.10:42991|priority:0|startupRole:FOLLOWER, 00867d28-7830-4d3d-a4c5-0b9d063e06a7|rpc:10.1.0.10:46797|dataStream:10.1.0.10:39523|priority:1|startupRole:FOLLOWER, 044bfaef-c902-47be-95bf-0f9e32226746|rpc:10.1.0.10:40849|dataStream:10.1.0.10:43085|priority:0|startupRole:FOLLOWER] for 24 attempts with RequestTypeDependentRetryPolicy{WRITE->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@c3f4bbf, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->org.apache.ratis.retry.ExponentialBackoffRetry@c3f4bbf}), WATCH->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@c3f4bbf, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->NoRetry})}
	at org.apache.ratis.client.impl.RaftClientImpl.noMoreRetries(RaftClientImpl.java:307)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:119)
	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:106)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:102)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:642)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:99)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:223)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:170)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:98)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:134)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:99)
	... 15 more
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:271)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:252)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:165)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:507)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:172)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:221)
	... 19 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: /10.1.0.10:46797
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.newConnectException0(Errors.java:155)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.handleConnectErrno(Errors.java:128)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Socket.finishConnect(Socket.java:321)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:710)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:687)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:567)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:477)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:385)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:40:31,825 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=29f4efd4-aa8f-45ea-a1c0-6c6ec40b5bf1.
2023-03-20 21:40:31,826 [Command processor thread] WARN  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$1(110)) - Add group failed for 9d2a4ecd-2086-4135-bf3e-5d16e44246f0(fv-az985-449/10.1.0.10)
java.io.InterruptedIOException: retry policy=RequestTypeDependentRetryPolicy{WRITE->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@657a7c7e, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->org.apache.ratis.retry.ExponentialBackoffRetry@657a7c7e}), WATCH->ExceptionDependentRetry(maxAttempts=2147483647; defaultPolicy=MultipleLinearRandomRetry[5x5s, 5x10s, 5x15s, 5x20s, 5x25s, 10x60s]; map={org.apache.ratis.protocol.exceptions.GroupMismatchException->NoRetry, org.apache.ratis.protocol.exceptions.NotReplicatedException->NoRetry, org.apache.ratis.protocol.exceptions.ResourceUnavailableException->org.apache.ratis.retry.ExponentialBackoffRetry@657a7c7e, org.apache.ratis.protocol.exceptions.StateMachineException->NoRetry, org.apache.ratis.protocol.exceptions.TimeoutIOException->NoRetry})}
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:125)
	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:106)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:102)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:642)
	at java.lang.Thread.run(Thread.java:750)
2023-03-20 21:40:31,826 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=f3aa6e2d-4ee0-422f-8d86-16f0494636ec.
2023-03-20 21:40:31,826 [Listener at 127.0.0.1/40507] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-20 21:40:31,826 [Listener at 127.0.0.1/40507] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 3b791506-899f-4927-929a-007385ffa693: close
2023-03-20 21:40:31,827 [3b791506-899f-4927-929a-007385ffa693-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: shutdown
2023-03-20 21:40:31,827 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 3b791506-899f-4927-929a-007385ffa693: shutdown server GrpcServerProtocolService now
2023-03-20 21:40:31,827 [3b791506-899f-4927-929a-007385ffa693-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-16F0494636EC,id=3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:40:31,828 [Listener at 127.0.0.1/40507] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 73dcf697-4659-4759-9fac-94f9a54bb6a2 Close channels
2023-03-20 21:40:31,829 [3b791506-899f-4927-929a-007385ffa693-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC: shutdown
2023-03-20 21:40:31,833 [Listener at 127.0.0.1/40507] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 9d2a4ecd-2086-4135-bf3e-5d16e44246f0 Close channels
2023-03-20 21:40:31,833 [3b791506-899f-4927-929a-007385ffa693-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F06956C75EC,id=3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:40:31,833 [Listener at 127.0.0.1/40507] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 3b791506-899f-4927-929a-007385ffa693: shutdown server GrpcServerProtocolService successfully
2023-03-20 21:40:31,833 [3b791506-899f-4927-929a-007385ffa693-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-LeaderStateImpl
2023-03-20 21:40:31,833 [3b791506-899f-4927-929a-007385ffa693-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa4029890, L:/0:0:0:0:0:0:0:0:39527] CLOSE
2023-03-20 21:40:31,833 [3b791506-899f-4927-929a-007385ffa693-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-PendingRequests: sendNotLeaderResponses
2023-03-20 21:40:31,833 [3b791506-899f-4927-929a-007385ffa693-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa4029890, L:/0:0:0:0:0:0:0:0:39527] INACTIVE
2023-03-20 21:40:31,834 [3b791506-899f-4927-929a-007385ffa693-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa4029890, L:/0:0:0:0:0:0:0:0:39527] UNREGISTERED
2023-03-20 21:40:31,834 [3b791506-899f-4927-929a-007385ffa693-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-StateMachineUpdater: set stopIndex = 0
2023-03-20 21:40:31,834 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-0F06956C75EC: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/7676672b-f26c-4de6-85a4-0f06956c75ec/sm/snapshot.1_0
2023-03-20 21:40:31,834 [3b791506-899f-4927-929a-007385ffa693-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3b791506-899f-4927-929a-007385ffa693: shutdown 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState
2023-03-20 21:40:31,835 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-0F06956C75EC: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data/ratis/7676672b-f26c-4de6-85a4-0f06956c75ec/sm/snapshot.1_0 took: 0 ms
2023-03-20 21:40:31,835 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-StateMachineUpdater: Took a snapshot at index 0
2023-03-20 21:40:31,835 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-20 21:40:31,835 [3b791506-899f-4927-929a-007385ffa693-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC: closes. applyIndex: 0
2023-03-20 21:40:31,835 [3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:40:31,835 [3b791506-899f-4927-929a-007385ffa693-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 3b791506-899f-4927-929a-007385ffa693@group-0F06956C75EC-SegmentedRaftLogWorker close()
2023-03-20 21:40:31,837 [3b791506-899f-4927-929a-007385ffa693-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-StateMachineUpdater: set stopIndex = -1
2023-03-20 21:40:31,837 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-FollowerState was interrupted
2023-03-20 21:40:31,837 [3b791506-899f-4927-929a-007385ffa693-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC: closes. applyIndex: -1
2023-03-20 21:40:31,837 [3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-20 21:40:31,837 [3b791506-899f-4927-929a-007385ffa693-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 3b791506-899f-4927-929a-007385ffa693@group-16F0494636EC-SegmentedRaftLogWorker close()
2023-03-20 21:40:31,844 [JvmPauseMonitor101] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-3b791506-899f-4927-929a-007385ffa693: Stopped
2023-03-20 21:40:32,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:32,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:33,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:33,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:33,851 [Listener at 127.0.0.1/40507] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(437)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-68dc73ea-0a5a-4ab1-885e-be108a6d02c2/datanode-0/data-0/containers/hdds/68dc73ea-0a5a-4ab1-885e-be108a6d02c2/DS-2e14535f-64a8-4d5a-ade5-c4984d433ed3/container.db for volume DS-2e14535f-64a8-4d5a-ade5-c4984d433ed3
2023-03-20 21:40:33,851 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-20 21:40:33,851 [Listener at 127.0.0.1/40507] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-20 21:40:33,854 [Listener at 127.0.0.1/40507] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-20 21:40:33,863 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2ef8ff59{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-20 21:40:33,863 [Listener at 127.0.0.1/40507] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6abdc8d1{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-20 21:40:33,863 [Listener at 127.0.0.1/40507] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-20 21:40:33,863 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6d640db8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-20 21:40:33,863 [Listener at 127.0.0.1/40507] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3f7dde3c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-20 21:40:34,075 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 3b791506-899f-4927-929a-007385ffa693(fv-az985-449/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=7676672b-f26c-4de6-85a4-0f06956c75ec]
2023-03-20 21:40:34,075 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 7676672b-f26c-4de6-85a4-0f06956c75ec, Nodes: 3b791506-899f-4927-929a-007385ffa693(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3b791506-899f-4927-929a-007385ffa693, CreationTimestamp2023-03-20T21:34:53.979Z[Etc/UTC]] moved to CLOSED state
2023-03-20 21:40:34,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:34,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:35,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:35,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:36,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:36,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:36,994 [BlockDeletingService#3] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:40:37,077 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 3b791506-899f-4927-929a-007385ffa693(fv-az985-449/10.1.0.10)
2023-03-20 21:40:37,077 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=7676672b-f26c-4de6-85a4-0f06956c75ec close command to datanode 3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:40:37,077 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 7676672b-f26c-4de6-85a4-0f06956c75ec, Nodes: 3b791506-899f-4927-929a-007385ffa693(fv-az985-449/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:3b791506-899f-4927-929a-007385ffa693, CreationTimestamp2023-03-20T21:34:53.979Z[Etc/UTC]] removed.
2023-03-20 21:40:37,077 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/3b791506-899f-4927-929a-007385ffa693
2023-03-20 21:40:37,305 [BlockDeletingService#3] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:40:37,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:37,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:37,707 [BlockDeletingService#3] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:40:38,013 [BlockDeletingService#3] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:40:38,338 [BlockDeletingService#3] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:40:38,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:38,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:38,701 [BlockDeletingService#3] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:40:38,997 [BlockDeletingService#3] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:40:39,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:39,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:40,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:40,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:40,959 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:40:41,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:41,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:42,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:42,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:43,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:43,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:44,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:44,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:45,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:45,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:46,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:46,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:47,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:47,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:48,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:48,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:49,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:49,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:50,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:50,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:51,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:51,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:52,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:52,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:53,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:53,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:54,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:54,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:55,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:55,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:56,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:56,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:57,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:57,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:58,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:58,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:40:59,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:40:59,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:00,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:00,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:01,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:01,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:02,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:02,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:03,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:03,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:04,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:04,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:05,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:05,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:06,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:06,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:07,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:07,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:08,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:08,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:09,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:09,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:10,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:10,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:11,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:11,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:12,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:12,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:13,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:13,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:14,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:14,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:15,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:15,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:16,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:16,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:17,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:17,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:18,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:18,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:19,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:19,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:20,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:20,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:21,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:21,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:22,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:22,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:23,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:23,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:24,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:24,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:25,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:25,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:26,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:26,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:27,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:27,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:28,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:28,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:41:29,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:29,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:30,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:30,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:31,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:31,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:32,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:32,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:33,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:33,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:34,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:34,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:35,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:35,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:36,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:36,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:36,994 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:41:37,306 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:41:37,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:37,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:37,707 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:41:38,014 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:41:38,338 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:41:38,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:38,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:38,701 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:41:38,997 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:41:39,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:39,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:40,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:40,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:41,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:41,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:42,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:42,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:43,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:43,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:44,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:44,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:45,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:45,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:46,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:46,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:47,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:47,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:48,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:48,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:49,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:49,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:50,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:50,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:51,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:51,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:52,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:52,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:53,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:53,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:54,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:54,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:55,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:55,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:56,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:56,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:57,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:57,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:58,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:58,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:41:59,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:41:59,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:00,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:00,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:01,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:01,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:02,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:02,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:42:03,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:03,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:04,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:04,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:05,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:05,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:06,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:06,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:07,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:07,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:42:08,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:08,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:09,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:09,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:10,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:10,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:11,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:11,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:12,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:12,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:42:13,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:13,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:14,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:14,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:15,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:15,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:16,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:16,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:17,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:17,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:18,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:18,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:19,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:19,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:20,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:20,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:21,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:21,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:22,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:22,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:23,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:23,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:24,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:24,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:25,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:25,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:26,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:26,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:27,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:27,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:28,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:28,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:29,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:29,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:30,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:30,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:31,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:31,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:32,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:32,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:33,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:33,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:34,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:34,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:35,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:35,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:36,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:36,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:36,994 [BlockDeletingService#4] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:42:37,306 [BlockDeletingService#4] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:42:37,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:37,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:37,708 [BlockDeletingService#4] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:42:38,014 [BlockDeletingService#4] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:42:38,338 [BlockDeletingService#4] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:42:38,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:38,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:38,701 [BlockDeletingService#4] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:42:38,997 [BlockDeletingService#4] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:42:39,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:39,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:40,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:40,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:40,959 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:42:41,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:41,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:42,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:42,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:43,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:43,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:44,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:44,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:45,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:45,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:46,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:46,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:47,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:47,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:48,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:48,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:49,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:49,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:50,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:50,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:51,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:51,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:52,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:52,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:53,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:53,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:54,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:54,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:55,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:55,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:56,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:56,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:57,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:57,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:58,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:58,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:42:59,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:42:59,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:00,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:00,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:01,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:01,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:02,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:02,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:03,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:03,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:04,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:04,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:05,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:05,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:06,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:06,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:07,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:07,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:08,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:08,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:09,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:09,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:43:10,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:10,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:11,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:11,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:12,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:12,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:13,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:13,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:14,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:14,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:15,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:15,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:16,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:16,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:17,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:17,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:18,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:18,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:19,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:19,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:20,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:20,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:43:21,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:21,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:22,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:22,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:23,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:23,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:24,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:24,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:25,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:25,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:26,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:26,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:27,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:27,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:28,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:28,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:29,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:29,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:30,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:30,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:31,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:31,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:32,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:32,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:33,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:33,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:34,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:34,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:35,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:35,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:36,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:36,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:43:36,995 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:43:37,306 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:43:37,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:37,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:37,708 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:43:38,014 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:43:38,338 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:43:38,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:38,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:38,701 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:43:38,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:43:39,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:39,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:40,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:40,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:41,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:41,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:43:42,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:42,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:43,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:43,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:44,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:44,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:45,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:45,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:46,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:46,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:47,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:47,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:48,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:48,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:49,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:49,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:50,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:50,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:51,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:51,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:52,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:52,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:53,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:53,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:54,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:54,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:55,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:55,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:56,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:56,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:57,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:57,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:58,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:58,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:43:59,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:43:59,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:00,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:00,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:01,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:01,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:02,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:02,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:03,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:03,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:04,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:04,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:05,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:05,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:06,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:06,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:07,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:07,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:08,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:08,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:09,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:09,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:10,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:10,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:11,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:11,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:12,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:12,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:13,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:13,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:14,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:14,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:15,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:15,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:16,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:16,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:17,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:17,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:18,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:18,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:19,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:19,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:20,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:20,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:21,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:21,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:22,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:22,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:23,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:23,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:24,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:24,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:25,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:25,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:26,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:26,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:27,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:27,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:28,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:28,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:29,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:29,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:30,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:30,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:31,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:31,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:32,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:32,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:33,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:33,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:34,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:34,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:35,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:35,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:36,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:36,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:36,995 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:44:37,306 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:44:37,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:37,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:44:37,708 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:44:38,014 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:44:38,339 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:44:38,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:38,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:38,702 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:44:38,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:44:39,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:39,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:40,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:40,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:40,959 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:44:41,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:41,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:42,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:42,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:43,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:43,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:44,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:44,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:45,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:45,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:46,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:46,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:47,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:47,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:48,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:48,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:49,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:49,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:50,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:50,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:51,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:51,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:52,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:52,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:53,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:53,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:54,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:54,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:55,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:55,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:56,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:56,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:57,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:57,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:58,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:58,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:44:59,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:44:59,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:00,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:00,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:01,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:01,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:02,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:02,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:03,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:03,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:04,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:04,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:05,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:05,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:06,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:06,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:07,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:07,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:08,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:08,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:09,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:09,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:10,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:10,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:11,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:11,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:12,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:12,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:13,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:13,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:14,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:14,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:15,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:15,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:16,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:16,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:17,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:17,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:18,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:18,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:19,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:19,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:20,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:20,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:21,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:21,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:22,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:22,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:23,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:23,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:24,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:24,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:25,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:25,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:26,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:26,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:27,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:27,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:28,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:28,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:29,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:29,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:30,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:30,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:31,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:31,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:32,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:32,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:33,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:33,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:45:34,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:34,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:35,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:35,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:36,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:36,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:36,995 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:45:37,307 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:45:37,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:37,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:37,708 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:45:38,015 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:45:38,339 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:45:38,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:38,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:38,702 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:45:38,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:45:39,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:39,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:40,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:40,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:41,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:41,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:42,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:42,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:43,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:43,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:44,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:44,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:45,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:45,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:46,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:46,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:47,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:47,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:48,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:48,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:49,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:49,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:50,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:50,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:51,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:51,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:52,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:52,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:53,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:53,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:54,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:54,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:55,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:55,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:56,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:56,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:57,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:57,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:58,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:58,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:45:59,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:45:59,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:00,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:00,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:01,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:01,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:02,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:02,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:03,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:03,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:04,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:04,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:05,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:05,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:06,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:06,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:07,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:07,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:08,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:08,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:09,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:09,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:10,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:10,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:11,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:11,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:12,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:12,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:13,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:13,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:14,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:14,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:15,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:15,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:16,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:16,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:17,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:17,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:18,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:18,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:19,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:19,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:20,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:20,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:21,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:21,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:22,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:22,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:23,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:23,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:24,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:24,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:25,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:25,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:26,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:26,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:27,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:27,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:28,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:28,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:29,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:29,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:30,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:30,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:31,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:31,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:32,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:32,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:33,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:33,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:34,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:34,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:35,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:35,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:36,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:36,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:36,995 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:46:37,307 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:46:37,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:37,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:37,709 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:46:38,015 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:46:38,339 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:46:38,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:38,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:38,702 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:46:38,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:46:39,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:39,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:40,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:40,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:40,960 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:46:41,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:41,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:42,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:42,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:43,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:43,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:44,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:44,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:45,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:45,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:46,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:46,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:47,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:47,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:48,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:48,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:49,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:49,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:50,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:50,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:51,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:51,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:52,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:52,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:53,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:53,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:54,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:54,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:55,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:55,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:56,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:56,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:57,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:57,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:58,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:58,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:46:59,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:46:59,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:00,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:00,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:01,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:01,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:02,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:02,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:03,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:03,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:04,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:04,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:05,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:05,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:06,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:06,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:07,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:07,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:08,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:08,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:09,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:09,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:10,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:10,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:47:11,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:11,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:12,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:12,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:13,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:13,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:14,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:14,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:15,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:15,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:16,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:16,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:17,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:17,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:18,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:18,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:19,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:19,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:20,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:20,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:21,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:21,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:22,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:22,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:23,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:23,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:24,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:24,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:25,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:25,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:26,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:26,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:47:27,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:27,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:28,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:28,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:29,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:29,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:30,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:30,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:31,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:31,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:32,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:32,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:33,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:33,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:34,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:34,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:35,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:35,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:36,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:36,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:36,996 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:47:37,307 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:47:37,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:37,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:37,709 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:47:38,015 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:47:38,339 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:47:38,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:38,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:38,702 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:47:38,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:47:39,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:39,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:40,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:40,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:41,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:41,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:42,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:42,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:43,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:43,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:44,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:44,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:45,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:45,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:46,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:46,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:47,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:47,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:48,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:48,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:49,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:49,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:50,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:50,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:51,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:51,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:52,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:52,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:53,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:53,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:54,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:54,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:55,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:55,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:56,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:56,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:57,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:57,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:58,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:58,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:47:59,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:47:59,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:00,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:00,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:01,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:01,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:02,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:02,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:03,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:03,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:48:04,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:04,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:05,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:05,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:06,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:06,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:07,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:07,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:08,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:08,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:09,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:09,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:10,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:10,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:11,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:11,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:12,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:12,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:13,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:13,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:14,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:14,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:15,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:15,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:16,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:16,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:17,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:17,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:18,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:18,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:19,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:19,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:48:20,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:20,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:21,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:21,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:22,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:22,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:23,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:23,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:24,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:24,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:25,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:25,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:26,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:26,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:27,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:27,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:28,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:28,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:29,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:29,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:30,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:30,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:31,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:31,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:32,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:32,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:33,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:33,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:34,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:34,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:35,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:35,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:36,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:36,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:36,996 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:48:37,307 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:48:37,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:37,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:37,709 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:48:38,015 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:48:38,340 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:48:38,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:38,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:38,703 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:48:38,999 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:48:39,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:39,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:40,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:40,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:40,960 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:48:41,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:41,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:42,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:42,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:43,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:43,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:44,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:44,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:48:45,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:45,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:46,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:46,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:47,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:47,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:48,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:48,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:49,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:49,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:50,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:50,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:51,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:51,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:52,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:52,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:53,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:53,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:54,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:54,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:55,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:55,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:56,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:56,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:57,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:57,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:58,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:58,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:48:59,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:48:59,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:00,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:00,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:49:01,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:01,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:02,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:02,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:03,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:03,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:04,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:04,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:05,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:05,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:06,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:06,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:07,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:07,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:08,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:08,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:09,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:09,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:10,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:10,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:11,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:11,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:12,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:12,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:13,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:13,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:14,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:14,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:15,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:15,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:16,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:16,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:17,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:17,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:18,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:18,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:19,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:19,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:20,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:20,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:21,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:21,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:22,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:22,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:23,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:23,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:24,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:24,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:25,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:25,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:26,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:26,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:27,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:27,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:28,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:28,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:29,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:29,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:30,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:30,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:31,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:31,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:49:32,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:32,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:33,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:33,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:34,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:34,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:35,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:35,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:36,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:36,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:49:36,996 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:49:37,307 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:49:37,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:37,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:37,709 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:49:38,016 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:49:38,340 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:49:38,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:38,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:38,703 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:49:38,999 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:49:39,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:39,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:40,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:40,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:41,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:41,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:42,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:42,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:43,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:43,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:44,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:44,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:45,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:45,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:46,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:46,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:47,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:47,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:48,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:48,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:49,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:49,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:50,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:50,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:51,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:51,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:52,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:52,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:53,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:53,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:54,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:54,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:55,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:55,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:56,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:56,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:57,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:57,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:58,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:58,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:49:59,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:49:59,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:00,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:00,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:01,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:01,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:02,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:02,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:03,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:03,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:04,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:04,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:05,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:05,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:06,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:06,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:07,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:07,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:08,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:08,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:09,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:09,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:10,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:10,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:11,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:11,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:12,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:12,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:13,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:13,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:50:14,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:14,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:15,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:15,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:16,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:16,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:17,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:17,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:18,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:18,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:19,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:19,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:20,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:20,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:21,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:21,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:22,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:22,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:23,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:23,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:24,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:24,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:25,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:25,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:26,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:26,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:27,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:27,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:28,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:28,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:29,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:29,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:30,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:30,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:31,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:31,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:32,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:32,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:33,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:33,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:34,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:34,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:35,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:35,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:36,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:36,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:36,996 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:50:37,308 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:50:37,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:37,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:37,710 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:50:38,016 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:50:38,340 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:50:38,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:38,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:38,703 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:50:38,999 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:50:39,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:39,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:50:40,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:40,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:40,961 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:50:41,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:41,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:42,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:42,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:43,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:43,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:44,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:44,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:50:45,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:45,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:46,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:46,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:47,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:47,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:48,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:48,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:49,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:49,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:50:50,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:50,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:51,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:51,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:52,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:52,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:53,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:53,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:54,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:54,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:55,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:55,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:56,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:56,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:57,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:57,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:58,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:58,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:50:59,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:50:59,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:00,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:00,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:01,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:01,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:02,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:02,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:03,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:03,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:04,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:04,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:05,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:05,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:06,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:06,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:07,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:07,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:08,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:08,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:09,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:09,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:10,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:10,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:11,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:11,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:12,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:12,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:13,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:13,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:14,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:14,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:15,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:15,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:51:16,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:16,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:17,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:17,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:18,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:18,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:19,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:19,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:20,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:20,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:21,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:21,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:22,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:22,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:23,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:23,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:24,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:24,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:25,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:25,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:26,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:26,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:27,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:27,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:28,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:28,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:29,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:29,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:30,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:30,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:51:31,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:31,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:32,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:32,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:33,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:33,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:34,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:34,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:35,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:35,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:36,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:36,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:36,996 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:51:37,308 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:51:37,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:37,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:37,710 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:51:38,016 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:51:38,340 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:51:38,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:38,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:38,703 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:51:38,999 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:51:39,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:39,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:40,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:40,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:41,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:41,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:42,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:42,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:43,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:43,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:44,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:44,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:45,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:45,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:46,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:46,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:47,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:47,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:48,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:48,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:49,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:49,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:50,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:50,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:51,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:51,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:51:52,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:52,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:53,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:53,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:54,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:54,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:55,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:55,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:56,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:56,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:57,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:57,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:58,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:58,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:51:59,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:51:59,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:00,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:00,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:01,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:01,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:02,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:02,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:03,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:03,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:04,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:04,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:05,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:05,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:06,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:06,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:07,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:07,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:08,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:08,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:09,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:09,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:10,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:10,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:11,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:11,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:12,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:12,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:13,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:13,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:14,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:14,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:15,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:15,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:16,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:16,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:17,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:17,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:18,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:18,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:19,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:19,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:20,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:20,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:21,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:21,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:22,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:22,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:23,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:23,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:24,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:24,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:25,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:25,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:26,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:26,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:27,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:27,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:28,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:28,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:29,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:29,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:30,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:30,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:52:31,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:31,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:32,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:32,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:33,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:33,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:34,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:34,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:35,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:35,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:36,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:36,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:36,997 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:52:37,308 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:52:37,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:37,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:37,710 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:52:38,016 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:52:38,341 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:52:38,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:38,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:38,703 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:52:38,999 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:52:39,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:39,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:40,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:40,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:40,961 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:52:41,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:41,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:42,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:42,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:43,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:43,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:44,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:44,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:45,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:45,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:46,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:46,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:47,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:47,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:48,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:48,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:49,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:49,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:50,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:50,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:51,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:51,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:52,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:52,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:53,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:53,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:54,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:54,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:55,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:55,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:56,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:56,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:57,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:57,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:58,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:58,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:52:59,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:52:59,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:00,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:00,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:01,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:01,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:02,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:02,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:03,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:03,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:04,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:04,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:05,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:05,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:06,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:06,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:07,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:07,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:08,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:08,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:09,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:09,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:10,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:10,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:11,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:11,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:12,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:12,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:13,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:13,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:14,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:14,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:15,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:15,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:16,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:16,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:17,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:17,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:18,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:18,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:19,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:19,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:20,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:20,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:21,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:21,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:22,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:22,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:23,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:23,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:24,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:24,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:25,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:25,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:26,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:26,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:27,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:27,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:28,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:28,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:29,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:29,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:30,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:30,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:31,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:31,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:32,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:32,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:33,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:33,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:34,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:34,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:35,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:35,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:36,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:36,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:36,997 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:53:37,308 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:53:37,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:37,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:53:37,710 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:53:38,017 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:53:38,341 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:53:38,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:38,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:38,704 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:53:39,000 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:53:39,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:39,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:40,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:40,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:41,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:41,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:42,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:42,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:43,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:43,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:44,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:44,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:45,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:45,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:46,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:46,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:47,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:47,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:48,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:48,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:49,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:49,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:50,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:50,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:51,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:51,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:52,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:52,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:53,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:53,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:54,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:54,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:55,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:55,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:56,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:56,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:57,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:57,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:58,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:58,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:53:59,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:53:59,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:00,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:00,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:01,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:01,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:02,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:02,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:03,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:03,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:04,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:04,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:05,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:05,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:06,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:06,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:07,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:07,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:08,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:08,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:09,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:09,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:10,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:10,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:11,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:11,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:12,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:12,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:13,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:13,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:14,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:14,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:15,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:15,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:16,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:16,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:17,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:17,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:18,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:18,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:19,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:19,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:20,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:20,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:21,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:21,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:22,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:22,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:23,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:23,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:24,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:24,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:25,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:25,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:26,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:26,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:27,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:27,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:28,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:28,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:29,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:29,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:30,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:30,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:31,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:31,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:32,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:32,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:54:33,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:33,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:34,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:34,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:35,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:35,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:36,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:36,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:36,997 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:54:37,309 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:54:37,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:37,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:37,710 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:54:38,017 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:54:38,341 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:54:38,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:38,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:38,704 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:54:39,000 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:54:39,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:39,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:40,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:40,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:40,962 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:54:41,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:41,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:42,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:42,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:43,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:43,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:44,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:44,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:45,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:45,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:46,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:46,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:47,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:47,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:48,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:48,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:49,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:49,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:50,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:50,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:51,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:51,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:52,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:52,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:53,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:53,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:54,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:54,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:55,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:55,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:56,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:56,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:57,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:57,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:58,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:58,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:54:59,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:54:59,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:00,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:00,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:01,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:01,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:02,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:02,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:03,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:03,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:04,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:04,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:05,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:05,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:06,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:06,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:07,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:07,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:08,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:08,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:09,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:09,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:10,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:10,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:11,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:11,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:12,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:12,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:13,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:13,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:14,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:14,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:15,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:15,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:16,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:16,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:17,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:17,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:18,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:18,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:19,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:19,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:20,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:20,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:21,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:21,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:55:22,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:22,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:23,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:23,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:24,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:24,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:25,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:25,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:26,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:26,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:55:27,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:27,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:28,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:28,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:29,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:29,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:30,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:30,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:31,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:31,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:32,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:32,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:33,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:33,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:34,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:34,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:35,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:35,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:36,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:36,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:36,997 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:55:37,309 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:55:37,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:37,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:37,711 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:55:38,017 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:55:38,341 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:55:38,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:38,704 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:55:38,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:39,000 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:55:39,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:39,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:40,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:40,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:41,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:41,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:42,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:42,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:43,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:43,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:44,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:44,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:45,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:45,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:46,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:46,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:47,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:47,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:48,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:48,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:49,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:49,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:50,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:50,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:51,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:51,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:52,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:52,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:53,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:53,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:54,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:54,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:55,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:55,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:56,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:56,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:57,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:57,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:55:58,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:58,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:55:59,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:55:59,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:00,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:00,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:01,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:01,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:02,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:02,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:03,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:03,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:04,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:04,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:05,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:05,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:06,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:06,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:07,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:07,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:08,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:08,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:09,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:09,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:10,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:10,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:11,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:11,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:12,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:12,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:13,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:13,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:14,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:14,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:15,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:15,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:16,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:16,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:17,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:17,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:18,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:18,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:19,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:19,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:20,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:20,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:21,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:21,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:22,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:22,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:23,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:23,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:24,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:24,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:25,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:25,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:26,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:26,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:27,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:27,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:56:28,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:28,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:29,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:29,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:30,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:30,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:31,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:31,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:32,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:32,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:33,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:33,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:34,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:34,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:35,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:35,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:36,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:36,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:36,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:56:37,309 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:56:37,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:37,711 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:56:37,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:38,017 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:56:38,341 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:56:38,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:38,704 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:56:38,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:56:39,000 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:56:39,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:39,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:40,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:40,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:40,963 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:56:41,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:41,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:42,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:42,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:43,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:43,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:44,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:44,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:45,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:45,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:46,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:46,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:47,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:47,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:48,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:48,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:49,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:49,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:50,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:50,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:51,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:51,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:52,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:52,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:53,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:53,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:54,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:54,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:55,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:55,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:56,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:56,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:57,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:57,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:58,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:58,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:56:59,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:56:59,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:00,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:00,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:01,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:01,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:02,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:02,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:03,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:03,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:04,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:04,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:05,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:05,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:06,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:06,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:07,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:07,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:08,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:08,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:09,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:09,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:10,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:10,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:11,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:11,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:12,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:12,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:13,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:13,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:14,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:14,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:15,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:15,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:16,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:16,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:17,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:17,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:18,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:18,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:19,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:19,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:20,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:20,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:21,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:21,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:22,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:22,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:23,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:23,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:24,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:24,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:25,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:25,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:26,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:26,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:27,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:27,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:28,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:28,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:29,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:29,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:30,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:30,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:31,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:31,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:32,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:32,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:33,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:33,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:34,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:34,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:35,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:35,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:36,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:36,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:36,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:57:37,309 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:57:37,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:37,711 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:57:37,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:38,018 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:57:38,342 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:57:38,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:38,705 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:57:38,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:39,001 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:57:39,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:39,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:57:40,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:40,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:41,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:41,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:42,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:42,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:43,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:43,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:44,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:44,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:45,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:45,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:46,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:46,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:47,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:47,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:48,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:48,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:49,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:49,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:50,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:50,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:51,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:51,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:52,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:52,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:53,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:53,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:54,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:54,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:55,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:55,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:56,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:56,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:57,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:57,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:58,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:58,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:57:59,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:57:59,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:00,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:00,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:01,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:01,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:02,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:02,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:03,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:03,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:04,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:04,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:58:05,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:05,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:06,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:06,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:07,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:07,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:08,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:08,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:09,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:09,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:10,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:10,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:11,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:11,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:12,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:12,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:13,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:13,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:14,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:14,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:15,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:15,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:16,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:16,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:17,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:17,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:18,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:18,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:19,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:19,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:20,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:20,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:21,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:21,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:22,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:22,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:23,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:23,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:24,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:24,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:25,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:25,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:26,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:26,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:27,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:27,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:28,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:28,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:29,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:29,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:30,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:30,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:31,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:31,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:32,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:32,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:33,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:33,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:34,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:34,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:35,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:35,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:36,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:36,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:36,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:58:37,310 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:58:37,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:37,711 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:58:37,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:38,018 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:58:38,342 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:58:38,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:38,705 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:58:38,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:39,001 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:58:39,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:39,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:40,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:40,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:40,963 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 21:58:41,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:41,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:42,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:42,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:43,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:43,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:44,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:44,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:45,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:45,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:46,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:46,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:47,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:47,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:48,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:48,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:49,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:49,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:50,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:50,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:51,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:51,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:52,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:52,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:53,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:53,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:54,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:54,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:55,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:55,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:56,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:56,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:57,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:57,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:58,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:58,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:58:59,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:58:59,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:00,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:00,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:01,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:01,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:02,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:02,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:03,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:03,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:04,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:04,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:05,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:05,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:06,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:06,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:07,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:07,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:08,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:08,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:09,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:09,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:10,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:10,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:11,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:11,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:12,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:12,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:13,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:13,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:14,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:14,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:15,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:15,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:16,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:16,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:17,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:17,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:18,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:18,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:19,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:19,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:20,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:20,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:21,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:21,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:22,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:22,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:23,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:23,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:24,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:24,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:25,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:25,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:26,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:26,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:27,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:27,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:28,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:28,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:29,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:29,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:30,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:30,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:31,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:31,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:32,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:32,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:33,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:33,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:34,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:34,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:35,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:35,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:36,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:36,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:36,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:59:37,310 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:59:37,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:37,711 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:59:37,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:38,018 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:59:38,342 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:59:38,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:38,705 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:59:38,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:39,001 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 21:59:39,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:39,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:40,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:40,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:41,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:41,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:42,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:42,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:43,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:43,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:44,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:44,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:45,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:45,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:46,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:46,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:47,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:47,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:48,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:48,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:49,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:49,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:59:50,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:50,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:51,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:51,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:52,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:52,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:53,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:53,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:54,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:54,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 21:59:55,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:55,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:56,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:56,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:57,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:57,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:58,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:58,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 21:59:59,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 21:59:59,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:00:00,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:00,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:01,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:01,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:02,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:02,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:03,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:03,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:04,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:04,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:05,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:05,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:06,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:06,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:07,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:07,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:08,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:08,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:09,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:09,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:10,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:10,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:11,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:11,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:12,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:12,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:13,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:13,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:14,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:14,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:15,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:15,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:16,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:16,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:17,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:17,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:18,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:18,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:19,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:19,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:00:20,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:20,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:21,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:21,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:22,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:22,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:23,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:23,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:24,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:24,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:25,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:25,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:26,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:26,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:27,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:27,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:28,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:28,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:29,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:29,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:30,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:30,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:31,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:31,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:32,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:32,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:33,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:33,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:00:34,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:34,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:35,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:35,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:36,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:36,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:36,998 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:00:37,310 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:00:37,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:37,712 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:00:37,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:38,018 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:00:38,342 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:00:38,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:38,705 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:00:38,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:39,001 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:00:39,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:39,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:40,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:40,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:40,963 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:00:41,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:41,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:42,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:42,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:43,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:43,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:00:44,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:44,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:45,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:45,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:46,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:46,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:47,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:47,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:48,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:48,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:49,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:49,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:50,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:50,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:51,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:51,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:52,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:52,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:53,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:53,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:54,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:54,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:55,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:55,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:56,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:56,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:57,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:57,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:58,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:58,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:00:59,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:00:59,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:00,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:00,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:01,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:01,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:02,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:02,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:03,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:03,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:04,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:04,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:05,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:05,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:06,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:06,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:07,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:07,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:08,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:08,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:09,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:09,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:10,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:10,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:11,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:11,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:12,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:12,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:13,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:13,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:01:14,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:14,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:15,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:15,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:16,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:16,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:17,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:17,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:18,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:18,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:19,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:19,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:20,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:20,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:21,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:21,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:22,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:22,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:23,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:23,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:01:24,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:24,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:25,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:25,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:26,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:26,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:27,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:27,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:28,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:28,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:01:29,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:29,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:30,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:30,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:31,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:31,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:32,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:32,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:33,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:33,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:34,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:34,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:35,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:35,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:36,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:36,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:36,999 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:01:37,310 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:01:37,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:37,712 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:01:37,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:38,019 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:01:38,343 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:01:38,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:38,705 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:01:38,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:01:39,002 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:01:39,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:39,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:40,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:40,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:41,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:41,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:42,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:42,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:43,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:43,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:44,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:44,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:45,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:45,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:46,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:46,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:47,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:47,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:48,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:48,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:49,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:49,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:50,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:50,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:51,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:51,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:52,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:52,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:53,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:53,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:54,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:54,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:55,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:55,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:56,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:56,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:57,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:57,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:58,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:58,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:01:59,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:01:59,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:00,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:00,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:01,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:01,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:02:02,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:02,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:03,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:03,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:04,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:04,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:05,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:05,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:06,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:06,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:07,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:07,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:08,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:08,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:09,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:09,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:10,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:10,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:11,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:11,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:12,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:12,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:13,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:13,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:14,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:14,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:15,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:15,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:16,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:16,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:17,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:17,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:18,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:18,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:19,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:19,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:20,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:20,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:21,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:21,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:02:22,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:22,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:23,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:23,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:24,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:24,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:25,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:25,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:26,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:26,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:02:27,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:27,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:28,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:28,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:29,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:29,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:30,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:30,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:31,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:31,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:32,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:32,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:33,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:33,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:34,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:34,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:35,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:35,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:36,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:36,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:02:36,999 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:02:37,311 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:02:37,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:37,712 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:02:37,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:38,019 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:02:38,343 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:02:38,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:38,706 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:02:38,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:39,002 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:02:39,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:39,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:40,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:40,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:40,964 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:02:41,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:41,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:42,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:42,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:43,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:43,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:44,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:44,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:45,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:45,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:46,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:46,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:47,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:47,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:48,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:48,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:49,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:49,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:50,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:50,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:51,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:51,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:52,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:52,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:53,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:53,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:54,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:54,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:55,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:55,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:56,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:56,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:57,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:57,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:58,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:58,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:02:59,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:02:59,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:00,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:00,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:01,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:01,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:02,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:02,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:03,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:03,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:04,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:04,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:05,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:05,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:06,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:06,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:07,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:07,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:08,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:08,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:09,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:09,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:10,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:10,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:11,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:11,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:12,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:12,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:13,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:13,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:14,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:14,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:03:15,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:15,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:16,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:16,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:17,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:17,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:18,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:18,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:19,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:19,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:20,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:20,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:21,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:21,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:22,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:22,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:23,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:23,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:24,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:24,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:25,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:25,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:26,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:26,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:27,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:27,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:28,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:28,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:29,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:29,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:30,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:30,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:31,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:31,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:32,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:32,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:33,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:33,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:34,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:34,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:03:35,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:35,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:36,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:36,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:36,999 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:03:37,311 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:03:37,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:37,712 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:03:37,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:38,019 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:03:38,343 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:03:38,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:38,706 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:03:38,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:39,002 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:03:39,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:39,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:40,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:40,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:41,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:41,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:42,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:42,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:43,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:43,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:44,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:44,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:45,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:45,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:46,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:46,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:47,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:47,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:48,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:48,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:49,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:49,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:50,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:50,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:51,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:51,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:52,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:52,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:53,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:53,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:54,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:54,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:55,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:55,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:56,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:56,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:57,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:57,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:58,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:58,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:03:59,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:03:59,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:00,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:00,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:01,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:01,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:02,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:02,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:03,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:03,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:04,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:04,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:05,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:05,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:04:06,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:06,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:07,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:07,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:08,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:08,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:09,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:09,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:10,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:10,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:11,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:11,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:12,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:12,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:13,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:13,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:14,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:14,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:15,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:15,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:16,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:16,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:17,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:17,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:18,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:18,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:19,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:19,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:20,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:20,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:21,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:21,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:22,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:22,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:23,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:23,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:24,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:24,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:25,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:25,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:26,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:26,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:27,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:27,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:28,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:28,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:29,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:29,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:30,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:30,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:31,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:31,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:32,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:32,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:33,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:33,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:34,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:34,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:35,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:35,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:36,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:36,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:36,999 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:04:37,311 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:04:37,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:37,712 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:04:37,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:38,019 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:04:38,343 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:04:38,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:38,706 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:04:38,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:39,002 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:04:39,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:39,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:40,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:40,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:04:40,964 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:04:41,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:41,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:42,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:42,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:43,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:43,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:44,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:44,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:45,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:45,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:04:46,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:46,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:47,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:47,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:48,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:48,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:49,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:49,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:50,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:50,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:51,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:51,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:52,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:52,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:53,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:53,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:54,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:54,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:55,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:55,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:56,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:56,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:57,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:57,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:58,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:58,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:04:59,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:04:59,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:00,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:00,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:01,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:01,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:02,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:02,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:03,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:03,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:04,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:04,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:05,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:05,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:06,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:06,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:07,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:07,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:08,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:08,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:09,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:09,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:10,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:10,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:11,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:11,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:05:12,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:12,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:13,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:13,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:14,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:14,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:15,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:15,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:16,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:16,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:17,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:17,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:18,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:18,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:19,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:19,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:20,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:20,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:21,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:21,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:22,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:22,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:23,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:23,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:24,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:24,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:25,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:25,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:26,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:26,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:27,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:27,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:28,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:28,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:29,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:29,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:30,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:30,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:31,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:31,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:32,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:32,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:05:33,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:33,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:34,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:34,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:35,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:35,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:36,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:36,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:37,000 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:05:37,311 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:05:37,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:37,713 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:05:37,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:05:38,020 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:05:38,344 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:05:38,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:38,706 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:05:38,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:39,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:05:39,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:39,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:40,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:40,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:41,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:41,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:42,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:42,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:05:43,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:43,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:44,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:44,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:45,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:45,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:46,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:46,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:47,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:47,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:05:48,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:48,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:49,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:49,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:50,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:50,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:51,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:51,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:52,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:52,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:05:53,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:53,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:54,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:54,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:55,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:55,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:56,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:56,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:57,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:57,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:58,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:58,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:05:59,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:05:59,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:00,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:00,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:01,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:01,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:02,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:02,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:03,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:03,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:04,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:04,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:05,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:05,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:06,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:06,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:07,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:07,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:08,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:08,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:09,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:09,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:10,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:10,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:11,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:11,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:12,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:12,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:13,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:13,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:14,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:14,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:15,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:15,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:16,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:16,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:17,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:17,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:18,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:18,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:19,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:19,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:20,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:20,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:21,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:21,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:22,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:22,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:23,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:23,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:24,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:24,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:25,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:25,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:26,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:26,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:27,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:27,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:28,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:28,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:29,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:29,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:30,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:30,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:31,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:31,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:32,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:32,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:33,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:33,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:34,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:34,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:35,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:35,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:36,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:36,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:37,000 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:06:37,312 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:06:37,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:37,713 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:06:37,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:38,020 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:06:38,344 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:06:38,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:38,707 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:06:38,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:39,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:06:39,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:39,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:40,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:40,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:40,965 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:06:41,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:41,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:42,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:42,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:43,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:43,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:44,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:44,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:45,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:45,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:46,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:46,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:47,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:47,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:48,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:48,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:49,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:49,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:50,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:50,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:51,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:51,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:52,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:52,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:53,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:53,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:54,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:54,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:55,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:55,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:56,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:56,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:57,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:57,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:58,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:58,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:06:59,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:06:59,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:07:00,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:00,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:01,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:01,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:02,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:02,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:03,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:03,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:04,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:04,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:07:05,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:05,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:06,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:06,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:07,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:07,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:08,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:08,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:09,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:09,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:10,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:10,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:11,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:11,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:12,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:12,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:13,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:13,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:14,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:14,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:15,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:15,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:07:16,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:16,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:17,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:17,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:18,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:18,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:19,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:19,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:20,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:20,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:21,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:21,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:22,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:22,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:23,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:23,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:24,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:24,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:25,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:25,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:26,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:26,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:27,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:27,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:28,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:28,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:29,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:29,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:30,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:30,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:07:31,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:31,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:32,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:32,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:33,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:33,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:34,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:34,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:35,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:35,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:36,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:36,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:37,000 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:07:37,312 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:07:37,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:37,713 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:07:37,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:38,020 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:07:38,344 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:07:38,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:38,707 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:07:38,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:39,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:07:39,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:39,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:40,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:40,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:41,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:41,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:42,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:42,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:43,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:43,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:44,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:44,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:45,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:45,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:46,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:46,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:47,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:47,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:48,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:48,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:49,669 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:49,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:50,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:50,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:51,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:51,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:52,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:52,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:53,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:53,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:54,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:54,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:55,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:55,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:56,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:56,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:57,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:57,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:58,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:58,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:07:59,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:07:59,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:00,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:00,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:01,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:01,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:02,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:02,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:03,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:03,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:04,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:04,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:05,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:05,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:06,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:06,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:07,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:07,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:08,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:08,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:09,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:09,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:10,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:10,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:11,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:11,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:12,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:12,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:13,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:13,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:14,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:14,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:15,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:15,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:16,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:16,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:17,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:17,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:18,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:18,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:19,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:19,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:20,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:20,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:21,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:21,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:22,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:22,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:23,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:23,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:24,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:24,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:25,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:25,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:26,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:26,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:27,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:27,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:28,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:28,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:29,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:29,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:30,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:30,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:31,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:31,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:32,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:32,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:33,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:33,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:34,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:34,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:35,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:35,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:36,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:36,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:37,000 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:08:37,312 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:08:37,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:37,713 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:08:37,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:38,020 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:08:38,344 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:08:38,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:38,707 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:08:38,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:39,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:08:39,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:39,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:40,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:40,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:40,966 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:08:41,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:41,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:42,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:42,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:08:43,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:43,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:44,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:44,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:45,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:45,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:46,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:46,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:47,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:47,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:48,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:48,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:49,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:49,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:50,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:50,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:51,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:51,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:52,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:52,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:53,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:53,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:54,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:54,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:55,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:55,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:56,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:56,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:57,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:57,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:58,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:58,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:08:59,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:08:59,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:00,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:00,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:01,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:01,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:02,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:02,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:03,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:03,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:04,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:04,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:05,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:05,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:06,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:06,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:07,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:07,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:08,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:08,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:09,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:09,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:10,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:10,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:11,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:11,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:12,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:12,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:13,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:13,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:14,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:14,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:15,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:15,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:16,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:16,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:17,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:17,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:18,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:18,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:19,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:19,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:20,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:20,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:21,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:21,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:22,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:22,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:23,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:23,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:24,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:24,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:25,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:25,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:26,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:26,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:27,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:27,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:28,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:28,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:29,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:29,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:30,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:30,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:31,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:31,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:32,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:32,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:33,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:33,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:34,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:34,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:35,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:35,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:36,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:36,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:37,001 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:09:37,312 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:09:37,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:37,714 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:09:37,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:38,021 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:09:38,344 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:09:38,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:38,707 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:09:38,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:39,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:09:39,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:39,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:40,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:40,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:41,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:41,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:42,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:42,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:43,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:43,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:44,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:44,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:45,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:45,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:46,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:46,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:47,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:47,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:48,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:48,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:49,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:49,877 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:50,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:50,877 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:51,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:51,877 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:52,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:52,877 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:53,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:53,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:54,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:54,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:55,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:55,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:56,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:56,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:57,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:57,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:09:58,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:58,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:09:59,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:09:59,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:00,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:00,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:01,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:01,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:02,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:02,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:03,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:03,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:10:04,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:04,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:05,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:05,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:06,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:06,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:07,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:07,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:08,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:08,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:10:09,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:09,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:10,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:10,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:11,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:11,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:12,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:12,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:13,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:13,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:14,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:14,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:15,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:15,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:16,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:16,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:17,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:17,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:18,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:18,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:19,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:19,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:20,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:20,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:21,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:21,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:22,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:22,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:23,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:23,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:24,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:24,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:25,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:25,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:26,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:26,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:27,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:27,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:28,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:28,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:29,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:29,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:30,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:30,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:31,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:31,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:32,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:32,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:33,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:33,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:34,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:34,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:35,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:35,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:36,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:36,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:37,001 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:10:37,313 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:10:37,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:37,714 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:10:37,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:38,021 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:10:38,345 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:10:38,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:38,708 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:10:38,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:39,004 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:10:39,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:39,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:40,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:40,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:40,966 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:10:41,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:41,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:42,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:42,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:43,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:43,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:44,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:44,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:45,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:45,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:46,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:46,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:47,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:47,888 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:48,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:48,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:49,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:49,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:50,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:50,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:51,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:51,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:52,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:52,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:53,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:53,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:54,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:54,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:55,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:55,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:56,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:56,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:57,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:57,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:58,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:58,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:10:59,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:10:59,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:00,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:00,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:01,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:01,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:02,700 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:02,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:03,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:03,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:04,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:04,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:05,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:05,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:06,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:06,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:07,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:07,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:08,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:08,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:09,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:09,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:10,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:10,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:11,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:11,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:12,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:12,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:13,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:13,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:11:14,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:14,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:15,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:15,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:16,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:16,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:17,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:17,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:18,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:18,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:19,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:19,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:20,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:20,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:21,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:21,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:22,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:22,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:23,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:23,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:24,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:24,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:25,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:25,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:26,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:26,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:27,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:27,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:28,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:28,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:29,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:29,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:30,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:30,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:31,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:31,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:32,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:32,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:33,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:33,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:34,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:34,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:35,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:35,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:36,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:36,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:37,001 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:11:37,313 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:11:37,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:37,714 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:11:37,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:38,021 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:11:38,345 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:11:38,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:38,708 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:11:38,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:39,004 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:11:39,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:39,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:40,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:40,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:41,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:41,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:42,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:42,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:43,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:43,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:44,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:44,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:45,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:45,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:46,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:46,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:47,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:47,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:48,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:48,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:49,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:49,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:50,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:50,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:51,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:51,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:52,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:52,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:53,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:53,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:54,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:54,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:11:55,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:55,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:56,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:56,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:57,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:57,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:58,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:58,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:11:59,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:11:59,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:00,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:00,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:01,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:01,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:02,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:02,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:03,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:03,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:04,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:04,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:05,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:05,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:06,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:06,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:07,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:07,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:08,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:08,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:09,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:09,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:10,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:10,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:11,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:11,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:12,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:12,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:13,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:13,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:14,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:14,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:15,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:15,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:16,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:16,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:17,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:17,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:18,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:18,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:19,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:19,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:20,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:20,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:21,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:21,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:22,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:22,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:23,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:23,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:24,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:24,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:25,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:25,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:26,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:26,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:27,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:27,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:28,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:28,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:29,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:29,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:30,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:30,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:31,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:31,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:32,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:32,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:33,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:33,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:34,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:34,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:35,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:35,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:36,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:36,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:37,001 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:12:37,313 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:12:37,714 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:12:37,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:37,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:38,021 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:12:38,345 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:12:38,708 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:12:38,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:38,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:39,004 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:12:39,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:39,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:40,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:40,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:40,966 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:12:41,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:41,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:42,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:42,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:43,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:43,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:44,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:44,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:12:45,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:45,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:46,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:46,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:47,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:47,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:48,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:48,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:49,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:49,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:50,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:50,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:51,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:51,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:52,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:52,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:53,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:53,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:54,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:54,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:55,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:55,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:56,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:56,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:57,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:57,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:58,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:58,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:12:59,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:12:59,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:00,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:00,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:01,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:01,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:02,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:02,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:03,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:03,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:04,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:04,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:05,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:05,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:06,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:06,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:07,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:07,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:08,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:08,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:09,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:09,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:10,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:10,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:11,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:11,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:12,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:12,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:13,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:13,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:14,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:14,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:15,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:15,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:16,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:16,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:17,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:17,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:18,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:18,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:19,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:19,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:20,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:20,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:21,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:21,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:22,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:22,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:23,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:23,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:24,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:24,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:25,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:25,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:26,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:26,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:27,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:27,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:28,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:28,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:29,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:29,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:30,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:30,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:31,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:31,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:32,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:32,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:33,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:33,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:34,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:34,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:35,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:35,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:36,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:36,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:37,002 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:13:37,313 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:13:37,714 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:13:37,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:37,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:38,022 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:13:38,345 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:13:38,708 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:13:38,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:38,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:39,004 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:13:39,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:39,921 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:40,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:40,921 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:41,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:41,921 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:42,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:42,921 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:43,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:43,921 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:44,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:44,921 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:45,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:45,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:46,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:46,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:47,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:47,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:48,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:48,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:49,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:49,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:50,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:50,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:51,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:51,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:52,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:52,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:53,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:53,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:54,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:54,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:55,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:55,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:56,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:56,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:57,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:57,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:58,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:58,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:13:59,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:13:59,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:00,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:00,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:01,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:01,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:02,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:02,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:03,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:03,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:04,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:04,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:05,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:05,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:06,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:06,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:14:07,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:07,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:08,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:08,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:09,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:09,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:10,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:10,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:11,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:11,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:12,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:12,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:13,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:13,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:14,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:14,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:15,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:15,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:16,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:16,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:17,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:17,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:14:18,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:18,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:19,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:19,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:20,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:20,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:21,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:21,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:22,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:22,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:23,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:23,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:24,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:24,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:25,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:25,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:26,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:26,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:27,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:27,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:28,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:28,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:29,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:29,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:30,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:30,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:31,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:31,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:32,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:32,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:33,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:33,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:34,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:34,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:35,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:35,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:36,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:36,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:37,002 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:14:37,314 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:14:37,715 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:14:37,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:37,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:38,022 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:14:38,346 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:14:38,708 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:14:38,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:38,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:39,005 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:14:39,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:39,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:40,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:40,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:40,967 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:14:41,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:41,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:42,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:42,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:43,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:43,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:44,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:44,932 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:45,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:45,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:46,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:46,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:47,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:47,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:48,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:48,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:49,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:49,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:50,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:50,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:51,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:51,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:52,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:52,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:53,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:53,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:54,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:54,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:55,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:55,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:56,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:56,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:57,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:57,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:58,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:58,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:14:59,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:14:59,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:00,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:00,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:01,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:01,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:02,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:02,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:03,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:03,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:04,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:04,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:05,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:05,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:06,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:06,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:07,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:07,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:08,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:08,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:09,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:09,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:10,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:10,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:11,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:11,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:12,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:12,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:15:13,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:13,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:14,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:14,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:15,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:15,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:16,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:16,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:17,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:17,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:18,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:18,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:19,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:19,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:20,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:20,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:21,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:21,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:22,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:22,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:23,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:23,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:24,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:24,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:25,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:25,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:26,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:26,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:27,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:27,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:28,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:28,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:29,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:29,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:15:30,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:30,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:31,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:31,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:32,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:32,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:33,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:33,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:34,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:34,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:35,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:35,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:15:36,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:36,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:37,002 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:15:37,314 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:15:37,715 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:15:37,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:37,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:38,022 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:15:38,346 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:15:38,709 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:15:38,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:38,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:39,005 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:15:39,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:39,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:40,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:40,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:41,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:41,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:42,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:42,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:43,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:43,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:44,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:44,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:45,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:45,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:46,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:46,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:47,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:47,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:48,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:48,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:49,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:49,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:50,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:50,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:51,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:51,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:52,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:52,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:53,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:53,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:54,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:54,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:55,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:55,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:56,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:56,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:57,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:57,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:58,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:58,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:15:59,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:15:59,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:00,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:00,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:01,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:01,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:02,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:02,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:03,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:03,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:04,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:04,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:05,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:05,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:06,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:06,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:07,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:07,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:08,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:08,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:09,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:09,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:10,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:10,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:11,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:11,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:12,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:12,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:13,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:13,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:14,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:14,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:15,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:15,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:16,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:16,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:17,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:17,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:18,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:18,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:19,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:19,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:20,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:20,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:21,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:21,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:22,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:22,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:23,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:23,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:24,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:24,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:25,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:25,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:26,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:26,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:27,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:27,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:28,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:28,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:29,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:29,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:30,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:30,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:31,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:31,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:32,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:32,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:33,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:33,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:34,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:34,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:35,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:35,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:36,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:36,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:37,002 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:16:37,314 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:16:37,715 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:16:37,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:37,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:38,022 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:16:38,346 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:16:38,709 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:16:38,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:38,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:39,005 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:16:39,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:39,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:40,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:40,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:40,967 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:16:41,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:41,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:42,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:42,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:43,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:43,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:44,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:44,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:45,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:45,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:46,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:46,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:16:47,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:47,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:48,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:48,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:49,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:49,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:50,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:50,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:51,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:51,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:52,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:52,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:53,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:53,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:54,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:54,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:55,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:55,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:56,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:56,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:57,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:57,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:58,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:58,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:16:59,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:16:59,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:00,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:00,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:01,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:01,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:02,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:02,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:17:03,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:03,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:04,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:04,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:05,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:05,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:06,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:06,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:07,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:07,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:08,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:08,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:09,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:09,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:10,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:10,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:11,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:11,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:12,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:12,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:13,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:13,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:14,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:14,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:15,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:15,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:16,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:16,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:17,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:17,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:18,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:18,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:19,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:19,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:20,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:20,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:21,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:21,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:22,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:22,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:23,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:23,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:24,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:24,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:25,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:25,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:26,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:26,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:27,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:27,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:28,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:28,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:29,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:29,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:30,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:30,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:31,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:31,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:32,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:32,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:33,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:33,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:34,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:34,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:35,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:35,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:36,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:36,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:17:37,002 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:17:37,314 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:17:37,715 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:17:37,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:37,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:38,023 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:17:38,346 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:17:38,709 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:17:38,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:38,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:39,005 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:17:39,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:39,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:40,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:40,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:41,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:41,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:42,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:42,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:43,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:43,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:44,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:44,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:45,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:45,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:46,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:46,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:47,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:47,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:48,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:48,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:49,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:49,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:50,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:50,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:51,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:51,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:52,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:52,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:53,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:53,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:54,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:54,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:55,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:55,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:56,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:56,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:57,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:57,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:58,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:58,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:17:59,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:17:59,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:00,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:00,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:01,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:01,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:02,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:02,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:03,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:03,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:04,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:04,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:05,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:05,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:06,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:06,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:07,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:07,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:08,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:08,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:09,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:09,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:10,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:10,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:11,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:11,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:12,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:12,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:13,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:13,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:14,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:14,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:15,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:15,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:16,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:16,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:17,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:17,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:18,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:18,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:19,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:19,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:20,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:20,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:18:21,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:21,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:22,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:22,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:23,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:23,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:24,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:24,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:25,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:25,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:26,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:26,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:27,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:27,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:28,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:28,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:29,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:29,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:30,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:30,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:31,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:31,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:18:32,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:32,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:33,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:33,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:34,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:34,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:35,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:35,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:36,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:36,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:37,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:18:37,314 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:18:37,716 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:18:37,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:37,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:38,023 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:18:38,347 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:18:38,709 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:18:38,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:38,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:39,005 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:18:39,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:39,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:40,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:40,968 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:18:40,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:41,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:41,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:42,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:42,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:43,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:43,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:44,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:44,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:45,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:45,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:46,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:46,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:47,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:47,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:48,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:48,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:49,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:49,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:50,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:50,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:51,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:51,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:52,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:52,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:53,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:53,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:54,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:54,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:55,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:55,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:56,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:56,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:57,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:57,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:58,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:58,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:18:59,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:18:59,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:19:00,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:00,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:01,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:01,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:02,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:02,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:03,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:03,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:04,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:04,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:05,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:05,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:06,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:06,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:07,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:07,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:08,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:08,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:09,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:09,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:10,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:10,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:11,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:11,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:12,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:12,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:13,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:13,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:14,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:14,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:15,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:15,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:16,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:16,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:17,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:17,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:18,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:18,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:19,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:19,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:20,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:20,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:21,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:21,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:22,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:22,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:23,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:23,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:24,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:24,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:25,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:25,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:26,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:26,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:27,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:27,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:28,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:28,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:29,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:29,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:30,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:30,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:31,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:31,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:32,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:32,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:33,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:33,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:34,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:34,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:35,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:35,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:36,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:36,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:37,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:19:37,315 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:19:37,716 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:19:37,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:37,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:38,023 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:19:38,347 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:19:38,709 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:19:38,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:38,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:39,006 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:19:39,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:39,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:40,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:40,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:41,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:41,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:42,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:42,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:43,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:43,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:44,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:44,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:45,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:45,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:46,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:46,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:47,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:47,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:48,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:48,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:49,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:49,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:50,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:50,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:51,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:51,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:52,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:52,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:53,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:53,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:54,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:54,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:55,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:55,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:56,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:56,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:57,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:57,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:58,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:58,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:19:59,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:19:59,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:00,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:00,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:01,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:01,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:02,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:02,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:03,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:03,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:04,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:04,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:05,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:05,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:06,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:06,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:07,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:07,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:08,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:08,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:09,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:09,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:10,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:10,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:11,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:11,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:12,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:12,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:13,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:13,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:14,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:14,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:15,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:15,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:16,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:16,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:17,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:17,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:18,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:18,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:19,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:19,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:20,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:20,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:21,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:21,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:22,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:22,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:23,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:23,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:24,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:24,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:25,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:25,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:26,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:26,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:27,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:27,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:28,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:28,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:29,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:29,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:30,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:30,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:31,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:31,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:32,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:32,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:33,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:33,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:34,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:34,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:35,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:35,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:36,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:36,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:37,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:20:37,315 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:20:37,716 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:20:37,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:37,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:38,023 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:20:38,347 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:20:38,710 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:20:38,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:38,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:39,006 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:20:39,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:39,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:40,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:40,968 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:20:40,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:41,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:41,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:42,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:42,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:43,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:43,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:44,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:44,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:45,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:45,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:46,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:46,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:47,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:47,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:48,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:48,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:49,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:49,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:50,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:50,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:51,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:52,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:52,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:53,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:53,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:54,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:54,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:55,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:55,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:56,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:56,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:57,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:57,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:58,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:58,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:20:59,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:20:59,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:00,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:00,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:01,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:01,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:02,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:02,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:03,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:03,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:04,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:04,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:05,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:05,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:06,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:06,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:07,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:07,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:08,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:08,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:09,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:09,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:10,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:10,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:11,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:11,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:12,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:12,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:13,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:13,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:14,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:14,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:15,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:15,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:16,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:16,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:17,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:17,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:18,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:18,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:19,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:19,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:20,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:20,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:21,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:21,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:22,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:22,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:23,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:23,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:24,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:24,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:25,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:25,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:26,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:26,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:27,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:21:27,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:28,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:28,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:29,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:29,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:30,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:30,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:31,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:31,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:32,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:32,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:33,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:33,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:34,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:34,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:35,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:35,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:36,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:36,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:37,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:21:37,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:37,315 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:21:37,716 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:21:37,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:38,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:38,023 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:21:38,347 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:21:38,710 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:21:38,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:39,006 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:21:39,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:39,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:40,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:40,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:41,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:41,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:42,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:42,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:43,009 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:43,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:44,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:44,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:45,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:45,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:46,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:46,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:47,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:47,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:48,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:48,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:49,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:49,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:50,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:50,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:51,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:51,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:52,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:52,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:53,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:53,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:54,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:54,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:55,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:55,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:56,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:56,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:57,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:57,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:58,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:58,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:21:59,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:21:59,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:00,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:00,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:01,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:01,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:02,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:02,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:03,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:03,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:04,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:04,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:05,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:05,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:06,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:06,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:07,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:07,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:08,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:08,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:09,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:09,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:10,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:10,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:11,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:11,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:12,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:12,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:13,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:13,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:14,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:14,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:15,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:15,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:16,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:22:16,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:17,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:17,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:18,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:18,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:19,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:19,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:20,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:20,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:21,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:21,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:22,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:22,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:23,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:23,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:24,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:24,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:25,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:25,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:26,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:26,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:27,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:27,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:28,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:28,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:29,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:29,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:30,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:30,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:31,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:31,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:32,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:32,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:33,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:33,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:34,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:34,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:35,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:35,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:36,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:36,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:37,003 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:22:37,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:37,315 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:22:37,716 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:22:37,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:38,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:38,024 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:22:38,348 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:22:38,710 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:22:38,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:39,006 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:22:39,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:39,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:40,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:40,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:40,969 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:22:41,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:41,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:42,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:42,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:43,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:43,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:44,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:44,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:45,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:45,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:46,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:46,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:47,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:47,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:48,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:48,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:49,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:49,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:50,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:50,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:51,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:22:51,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:52,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:52,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:53,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:53,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:54,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:54,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:55,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:55,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:56,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:56,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:57,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:57,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:58,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:58,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:22:59,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:22:59,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:00,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:00,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:01,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:01,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:02,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:02,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:03,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:03,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:04,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:04,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:05,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:05,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:06,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:06,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:07,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:07,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:08,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:08,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:09,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:09,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:10,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:10,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:11,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:11,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:12,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:12,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:13,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:13,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:14,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:14,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:15,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:15,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:16,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:16,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:17,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:17,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:18,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:18,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:19,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:19,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:20,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:20,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:21,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:21,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:22,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:22,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:23,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:23,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:24,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:24,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:25,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:25,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:26,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:26,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:27,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:27,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:28,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:28,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:29,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:29,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:30,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:30,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:31,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:31,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:32,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:32,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:33,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:33,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:34,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:34,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:35,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:35,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:36,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:36,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:37,004 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:23:37,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:37,316 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:23:37,717 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:23:37,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:38,024 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:23:38,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:38,348 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:23:38,710 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:23:38,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:39,007 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:23:39,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:39,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:40,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:40,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:41,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:41,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:42,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:42,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:43,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:43,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:44,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:44,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:45,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:45,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:46,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:46,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:47,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:47,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:48,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:48,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:49,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:49,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:50,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:50,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:51,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:51,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:52,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:52,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:53,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:53,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:54,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:54,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:55,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:55,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:56,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:23:56,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:57,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:57,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:58,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:58,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:23:59,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:23:59,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:00,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:00,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:01,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:01,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:02,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:02,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:03,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:03,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:04,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:04,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:05,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:05,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:06,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:06,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:07,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:07,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:08,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:08,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:09,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:09,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:10,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:10,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:11,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:11,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:12,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:12,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:13,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:13,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:14,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:14,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:15,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:15,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:16,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:16,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:17,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:17,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:18,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:18,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:19,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:19,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:20,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:20,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:21,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:21,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:22,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:22,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:23,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:23,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:24,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:24,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:25,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:25,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:26,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:26,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:27,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:27,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:28,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:28,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:29,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:29,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:30,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:30,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:31,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:31,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:32,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:32,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:33,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:33,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:34,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:34,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:35,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:35,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:36,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:36,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:37,004 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:24:37,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:24:37,316 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:24:37,717 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:24:37,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:38,024 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:24:38,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:38,348 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:24:38,711 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:24:38,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:39,007 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:24:39,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:39,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:40,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:40,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:40,970 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:24:41,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:41,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:42,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:42,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:43,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:43,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:44,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:44,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:45,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:45,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:46,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:46,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:47,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:47,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:48,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:48,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:49,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:49,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:50,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:50,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:51,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:51,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:52,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:52,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:53,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:53,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:54,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:54,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:55,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:55,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:56,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:56,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:57,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:57,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:58,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:58,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:24:59,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:24:59,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:00,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:00,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:01,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:01,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:02,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:02,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:03,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:03,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:04,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:04,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:05,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:05,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:06,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:06,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:07,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:07,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:08,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:08,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:09,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:09,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:10,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:10,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:11,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:11,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:12,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:12,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:13,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:13,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:14,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:14,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:15,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:15,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:16,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:16,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:17,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:17,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:18,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:18,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:19,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:19,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:20,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:20,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:21,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:21,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:22,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:22,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:23,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:23,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:24,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:24,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:25,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:25,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:26,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:26,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:27,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:27,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:28,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:28,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:29,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:29,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:30,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:30,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:31,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:31,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:32,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:32,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:33,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:33,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:34,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:34,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:35,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:35,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:36,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:36,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:37,004 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:25:37,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:37,316 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:25:37,717 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:25:37,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:38,024 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:25:38,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:38,348 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:25:38,711 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:25:38,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:39,007 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:25:39,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:39,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:40,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:40,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:41,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:41,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:42,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:42,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:43,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:43,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:44,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:44,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:45,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:45,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:46,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:46,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:47,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:47,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:48,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:48,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:49,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:49,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:50,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:25:50,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:51,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:51,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:52,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:52,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:53,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:53,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:54,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:54,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:55,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:55,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:56,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:56,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:57,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:57,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:58,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:58,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:25:59,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:25:59,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:00,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:00,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:01,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:01,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:02,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:02,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:03,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:03,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:04,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:04,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:05,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:05,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:06,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:06,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:07,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:07,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:08,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:08,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:09,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:09,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:10,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:10,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:11,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:11,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:12,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:12,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:13,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:13,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:14,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:14,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:15,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:15,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:16,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:16,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:17,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:17,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:18,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:18,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:19,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:19,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:20,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:20,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:21,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:21,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:22,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:22,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:23,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:23,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:24,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:24,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:25,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:25,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:26,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:26,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:27,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:27,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:28,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:28,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:29,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:29,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:30,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:30,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:31,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:31,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:32,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:32,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:33,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:33,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:34,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:34,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:35,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:35,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:36,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:36,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:37,004 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:26:37,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:37,316 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:26:37,717 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:26:37,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:38,025 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:26:38,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:38,349 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:26:38,711 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:26:38,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:39,007 [BlockDeletingService#2] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-20 22:26:39,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:39,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:40,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:40,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:40,970 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-20 22:26:41,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:41,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:42,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:42,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:43,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:43,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:44,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:44,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:45,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:45,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:46,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:46,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:47,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:47,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:48,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:48,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:49,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:49,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:50,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:50,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:51,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:51,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:52,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:52,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:53,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:53,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:54,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:54,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:55,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:55,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:56,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:56,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:57,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:57,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:58,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:58,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:26:59,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:26:59,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:00,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:00,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:01,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:01,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:02,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:02,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:03,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:03,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:04,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:04,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:05,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:05,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:06,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:06,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:07,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:07,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:08,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:08,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:09,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:09,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:10,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:10,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:11,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:11,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:12,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:12,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:13,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:13,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:14,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:14,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:15,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:15,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:16,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:16,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:17,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:17,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:18,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:18,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:19,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:19,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:20,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:20,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:21,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:21,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:22,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-20 22:27:22,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:23,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:23,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:24,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:24,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:25,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:25,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:26,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:26,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:27,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:27,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:28,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:28,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:29,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:29,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:30,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:30,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:31,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:31,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:32,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:32,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-20 22:27:33,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(381)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-20 22:27:33,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(348)) - Replication Manager is not ready to run until 3000ms after safemode exit
