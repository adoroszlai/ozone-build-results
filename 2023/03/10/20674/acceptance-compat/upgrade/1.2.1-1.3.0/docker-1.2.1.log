Attaching to ha_om3_1, ha_om2_1, ha_dn5_1, ha_dn1_1, ha_s3g_1, ha_dn3_1, ha_dn4_1, ha_om1_1, ha_recon_1, ha_dn2_1, ha_scm_1
dn2_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn2_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn2_1    | 2023-03-10 22:40:54,089 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn2_1    | /************************************************************
dn2_1    | STARTUP_MSG: Starting HddsDatanodeService
dn2_1    | STARTUP_MSG:   host = dd6e12a1cd84/10.9.0.16
dn2_1    | STARTUP_MSG:   args = []
dn2_1    | STARTUP_MSG:   version = 1.2.1
dn2_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.1.jar
dn2_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
dn2_1    | STARTUP_MSG:   java = 11.0.13
dn2_1    | ************************************************************/
dn2_1    | 2023-03-10 22:40:54,166 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn2_1    | 2023-03-10 22:40:56,967 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn2_1    | 2023-03-10 22:40:57,789 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn2_1    | 2023-03-10 22:40:59,062 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn2_1    | 2023-03-10 22:40:59,062 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn2_1    | 2023-03-10 22:41:00,391 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:dd6e12a1cd84 ip:10.9.0.16
dn2_1    | 2023-03-10 22:41:02,668 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
dn2_1    | 2023-03-10 22:41:03,823 [main] INFO reflections.Reflections: Reflections took 919 ms to scan 2 urls, producing 84 keys and 167 values 
dn2_1    | 2023-03-10 22:41:06,482 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
dn2_1    | 2023-03-10 22:41:06,578 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn2_1    | 2023-03-10 22:41:06,582 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn2_1    | 2023-03-10 22:41:06,614 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn2_1    | 2023-03-10 22:41:06,803 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn2_1    | 2023-03-10 22:41:07,003 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2023-03-10 22:41:07,032 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
dn2_1    | 2023-03-10 22:41:07,061 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn2_1    | 2023-03-10 22:41:07,061 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn2_1    | 2023-03-10 22:41:07,065 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn2_1    | 2023-03-10 22:41:07,291 [Thread-5] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn2_1    | 2023-03-10 22:41:07,303 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn2_1    | 2023-03-10 22:41:19,444 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2023-03-10 22:41:20,427 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn2_1    | 2023-03-10 22:41:22,208 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn2_1    | 2023-03-10 22:41:22,250 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn2_1    | 2023-03-10 22:41:22,256 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn2_1    | 2023-03-10 22:41:22,272 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn2_1    | 2023-03-10 22:41:22,277 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2023-03-10 22:41:22,288 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn2_1    | 2023-03-10 22:41:22,297 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2023-03-10 22:41:25,593 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn2_1    | 2023-03-10 22:41:25,625 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2023-03-10 22:41:25,625 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2023-03-10 22:41:25,745 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2023-03-10 22:41:26,856 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn2_1    | 2023-03-10 22:41:27,110 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn2_1    | 2023-03-10 22:41:27,584 [main] INFO util.log: Logging initialized @43694ms to org.eclipse.jetty.util.log.Slf4jLog
dn2_1    | 2023-03-10 22:41:28,920 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn2_1    | 2023-03-10 22:41:28,972 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn2_1    | 2023-03-10 22:41:29,170 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn2_1    | 2023-03-10 22:41:29,200 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn2_1    | 2023-03-10 22:41:29,241 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn2_1    | 2023-03-10 22:41:29,241 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn2_1    | 2023-03-10 22:41:29,629 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn2_1    | 2023-03-10 22:41:29,642 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
dn2_1    | 2023-03-10 22:41:29,864 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn2_1    | 2023-03-10 22:41:29,878 [main] INFO server.session: No SessionScavenger set, using defaults
dn2_1    | 2023-03-10 22:41:29,880 [main] INFO server.session: node0 Scavenging every 660000ms
dn2_1    | 2023-03-10 22:41:29,987 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@b791a81{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn2_1    | 2023-03-10 22:41:29,988 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@286855ea{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/static,AVAILABLE}
dn2_1    | 2023-03-10 22:41:32,309 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@193eb1ba{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_1_jar-_-any-10596731570886602764/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/hddsDatanode}
dn2_1    | 2023-03-10 22:41:32,405 [main] INFO server.AbstractConnector: Started ServerConnector@626d2016{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn2_1    | 2023-03-10 22:41:32,407 [main] INFO server.Server: Started @48557ms
dn2_1    | 2023-03-10 22:41:32,426 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn2_1    | 2023-03-10 22:41:32,426 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn2_1    | 2023-03-10 22:41:32,446 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn2_1    | 2023-03-10 22:41:32,529 [Datanode State Machine Thread - 0] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn2_1    | 2023-03-10 22:41:32,843 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c13d9e4] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn2_1    | 2023-03-10 22:41:33,783 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn2_1    | 2023-03-10 22:41:34,356 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn2_1    | 2023-03-10 22:41:36,670 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:36,708 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:37,671 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:37,709 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:38,672 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:38,711 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:39,672 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:40,673 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:41,674 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:42,742 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:43,740 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn2_1    | java.net.SocketTimeoutException: Call From dd6e12a1cd84/10.9.0.16 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.16:38570 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn2_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn2_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn2_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
dn2_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.16:38570 remote=recon/10.9.0.20:9891]
dn2_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn2_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn2_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn2_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn2_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn2_1    | 2023-03-10 22:41:43,753 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:45,763 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn2_1    | 2023-03-10 22:41:45,767 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn2_1    | 2023-03-10 22:41:46,347 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3892a4e1-c878-42af-adb7-db66a90d61f4
dn2_1    | 2023-03-10 22:41:46,552 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 3892a4e1-c878-42af-adb7-db66a90d61f4: start RPC server
dn2_1    | 2023-03-10 22:41:46,591 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 3892a4e1-c878-42af-adb7-db66a90d61f4: GrpcService started, listening on 9856
dn2_1    | 2023-03-10 22:41:46,603 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 3892a4e1-c878-42af-adb7-db66a90d61f4: GrpcService started, listening on 9857
dn2_1    | 2023-03-10 22:41:46,618 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 3892a4e1-c878-42af-adb7-db66a90d61f4: GrpcService started, listening on 9858
dn2_1    | 2023-03-10 22:41:46,661 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3892a4e1-c878-42af-adb7-db66a90d61f4 is started using port 9858 for RATIS
dn2_1    | 2023-03-10 22:41:46,661 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3892a4e1-c878-42af-adb7-db66a90d61f4 is started using port 9857 for RATIS_ADMIN
dn2_1    | 2023-03-10 22:41:46,662 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3892a4e1-c878-42af-adb7-db66a90d61f4 is started using port 9856 for RATIS_SERVER
dn2_1    | 2023-03-10 22:41:46,671 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$309/0x00000008404bec40@a274020] INFO util.JvmPauseMonitor: JvmPauseMonitor-3892a4e1-c878-42af-adb7-db66a90d61f4: Started
dn2_1    | 2023-03-10 22:41:50,005 [Command processor thread] INFO server.RaftServer: 3892a4e1-c878-42af-adb7-db66a90d61f4: addNew group-CBC13A60F575:[e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0] returns group-CBC13A60F575:java.util.concurrent.CompletableFuture@1d4b2429[Not completed]
dn2_1    | 2023-03-10 22:41:50,223 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4: new RaftServerImpl for group-CBC13A60F575:[e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0] with ContainerStateMachine:uninitialized
dn2_1    | 2023-03-10 22:41:50,241 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2023-03-10 22:41:50,249 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2023-03-10 22:41:50,249 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2023-03-10 22:41:50,249 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2023-03-10 22:41:50,250 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2023-03-10 22:41:50,250 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2023-03-10 22:41:50,251 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2023-03-10 22:41:50,268 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: ConfigurationManager, init=-1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn2_1    | 2023-03-10 22:41:50,270 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2023-03-10 22:41:50,276 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2023-03-10 22:41:50,281 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2023-03-10 22:41:50,285 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575 does not exist. Creating ...
dn2_1    | 2023-03-10 22:41:50,328 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/in_use.lock acquired by nodename 6@dd6e12a1cd84
dn2_1    | 2023-03-10 22:41:50,386 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575 has been successfully formatted.
dn2_1    | 2023-03-10 22:41:50,411 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn2_1    | 2023-03-10 22:41:50,423 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-CBC13A60F575: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2023-03-10 22:41:50,435 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2023-03-10 22:41:50,437 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2023-03-10 22:41:50,505 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2023-03-10 22:41:50,520 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2023-03-10 22:41:50,622 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2023-03-10 22:41:50,678 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2023-03-10 22:41:50,686 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2023-03-10 22:41:50,742 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575
dn2_1    | 2023-03-10 22:41:50,748 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | 2023-03-10 22:41:50,755 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2023-03-10 22:41:50,756 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2023-03-10 22:41:50,772 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2023-03-10 22:41:50,773 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2023-03-10 22:41:50,776 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2023-03-10 22:41:50,792 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2023-03-10 22:41:50,797 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2023-03-10 22:41:50,918 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2023-03-10 22:41:50,920 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2023-03-10 22:41:50,995 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn2_1    | 2023-03-10 22:41:51,021 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2023-03-10 22:41:51,053 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2023-03-10 22:41:51,138 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2023-03-10 22:41:51,139 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2023-03-10 22:41:51,140 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2023-03-10 22:41:51,190 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2023-03-10 22:41:51,190 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2023-03-10 22:41:51,812 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: start as a follower, conf=-1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0], old=null
dn2_1    | 2023-03-10 22:41:51,843 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn2_1    | 2023-03-10 22:41:51,853 [pool-22-thread-1] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState
dn2_1    | 2023-03-10 22:41:51,920 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CBC13A60F575,id=3892a4e1-c878-42af-adb7-db66a90d61f4
dn2_1    | 2023-03-10 22:41:52,263 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575
dn2_1    | 2023-03-10 22:41:56,898 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$309/0x00000008404bec40@a274020] WARN util.JvmPauseMonitor: JvmPauseMonitor-3892a4e1-c878-42af-adb7-db66a90d61f4: Detected pause in JVM or host machine (eg GC): pause of approximately 104958579ns.
dn2_1    | GC pool 'ParNew' had collection(s): count=1 time=185ms
dn2_1    | 2023-03-10 22:41:57,163 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState] INFO impl.FollowerState: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5310136957ns, electionTimeout:5198ms
dn2_1    | 2023-03-10 22:41:57,164 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState
dn2_1    | 2023-03-10 22:41:57,164 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn2_1    | 2023-03-10 22:41:57,167 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2023-03-10 22:41:57,171 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1
dn2_1    | 2023-03-10 22:41:57,216 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0], old=null
dn2_1    | 2023-03-10 22:41:57,704 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e78c5ce1-46ab-4889-a0cd-5903ae46614d: group-CBC13A60F575 not found.
dn2_1    | 2023-03-10 22:41:58,104 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1: ELECTION PASSED received 1 response(s) and 1 exception(s):
dn2_1    | 2023-03-10 22:41:58,122 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO impl.LeaderElection:   Response 0: 3892a4e1-c878-42af-adb7-db66a90d61f4<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:OK-t1
dn2_1    | 2023-03-10 22:41:58,126 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e78c5ce1-46ab-4889-a0cd-5903ae46614d: group-CBC13A60F575 not found.
dn2_1    | 2023-03-10 22:41:58,157 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4: new RaftServerImpl for group-5B98FDC36F00:[178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
dn2_1    | 2023-03-10 22:41:58,200 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2023-03-10 22:41:58,201 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2023-03-10 22:41:58,201 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1 ELECTION round 0: result PASSED
dn2_1    | 2023-03-10 22:41:58,202 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1
dn2_1    | 2023-03-10 22:41:58,202 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn2_1    | 2023-03-10 22:41:58,208 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CBC13A60F575 with new leaderId: 3892a4e1-c878-42af-adb7-db66a90d61f4
dn2_1    | 2023-03-10 22:41:58,208 [grpc-default-executor-0] INFO server.RaftServer: 3892a4e1-c878-42af-adb7-db66a90d61f4: addNew group-5B98FDC36F00:[178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0] returns group-5B98FDC36F00:java.util.concurrent.CompletableFuture@7995f1de[Not completed]
dn2_1    | 2023-03-10 22:41:58,209 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: change Leader from null to 3892a4e1-c878-42af-adb7-db66a90d61f4 at term 1 for becomeLeader, leader elected after 7771ms
dn2_1    | 2023-03-10 22:41:58,209 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn2_1    | 2023-03-10 22:41:58,218 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2023-03-10 22:41:58,243 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2023-03-10 22:41:58,244 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2023-03-10 22:41:58,245 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2023-03-10 22:41:58,249 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2023-03-10 22:41:58,251 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: ConfigurationManager, init=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
dn2_1    | 2023-03-10 22:41:58,252 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2023-03-10 22:41:58,262 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2023-03-10 22:41:58,267 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2023-03-10 22:41:58,353 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00 does not exist. Creating ...
dn2_1    | 2023-03-10 22:41:58,361 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00/in_use.lock acquired by nodename 6@dd6e12a1cd84
dn2_1    | 2023-03-10 22:41:58,424 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00 has been successfully formatted.
dn2_1    | 2023-03-10 22:41:58,425 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-5B98FDC36F00: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2023-03-10 22:41:58,438 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2023-03-10 22:41:58,426 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn2_1    | 2023-03-10 22:41:58,445 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2023-03-10 22:41:58,444 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2023-03-10 22:41:58,521 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2023-03-10 22:41:58,522 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2023-03-10 22:41:58,525 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2023-03-10 22:41:58,526 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2023-03-10 22:41:58,526 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn1_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn1_1    | 2023-03-10 22:40:56,445 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn1_1    | /************************************************************
dn1_1    | STARTUP_MSG: Starting HddsDatanodeService
dn1_1    | STARTUP_MSG:   host = f8784d6ff179/10.9.0.15
dn1_1    | STARTUP_MSG:   args = []
dn1_1    | STARTUP_MSG:   version = 1.2.1
dn1_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.1.jar
dn1_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
dn1_1    | STARTUP_MSG:   java = 11.0.13
dn1_1    | ************************************************************/
dn1_1    | 2023-03-10 22:40:56,568 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn1_1    | 2023-03-10 22:40:59,303 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn1_1    | 2023-03-10 22:41:00,153 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn1_1    | 2023-03-10 22:41:01,277 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn1_1    | 2023-03-10 22:41:01,278 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn1_1    | 2023-03-10 22:41:02,688 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f8784d6ff179 ip:10.9.0.15
dn1_1    | 2023-03-10 22:41:05,233 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
dn1_1    | 2023-03-10 22:41:06,742 [main] INFO reflections.Reflections: Reflections took 1164 ms to scan 2 urls, producing 84 keys and 167 values 
dn1_1    | 2023-03-10 22:41:09,068 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
dn1_1    | 2023-03-10 22:41:09,146 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn1_1    | 2023-03-10 22:41:09,150 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn1_1    | 2023-03-10 22:41:09,178 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn1_1    | 2023-03-10 22:41:09,493 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn1_1    | 2023-03-10 22:41:09,637 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2023-03-10 22:41:09,710 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
dn1_1    | 2023-03-10 22:41:09,721 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn1_1    | 2023-03-10 22:41:09,721 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn1_1    | 2023-03-10 22:41:09,733 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn1_1    | 2023-03-10 22:41:09,953 [Thread-5] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn1_1    | 2023-03-10 22:41:09,967 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn1_1    | 2023-03-10 22:41:21,787 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2023-03-10 22:41:22,374 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn1_1    | 2023-03-10 22:41:23,849 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn1_1    | 2023-03-10 22:41:23,861 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn1_1    | 2023-03-10 22:41:23,862 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn1_1    | 2023-03-10 22:41:23,884 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn1_1    | 2023-03-10 22:41:23,910 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2023-03-10 22:41:23,911 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn1_1    | 2023-03-10 22:41:23,912 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2023-03-10 22:41:26,776 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn1_1    | 2023-03-10 22:41:26,786 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2023-03-10 22:41:26,809 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2023-03-10 22:41:26,872 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2023-03-10 22:41:28,880 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn1_1    | 2023-03-10 22:41:29,123 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn1_1    | 2023-03-10 22:41:29,480 [main] INFO util.log: Logging initialized @42732ms to org.eclipse.jetty.util.log.Slf4jLog
dn1_1    | 2023-03-10 22:41:30,761 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn1_1    | 2023-03-10 22:41:30,832 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn1_1    | 2023-03-10 22:41:30,893 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn1_1    | 2023-03-10 22:41:30,925 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn2_1    | 2023-03-10 22:41:58,526 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00
dn3_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn3_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn3_1    | 2023-03-10 22:40:55,673 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn3_1    | /************************************************************
dn3_1    | STARTUP_MSG: Starting HddsDatanodeService
dn3_1    | STARTUP_MSG:   host = 55d4a52ef53d/10.9.0.17
dn3_1    | STARTUP_MSG:   args = []
dn3_1    | STARTUP_MSG:   version = 1.2.1
dn3_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.1.jar
dn3_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
dn3_1    | STARTUP_MSG:   java = 11.0.13
dn3_1    | ************************************************************/
dn3_1    | 2023-03-10 22:40:55,806 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn3_1    | 2023-03-10 22:40:58,552 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn3_1    | 2023-03-10 22:40:59,504 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn3_1    | 2023-03-10 22:41:00,777 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn3_1    | 2023-03-10 22:41:00,777 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn3_1    | 2023-03-10 22:41:02,255 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:55d4a52ef53d ip:10.9.0.17
dn3_1    | 2023-03-10 22:41:04,808 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
dn3_1    | 2023-03-10 22:41:06,067 [main] INFO reflections.Reflections: Reflections took 941 ms to scan 2 urls, producing 84 keys and 167 values 
dn3_1    | 2023-03-10 22:41:08,330 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
dn3_1    | 2023-03-10 22:41:08,367 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn3_1    | 2023-03-10 22:41:08,400 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn3_1    | 2023-03-10 22:41:08,420 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn3_1    | 2023-03-10 22:41:08,658 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn3_1    | 2023-03-10 22:41:08,875 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2023-03-10 22:41:08,885 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
dn3_1    | 2023-03-10 22:41:08,911 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn3_1    | 2023-03-10 22:41:08,913 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn3_1    | 2023-03-10 22:41:08,915 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn3_1    | 2023-03-10 22:41:09,106 [Thread-5] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn3_1    | 2023-03-10 22:41:09,132 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn3_1    | 2023-03-10 22:41:21,852 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2023-03-10 22:41:22,462 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn3_1    | 2023-03-10 22:41:23,986 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn3_1    | 2023-03-10 22:41:24,081 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn3_1    | 2023-03-10 22:41:24,083 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn3_1    | 2023-03-10 22:41:24,091 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn3_1    | 2023-03-10 22:41:24,101 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2023-03-10 22:41:24,118 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn3_1    | 2023-03-10 22:41:24,125 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2023-03-10 22:41:26,879 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn3_1    | 2023-03-10 22:41:26,910 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2023-03-10 22:41:26,910 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2023-03-10 22:41:27,325 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2023-03-10 22:41:28,751 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn3_1    | 2023-03-10 22:41:28,954 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn3_1    | 2023-03-10 22:41:29,279 [main] INFO util.log: Logging initialized @43460ms to org.eclipse.jetty.util.log.Slf4jLog
dn3_1    | 2023-03-10 22:41:30,434 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn3_1    | 2023-03-10 22:41:30,514 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn3_1    | 2023-03-10 22:41:30,547 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn3_1    | 2023-03-10 22:41:30,613 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn3_1    | 2023-03-10 22:41:30,613 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn3_1    | 2023-03-10 22:41:30,613 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn3_1    | 2023-03-10 22:41:31,581 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn3_1    | 2023-03-10 22:41:31,622 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
dn3_1    | 2023-03-10 22:41:32,041 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn3_1    | 2023-03-10 22:41:32,077 [main] INFO server.session: No SessionScavenger set, using defaults
dn3_1    | 2023-03-10 22:41:32,085 [main] INFO server.session: node0 Scavenging every 660000ms
dn3_1    | 2023-03-10 22:41:32,276 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1e1232cf{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn3_1    | 2023-03-10 22:41:32,296 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3730f716{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/static,AVAILABLE}
dn3_1    | 2023-03-10 22:41:35,066 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5c931134{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_1_jar-_-any-13912153740855863387/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/hddsDatanode}
dn3_1    | 2023-03-10 22:41:35,131 [main] INFO server.AbstractConnector: Started ServerConnector@5809fa26{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn3_1    | 2023-03-10 22:41:35,154 [main] INFO server.Server: Started @49334ms
dn3_1    | 2023-03-10 22:41:35,168 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn3_1    | 2023-03-10 22:41:35,168 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn3_1    | 2023-03-10 22:41:35,175 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn3_1    | 2023-03-10 22:41:35,201 [Datanode State Machine Thread - 0] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn3_1    | 2023-03-10 22:41:35,763 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@16138e20] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn3_1    | 2023-03-10 22:41:36,255 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn3_1    | 2023-03-10 22:41:36,747 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn3_1    | 2023-03-10 22:41:39,155 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2023-03-10 22:41:58,530 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | 2023-03-10 22:41:58,530 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2023-03-10 22:41:58,530 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2023-03-10 22:41:58,531 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2023-03-10 22:41:58,531 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2023-03-10 22:41:58,531 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2023-03-10 22:41:58,532 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2023-03-10 22:41:58,540 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2023-03-10 22:41:58,548 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2023-03-10 22:41:58,574 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2023-03-10 22:41:58,591 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn2_1    | 2023-03-10 22:41:58,593 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2023-03-10 22:41:58,603 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2023-03-10 22:41:58,618 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2023-03-10 22:41:58,623 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2023-03-10 22:41:58,623 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2023-03-10 22:41:58,623 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2023-03-10 22:41:58,623 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2023-03-10 22:41:58,624 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2023-03-10 22:41:58,625 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: start as a follower, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:41:58,637 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn2_1    | 2023-03-10 22:41:58,649 [pool-22-thread-1] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState
dn2_1    | 2023-03-10 22:41:58,657 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn2_1    | 2023-03-10 22:41:58,729 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5B98FDC36F00,id=3892a4e1-c878-42af-adb7-db66a90d61f4
dn2_1    | 2023-03-10 22:41:58,759 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn2_1    | 2023-03-10 22:41:58,847 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2023-03-10 22:41:58,847 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2023-03-10 22:41:58,971 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: receive requestVote(ELECTION, 178b30e1-b74d-4f4d-a142-c930eee71455, group-5B98FDC36F00, 1, (t:0, i:0))
dn2_1    | 2023-03-10 22:41:58,978 [grpc-default-executor-0] INFO impl.VoteContext: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FOLLOWER: reject ELECTION from 178b30e1-b74d-4f4d-a142-c930eee71455: our priority 1 > candidate's priority 0
dn2_1    | 2023-03-10 22:41:58,985 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:178b30e1-b74d-4f4d-a142-c930eee71455
dn2_1    | 2023-03-10 22:41:58,985 [grpc-default-executor-0] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState
dn2_1    | 2023-03-10 22:41:58,997 [grpc-default-executor-0] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState
dn2_1    | 2023-03-10 22:41:58,997 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState was interrupted: {}
dn2_1    | java.lang.InterruptedException: sleep interrupted
dn2_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn2_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn2_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn2_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn2_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn2_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn2_1    | 2023-03-10 22:41:59,042 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2023-03-10 22:41:59,044 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn2_1    | 2023-03-10 22:41:59,222 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00 replies to ELECTION vote request: 178b30e1-b74d-4f4d-a142-c930eee71455<-3892a4e1-c878-42af-adb7-db66a90d61f4#0:FAIL-t1. Peer's state: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00:t1, leader=null, voted=null, raftlog=3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:41:59,389 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575.
dn2_1    | 2023-03-10 22:41:59,389 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn2_1    | 2023-03-10 22:41:59,438 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2023-03-10 22:41:59,440 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn2_1    | 2023-03-10 22:41:59,430 [Command processor thread] INFO server.RaftServer: 3892a4e1-c878-42af-adb7-db66a90d61f4: addNew group-676BAB171C02:[3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1] returns group-676BAB171C02:java.util.concurrent.CompletableFuture@79e34ab9[Not completed]
dn2_1    | 2023-03-10 22:41:59,444 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn2_1    | 2023-03-10 22:41:59,461 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2023-03-10 22:41:59,461 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2023-03-10 22:41:59,507 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn2_1    | 2023-03-10 22:41:59,521 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4: new RaftServerImpl for group-676BAB171C02:[3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1] with ContainerStateMachine:uninitialized
dn2_1    | 2023-03-10 22:41:59,524 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2023-03-10 22:41:59,525 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2023-03-10 22:41:59,525 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2023-03-10 22:41:59,525 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2023-03-10 22:41:59,526 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2023-03-10 22:41:59,526 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2023-03-10 22:41:59,526 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2023-03-10 22:41:59,526 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02: ConfigurationManager, init=-1: [3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn2_1    | 2023-03-10 22:41:59,528 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2023-03-10 22:41:59,529 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2023-03-10 22:41:59,529 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2023-03-10 22:41:59,532 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2d4f1397-2cdc-4336-a562-676bab171c02 does not exist. Creating ...
dn2_1    | 2023-03-10 22:41:59,551 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2d4f1397-2cdc-4336-a562-676bab171c02/in_use.lock acquired by nodename 6@dd6e12a1cd84
dn2_1    | 2023-03-10 22:41:59,553 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2023-03-10 22:41:59,553 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn2_1    | 2023-03-10 22:41:59,555 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn2_1    | 2023-03-10 22:41:59,555 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2023-03-10 22:41:30,934 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn1_1    | 2023-03-10 22:41:30,935 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn1_1    | 2023-03-10 22:41:31,543 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn1_1    | 2023-03-10 22:41:31,552 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
dn1_1    | 2023-03-10 22:41:32,050 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn1_1    | 2023-03-10 22:41:32,050 [main] INFO server.session: No SessionScavenger set, using defaults
dn1_1    | 2023-03-10 22:41:32,105 [main] INFO server.session: node0 Scavenging every 600000ms
dn1_1    | 2023-03-10 22:41:32,280 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6579cdbb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn1_1    | 2023-03-10 22:41:32,280 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64bebd55{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/static,AVAILABLE}
dn1_1    | 2023-03-10 22:41:35,492 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3e1f1046{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_1_jar-_-any-2877083921068680989/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/hddsDatanode}
dn2_1    | 2023-03-10 22:41:59,556 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2023-03-10 22:41:59,555 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2d4f1397-2cdc-4336-a562-676bab171c02 has been successfully formatted.
dn2_1    | 2023-03-10 22:41:59,566 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn2_1    | 2023-03-10 22:41:59,605 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-676BAB171C02: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2023-03-10 22:41:59,606 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2023-03-10 22:41:59,606 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2023-03-10 22:41:59,606 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2023-03-10 22:41:59,606 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2023-03-10 22:41:59,607 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2023-03-10 22:41:59,607 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2023-03-10 22:41:59,608 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2023-03-10 22:41:59,610 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/2d4f1397-2cdc-4336-a562-676bab171c02
dn2_1    | 2023-03-10 22:41:59,620 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | 2023-03-10 22:41:59,621 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2023-03-10 22:41:59,622 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2023-03-10 22:41:59,625 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2023-03-10 22:41:59,629 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2023-03-10 22:41:35,591 [main] INFO server.AbstractConnector: Started ServerConnector@78b7f805{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn1_1    | 2023-03-10 22:41:35,593 [main] INFO server.Server: Started @48846ms
dn1_1    | 2023-03-10 22:41:35,620 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn1_1    | 2023-03-10 22:41:35,622 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn1_1    | 2023-03-10 22:41:35,670 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn1_1    | 2023-03-10 22:41:35,697 [Datanode State Machine Thread - 0] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn1_1    | 2023-03-10 22:41:36,040 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@348e03ce] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn1_1    | 2023-03-10 22:41:36,766 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn1_1    | 2023-03-10 22:41:37,225 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn1_1    | 2023-03-10 22:41:39,334 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2023-03-10 22:41:39,335 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2023-03-10 22:41:40,336 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2023-03-10 22:41:41,337 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2023-03-10 22:41:42,338 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2023-03-10 22:41:43,339 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2023-03-10 22:41:44,367 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn1_1    | java.net.SocketTimeoutException: Call From f8784d6ff179/10.9.0.15 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.15:47580 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn1_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn1_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn1_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
dn1_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn1_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.15:47580 remote=recon/10.9.0.20:9891]
dn1_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn1_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn1_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn1_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn3_1    | 2023-03-10 22:41:39,165 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2023-03-10 22:41:39,722 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn3_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:269)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:456)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | Caused by: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	... 1 more
dn3_1    | 2023-03-10 22:41:40,166 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2023-03-10 22:41:41,167 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2023-03-10 22:41:41,724 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn3_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:269)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:456)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | Caused by: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	... 1 more
dn3_1    | 2023-03-10 22:41:42,168 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2023-03-10 22:41:43,169 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2023-03-10 22:41:43,726 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn3_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:269)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:456)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | Caused by: java.util.concurrent.TimeoutException
dn4_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn4_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn4_1    | 2023-03-10 22:40:55,020 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn4_1    | /************************************************************
dn4_1    | STARTUP_MSG: Starting HddsDatanodeService
dn4_1    | STARTUP_MSG:   host = 70399d395b30/10.9.0.18
dn4_1    | STARTUP_MSG:   args = []
dn4_1    | STARTUP_MSG:   version = 1.2.1
dn2_1    | 2023-03-10 22:41:59,610 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl
dn2_1    | 2023-03-10 22:41:59,675 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2023-03-10 22:41:59,713 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2023-03-10 22:41:59,714 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2023-03-10 22:41:59,717 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2023-03-10 22:41:59,719 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2023-03-10 22:41:59,736 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn2_1    | 2023-03-10 22:41:59,736 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2023-03-10 22:41:59,753 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2023-03-10 22:41:59,754 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2023-03-10 22:41:59,754 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2023-03-10 22:41:59,756 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2023-03-10 22:41:59,758 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2023-03-10 22:41:59,758 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2023-03-10 22:41:59,760 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02: start as a follower, conf=-1: [3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1], old=null
dn2_1    | 2023-03-10 22:41:59,772 [pool-22-thread-1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn2_1    | 2023-03-10 22:41:59,773 [pool-22-thread-1] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-FollowerState
dn2_1    | 2023-03-10 22:41:59,810 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-676BAB171C02,id=3892a4e1-c878-42af-adb7-db66a90d61f4
dn2_1    | 2023-03-10 22:41:59,812 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=2d4f1397-2cdc-4336-a562-676bab171c02
dn2_1    | 2023-03-10 22:41:59,823 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=2d4f1397-2cdc-4336-a562-676bab171c02.
dn2_1    | 2023-03-10 22:41:59,875 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker: Starting segment from index:0
dn2_1    | 2023-03-10 22:42:00,048 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderElection1] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: set configuration 0: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:42:00,356 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_inprogress_0
dn2_1    | 2023-03-10 22:42:04,257 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5259589555ns, electionTimeout:5124ms
dn2_1    | 2023-03-10 22:42:04,257 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState
dn2_1    | 2023-03-10 22:42:04,257 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn2_1    | 2023-03-10 22:42:04,258 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2023-03-10 22:42:04,258 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2
dn2_1    | 2023-03-10 22:42:04,272 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:42:04,368 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: receive requestVote(ELECTION, 1a6d358d-6662-4447-914c-d709a67ff716, group-5B98FDC36F00, 2, (t:0, i:0))
dn2_1    | 2023-03-10 22:42:04,369 [grpc-default-executor-0] INFO impl.VoteContext: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-CANDIDATE: reject ELECTION from 1a6d358d-6662-4447-914c-d709a67ff716: already has voted for 3892a4e1-c878-42af-adb7-db66a90d61f4 at current term 2
dn2_1    | 2023-03-10 22:42:04,369 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00 replies to ELECTION vote request: 1a6d358d-6662-4447-914c-d709a67ff716<-3892a4e1-c878-42af-adb7-db66a90d61f4#0:FAIL-t2. Peer's state: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00:t2, leader=null, voted=3892a4e1-c878-42af-adb7-db66a90d61f4, raftlog=3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:42:04,548 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: receive requestVote(ELECTION, 178b30e1-b74d-4f4d-a142-c930eee71455, group-5B98FDC36F00, 2, (t:0, i:0))
dn2_1    | 2023-03-10 22:42:04,548 [grpc-default-executor-0] INFO impl.VoteContext: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-CANDIDATE: reject ELECTION from 178b30e1-b74d-4f4d-a142-c930eee71455: already has voted for 3892a4e1-c878-42af-adb7-db66a90d61f4 at current term 2
dn2_1    | 2023-03-10 22:42:04,549 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00 replies to ELECTION vote request: 178b30e1-b74d-4f4d-a142-c930eee71455<-3892a4e1-c878-42af-adb7-db66a90d61f4#0:FAIL-t2. Peer's state: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00:t2, leader=null, voted=3892a4e1-c878-42af-adb7-db66a90d61f4, raftlog=3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:42:04,634 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn2_1    | 2023-03-10 22:42:04,635 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection:   Response 0: 3892a4e1-c878-42af-adb7-db66a90d61f4<-178b30e1-b74d-4f4d-a142-c930eee71455#0:FAIL-t2
dn2_1    | 2023-03-10 22:42:04,635 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection:   Response 1: 3892a4e1-c878-42af-adb7-db66a90d61f4<-1a6d358d-6662-4447-914c-d709a67ff716#0:FAIL-t2
dn2_1    | 2023-03-10 22:42:04,635 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2 ELECTION round 0: result REJECTED
dn2_1    | 2023-03-10 22:42:04,636 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
dn2_1    | 2023-03-10 22:42:04,636 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2
dn2_1    | 2023-03-10 22:42:04,636 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection2] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState
dn2_1    | 2023-03-10 22:42:04,904 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-FollowerState] INFO impl.FollowerState: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5130882398ns, electionTimeout:5092ms
dn2_1    | 2023-03-10 22:42:04,904 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-FollowerState] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-FollowerState
dn2_1    | 2023-03-10 22:42:04,904 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-FollowerState] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn2_1    | 2023-03-10 22:42:04,905 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2023-03-10 22:42:04,905 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-FollowerState] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3
dn2_1    | 2023-03-10 22:42:04,916 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1], old=null
dn2_1    | 2023-03-10 22:42:04,916 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3 ELECTION round 0: result PASSED (term=1)
dn2_1    | 2023-03-10 22:42:04,916 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3
dn2_1    | 2023-03-10 22:42:04,917 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn2_1    | 2023-03-10 22:42:04,917 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-676BAB171C02 with new leaderId: 3892a4e1-c878-42af-adb7-db66a90d61f4
dn2_1    | 2023-03-10 22:42:04,923 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02: change Leader from null to 3892a4e1-c878-42af-adb7-db66a90d61f4 at term 1 for becomeLeader, leader elected after 5311ms
dn2_1    | 2023-03-10 22:42:04,923 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2023-03-10 22:42:04,924 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn2_1    | 2023-03-10 22:42:04,924 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2023-03-10 22:42:04,924 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn2_1    | 2023-03-10 22:42:04,924 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn5_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn5_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn5_1    | 2023-03-10 22:40:55,675 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn5_1    | /************************************************************
dn5_1    | STARTUP_MSG: Starting HddsDatanodeService
dn5_1    | STARTUP_MSG:   host = c4f9b517a239/10.9.0.19
dn5_1    | STARTUP_MSG:   args = []
dn5_1    | STARTUP_MSG:   version = 1.2.1
dn5_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.1.jar
dn5_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
dn5_1    | STARTUP_MSG:   java = 11.0.13
dn5_1    | ************************************************************/
dn5_1    | 2023-03-10 22:40:55,855 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn5_1    | 2023-03-10 22:40:58,811 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn5_1    | 2023-03-10 22:40:59,664 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn5_1    | 2023-03-10 22:41:01,063 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn5_1    | 2023-03-10 22:41:01,064 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn5_1    | 2023-03-10 22:41:02,581 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:c4f9b517a239 ip:10.9.0.19
dn5_1    | 2023-03-10 22:41:05,002 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
dn5_1    | 2023-03-10 22:41:06,381 [main] INFO reflections.Reflections: Reflections took 1153 ms to scan 2 urls, producing 84 keys and 167 values 
dn5_1    | 2023-03-10 22:41:09,037 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
dn5_1    | 2023-03-10 22:41:09,065 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn5_1    | 2023-03-10 22:41:09,099 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn5_1    | 2023-03-10 22:41:09,102 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn5_1    | 2023-03-10 22:41:09,367 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn5_1    | 2023-03-10 22:41:09,572 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn5_1    | 2023-03-10 22:41:09,573 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
dn5_1    | 2023-03-10 22:41:09,637 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn5_1    | 2023-03-10 22:41:09,638 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn5_1    | 2023-03-10 22:41:09,641 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn5_1    | 2023-03-10 22:41:09,897 [Thread-5] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn5_1    | 2023-03-10 22:41:09,902 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn5_1    | 2023-03-10 22:41:22,633 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn5_1    | 2023-03-10 22:41:23,414 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn5_1    | 2023-03-10 22:41:25,350 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn5_1    | 2023-03-10 22:41:25,370 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn5_1    | 2023-03-10 22:41:25,371 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn5_1    | 2023-03-10 22:41:25,375 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn5_1    | 2023-03-10 22:41:25,385 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2023-03-10 22:41:25,389 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn5_1    | 2023-03-10 22:41:25,402 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn5_1    | 2023-03-10 22:41:26,922 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn5_1    | 2023-03-10 22:41:26,934 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2023-03-10 22:41:26,937 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2023-03-10 22:41:27,180 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2023-03-10 22:41:29,003 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn5_1    | 2023-03-10 22:41:29,270 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn5_1    | 2023-03-10 22:41:29,575 [main] INFO util.log: Logging initialized @43120ms to org.eclipse.jetty.util.log.Slf4jLog
dn5_1    | 2023-03-10 22:41:30,739 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn5_1    | 2023-03-10 22:41:30,785 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn5_1    | 2023-03-10 22:41:30,907 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn5_1    | 2023-03-10 22:41:30,910 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn5_1    | 2023-03-10 22:41:30,945 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn5_1    | 2023-03-10 22:41:30,947 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn5_1    | 2023-03-10 22:41:31,491 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn5_1    | 2023-03-10 22:41:31,502 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
dn5_1    | 2023-03-10 22:41:31,916 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn5_1    | 2023-03-10 22:41:31,916 [main] INFO server.session: No SessionScavenger set, using defaults
dn5_1    | 2023-03-10 22:41:31,919 [main] INFO server.session: node0 Scavenging every 660000ms
dn5_1    | 2023-03-10 22:41:32,087 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1e3df614{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn5_1    | 2023-03-10 22:41:32,098 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6b357eb6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/static,AVAILABLE}
dn5_1    | 2023-03-10 22:41:34,827 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@71560f51{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_1_jar-_-any-14672708940220172722/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/hddsDatanode}
dn4_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.1.jar
dn4_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
dn4_1    | STARTUP_MSG:   java = 11.0.13
dn4_1    | ************************************************************/
dn4_1    | 2023-03-10 22:40:55,151 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn4_1    | 2023-03-10 22:40:58,019 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn4_1    | 2023-03-10 22:40:58,718 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn4_1    | 2023-03-10 22:40:59,728 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn4_1    | 2023-03-10 22:40:59,728 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn4_1    | 2023-03-10 22:41:01,147 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:70399d395b30 ip:10.9.0.18
dn4_1    | 2023-03-10 22:41:03,326 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
dn4_1    | 2023-03-10 22:41:04,664 [main] INFO reflections.Reflections: Reflections took 1120 ms to scan 2 urls, producing 84 keys and 167 values 
dn4_1    | 2023-03-10 22:41:07,160 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
dn4_1    | 2023-03-10 22:41:07,222 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn4_1    | 2023-03-10 22:41:07,240 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn4_1    | 2023-03-10 22:41:07,264 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn4_1    | 2023-03-10 22:41:07,517 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn4_1    | 2023-03-10 22:41:07,737 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn4_1    | 2023-03-10 22:41:07,739 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
dn4_1    | 2023-03-10 22:41:07,779 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn4_1    | 2023-03-10 22:41:07,780 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn4_1    | 2023-03-10 22:41:07,799 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn4_1    | 2023-03-10 22:41:07,998 [Thread-5] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn4_1    | 2023-03-10 22:41:07,999 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn4_1    | 2023-03-10 22:41:21,077 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn4_1    | 2023-03-10 22:41:21,770 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn4_1    | 2023-03-10 22:41:23,386 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn4_1    | 2023-03-10 22:41:23,388 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn4_1    | 2023-03-10 22:41:23,392 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn4_1    | 2023-03-10 22:41:23,393 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn4_1    | 2023-03-10 22:41:23,398 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2023-03-10 22:41:23,401 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn4_1    | 2023-03-10 22:41:23,407 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn4_1    | 2023-03-10 22:41:26,055 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn4_1    | 2023-03-10 22:41:26,109 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2023-03-10 22:41:26,109 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2023-03-10 22:41:26,292 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2023-03-10 22:41:27,935 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn4_1    | 2023-03-10 22:41:28,216 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn4_1    | 2023-03-10 22:41:28,578 [main] INFO util.log: Logging initialized @43768ms to org.eclipse.jetty.util.log.Slf4jLog
dn4_1    | 2023-03-10 22:41:29,847 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn4_1    | 2023-03-10 22:41:29,887 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn4_1    | 2023-03-10 22:41:29,936 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn4_1    | 2023-03-10 22:41:29,942 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn4_1    | 2023-03-10 22:41:29,953 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn4_1    | 2023-03-10 22:41:29,956 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn4_1    | 2023-03-10 22:41:30,511 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn4_1    | 2023-03-10 22:41:30,551 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
dn4_1    | 2023-03-10 22:41:31,043 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn4_1    | 2023-03-10 22:41:31,043 [main] INFO server.session: No SessionScavenger set, using defaults
dn4_1    | 2023-03-10 22:41:31,069 [main] INFO server.session: node0 Scavenging every 600000ms
dn4_1    | 2023-03-10 22:41:31,204 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7a1b8a46{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn4_1    | 2023-03-10 22:41:31,205 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@40d52be7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/static,AVAILABLE}
dn4_1    | 2023-03-10 22:41:33,600 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@45a1d057{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_1_jar-_-any-5938814992994415925/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar!/webapps/hddsDatanode}
dn5_1    | 2023-03-10 22:41:34,950 [main] INFO server.AbstractConnector: Started ServerConnector@1c240cf2{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn5_1    | 2023-03-10 22:41:34,964 [main] INFO server.Server: Started @48509ms
dn5_1    | 2023-03-10 22:41:34,985 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn5_1    | 2023-03-10 22:41:34,985 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn5_1    | 2023-03-10 22:41:35,004 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn5_1    | 2023-03-10 22:41:35,053 [Datanode State Machine Thread - 0] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn5_1    | 2023-03-10 22:41:35,578 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7b211948] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn5_1    | 2023-03-10 22:41:36,258 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn5_1    | 2023-03-10 22:41:36,650 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn5_1    | 2023-03-10 22:41:39,021 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2023-03-10 22:41:39,027 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2023-03-10 22:41:40,034 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2023-03-10 22:41:41,035 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2023-03-10 22:41:42,036 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2023-03-10 22:41:43,036 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2023-03-10 22:41:44,082 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn5_1    | java.net.SocketTimeoutException: Call From c4f9b517a239/10.9.0.19 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.19:35734 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn5_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn5_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn5_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn5_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn5_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn5_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn5_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn5_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn5_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn5_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn5_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
dn5_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn5_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn5_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn5_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn5_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn5_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.19:35734 remote=recon/10.9.0.20:9891]
dn5_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn5_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn5_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn5_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn5_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn5_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn5_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn5_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn5_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn5_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn5_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn5_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn5_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn5_1    | 2023-03-10 22:41:45,794 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn5_1    | 2023-03-10 22:41:45,811 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn5_1    | 2023-03-10 22:41:46,434 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 178b30e1-b74d-4f4d-a142-c930eee71455
dn5_1    | 2023-03-10 22:41:46,609 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 178b30e1-b74d-4f4d-a142-c930eee71455: start RPC server
dn5_1    | 2023-03-10 22:41:46,640 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 178b30e1-b74d-4f4d-a142-c930eee71455: GrpcService started, listening on 9856
dn5_1    | 2023-03-10 22:41:46,653 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 178b30e1-b74d-4f4d-a142-c930eee71455: GrpcService started, listening on 9857
dn4_1    | 2023-03-10 22:41:33,715 [main] INFO server.AbstractConnector: Started ServerConnector@322e49ee{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn4_1    | 2023-03-10 22:41:33,730 [main] INFO server.Server: Started @48920ms
dn4_1    | 2023-03-10 22:41:33,758 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn4_1    | 2023-03-10 22:41:33,761 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn4_1    | 2023-03-10 22:41:33,766 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn4_1    | 2023-03-10 22:41:33,774 [Datanode State Machine Thread - 0] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn4_1    | 2023-03-10 22:41:34,085 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@638eca64] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn4_1    | 2023-03-10 22:41:34,979 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn4_1    | 2023-03-10 22:41:35,549 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn4_1    | 2023-03-10 22:41:37,466 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:37,504 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:38,467 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:38,504 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:39,468 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:39,505 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:40,469 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:41,470 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:42,471 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:43,472 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2023-03-10 22:41:44,573 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn4_1    | java.net.SocketTimeoutException: Call From 70399d395b30/10.9.0.18 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.18:40602 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn4_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn4_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn4_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn4_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn4_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn4_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn4_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn4_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn4_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn4_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn4_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
dn4_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn4_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn4_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn4_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.18:40602 remote=recon/10.9.0.20:9891]
dn4_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn4_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn4_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn4_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn4_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn4_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn4_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn4_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn4_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn4_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn4_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn4_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn4_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn4_1    | 2023-03-10 22:41:45,864 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn4_1    | 2023-03-10 22:41:45,869 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn4_1    | 2023-03-10 22:41:46,692 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn4_1    | 2023-03-10 22:41:46,886 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start RPC server
dn4_1    | 2023-03-10 22:41:46,946 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: e78c5ce1-46ab-4889-a0cd-5903ae46614d: GrpcService started, listening on 9856
dn4_1    | 2023-03-10 22:41:46,948 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: e78c5ce1-46ab-4889-a0cd-5903ae46614d: GrpcService started, listening on 9857
dn4_1    | 2023-03-10 22:41:46,967 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: e78c5ce1-46ab-4889-a0cd-5903ae46614d: GrpcService started, listening on 9858
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	... 1 more
dn3_1    | 2023-03-10 22:41:44,191 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn3_1    | java.net.SocketTimeoutException: Call From 55d4a52ef53d/10.9.0.17 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.17:58772 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn3_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn3_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn3_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
dn3_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.17:58772 remote=recon/10.9.0.20:9891]
dn3_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn3_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn3_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn3_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn3_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn3_1    | 2023-03-10 22:41:45,872 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn3_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:269)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:456)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | Caused by: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	... 1 more
dn4_1    | 2023-03-10 22:41:46,997 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e78c5ce1-46ab-4889-a0cd-5903ae46614d is started using port 9858 for RATIS
dn4_1    | 2023-03-10 22:41:46,998 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$309/0x00000008404bec40@1a30175f] INFO util.JvmPauseMonitor: JvmPauseMonitor-e78c5ce1-46ab-4889-a0cd-5903ae46614d: Started
dn4_1    | 2023-03-10 22:41:47,001 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e78c5ce1-46ab-4889-a0cd-5903ae46614d is started using port 9857 for RATIS_ADMIN
dn4_1    | 2023-03-10 22:41:47,013 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e78c5ce1-46ab-4889-a0cd-5903ae46614d is started using port 9856 for RATIS_SERVER
dn4_1    | 2023-03-10 22:41:51,136 [Command processor thread] INFO server.RaftServer: e78c5ce1-46ab-4889-a0cd-5903ae46614d: addNew group-0049FBBC23B3:[e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0] returns group-0049FBBC23B3:java.util.concurrent.CompletableFuture@4a056485[Not completed]
dn4_1    | 2023-03-10 22:41:51,431 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d: new RaftServerImpl for group-0049FBBC23B3:[e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0] with ContainerStateMachine:uninitialized
dn4_1    | 2023-03-10 22:41:51,461 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2023-03-10 22:41:51,469 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2023-03-10 22:41:51,480 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2023-03-10 22:41:51,482 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2023-03-10 22:41:51,485 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2023-03-10 22:41:51,487 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2023-03-10 22:41:51,488 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2023-03-10 22:41:51,538 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: ConfigurationManager, init=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn4_1    | 2023-03-10 22:41:51,547 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2023-03-10 22:41:51,593 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2023-03-10 22:41:51,598 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2023-03-10 22:41:51,647 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3 does not exist. Creating ...
dn4_1    | 2023-03-10 22:41:51,709 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3/in_use.lock acquired by nodename 6@70399d395b30
dn4_1    | 2023-03-10 22:41:51,830 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3 has been successfully formatted.
dn4_1    | 2023-03-10 22:41:51,875 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-0049FBBC23B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn4_1    | 2023-03-10 22:41:51,890 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2023-03-10 22:41:51,908 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2023-03-10 22:41:51,997 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2023-03-10 22:41:52,014 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2023-03-10 22:41:52,190 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2023-03-10 22:41:52,245 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn4_1    | 2023-03-10 22:41:52,249 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2023-03-10 22:41:52,295 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3
dn4_1    | 2023-03-10 22:41:52,297 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn4_1    | 2023-03-10 22:41:52,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2023-03-10 22:41:52,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2023-03-10 22:41:52,319 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn4_1    | 2023-03-10 22:41:52,320 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2023-03-10 22:41:52,338 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn1_1    | 2023-03-10 22:41:45,775 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn1_1    | 2023-03-10 22:41:45,790 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn1_1    | 2023-03-10 22:41:46,379 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e3e4587c-aa42-4e86-ae9a-d3e448365275
dn1_1    | 2023-03-10 22:41:46,579 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: e3e4587c-aa42-4e86-ae9a-d3e448365275: start RPC server
dn1_1    | 2023-03-10 22:41:46,639 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: e3e4587c-aa42-4e86-ae9a-d3e448365275: GrpcService started, listening on 9856
dn1_1    | 2023-03-10 22:41:46,641 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: e3e4587c-aa42-4e86-ae9a-d3e448365275: GrpcService started, listening on 9857
dn1_1    | 2023-03-10 22:41:46,650 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: e3e4587c-aa42-4e86-ae9a-d3e448365275: GrpcService started, listening on 9858
dn1_1    | 2023-03-10 22:41:46,673 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e3e4587c-aa42-4e86-ae9a-d3e448365275 is started using port 9858 for RATIS
dn1_1    | 2023-03-10 22:41:46,673 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e3e4587c-aa42-4e86-ae9a-d3e448365275 is started using port 9857 for RATIS_ADMIN
dn1_1    | 2023-03-10 22:41:46,673 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e3e4587c-aa42-4e86-ae9a-d3e448365275 is started using port 9856 for RATIS_SERVER
dn1_1    | 2023-03-10 22:41:46,742 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$309/0x00000008404bec40@132de926] INFO util.JvmPauseMonitor: JvmPauseMonitor-e3e4587c-aa42-4e86-ae9a-d3e448365275: Started
dn1_1    | 2023-03-10 22:41:51,215 [Command processor thread] INFO server.RaftServer: e3e4587c-aa42-4e86-ae9a-d3e448365275: addNew group-0049FBBC23B3:[e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0] returns group-0049FBBC23B3:java.util.concurrent.CompletableFuture@23a67d60[Not completed]
dn1_1    | 2023-03-10 22:41:51,675 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275: new RaftServerImpl for group-0049FBBC23B3:[e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0] with ContainerStateMachine:uninitialized
dn1_1    | 2023-03-10 22:41:51,751 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2023-03-10 22:41:51,755 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2023-03-10 22:41:51,757 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2023-03-10 22:41:51,757 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2023-03-10 22:41:51,761 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2023-03-10 22:41:51,769 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2023-03-10 22:41:51,780 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2023-03-10 22:41:51,808 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: ConfigurationManager, init=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn1_1    | 2023-03-10 22:41:51,821 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2023-03-10 22:41:51,899 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2023-03-10 22:41:51,905 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2023-03-10 22:41:51,932 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3 does not exist. Creating ...
dn1_1    | 2023-03-10 22:41:52,095 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3/in_use.lock acquired by nodename 7@f8784d6ff179
dn1_1    | 2023-03-10 22:41:52,172 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3 has been successfully formatted.
dn1_1    | 2023-03-10 22:41:52,218 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-0049FBBC23B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2023-03-10 22:41:52,219 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn1_1    | 2023-03-10 22:41:52,351 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2023-03-10 22:41:52,367 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2023-03-10 22:41:52,478 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2023-03-10 22:41:52,482 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2023-03-10 22:41:52,638 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2023-03-10 22:41:52,735 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2023-03-10 22:41:52,758 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2023-03-10 22:41:52,813 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3
dn1_1    | 2023-03-10 22:41:52,855 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn1_1    | 2023-03-10 22:41:52,856 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2023-03-10 22:41:52,860 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2023-03-10 22:41:52,869 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2023-03-10 22:41:52,872 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2023-03-10 22:41:52,888 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2023-03-10 22:41:52,888 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2023-03-10 22:41:52,893 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2023-03-10 22:41:53,063 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2023-03-10 22:41:53,069 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2023-03-10 22:41:53,174 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn1_1    | 2023-03-10 22:41:53,181 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2023-03-10 22:41:53,227 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2023-03-10 22:41:53,243 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2023-03-10 22:41:53,250 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2023-03-10 22:41:53,264 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2023-03-10 22:41:53,266 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2023-03-10 22:41:53,305 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2023-03-10 22:41:53,803 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: start as a follower, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn1_1    | 2023-03-10 22:41:53,804 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn1_1    | 2023-03-10 22:41:53,832 [pool-22-thread-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:41:53,884 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0049FBBC23B3,id=e3e4587c-aa42-4e86-ae9a-d3e448365275
dn1_1    | 2023-03-10 22:41:54,137 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3
dn1_1    | 2023-03-10 22:41:57,281 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275: new RaftServerImpl for group-CBC13A60F575:[e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
dn1_1    | 2023-03-10 22:41:57,311 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2023-03-10 22:41:57,312 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2023-03-10 22:41:57,312 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2023-03-10 22:41:57,312 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2023-03-10 22:41:57,313 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2023-03-10 22:41:57,313 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2023-03-10 22:41:57,313 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2023-03-10 22:41:57,313 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: ConfigurationManager, init=-1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
dn1_1    | 2023-03-10 22:41:57,314 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2023-03-10 22:41:57,317 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2023-03-10 22:41:57,317 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2023-03-10 22:41:57,317 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575 does not exist. Creating ...
dn1_1    | 2023-03-10 22:41:57,318 [grpc-default-executor-1] INFO server.RaftServer: e3e4587c-aa42-4e86-ae9a-d3e448365275: addNew group-CBC13A60F575:[e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0] returns group-CBC13A60F575:java.util.concurrent.CompletableFuture@53889855[Not completed]
dn4_1    | 2023-03-10 22:41:52,338 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2023-03-10 22:41:52,340 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2023-03-10 22:41:52,418 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2023-03-10 22:41:52,422 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2023-03-10 22:41:52,464 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn4_1    | 2023-03-10 22:41:52,464 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn4_1    | 2023-03-10 22:41:52,510 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2023-03-10 22:41:52,526 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2023-03-10 22:41:52,527 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2023-03-10 22:41:52,533 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2023-03-10 22:41:52,553 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn4_1    | 2023-03-10 22:41:52,554 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2023-03-10 22:41:52,911 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: start as a follower, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn4_1    | 2023-03-10 22:41:52,917 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn4_1    | 2023-03-10 22:41:52,922 [pool-22-thread-1] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState
dn4_1    | 2023-03-10 22:41:53,009 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0049FBBC23B3,id=e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn4_1    | 2023-03-10 22:41:53,197 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3
dn4_1    | 2023-03-10 22:41:57,580 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: e78c5ce1-46ab-4889-a0cd-5903ae46614d: Failed requestVote 3892a4e1-c878-42af-adb7-db66a90d61f4->e78c5ce1-46ab-4889-a0cd-5903ae46614d#0
dn4_1    | org.apache.ratis.protocol.exceptions.GroupMismatchException: e78c5ce1-46ab-4889-a0cd-5903ae46614d: group-CBC13A60F575 not found.
dn4_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
dn4_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
dn4_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
dn4_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
dn4_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
dn4_1    | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
dn4_1    | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
dn4_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
dn4_1    | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
dn4_1    | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
dn4_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn4_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn4_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn4_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn4_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | 2023-03-10 22:41:58,144 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5222091459ns, electionTimeout:5185ms
dn4_1    | 2023-03-10 22:41:58,149 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState
dn4_1    | 2023-03-10 22:41:58,164 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn4_1    | 2023-03-10 22:41:58,173 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2023-03-10 22:41:58,173 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1
dn4_1    | 2023-03-10 22:41:58,294 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn4_1    | 2023-03-10 22:41:58,539 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn4_1    | 2023-03-10 22:41:58,553 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1] INFO impl.LeaderElection:   Response 0: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t1
dn2_1    | 2023-03-10 22:42:04,924 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2023-03-10 22:42:04,925 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2023-03-10 22:42:04,936 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2023-03-10 22:42:04,937 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn2_1    | 2023-03-10 22:42:04,937 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderStateImpl
dn2_1    | 2023-03-10 22:42:04,938 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-SegmentedRaftLogWorker: Starting segment from index:0
dn2_1    | 2023-03-10 22:42:04,945 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2d4f1397-2cdc-4336-a562-676bab171c02/current/log_inprogress_0
dn2_1    | 2023-03-10 22:42:04,972 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02-LeaderElection3] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-676BAB171C02: set configuration 0: [3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2023-03-10 22:42:05,603 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl send StartLeaderElectionRequest to follower:e78c5ce1-46ab-4889-a0cd-5903ae46614d on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
dn2_1    | 2023-03-10 22:42:05,648 [Thread-47] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl received success reply of StartLeaderElectionRequest from follower:e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn2_1    | 2023-03-10 22:42:05,700 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: change Leader from 3892a4e1-c878-42af-adb7-db66a90d61f4 to null at term 2 for updateCurrentTerm
dn2_1    | 2023-03-10 22:42:05,700 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: changes role from    LEADER to FOLLOWER at term 2 for StepDownReason:HIGHER_TERM
dn2_1    | 2023-03-10 22:42:05,700 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl
dn2_1    | 2023-03-10 22:42:05,701 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575->e3e4587c-aa42-4e86-ae9a-d3e448365275-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575->e3e4587c-aa42-4e86-ae9a-d3e448365275-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
dn2_1    | 2023-03-10 22:42:05,705 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575->e78c5ce1-46ab-4889-a0cd-5903ae46614d-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575->e78c5ce1-46ab-4889-a0cd-5903ae46614d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
dn2_1    | 2023-03-10 22:42:05,706 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl] INFO impl.PendingRequests: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-PendingRequests: sendNotLeaderResponses
dn2_1    | 2023-03-10 22:42:05,707 [grpc-default-executor-0] INFO server.GrpcLogAppender: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575->e3e4587c-aa42-4e86-ae9a-d3e448365275-AppendLogResponseHandler: follower responses appendEntries COMPLETED
dn2_1    | 2023-03-10 22:42:05,711 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-LeaderStateImpl] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState
dn2_1    | 2023-03-10 22:42:05,712 [grpc-default-executor-0] INFO leader.FollowerInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575->e3e4587c-aa42-4e86-ae9a-d3e448365275: nextIndex: updateUnconditionally 1 -> 0
dn2_1    | 2023-03-10 22:42:05,851 [grpc-default-executor-0] INFO server.GrpcLogAppender: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575->e78c5ce1-46ab-4889-a0cd-5903ae46614d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
dn2_1    | 2023-03-10 22:42:05,851 [grpc-default-executor-0] INFO leader.FollowerInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575->e78c5ce1-46ab-4889-a0cd-5903ae46614d: nextIndex: updateUnconditionally 1 -> 0
dn2_1    | 2023-03-10 22:42:05,873 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-CBC13A60F575, 2, (t:1, i:0))
dn2_1    | 2023-03-10 22:42:05,873 [grpc-default-executor-0] INFO impl.VoteContext: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FOLLOWER: accept ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: our priority 0 <= candidate's priority 1
dn2_1    | 2023-03-10 22:42:05,874 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn2_1    | 2023-03-10 22:42:05,874 [grpc-default-executor-0] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState
dn2_1    | 2023-03-10 22:42:05,874 [grpc-default-executor-0] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState
dn2_1    | 2023-03-10 22:42:05,874 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState] INFO impl.FollowerState: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-FollowerState was interrupted: {}
dn2_1    | java.lang.InterruptedException: sleep interrupted
dn2_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn2_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn2_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn2_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn2_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn2_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn2_1    | 2023-03-10 22:42:05,880 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-3892a4e1-c878-42af-adb7-db66a90d61f4#0:OK-t2. Peer's state: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575:t2, leader=null, voted=e78c5ce1-46ab-4889-a0cd-5903ae46614d, raftlog=3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLog:OPENED:c0, conf=0: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:42:06,089 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CBC13A60F575 with new leaderId: e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn2_1    | 2023-03-10 22:42:06,090 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: change Leader from null to e78c5ce1-46ab-4889-a0cd-5903ae46614d at term 2 for appendEntries, leader elected after 389ms
dn2_1    | 2023-03-10 22:42:06,199 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575: set configuration 1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:42:06,209 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn2_1    | 2023-03-10 22:42:06,229 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_inprogress_0 to /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_0-0
dn2_1    | 2023-03-10 22:42:06,265 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-CBC13A60F575-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_inprogress_1
dn2_1    | 2023-03-10 22:42:09,679 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: receive requestVote(ELECTION, 1a6d358d-6662-4447-914c-d709a67ff716, group-5B98FDC36F00, 3, (t:0, i:0))
dn2_1    | 2023-03-10 22:42:09,682 [grpc-default-executor-0] INFO impl.VoteContext: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FOLLOWER: reject ELECTION from 1a6d358d-6662-4447-914c-d709a67ff716: our priority 1 > candidate's priority 0
dn2_1    | 2023-03-10 22:42:09,682 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:1a6d358d-6662-4447-914c-d709a67ff716
dn2_1    | 2023-03-10 22:42:09,682 [grpc-default-executor-0] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState
dn2_1    | 2023-03-10 22:42:09,682 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState was interrupted: {}
dn2_1    | java.lang.InterruptedException: sleep interrupted
dn2_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn2_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn2_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn2_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn2_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn2_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn2_1    | 2023-03-10 22:42:09,684 [grpc-default-executor-0] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState
dn2_1    | 2023-03-10 22:42:09,689 [grpc-default-executor-0] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00 replies to ELECTION vote request: 1a6d358d-6662-4447-914c-d709a67ff716<-3892a4e1-c878-42af-adb7-db66a90d61f4#0:FAIL-t3. Peer's state: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00:t3, leader=null, voted=null, raftlog=3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:42:14,825 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5140571260ns, electionTimeout:5139ms
dn2_1    | 2023-03-10 22:42:14,825 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState
dn2_1    | 2023-03-10 22:42:14,825 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn2_1    | 2023-03-10 22:42:14,826 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2023-03-10 22:42:14,826 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4
dn2_1    | 2023-03-10 22:42:14,829 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4 ELECTION round 0: submit vote requests at term 4 for -1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:42:14,846 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn2_1    | 2023-03-10 22:42:14,849 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO impl.LeaderElection:   Response 0: 3892a4e1-c878-42af-adb7-db66a90d61f4<-178b30e1-b74d-4f4d-a142-c930eee71455#0:OK-t4
dn2_1    | 2023-03-10 22:42:14,849 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO impl.LeaderElection: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4 ELECTION round 0: result PASSED
dn2_1    | 2023-03-10 22:42:14,857 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: shutdown 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4
dn2_1    | 2023-03-10 22:42:14,857 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn2_1    | 2023-03-10 22:42:14,857 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5B98FDC36F00 with new leaderId: 3892a4e1-c878-42af-adb7-db66a90d61f4
dn2_1    | 2023-03-10 22:42:14,859 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn2_1    | 2023-03-10 22:42:14,870 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: change Leader from null to 3892a4e1-c878-42af-adb7-db66a90d61f4 at term 4 for becomeLeader, leader elected after 16419ms
dn2_1    | 2023-03-10 22:42:14,870 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2023-03-10 22:42:14,902 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2023-03-10 22:41:46,024 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn3_1    | 2023-03-10 22:41:46,025 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn3_1    | 2023-03-10 22:41:46,462 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 1a6d358d-6662-4447-914c-d709a67ff716
dn3_1    | 2023-03-10 22:41:46,629 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 1a6d358d-6662-4447-914c-d709a67ff716: start RPC server
dn3_1    | 2023-03-10 22:41:46,683 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 1a6d358d-6662-4447-914c-d709a67ff716: GrpcService started, listening on 9856
dn3_1    | 2023-03-10 22:41:46,704 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 1a6d358d-6662-4447-914c-d709a67ff716: GrpcService started, listening on 9857
dn3_1    | 2023-03-10 22:41:46,722 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 1a6d358d-6662-4447-914c-d709a67ff716: GrpcService started, listening on 9858
dn3_1    | 2023-03-10 22:41:46,754 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1a6d358d-6662-4447-914c-d709a67ff716 is started using port 9858 for RATIS
dn3_1    | 2023-03-10 22:41:46,754 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1a6d358d-6662-4447-914c-d709a67ff716 is started using port 9857 for RATIS_ADMIN
dn3_1    | 2023-03-10 22:41:46,754 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1a6d358d-6662-4447-914c-d709a67ff716 is started using port 9856 for RATIS_SERVER
dn3_1    | 2023-03-10 22:41:46,768 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$309/0x00000008404bec40@186806db] INFO util.JvmPauseMonitor: JvmPauseMonitor-1a6d358d-6662-4447-914c-d709a67ff716: Started
dn3_1    | 2023-03-10 22:41:51,024 [Command processor thread] INFO server.RaftServer: 1a6d358d-6662-4447-914c-d709a67ff716: addNew group-0049FBBC23B3:[e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0] returns group-0049FBBC23B3:java.util.concurrent.CompletableFuture@4391230e[Not completed]
dn3_1    | 2023-03-10 22:41:51,291 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716: new RaftServerImpl for group-0049FBBC23B3:[e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0] with ContainerStateMachine:uninitialized
dn3_1    | 2023-03-10 22:41:51,322 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2023-03-10 22:41:51,351 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2023-03-10 22:41:51,359 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2023-03-10 22:41:51,361 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2023-03-10 22:41:51,361 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2023-03-10 22:41:51,362 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2023-03-10 22:41:51,369 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2023-03-10 22:41:51,400 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: ConfigurationManager, init=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn3_1    | 2023-03-10 22:41:51,421 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2023-03-10 22:41:51,487 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2023-03-10 22:41:51,502 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2023-03-10 22:41:51,508 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3 does not exist. Creating ...
dn3_1    | 2023-03-10 22:41:51,577 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3/in_use.lock acquired by nodename 7@55d4a52ef53d
dn3_1    | 2023-03-10 22:41:51,783 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3 has been successfully formatted.
dn3_1    | 2023-03-10 22:41:51,840 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn3_1    | 2023-03-10 22:41:51,927 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-0049FBBC23B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2023-03-10 22:41:51,993 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2023-03-10 22:41:52,023 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2023-03-10 22:41:52,091 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2023-03-10 22:41:52,099 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2023-03-10 22:41:52,376 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2023-03-10 22:41:52,457 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2023-03-10 22:41:52,498 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2023-03-10 22:41:52,618 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3
dn3_1    | 2023-03-10 22:41:52,625 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn3_1    | 2023-03-10 22:41:52,629 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2023-03-10 22:41:52,642 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2023-03-10 22:41:52,662 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2023-03-10 22:41:52,671 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2023-03-10 22:41:52,701 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2023-03-10 22:41:52,705 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2023-03-10 22:41:52,708 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2023-03-10 22:41:52,785 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2023-03-10 22:41:52,829 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2023-03-10 22:41:52,882 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn3_1    | 2023-03-10 22:41:52,894 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2023-03-10 22:41:52,932 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2023-03-10 22:41:52,945 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2023-03-10 22:41:52,946 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2023-03-10 22:41:52,948 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2023-03-10 22:41:52,953 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2023-03-10 22:41:52,958 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2023-03-10 22:41:53,259 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: start as a follower, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn3_1    | 2023-03-10 22:41:53,280 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn3_1    | 2023-03-10 22:41:53,295 [pool-22-thread-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState
dn3_1    | 2023-03-10 22:41:53,373 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0049FBBC23B3,id=1a6d358d-6662-4447-914c-d709a67ff716
dn3_1    | 2023-03-10 22:41:53,474 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3
dn3_1    | 2023-03-10 22:41:57,014 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716: new RaftServerImpl for group-5B98FDC36F00:[178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
dn3_1    | 2023-03-10 22:41:57,021 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2023-03-10 22:41:57,022 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2023-03-10 22:41:57,022 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2023-03-10 22:41:57,023 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2023-03-10 22:41:57,023 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2023-03-10 22:41:57,024 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2023-03-10 22:41:57,024 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2023-03-10 22:41:57,024 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: ConfigurationManager, init=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
dn3_1    | 2023-03-10 22:41:57,025 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2023-03-10 22:41:57,031 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2023-03-10 22:41:57,032 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2023-03-10 22:41:57,037 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00 does not exist. Creating ...
dn3_1    | 2023-03-10 22:41:57,044 [grpc-default-executor-0] INFO server.RaftServer: 1a6d358d-6662-4447-914c-d709a67ff716: addNew group-5B98FDC36F00:[178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0] returns group-5B98FDC36F00:java.util.concurrent.CompletableFuture@2ceadfe1[Not completed]
dn3_1    | 2023-03-10 22:41:57,059 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00/in_use.lock acquired by nodename 7@55d4a52ef53d
dn3_1    | 2023-03-10 22:41:57,077 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00 has been successfully formatted.
dn3_1    | 2023-03-10 22:41:57,079 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-5B98FDC36F00: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2023-03-10 22:41:57,079 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2023-03-10 22:41:57,085 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2023-03-10 22:41:57,080 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn3_1    | 2023-03-10 22:41:57,129 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2023-03-10 22:41:57,154 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2023-03-10 22:41:57,155 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2023-03-10 22:41:57,155 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2023-03-10 22:41:57,172 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2023-03-10 22:41:57,172 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00
dn3_1    | 2023-03-10 22:41:57,173 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn3_1    | 2023-03-10 22:41:57,174 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2023-03-10 22:41:57,178 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2023-03-10 22:42:14,902 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn2_1    | 2023-03-10 22:42:14,905 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn2_1    | 2023-03-10 22:42:14,925 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2023-03-10 22:42:14,925 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2023-03-10 22:42:14,926 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2023-03-10 22:42:14,926 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn2_1    | 2023-03-10 22:42:14,926 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn2_1    | 2023-03-10 22:42:14,927 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2023-03-10 22:42:14,927 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn2_1    | 2023-03-10 22:42:14,932 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn2_1    | 2023-03-10 22:42:14,932 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2023-03-10 22:42:14,933 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2023-03-10 22:42:14,934 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn2_1    | 2023-03-10 22:42:14,937 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2023-03-10 22:42:14,940 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn2_1    | 2023-03-10 22:42:14,941 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn2_1    | 2023-03-10 22:42:14,941 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2023-03-10 22:42:14,941 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2023-03-10 22:42:14,945 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO impl.RoleInfo: 3892a4e1-c878-42af-adb7-db66a90d61f4: start 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderStateImpl
dn2_1    | 2023-03-10 22:42:14,949 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLogWorker: Starting segment from index:0
dn2_1    | 2023-03-10 22:42:14,957 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00/current/log_inprogress_0
dn2_1    | 2023-03-10 22:42:14,992 [3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServer$Division: 3892a4e1-c878-42af-adb7-db66a90d61f4@group-5B98FDC36F00: set configuration 0: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn2_1    | 2023-03-10 22:42:37,898 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
om1_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1    | 2023-03-10 22:40:55,336 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1    | /************************************************************
om1_1    | STARTUP_MSG: Starting OzoneManager
om1_1    | STARTUP_MSG:   host = 5c449b62415d/10.9.0.11
om1_1    | STARTUP_MSG:   args = [--init]
om1_1    | STARTUP_MSG:   version = 1.2.1
om1_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar
om1_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:28Z
om1_1    | STARTUP_MSG:   java = 11.0.13
om1_1    | ************************************************************/
om1_1    | 2023-03-10 22:40:55,396 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1    | 2023-03-10 22:41:08,522 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om1_1    | 2023-03-10 22:41:09,475 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1    | 2023-03-10 22:41:09,483 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om1: om1
om1_1    | 2023-03-10 22:41:09,570 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2023-03-10 22:41:16,763 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:18,764 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:20,794 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:22,795 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:24,797 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:26,802 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:28,803 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:30,805 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:32,807 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:34,809 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:36,811 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:38,819 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2023-03-10 22:41:40,820 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
dn5_1    | 2023-03-10 22:41:46,662 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 178b30e1-b74d-4f4d-a142-c930eee71455: GrpcService started, listening on 9858
dn5_1    | 2023-03-10 22:41:46,724 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 178b30e1-b74d-4f4d-a142-c930eee71455 is started using port 9858 for RATIS
dn5_1    | 2023-03-10 22:41:46,725 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 178b30e1-b74d-4f4d-a142-c930eee71455 is started using port 9857 for RATIS_ADMIN
dn5_1    | 2023-03-10 22:41:46,725 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 178b30e1-b74d-4f4d-a142-c930eee71455 is started using port 9856 for RATIS_SERVER
dn5_1    | 2023-03-10 22:41:46,727 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$309/0x00000008404bec40@3290d006] INFO util.JvmPauseMonitor: JvmPauseMonitor-178b30e1-b74d-4f4d-a142-c930eee71455: Started
dn5_1    | 2023-03-10 22:41:50,660 [Command processor thread] INFO server.RaftServer: 178b30e1-b74d-4f4d-a142-c930eee71455: addNew group-8E287CACCC68:[178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1] returns group-8E287CACCC68:java.util.concurrent.CompletableFuture@42eeea1[Not completed]
dn5_1    | 2023-03-10 22:41:50,813 [pool-22-thread-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455: new RaftServerImpl for group-8E287CACCC68:[178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1] with ContainerStateMachine:uninitialized
dn5_1    | 2023-03-10 22:41:50,814 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn5_1    | 2023-03-10 22:41:50,815 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2023-03-10 22:41:50,824 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2023-03-10 22:41:50,824 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2023-03-10 22:41:50,824 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2023-03-10 22:41:50,824 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2023-03-10 22:41:50,827 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2023-03-10 22:41:50,845 [pool-22-thread-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68: ConfigurationManager, init=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn5_1    | 2023-03-10 22:41:50,848 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2023-03-10 22:41:50,905 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn5_1    | 2023-03-10 22:41:50,906 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2023-03-10 22:41:50,911 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b1358d3e-7575-4e13-af6d-8e287caccc68 does not exist. Creating ...
dn5_1    | 2023-03-10 22:41:50,933 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b1358d3e-7575-4e13-af6d-8e287caccc68/in_use.lock acquired by nodename 7@c4f9b517a239
dn5_1    | 2023-03-10 22:41:51,007 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b1358d3e-7575-4e13-af6d-8e287caccc68 has been successfully formatted.
dn5_1    | 2023-03-10 22:41:51,056 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn5_1    | 2023-03-10 22:41:51,171 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-8E287CACCC68: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn5_1    | 2023-03-10 22:41:51,216 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2023-03-10 22:41:51,318 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2023-03-10 22:41:51,359 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2023-03-10 22:41:51,401 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2023-03-10 22:41:51,857 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2023-03-10 22:41:52,011 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2023-03-10 22:41:52,028 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2023-03-10 22:41:52,076 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b1358d3e-7575-4e13-af6d-8e287caccc68
dn5_1    | 2023-03-10 22:41:52,100 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn5_1    | 2023-03-10 22:41:52,121 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2023-03-10 22:41:52,122 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2023-03-10 22:41:52,131 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2023-03-10 22:41:52,135 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn5_1    | 2023-03-10 22:41:52,151 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2023-03-10 22:41:52,164 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2023-03-10 22:41:52,169 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn5_1    | 2023-03-10 22:41:52,319 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2023-03-10 22:41:52,339 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2023-03-10 22:41:52,391 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn5_1    | 2023-03-10 22:41:52,421 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn5_1    | 2023-03-10 22:41:52,427 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2023-03-10 22:41:52,461 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2023-03-10 22:41:52,472 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn5_1    | 2023-03-10 22:41:52,475 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
om1_1    | 2023-03-10 22:41:42,824 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5c449b62415d/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-d8d7fcf8-04e0-4b43-9ae2-eefeb561683b;layoutVersion=0
om1_1    | 2023-03-10 22:41:45,717 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1    | /************************************************************
om1_1    | SHUTDOWN_MSG: Shutting down OzoneManager at 5c449b62415d/10.9.0.11
om1_1    | ************************************************************/
om1_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1    | 2023-03-10 22:41:53,544 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1    | /************************************************************
om1_1    | STARTUP_MSG: Starting OzoneManager
om1_1    | STARTUP_MSG:   host = 5c449b62415d/10.9.0.11
om1_1    | STARTUP_MSG:   args = [--]
om1_1    | STARTUP_MSG:   version = 1.2.1
dn4_1    | 2023-03-10 22:41:58,565 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1 ELECTION round 0: result REJECTED
dn4_1    | 2023-03-10 22:41:58,567 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
dn4_1    | 2023-03-10 22:41:58,567 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1
dn4_1    | 2023-03-10 22:41:58,569 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection1] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState
dn4_1    | 2023-03-10 22:41:58,741 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3.
dn4_1    | 2023-03-10 22:41:58,774 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d: new RaftServerImpl for group-CBC13A60F575:[e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0] with ContainerStateMachine:uninitialized
dn4_1    | 2023-03-10 22:41:58,803 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2023-03-10 22:41:58,804 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2023-03-10 22:41:58,804 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2023-03-10 22:41:58,804 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2023-03-10 22:41:58,804 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2023-03-10 22:41:58,806 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2023-03-10 22:41:58,806 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2023-03-10 22:41:58,806 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: ConfigurationManager, init=-1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn4_1    | 2023-03-10 22:41:58,807 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2023-03-10 22:41:58,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2023-03-10 22:41:58,813 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2023-03-10 22:41:58,813 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575 does not exist. Creating ...
dn4_1    | 2023-03-10 22:41:58,849 [Command processor thread] INFO server.RaftServer: e78c5ce1-46ab-4889-a0cd-5903ae46614d: addNew group-CBC13A60F575:[e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0] returns group-CBC13A60F575:java.util.concurrent.CompletableFuture@3dff7a7a[Not completed]
dn4_1    | 2023-03-10 22:41:58,881 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/in_use.lock acquired by nodename 6@70399d395b30
dn4_1    | 2023-03-10 22:41:58,903 [grpc-default-executor-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: receive requestVote(ELECTION, 1a6d358d-6662-4447-914c-d709a67ff716, group-0049FBBC23B3, 1, (t:0, i:0))
dn4_1    | 2023-03-10 22:41:58,907 [grpc-default-executor-1] INFO impl.VoteContext: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FOLLOWER: reject ELECTION from 1a6d358d-6662-4447-914c-d709a67ff716: already has voted for e78c5ce1-46ab-4889-a0cd-5903ae46614d at current term 1
dn4_1    | 2023-03-10 22:41:58,916 [grpc-default-executor-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3 replies to ELECTION vote request: 1a6d358d-6662-4447-914c-d709a67ff716<-e78c5ce1-46ab-4889-a0cd-5903ae46614d#0:FAIL-t1. Peer's state: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3:t1, leader=null, voted=e78c5ce1-46ab-4889-a0cd-5903ae46614d, raftlog=e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn4_1    | 2023-03-10 22:41:58,935 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575 has been successfully formatted.
dn4_1    | 2023-03-10 22:41:58,937 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-CBC13A60F575: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn4_1    | 2023-03-10 22:41:58,940 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2023-03-10 22:41:58,940 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2023-03-10 22:41:58,940 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2023-03-10 22:41:58,946 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2023-03-10 22:41:58,947 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2023-03-10 22:41:58,947 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn4_1    | 2023-03-10 22:41:58,948 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2023-03-10 22:41:58,948 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575
dn4_1    | 2023-03-10 22:41:58,948 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn4_1    | 2023-03-10 22:41:58,948 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2023-03-10 22:41:58,949 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2023-03-10 22:41:58,949 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2023-03-10 22:41:52,484 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn5_1    | 2023-03-10 22:41:52,490 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2023-03-10 22:41:52,904 [pool-22-thread-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68: start as a follower, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1], old=null
dn5_1    | 2023-03-10 22:41:52,914 [pool-22-thread-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn5_1    | 2023-03-10 22:41:52,933 [pool-22-thread-1] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-FollowerState
dn5_1    | 2023-03-10 22:41:52,981 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E287CACCC68,id=178b30e1-b74d-4f4d-a142-c930eee71455
dn5_1    | 2023-03-10 22:41:53,114 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=b1358d3e-7575-4e13-af6d-8e287caccc68
dn5_1    | 2023-03-10 22:41:53,120 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=b1358d3e-7575-4e13-af6d-8e287caccc68.
dn5_1    | 2023-03-10 22:41:53,122 [Command processor thread] INFO server.RaftServer: 178b30e1-b74d-4f4d-a142-c930eee71455: addNew group-5B98FDC36F00:[178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0] returns group-5B98FDC36F00:java.util.concurrent.CompletableFuture@3264b53[Not completed]
dn5_1    | 2023-03-10 22:41:53,189 [pool-22-thread-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455: new RaftServerImpl for group-5B98FDC36F00:[178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0] with ContainerStateMachine:uninitialized
dn5_1    | 2023-03-10 22:41:53,211 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn5_1    | 2023-03-10 22:41:53,216 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2023-03-10 22:41:53,217 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2023-03-10 22:41:53,218 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2023-03-10 22:41:53,223 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2023-03-10 22:41:53,223 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2023-03-10 22:41:53,223 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2023-03-10 22:41:53,223 [pool-22-thread-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: ConfigurationManager, init=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn5_1    | 2023-03-10 22:41:53,224 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2023-03-10 22:41:53,224 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn5_1    | 2023-03-10 22:41:53,231 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2023-03-10 22:41:53,237 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00 does not exist. Creating ...
dn5_1    | 2023-03-10 22:41:53,240 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00/in_use.lock acquired by nodename 7@c4f9b517a239
dn5_1    | 2023-03-10 22:41:53,269 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00 has been successfully formatted.
dn5_1    | 2023-03-10 22:41:53,270 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-5B98FDC36F00: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn5_1    | 2023-03-10 22:41:53,270 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn5_1    | 2023-03-10 22:41:53,317 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2023-03-10 22:41:53,329 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2023-03-10 22:41:53,330 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2023-03-10 22:41:53,330 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2023-03-10 22:41:53,330 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2023-03-10 22:41:53,339 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2023-03-10 22:41:53,339 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2023-03-10 22:41:53,343 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00
dn5_1    | 2023-03-10 22:41:53,345 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn5_1    | 2023-03-10 22:41:53,345 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2023-03-10 22:41:53,345 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2023-03-10 22:41:53,347 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2023-03-10 22:41:53,352 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn5_1    | 2023-03-10 22:41:53,352 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2023-03-10 22:41:53,353 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2023-03-10 22:41:53,353 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2023-03-10 22:41:57,321 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/in_use.lock acquired by nodename 7@f8784d6ff179
dn1_1    | 2023-03-10 22:41:57,338 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575 has been successfully formatted.
dn1_1    | 2023-03-10 22:41:57,344 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn1_1    | 2023-03-10 22:41:57,346 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-CBC13A60F575: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2023-03-10 22:41:57,363 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2023-03-10 22:41:57,364 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2023-03-10 22:41:57,365 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2023-03-10 22:41:57,373 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2023-03-10 22:41:57,377 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2023-03-10 22:41:57,398 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2023-03-10 22:41:57,415 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2023-03-10 22:41:57,415 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575
dn1_1    | 2023-03-10 22:41:57,415 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn1_1    | 2023-03-10 22:41:57,416 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2023-03-10 22:41:57,416 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2023-03-10 22:41:57,416 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2023-03-10 22:41:57,416 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2023-03-10 22:41:57,416 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2023-03-10 22:41:57,417 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2023-03-10 22:41:57,417 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2023-03-10 22:41:57,418 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2023-03-10 22:41:57,434 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2023-03-10 22:41:57,447 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn1_1    | 2023-03-10 22:41:57,451 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2023-03-10 22:41:57,470 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2023-03-10 22:41:57,470 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2023-03-10 22:41:57,489 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2023-03-10 22:41:57,490 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2023-03-10 22:41:57,490 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2023-03-10 22:41:57,490 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2023-03-10 22:41:57,491 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: start as a follower, conf=-1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn1_1    | 2023-03-10 22:41:57,558 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn1_1    | 2023-03-10 22:41:57,561 [pool-22-thread-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FollowerState
dn1_1    | 2023-03-10 22:41:57,589 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: receive requestVote(ELECTION, 3892a4e1-c878-42af-adb7-db66a90d61f4, group-CBC13A60F575, 1, (t:0, i:0))
dn1_1    | 2023-03-10 22:41:57,629 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CBC13A60F575,id=e3e4587c-aa42-4e86-ae9a-d3e448365275
dn1_1    | 2023-03-10 22:41:57,708 [grpc-default-executor-1] INFO impl.VoteContext: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FOLLOWER: accept ELECTION from 3892a4e1-c878-42af-adb7-db66a90d61f4: our priority 0 <= candidate's priority 0
dn1_1    | 2023-03-10 22:41:57,708 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:3892a4e1-c878-42af-adb7-db66a90d61f4
dn1_1    | 2023-03-10 22:41:57,709 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FollowerState
dn1_1    | 2023-03-10 22:41:57,766 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FollowerState
dn1_1    | 2023-03-10 22:41:57,766 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FollowerState] INFO impl.FollowerState: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FollowerState was interrupted: {}
dn1_1    | java.lang.InterruptedException: sleep interrupted
dn1_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn1_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn1_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn1_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn1_1    | 2023-03-10 22:41:57,930 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575 replies to ELECTION vote request: 3892a4e1-c878-42af-adb7-db66a90d61f4<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:OK-t1. Peer's state: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575:t1, leader=null, voted=3892a4e1-c878-42af-adb7-db66a90d61f4, raftlog=e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLog:OPENED:c-1, conf=-1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn1_1    | 2023-03-10 22:41:58,481 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-0049FBBC23B3, 1, (t:0, i:0))
dn1_1    | 2023-03-10 22:41:58,482 [grpc-default-executor-1] INFO impl.VoteContext: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FOLLOWER: reject ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: our priority 1 > candidate's priority 0
dn1_1    | 2023-03-10 22:41:58,482 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn1_1    | 2023-03-10 22:41:58,483 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:41:58,483 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState was interrupted: {}
dn1_1    | java.lang.InterruptedException: sleep interrupted
dn1_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn1_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn4_1    | 2023-03-10 22:41:58,952 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2023-03-10 22:41:58,963 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn4_1    | 2023-03-10 22:41:58,966 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2023-03-10 22:41:58,937 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn4_1    | 2023-03-10 22:41:58,972 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2023-03-10 22:41:59,023 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2023-03-10 22:41:59,069 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2023-03-10 22:41:59,070 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn4_1    | 2023-03-10 22:41:59,070 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn4_1    | 2023-03-10 22:41:59,099 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2023-03-10 22:41:59,099 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2023-03-10 22:41:59,100 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2023-03-10 22:41:59,100 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2023-03-10 22:41:59,100 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn4_1    | 2023-03-10 22:41:59,109 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2023-03-10 22:41:59,111 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: start as a follower, conf=-1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0], old=null
dn4_1    | 2023-03-10 22:41:59,118 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn4_1    | 2023-03-10 22:41:59,118 [pool-22-thread-1] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-FollowerState
dn4_1    | 2023-03-10 22:41:59,119 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CBC13A60F575,id=e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn4_1    | 2023-03-10 22:41:59,185 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575
dn4_1    | 2023-03-10 22:41:59,788 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575.
dn4_1    | 2023-03-10 22:41:59,789 [Command processor thread] INFO server.RaftServer: e78c5ce1-46ab-4889-a0cd-5903ae46614d: addNew group-D98E5419B7A9:[e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1] returns group-D98E5419B7A9:java.util.concurrent.CompletableFuture@676e4fbc[Not completed]
dn4_1    | 2023-03-10 22:41:59,825 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d: new RaftServerImpl for group-D98E5419B7A9:[e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1] with ContainerStateMachine:uninitialized
dn4_1    | 2023-03-10 22:41:59,825 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2023-03-10 22:41:59,825 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2023-03-10 22:41:59,826 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2023-03-10 22:41:59,826 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2023-03-10 22:41:59,826 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2023-03-10 22:41:59,826 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2023-03-10 22:41:59,826 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2023-03-10 22:41:59,826 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9: ConfigurationManager, init=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn4_1    | 2023-03-10 22:41:59,827 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2023-03-10 22:41:59,827 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2023-03-10 22:41:59,827 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2023-03-10 22:41:59,827 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8581ae3d-c50a-4a49-9d70-d98e5419b7a9 does not exist. Creating ...
dn4_1    | 2023-03-10 22:41:59,833 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8581ae3d-c50a-4a49-9d70-d98e5419b7a9/in_use.lock acquired by nodename 6@70399d395b30
dn4_1    | 2023-03-10 22:41:59,843 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8581ae3d-c50a-4a49-9d70-d98e5419b7a9 has been successfully formatted.
dn4_1    | 2023-03-10 22:41:59,845 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-D98E5419B7A9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn4_1    | 2023-03-10 22:41:59,846 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2023-03-10 22:41:59,847 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2023-03-10 22:41:59,848 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2023-03-10 22:41:59,850 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2023-03-10 22:41:59,852 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2023-03-10 22:41:59,853 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn4_1    | 2023-03-10 22:41:59,855 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2023-03-10 22:41:53,358 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2023-03-10 22:41:53,362 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2023-03-10 22:41:53,365 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn5_1    | 2023-03-10 22:41:53,368 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn5_1    | 2023-03-10 22:41:53,392 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2023-03-10 22:41:53,393 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2023-03-10 22:41:53,397 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn5_1    | 2023-03-10 22:41:53,397 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn5_1    | 2023-03-10 22:41:53,397 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn5_1    | 2023-03-10 22:41:53,398 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2023-03-10 22:41:53,399 [pool-22-thread-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: start as a follower, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn5_1    | 2023-03-10 22:41:53,402 [pool-22-thread-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn5_1    | 2023-03-10 22:41:53,403 [pool-22-thread-1] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState
dn5_1    | 2023-03-10 22:41:53,410 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5B98FDC36F00,id=178b30e1-b74d-4f4d-a142-c930eee71455
dn5_1    | 2023-03-10 22:41:53,411 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00
dn5_1    | 2023-03-10 22:41:55,986 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$309/0x00000008404bec40@3290d006] WARN util.JvmPauseMonitor: JvmPauseMonitor-178b30e1-b74d-4f4d-a142-c930eee71455: Detected pause in JVM or host machine (eg GC): pause of approximately 138286226ns.
dn5_1    | GC pool 'ParNew' had collection(s): count=1 time=309ms
dn5_1    | 2023-03-10 22:41:57,983 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-FollowerState] INFO impl.FollowerState: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5057448630ns, electionTimeout:5036ms
dn5_1    | 2023-03-10 22:41:57,984 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-FollowerState] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: shutdown 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-FollowerState
dn5_1    | 2023-03-10 22:41:57,985 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-FollowerState] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn5_1    | 2023-03-10 22:41:57,988 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2023-03-10 22:41:57,988 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-FollowerState] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1
dn5_1    | 2023-03-10 22:41:58,110 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO impl.LeaderElection: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1], old=null
dn5_1    | 2023-03-10 22:41:58,111 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO impl.LeaderElection: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1 ELECTION round 0: result PASSED (term=1)
dn5_1    | 2023-03-10 22:41:58,117 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: shutdown 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1
dn5_1    | 2023-03-10 22:41:58,123 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn5_1    | 2023-03-10 22:41:58,127 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8E287CACCC68 with new leaderId: 178b30e1-b74d-4f4d-a142-c930eee71455
dn5_1    | 2023-03-10 22:41:58,173 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68: change Leader from null to 178b30e1-b74d-4f4d-a142-c930eee71455 at term 1 for becomeLeader, leader elected after 6925ms
dn5_1    | 2023-03-10 22:41:58,174 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn5_1    | 2023-03-10 22:41:58,263 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn5_1    | 2023-03-10 22:41:58,350 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2023-03-10 22:41:58,363 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn5_1    | 2023-03-10 22:41:58,431 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn5_1    | 2023-03-10 22:41:58,436 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn5_1    | 2023-03-10 22:41:58,466 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn5_1    | 2023-03-10 22:41:58,531 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2023-03-10 22:41:58,577 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn5_1    | 2023-03-10 22:41:58,590 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5187425566ns, electionTimeout:5124ms
om1_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar
om1_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:28Z
om1_1    | STARTUP_MSG:   java = 11.0.13
om1_1    | ************************************************************/
om1_1    | 2023-03-10 22:41:53,619 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1    | 2023-03-10 22:42:01,740 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om1_1    | 2023-03-10 22:42:01,917 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1    | 2023-03-10 22:42:01,917 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om1: om1
om1_1    | 2023-03-10 22:42:01,920 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2023-03-10 22:42:01,996 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om1_1    | 2023-03-10 22:42:02,885 [main] INFO reflections.Reflections: Reflections took 766 ms to scan 1 urls, producing 95 keys and 258 values [using 2 cores]
om1_1    | 2023-03-10 22:42:02,953 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2023-03-10 22:42:07,402 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2023-03-10 22:42:07,994 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1    | 2023-03-10 22:42:07,998 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1    | 2023-03-10 22:42:08,764 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om1_1    | 2023-03-10 22:42:08,940 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1    | 2023-03-10 22:42:08,941 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1    | 2023-03-10 22:42:09,170 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1    | 2023-03-10 22:42:10,099 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1    | 2023-03-10 22:42:10,281 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1    | 2023-03-10 22:42:10,494 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om1:9872, om3:9872, om2:9872
om1_1    | 2023-03-10 22:42:10,565 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1    | 2023-03-10 22:42:10,690 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1    | 2023-03-10 22:42:11,230 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1    | 2023-03-10 22:42:11,231 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1    | 2023-03-10 22:42:11,232 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1    | 2023-03-10 22:42:11,232 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1    | 2023-03-10 22:42:11,232 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1    | 2023-03-10 22:42:11,240 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1    | 2023-03-10 22:42:11,251 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2023-03-10 22:42:11,275 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1    | 2023-03-10 22:42:11,275 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1    | 2023-03-10 22:42:12,446 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1    | 2023-03-10 22:42:12,460 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1    | 2023-03-10 22:42:12,461 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1    | 2023-03-10 22:42:12,495 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1    | 2023-03-10 22:42:12,525 [main] INFO server.RaftServer: om1: addNew group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@2b73bd6b[Not completed]
om1_1    | 2023-03-10 22:42:12,528 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1    | 2023-03-10 22:42:12,594 [pool-23-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1    | 2023-03-10 22:42:12,642 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1    | 2023-03-10 22:42:12,646 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1    | 2023-03-10 22:42:12,646 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1    | 2023-03-10 22:42:12,646 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1    | 2023-03-10 22:42:12,647 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1    | 2023-03-10 22:42:12,647 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1    | 2023-03-10 22:42:12,648 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1    | 2023-03-10 22:42:12,675 [pool-23-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1    | 2023-03-10 22:42:12,684 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1    | 2023-03-10 22:42:12,729 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1    | 2023-03-10 22:42:12,730 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2023-03-10 22:41:59,856 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/8581ae3d-c50a-4a49-9d70-d98e5419b7a9
dn4_1    | 2023-03-10 22:41:59,856 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn4_1    | 2023-03-10 22:41:59,856 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2023-03-10 22:41:59,856 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2023-03-10 22:41:59,856 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn4_1    | 2023-03-10 22:41:59,856 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2023-03-10 22:41:59,846 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn4_1    | 2023-03-10 22:41:59,867 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn4_1    | 2023-03-10 22:41:59,867 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2023-03-10 22:41:59,867 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2023-03-10 22:41:59,872 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2023-03-10 22:41:59,879 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2023-03-10 22:41:59,894 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn4_1    | 2023-03-10 22:41:59,894 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn4_1    | 2023-03-10 22:41:59,920 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2023-03-10 22:41:59,920 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2023-03-10 22:41:59,921 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2023-03-10 22:41:59,921 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2023-03-10 22:41:59,921 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn4_1    | 2023-03-10 22:41:59,921 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2023-03-10 22:41:59,923 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9: start as a follower, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1], old=null
dn4_1    | 2023-03-10 22:41:59,929 [pool-22-thread-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn4_1    | 2023-03-10 22:41:59,930 [pool-22-thread-1] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-FollowerState
dn4_1    | 2023-03-10 22:41:59,969 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D98E5419B7A9,id=e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn4_1    | 2023-03-10 22:41:59,973 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=8581ae3d-c50a-4a49-9d70-d98e5419b7a9
dn4_1    | 2023-03-10 22:41:59,974 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=8581ae3d-c50a-4a49-9d70-d98e5419b7a9.
dn4_1    | 2023-03-10 22:42:00,154 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CBC13A60F575 with new leaderId: 3892a4e1-c878-42af-adb7-db66a90d61f4
dn4_1    | 2023-03-10 22:42:00,154 [grpc-default-executor-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: change Leader from null to 3892a4e1-c878-42af-adb7-db66a90d61f4 at term 1 for appendEntries, leader elected after 1214ms
dn4_1    | 2023-03-10 22:42:00,285 [grpc-default-executor-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: set configuration 0: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn4_1    | 2023-03-10 22:42:00,313 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker: Starting segment from index:0
dn4_1    | 2023-03-10 22:42:00,613 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_inprogress_0
dn4_1    | 2023-03-10 22:42:03,641 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5071696122ns, electionTimeout:5021ms
dn4_1    | 2023-03-10 22:42:03,641 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState
dn4_1    | 2023-03-10 22:42:03,642 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn4_1    | 2023-03-10 22:42:03,642 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2023-03-10 22:42:03,642 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2
dn4_1    | 2023-03-10 22:42:03,650 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn3_1    | 2023-03-10 22:41:57,178 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2023-03-10 22:41:57,178 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2023-03-10 22:41:57,179 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2023-03-10 22:41:57,179 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2023-03-10 22:41:57,182 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2023-03-10 22:41:57,183 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2023-03-10 22:41:57,199 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2023-03-10 22:41:57,224 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn3_1    | 2023-03-10 22:41:57,232 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2023-03-10 22:41:57,236 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2023-03-10 22:41:57,236 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2023-03-10 22:41:57,236 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2023-03-10 22:41:57,237 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2023-03-10 22:41:57,237 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2023-03-10 22:41:57,237 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2023-03-10 22:41:57,238 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: start as a follower, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn3_1    | 2023-03-10 22:41:57,238 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn3_1    | 2023-03-10 22:41:57,241 [pool-22-thread-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState
dn3_1    | 2023-03-10 22:41:57,243 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5B98FDC36F00,id=1a6d358d-6662-4447-914c-d709a67ff716
dn3_1    | 2023-03-10 22:41:58,251 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3.
dn3_1    | 2023-03-10 22:41:58,268 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716: new RaftServerImpl for group-5C511402A23E:[1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1] with ContainerStateMachine:uninitialized
dn3_1    | 2023-03-10 22:41:58,297 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2023-03-10 22:41:58,298 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2023-03-10 22:41:58,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2023-03-10 22:41:58,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2023-03-10 22:41:58,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2023-03-10 22:41:58,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2023-03-10 22:41:58,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2023-03-10 22:41:58,307 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E: ConfigurationManager, init=-1: [1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn3_1    | 2023-03-10 22:41:58,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2023-03-10 22:41:58,308 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2023-03-10 22:41:58,281 [Command processor thread] INFO server.RaftServer: 1a6d358d-6662-4447-914c-d709a67ff716: addNew group-5C511402A23E:[1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1] returns group-5C511402A23E:java.util.concurrent.CompletableFuture@275bd819[Not completed]
dn3_1    | 2023-03-10 22:41:58,310 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2023-03-10 22:41:58,310 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7572f4a9-8e86-407b-b624-5c511402a23e does not exist. Creating ...
dn3_1    | 2023-03-10 22:41:58,316 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7572f4a9-8e86-407b-b624-5c511402a23e/in_use.lock acquired by nodename 7@55d4a52ef53d
dn3_1    | 2023-03-10 22:41:58,328 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7572f4a9-8e86-407b-b624-5c511402a23e has been successfully formatted.
dn3_1    | 2023-03-10 22:41:58,328 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-5C511402A23E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2023-03-10 22:41:58,343 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2023-03-10 22:41:58,344 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2023-03-10 22:41:58,329 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn3_1    | 2023-03-10 22:41:58,344 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2023-03-10 22:41:58,344 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2023-03-10 22:41:58,345 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2023-03-10 22:41:58,355 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2023-03-10 22:41:58,356 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2023-03-10 22:42:03,756 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn4_1    | 2023-03-10 22:42:03,757 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2] INFO impl.LeaderElection:   Response 0: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t2
dn4_1    | 2023-03-10 22:42:03,757 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2 ELECTION round 0: result REJECTED
dn4_1    | 2023-03-10 22:42:03,761 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
dn4_1    | 2023-03-10 22:42:03,761 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2
dn4_1    | 2023-03-10 22:42:03,761 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection2] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState
dn4_1    | 2023-03-10 22:42:05,130 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-FollowerState] INFO impl.FollowerState: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5200617081ns, electionTimeout:5160ms
dn4_1    | 2023-03-10 22:42:05,131 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-FollowerState
dn4_1    | 2023-03-10 22:42:05,131 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-FollowerState] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn4_1    | 2023-03-10 22:42:05,132 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2023-03-10 22:42:05,132 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3
dn4_1    | 2023-03-10 22:42:05,140 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1], old=null
dn4_1    | 2023-03-10 22:42:05,141 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3 ELECTION round 0: result PASSED (term=1)
dn4_1    | 2023-03-10 22:42:05,141 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3
dn4_1    | 2023-03-10 22:42:05,141 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn4_1    | 2023-03-10 22:42:05,141 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D98E5419B7A9 with new leaderId: e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn4_1    | 2023-03-10 22:42:05,142 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9: change Leader from null to e78c5ce1-46ab-4889-a0cd-5903ae46614d at term 1 for becomeLeader, leader elected after 5295ms
dn4_1    | 2023-03-10 22:42:05,142 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn4_1    | 2023-03-10 22:42:05,148 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn4_1    | 2023-03-10 22:42:05,162 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2023-03-10 22:42:05,163 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn4_1    | 2023-03-10 22:42:05,196 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn4_1    | 2023-03-10 22:42:05,217 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn4_1    | 2023-03-10 22:42:05,218 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn4_1    | 2023-03-10 22:42:05,244 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2023-03-10 22:42:05,260 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn4_1    | 2023-03-10 22:42:05,271 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderStateImpl
dn4_1    | 2023-03-10 22:42:05,329 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-SegmentedRaftLogWorker: Starting segment from index:0
dn4_1    | 2023-03-10 22:42:05,335 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8581ae3d-c50a-4a49-9d70-d98e5419b7a9/current/log_inprogress_0
dn4_1    | 2023-03-10 22:42:05,351 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9-LeaderElection3] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-D98E5419B7A9: set configuration 0: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2023-03-10 22:42:05,610 [grpc-default-executor-1] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-FollowerState
dn4_1    | 2023-03-10 22:42:05,611 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-FollowerState] INFO impl.FollowerState: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-FollowerState was interrupted: {}
dn4_1    | java.lang.InterruptedException: sleep interrupted
dn4_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn4_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn4_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn4_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn4_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn4_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn4_1    | 2023-03-10 22:42:05,611 [grpc-default-executor-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn4_1    | 2023-03-10 22:42:05,613 [grpc-default-executor-1] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4
dn4_1    | 2023-03-10 22:42:05,628 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: change Leader from 3892a4e1-c878-42af-adb7-db66a90d61f4 to null at term 1 for ELECTION
dn4_1    | 2023-03-10 22:42:05,647 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for 0: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn4_1    | 2023-03-10 22:42:05,756 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn4_1    | 2023-03-10 22:42:05,757 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO impl.LeaderElection:   Response 0: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:OK-t2
dn4_1    | 2023-03-10 22:42:05,757 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4 ELECTION round 0: result PASSED
dn4_1    | 2023-03-10 22:42:05,757 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4
dn4_1    | 2023-03-10 22:42:05,781 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
dn4_1    | 2023-03-10 22:42:05,781 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CBC13A60F575 with new leaderId: e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn4_1    | 2023-03-10 22:42:05,781 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: change Leader from null to e78c5ce1-46ab-4889-a0cd-5903ae46614d at term 2 for becomeLeader, leader elected after 152ms
dn4_1    | 2023-03-10 22:42:05,784 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn4_1    | 2023-03-10 22:42:05,784 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2023-03-10 22:42:05,785 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn4_1    | 2023-03-10 22:42:05,785 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn4_1    | 2023-03-10 22:42:05,758 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e78c5ce1-46ab-4889-a0cd-5903ae46614d: Completed APPEND_ENTRIES, lastRequest: 3892a4e1-c878-42af-adb7-db66a90d61f4->e78c5ce1-46ab-4889-a0cd-5903ae46614d#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
dn4_1    | 2023-03-10 22:42:05,785 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn4_1    | 2023-03-10 22:42:05,783 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn4_1    | 2023-03-10 22:42:05,831 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn4_1    | 2023-03-10 22:42:05,831 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2023-03-10 22:42:05,833 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn4_1    | 2023-03-10 22:42:05,887 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn4_1    | 2023-03-10 22:42:05,893 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2023-03-10 22:42:05,896 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn4_1    | 2023-03-10 22:42:05,936 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn4_1    | 2023-03-10 22:42:05,936 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn4_1    | 2023-03-10 22:42:05,937 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2023-03-10 22:41:58,356 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/7572f4a9-8e86-407b-b624-5c511402a23e
dn3_1    | 2023-03-10 22:41:58,357 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn3_1    | 2023-03-10 22:41:58,360 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2023-03-10 22:41:58,361 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2023-03-10 22:41:58,361 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2023-03-10 22:41:58,361 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2023-03-10 22:41:58,361 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2023-03-10 22:41:58,361 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2023-03-10 22:41:58,362 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2023-03-10 22:41:58,364 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2023-03-10 22:41:58,371 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2023-03-10 22:41:58,371 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn3_1    | 2023-03-10 22:41:58,372 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2023-03-10 22:41:58,372 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2023-03-10 22:41:58,402 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2023-03-10 22:41:58,402 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2023-03-10 22:41:58,402 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2023-03-10 22:41:58,405 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2023-03-10 22:41:58,405 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2023-03-10 22:41:58,406 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E: start as a follower, conf=-1: [1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1], old=null
dn3_1    | 2023-03-10 22:41:58,412 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5117523157ns, electionTimeout:5079ms
dn3_1    | 2023-03-10 22:41:58,419 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState
dn3_1    | 2023-03-10 22:41:58,421 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn3_1    | 2023-03-10 22:41:58,424 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2023-03-10 22:41:58,431 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1
dn3_1    | 2023-03-10 22:41:58,432 [pool-22-thread-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn3_1    | 2023-03-10 22:41:58,436 [pool-22-thread-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-FollowerState
dn3_1    | 2023-03-10 22:41:58,443 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5C511402A23E,id=1a6d358d-6662-4447-914c-d709a67ff716
dn3_1    | 2023-03-10 22:41:58,497 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=7572f4a9-8e86-407b-b624-5c511402a23e
dn3_1    | 2023-03-10 22:41:58,509 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=7572f4a9-8e86-407b-b624-5c511402a23e.
dn3_1    | 2023-03-10 22:41:58,591 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn3_1    | 2023-03-10 22:41:58,616 [grpc-default-executor-0] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-0049FBBC23B3, 1, (t:0, i:0))
dn3_1    | 2023-03-10 22:41:58,639 [grpc-default-executor-0] INFO impl.VoteContext: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-CANDIDATE: reject ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: already has voted for 1a6d358d-6662-4447-914c-d709a67ff716 at current term 1
dn3_1    | 2023-03-10 22:41:58,652 [grpc-default-executor-0] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-1a6d358d-6662-4447-914c-d709a67ff716#0:FAIL-t1. Peer's state: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3:t1, leader=null, voted=1a6d358d-6662-4447-914c-d709a67ff716, raftlog=1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn3_1    | 2023-03-10 22:41:58,984 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn3_1    | 2023-03-10 22:41:59,041 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1] INFO impl.LeaderElection:   Response 0: 1a6d358d-6662-4447-914c-d709a67ff716<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t1
dn5_1    | 2023-03-10 22:41:58,600 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: shutdown 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState
dn5_1    | 2023-03-10 22:41:58,601 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn5_1    | 2023-03-10 22:41:58,601 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2023-03-10 22:41:58,601 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2
dn5_1    | 2023-03-10 22:41:58,646 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderStateImpl
dn5_1    | 2023-03-10 22:41:58,632 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn5_1    | 2023-03-10 22:41:58,892 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-SegmentedRaftLogWorker: Starting segment from index:0
dn5_1    | 2023-03-10 22:41:59,249 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-LeaderElection1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68: set configuration 0: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2023-03-10 22:41:59,338 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn5_1    | 2023-03-10 22:41:59,351 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection:   Response 0: 178b30e1-b74d-4f4d-a142-c930eee71455<-3892a4e1-c878-42af-adb7-db66a90d61f4#0:FAIL-t1
dn5_1    | 2023-03-10 22:41:59,352 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection:   Response 1: 178b30e1-b74d-4f4d-a142-c930eee71455<-1a6d358d-6662-4447-914c-d709a67ff716#0:OK-t1
dn5_1    | 2023-03-10 22:41:59,364 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2] INFO impl.LeaderElection: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2 ELECTION round 0: result REJECTED
dn5_1    | 2023-03-10 22:41:59,362 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00.
dn5_1    | 2023-03-10 22:41:59,381 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
dn5_1    | 2023-03-10 22:41:59,381 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: shutdown 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2
dn5_1    | 2023-03-10 22:41:59,383 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection2] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState
dn5_1    | 2023-03-10 22:41:59,765 [178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 178b30e1-b74d-4f4d-a142-c930eee71455@group-8E287CACCC68-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b1358d3e-7575-4e13-af6d-8e287caccc68/current/log_inprogress_0
dn5_1    | 2023-03-10 22:42:04,422 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5039601536ns, electionTimeout:5003ms
dn5_1    | 2023-03-10 22:42:04,423 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: shutdown 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState
dn5_1    | 2023-03-10 22:42:04,423 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn5_1    | 2023-03-10 22:42:04,423 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2023-03-10 22:42:04,423 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3
dn5_1    | 2023-03-10 22:42:04,501 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: receive requestVote(ELECTION, 1a6d358d-6662-4447-914c-d709a67ff716, group-5B98FDC36F00, 2, (t:0, i:0))
dn5_1    | 2023-03-10 22:42:04,517 [grpc-default-executor-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: receive requestVote(ELECTION, 3892a4e1-c878-42af-adb7-db66a90d61f4, group-5B98FDC36F00, 2, (t:0, i:0))
dn5_1    | 2023-03-10 22:42:04,527 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3] INFO impl.LeaderElection: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn5_1    | 2023-03-10 22:42:04,528 [grpc-default-executor-1] INFO impl.VoteContext: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-CANDIDATE: reject ELECTION from 3892a4e1-c878-42af-adb7-db66a90d61f4: already has voted for 178b30e1-b74d-4f4d-a142-c930eee71455 at current term 2
dn5_1    | 2023-03-10 22:42:04,573 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3] INFO impl.LeaderElection: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn5_1    | 2023-03-10 22:42:04,574 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3] INFO impl.LeaderElection:   Response 0: 178b30e1-b74d-4f4d-a142-c930eee71455<-3892a4e1-c878-42af-adb7-db66a90d61f4#0:FAIL-t2
dn5_1    | 2023-03-10 22:42:04,579 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3] INFO impl.LeaderElection: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3 ELECTION round 0: result REJECTED
om1_1    | 2023-03-10 22:42:12,733 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c does not exist. Creating ...
om1_1    | 2023-03-10 22:42:12,739 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1    | 2023-03-10 22:42:12,809 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 7@5c449b62415d
om1_1    | 2023-03-10 22:42:12,822 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1    | 2023-03-10 22:42:12,918 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c has been successfully formatted.
om1_1    | 2023-03-10 22:42:12,940 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1    | 2023-03-10 22:42:12,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1    | 2023-03-10 22:42:12,997 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1    | 2023-03-10 22:42:13,009 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2023-03-10 22:42:13,115 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1    | 2023-03-10 22:42:13,157 [Listener at om1/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om1_1    | 2023-03-10 22:42:13,161 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1    | 2023-03-10 22:42:13,173 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1    | 2023-03-10 22:42:13,203 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om1_1    | 2023-03-10 22:42:13,211 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1    | 2023-03-10 22:42:13,221 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1    | 2023-03-10 22:42:13,224 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1    | 2023-03-10 22:42:13,231 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1    | 2023-03-10 22:42:13,232 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1    | 2023-03-10 22:42:13,236 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1    | 2023-03-10 22:42:13,247 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1    | 2023-03-10 22:42:13,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1    | 2023-03-10 22:42:13,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1    | 2023-03-10 22:42:13,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1    | 2023-03-10 22:42:13,360 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1    | 2023-03-10 22:42:13,360 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1    | 2023-03-10 22:42:13,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1    | 2023-03-10 22:42:13,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1    | 2023-03-10 22:42:13,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1    | 2023-03-10 22:42:13,393 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1    | 2023-03-10 22:42:13,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1    | 2023-03-10 22:42:13,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1    | 2023-03-10 22:42:13,752 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1    | 2023-03-10 22:42:13,817 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1    | 2023-03-10 22:42:13,817 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1    | 2023-03-10 22:42:14,127 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/10.9.0.11:9862
om1_1    | 2023-03-10 22:42:14,128 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1    | 2023-03-10 22:42:14,142 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-D66704EFC61C: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1    | 2023-03-10 22:42:14,149 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1    | 2023-03-10 22:42:14,160 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-FollowerState
om1_1    | 2023-03-10 22:42:14,170 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om1
om1_1    | 2023-03-10 22:42:14,194 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1    | 2023-03-10 22:42:14,542 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1    | 2023-03-10 22:42:14,624 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1    | 2023-03-10 22:42:14,625 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$383/0x00000008404f9840@25791d40] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1    | 2023-03-10 22:42:14,811 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1    | 2023-03-10 22:42:14,813 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om1_1    | 2023-03-10 22:42:15,002 [Listener at om1/9862] INFO util.log: Logging initialized @28160ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1    | 2023-03-10 22:42:15,598 [Listener at om1/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om1_1    | 2023-03-10 22:42:15,613 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1    | 2023-03-10 22:42:15,627 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn1_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn1_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn1_1    | 2023-03-10 22:41:58,484 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:41:58,500 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t1. Peer's state: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3:t1, leader=null, voted=null, raftlog=e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn1_1    | 2023-03-10 22:41:58,635 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3.
dn1_1    | 2023-03-10 22:41:58,640 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275: new RaftServerImpl for group-D0B7AA0D159E:[e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1] with ContainerStateMachine:uninitialized
dn1_1    | 2023-03-10 22:41:58,648 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2023-03-10 22:41:58,648 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2023-03-10 22:41:58,648 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2023-03-10 22:41:58,649 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2023-03-10 22:41:58,653 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2023-03-10 22:41:58,648 [Command processor thread] INFO server.RaftServer: e3e4587c-aa42-4e86-ae9a-d3e448365275: addNew group-D0B7AA0D159E:[e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1] returns group-D0B7AA0D159E:java.util.concurrent.CompletableFuture@6354247f[Not completed]
dn1_1    | 2023-03-10 22:41:58,659 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2023-03-10 22:41:58,662 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2023-03-10 22:41:58,662 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E: ConfigurationManager, init=-1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn1_1    | 2023-03-10 22:41:58,662 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2023-03-10 22:41:58,664 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2023-03-10 22:41:58,666 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2023-03-10 22:41:58,666 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e does not exist. Creating ...
dn1_1    | 2023-03-10 22:41:58,673 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e/in_use.lock acquired by nodename 7@f8784d6ff179
dn1_1    | 2023-03-10 22:41:58,680 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e has been successfully formatted.
dn1_1    | 2023-03-10 22:41:58,683 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-D0B7AA0D159E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2023-03-10 22:41:58,683 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn1_1    | 2023-03-10 22:41:58,722 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2023-03-10 22:41:58,722 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2023-03-10 22:41:58,722 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2023-03-10 22:41:58,722 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2023-03-10 22:41:58,728 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2023-03-10 22:41:58,729 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2023-03-10 22:41:58,730 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2023-03-10 22:41:58,735 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e
dn1_1    | 2023-03-10 22:41:58,753 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn1_1    | 2023-03-10 22:41:58,754 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2023-03-10 22:41:58,763 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2023-03-10 22:41:58,764 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2023-03-10 22:41:58,764 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2023-03-10 22:41:58,764 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2023-03-10 22:41:58,765 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2023-03-10 22:41:58,766 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2023-03-10 22:41:58,767 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2023-03-10 22:41:58,784 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2023-03-10 22:41:58,788 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn1_1    | 2023-03-10 22:41:58,791 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2023-03-10 22:41:58,794 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2023-03-10 22:41:58,797 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om1_1    | 2023-03-10 22:42:15,629 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om1_1    | 2023-03-10 22:42:15,629 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om1_1    | 2023-03-10 22:42:15,629 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om1_1    | 2023-03-10 22:42:15,732 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1    | 2023-03-10 22:42:15,755 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
om1_1    | 2023-03-10 22:42:15,904 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1    | 2023-03-10 22:42:15,904 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1    | 2023-03-10 22:42:15,911 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1    | 2023-03-10 22:42:15,967 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@545d2560{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1    | 2023-03-10 22:42:15,967 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@d8835af{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar!/webapps/static,AVAILABLE}
om1_1    | 2023-03-10 22:42:17,000 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7a572ea0{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_1_jar-_-any-5182671030330266908/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar!/webapps/ozoneManager}
om1_1    | 2023-03-10 22:42:17,040 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@72c4a3aa{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1    | 2023-03-10 22:42:17,042 [Listener at om1/9862] INFO server.Server: Started @30200ms
om1_1    | 2023-03-10 22:42:17,047 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1    | 2023-03-10 22:42:17,048 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1    | 2023-03-10 22:42:17,053 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1    | 2023-03-10 22:42:17,076 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1    | 2023-03-10 22:42:17,110 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1    | 2023-03-10 22:42:17,174 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1    | 2023-03-10 22:42:17,232 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7de147e9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1    | 2023-03-10 22:42:19,228 [om1@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om1@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5068265870ns, electionTimeout:5043ms
om1_1    | 2023-03-10 22:42:19,229 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-FollowerState
om1_1    | 2023-03-10 22:42:19,229 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1    | 2023-03-10 22:42:19,232 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1    | 2023-03-10 22:42:19,232 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderElection1
om1_1    | 2023-03-10 22:42:19,248 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1    | 2023-03-10 22:42:20,924 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1    | 2023-03-10 22:42:20,925 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t1
om1_1    | 2023-03-10 22:42:20,925 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 ELECTION round 0: result PASSED
om1_1    | 2023-03-10 22:42:20,925 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-LeaderElection1
om1_1    | 2023-03-10 22:42:20,926 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om1_1    | 2023-03-10 22:42:20,926 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 7985ms
om1_1    | 2023-03-10 22:42:20,940 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1    | 2023-03-10 22:42:20,948 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1    | 2023-03-10 22:42:20,949 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1    | 2023-03-10 22:42:20,958 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1    | 2023-03-10 22:42:20,958 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1    | 2023-03-10 22:42:20,959 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1    | 2023-03-10 22:42:20,965 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1    | 2023-03-10 22:42:20,966 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1    | 2023-03-10 22:42:20,975 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1    | 2023-03-10 22:42:20,975 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2023-03-10 22:42:20,975 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1    | 2023-03-10 22:42:20,982 [om1@group-D66704EFC61C-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1    | 2023-03-10 22:42:20,982 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1    | 2023-03-10 22:42:20,982 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1    | 2023-03-10 22:42:20,987 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1    | 2023-03-10 22:42:20,987 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2023-03-10 22:41:58,797 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2023-03-10 22:42:05,957 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn4_1    | 2023-03-10 22:42:05,965 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2023-03-10 22:42:05,965 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn4_1    | 2023-03-10 22:42:05,965 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn4_1    | 2023-03-10 22:42:05,966 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn4_1    | 2023-03-10 22:42:05,966 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2023-03-10 22:42:05,975 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderStateImpl
dn4_1    | 2023-03-10 22:42:05,989 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn4_1    | 2023-03-10 22:42:06,019 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_inprogress_0 to /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_0-0
dn4_1    | 2023-03-10 22:42:06,032 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_inprogress_1
dn4_1    | 2023-03-10 22:42:06,033 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575-LeaderElection4] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-CBC13A60F575: set configuration 1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn4_1    | 2023-03-10 22:42:08,802 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5041102074ns, electionTimeout:5013ms
dn4_1    | 2023-03-10 22:42:08,803 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState
dn4_1    | 2023-03-10 22:42:08,803 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
dn4_1    | 2023-03-10 22:42:08,803 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2023-03-10 22:42:08,803 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5
dn4_1    | 2023-03-10 22:42:08,812 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn4_1    | 2023-03-10 22:42:08,845 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn4_1    | 2023-03-10 22:42:08,846 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5] INFO impl.LeaderElection:   Response 0: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t3
dn4_1    | 2023-03-10 22:42:08,847 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5 ELECTION round 0: result REJECTED
dn4_1    | 2023-03-10 22:42:08,847 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
dn4_1    | 2023-03-10 22:42:08,847 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5
dn4_1    | 2023-03-10 22:42:08,848 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection5] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState
dn4_1    | 2023-03-10 22:42:14,034 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5186096041ns, electionTimeout:5171ms
dn4_1    | 2023-03-10 22:42:14,034 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState
dn4_1    | 2023-03-10 22:42:14,034 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn4_1    | 2023-03-10 22:42:14,035 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2023-03-10 22:42:14,035 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6
dn4_1    | 2023-03-10 22:42:14,039 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn4_1    | 2023-03-10 22:42:14,151 [grpc-default-executor-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: receive requestVote(ELECTION, e3e4587c-aa42-4e86-ae9a-d3e448365275, group-0049FBBC23B3, 4, (t:0, i:0))
dn4_1    | 2023-03-10 22:42:14,151 [grpc-default-executor-1] INFO impl.VoteContext: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-CANDIDATE: reject ELECTION from e3e4587c-aa42-4e86-ae9a-d3e448365275: already has voted for e78c5ce1-46ab-4889-a0cd-5903ae46614d at current term 4
dn4_1    | 2023-03-10 22:42:14,151 [grpc-default-executor-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3 replies to ELECTION vote request: e3e4587c-aa42-4e86-ae9a-d3e448365275<-e78c5ce1-46ab-4889-a0cd-5903ae46614d#0:FAIL-t4. Peer's state: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3:t4, leader=null, voted=e78c5ce1-46ab-4889-a0cd-5903ae46614d, raftlog=e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn5_1    | 2023-03-10 22:42:04,580 [grpc-default-executor-1] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00 replies to ELECTION vote request: 3892a4e1-c878-42af-adb7-db66a90d61f4<-178b30e1-b74d-4f4d-a142-c930eee71455#0:FAIL-t2. Peer's state: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00:t2, leader=null, voted=178b30e1-b74d-4f4d-a142-c930eee71455, raftlog=178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn5_1    | 2023-03-10 22:42:04,593 [grpc-default-executor-0] INFO impl.VoteContext: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-CANDIDATE: reject ELECTION from 1a6d358d-6662-4447-914c-d709a67ff716: already has voted for 178b30e1-b74d-4f4d-a142-c930eee71455 at current term 2
dn5_1    | 2023-03-10 22:42:04,598 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00 replies to ELECTION vote request: 1a6d358d-6662-4447-914c-d709a67ff716<-178b30e1-b74d-4f4d-a142-c930eee71455#0:FAIL-t2. Peer's state: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00:t2, leader=null, voted=178b30e1-b74d-4f4d-a142-c930eee71455, raftlog=178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn5_1    | 2023-03-10 22:42:04,598 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
dn5_1    | 2023-03-10 22:42:04,603 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: shutdown 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3
dn5_1    | 2023-03-10 22:42:04,603 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-LeaderElection3] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState
dn5_1    | 2023-03-10 22:42:09,665 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: receive requestVote(ELECTION, 1a6d358d-6662-4447-914c-d709a67ff716, group-5B98FDC36F00, 3, (t:0, i:0))
dn5_1    | 2023-03-10 22:42:09,665 [grpc-default-executor-0] INFO impl.VoteContext: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FOLLOWER: accept ELECTION from 1a6d358d-6662-4447-914c-d709a67ff716: our priority 0 <= candidate's priority 0
dn5_1    | 2023-03-10 22:42:09,666 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:1a6d358d-6662-4447-914c-d709a67ff716
dn5_1    | 2023-03-10 22:42:09,666 [grpc-default-executor-0] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: shutdown 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState
dn5_1    | 2023-03-10 22:42:09,666 [grpc-default-executor-0] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState
dn5_1    | 2023-03-10 22:42:09,666 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState was interrupted: {}
dn5_1    | java.lang.InterruptedException: sleep interrupted
dn5_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn5_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn5_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn5_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn5_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn5_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn5_1    | 2023-03-10 22:42:09,687 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00 replies to ELECTION vote request: 1a6d358d-6662-4447-914c-d709a67ff716<-178b30e1-b74d-4f4d-a142-c930eee71455#0:OK-t3. Peer's state: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00:t3, leader=null, voted=1a6d358d-6662-4447-914c-d709a67ff716, raftlog=178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn5_1    | 2023-03-10 22:42:14,834 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: receive requestVote(ELECTION, 3892a4e1-c878-42af-adb7-db66a90d61f4, group-5B98FDC36F00, 4, (t:0, i:0))
dn5_1    | 2023-03-10 22:42:14,835 [grpc-default-executor-0] INFO impl.VoteContext: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FOLLOWER: accept ELECTION from 3892a4e1-c878-42af-adb7-db66a90d61f4: our priority 0 <= candidate's priority 1
dn5_1    | 2023-03-10 22:42:14,835 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:3892a4e1-c878-42af-adb7-db66a90d61f4
dn5_1    | 2023-03-10 22:42:14,835 [grpc-default-executor-0] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: shutdown 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState
dn5_1    | 2023-03-10 22:42:14,835 [grpc-default-executor-0] INFO impl.RoleInfo: 178b30e1-b74d-4f4d-a142-c930eee71455: start 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState
dn5_1    | 2023-03-10 22:42:14,835 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-FollowerState was interrupted: {}
dn5_1    | java.lang.InterruptedException: sleep interrupted
dn5_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn5_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn5_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn5_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn5_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn5_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om1_1    | 2023-03-10 22:42:20,987 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1    | 2023-03-10 22:42:20,987 [om1@group-D66704EFC61C-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1    | 2023-03-10 22:42:20,987 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1    | 2023-03-10 22:42:20,987 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1    | 2023-03-10 22:42:20,997 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderStateImpl
om1_1    | 2023-03-10 22:42:21,028 [om1@group-D66704EFC61C-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: Starting segment from index:0
om1_1    | 2023-03-10 22:42:21,201 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2023-03-10 22:42:21,825 [om1@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_0
om1_1    | 2023-03-10 22:42:22,080 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: receive requestVote(ELECTION, om3, group-D66704EFC61C, 1, (t:0, i:~))
om1_1    | 2023-03-10 22:42:22,083 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-D66704EFC61C-LEADER: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1    | 2023-03-10 22:42:22,098 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-D66704EFC61C:t1, leader=om1, voted=om1, raftlog=om1@group-D66704EFC61C-SegmentedRaftLog:OPENED:c0, conf=0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2023-03-10 22:42:22,187 [om1@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1    | [id: "om1"
om1_1    | address: "om1:9872"
om1_1    | , id: "om3"
om1_1    | address: "om3:9872"
om1_1    | , id: "om2"
om1_1    | address: "om2:9872"
om1_1    | ]
om1_1    | 2023-03-10 22:42:28,568 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:old1-volume for user:hadoop
om1_1    | 2023-03-10 22:42:44,863 [qtp1526901124-43] INFO utils.DBCheckpointServlet: Received request to obtain DB checkpoint snapshot
om1_1    | 2023-03-10 22:42:44,915 [qtp1526901124-43] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1678488164866 in 47 milliseconds
om1_1    | 2023-03-10 22:42:44,968 [qtp1526901124-43] INFO utils.DBCheckpointServlet: Time taken to write the checkpoint to response output stream: 50 milliseconds
om1_1    | 2023-03-10 22:42:44,968 [qtp1526901124-43] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1678488164866
om1_1    | 2023-03-10 22:42:51,781 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:old1-bucket in volume:s3v
om1_1    | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1    | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om1_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:248)
om1_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1    | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | 2023-03-10 22:42:14,305 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn4_1    | 2023-03-10 22:42:14,305 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6] INFO impl.LeaderElection:   Response 0: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t4
dn4_1    | 2023-03-10 22:42:14,305 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6] INFO impl.LeaderElection:   Response 1: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-1a6d358d-6662-4447-914c-d709a67ff716#0:FAIL-t4
dn4_1    | 2023-03-10 22:42:14,305 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6] INFO impl.LeaderElection: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6 ELECTION round 0: result REJECTED
dn4_1    | 2023-03-10 22:42:14,305 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
dn4_1    | 2023-03-10 22:42:14,305 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: shutdown e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6
dn4_1    | 2023-03-10 22:42:14,305 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-LeaderElection6] INFO impl.RoleInfo: e78c5ce1-46ab-4889-a0cd-5903ae46614d: start e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-FollowerState
dn4_1    | 2023-03-10 22:42:14,327 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0049FBBC23B3 with new leaderId: e3e4587c-aa42-4e86-ae9a-d3e448365275
dn4_1    | 2023-03-10 22:42:14,327 [grpc-default-executor-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: change Leader from null to e3e4587c-aa42-4e86-ae9a-d3e448365275 at term 4 for appendEntries, leader elected after 22437ms
dn4_1    | 2023-03-10 22:42:14,424 [grpc-default-executor-1] INFO server.RaftServer$Division: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3: set configuration 0: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn4_1    | 2023-03-10 22:42:14,427 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-SegmentedRaftLogWorker: Starting segment from index:0
dn4_1    | 2023-03-10 22:42:14,431 [e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e78c5ce1-46ab-4889-a0cd-5903ae46614d@group-0049FBBC23B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3/current/log_inprogress_0
dn4_1    | 2023-03-10 22:42:47,962 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn3_1    | 2023-03-10 22:41:59,041 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1 ELECTION round 0: result REJECTED
dn3_1    | 2023-03-10 22:41:59,056 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
dn3_1    | 2023-03-10 22:41:59,056 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1
dn3_1    | 2023-03-10 22:41:59,077 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-LeaderElection1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState
dn3_1    | 2023-03-10 22:41:59,033 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: receive requestVote(ELECTION, 178b30e1-b74d-4f4d-a142-c930eee71455, group-5B98FDC36F00, 1, (t:0, i:0))
dn3_1    | 2023-03-10 22:41:59,109 [grpc-default-executor-1] INFO impl.VoteContext: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FOLLOWER: accept ELECTION from 178b30e1-b74d-4f4d-a142-c930eee71455: our priority 0 <= candidate's priority 0
dn3_1    | 2023-03-10 22:41:59,110 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:178b30e1-b74d-4f4d-a142-c930eee71455
dn3_1    | 2023-03-10 22:41:59,113 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState
dn3_1    | 2023-03-10 22:41:59,118 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState was interrupted: {}
dn3_1    | java.lang.InterruptedException: sleep interrupted
dn3_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn3_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn3_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn3_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn3_1    | 2023-03-10 22:41:59,126 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState
dn3_1    | 2023-03-10 22:41:59,131 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00 replies to ELECTION vote request: 178b30e1-b74d-4f4d-a142-c930eee71455<-1a6d358d-6662-4447-914c-d709a67ff716#0:OK-t1. Peer's state: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00:t1, leader=null, voted=178b30e1-b74d-4f4d-a142-c930eee71455, raftlog=1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn3_1    | 2023-03-10 22:42:03,663 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-FollowerState] INFO impl.FollowerState: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5227513419ns, electionTimeout:5150ms
dn3_1    | 2023-03-10 22:42:03,664 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-FollowerState] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-FollowerState
dn3_1    | 2023-03-10 22:42:03,664 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-FollowerState] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn3_1    | 2023-03-10 22:42:03,665 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2023-03-10 22:42:03,665 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-FollowerState] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2
dn3_1    | 2023-03-10 22:42:03,668 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1], old=null
dn3_1    | 2023-03-10 22:42:03,669 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2 ELECTION round 0: result PASSED (term=1)
dn3_1    | 2023-03-10 22:42:03,669 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2
dn3_1    | 2023-03-10 22:42:03,669 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn3_1    | 2023-03-10 22:42:03,669 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5C511402A23E with new leaderId: 1a6d358d-6662-4447-914c-d709a67ff716
dn3_1    | 2023-03-10 22:42:03,671 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E: change Leader from null to 1a6d358d-6662-4447-914c-d709a67ff716 at term 1 for becomeLeader, leader elected after 5327ms
dn3_1    | 2023-03-10 22:42:03,671 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn3_1    | 2023-03-10 22:42:03,700 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-0049FBBC23B3, 2, (t:0, i:0))
dn3_1    | 2023-03-10 22:42:03,700 [grpc-default-executor-1] INFO impl.VoteContext: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FOLLOWER: accept ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: our priority 0 <= candidate's priority 0
dn3_1    | 2023-03-10 22:42:03,700 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn3_1    | 2023-03-10 22:42:03,700 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState
dn3_1    | 2023-03-10 22:42:03,700 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState was interrupted: {}
dn3_1    | java.lang.InterruptedException: sleep interrupted
dn3_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn3_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn3_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn3_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn3_1    | 2023-03-10 22:42:03,701 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState
dn3_1    | 2023-03-10 22:42:03,739 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-1a6d358d-6662-4447-914c-d709a67ff716#0:OK-t2. Peer's state: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3:t2, leader=null, voted=e78c5ce1-46ab-4889-a0cd-5903ae46614d, raftlog=1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn3_1    | 2023-03-10 22:42:03,743 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2023-03-10 22:42:03,785 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2023-03-10 22:42:03,791 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn3_1    | 2023-03-10 22:42:03,834 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2023-03-10 22:42:03,834 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2023-03-10 22:42:03,836 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2023-03-10 22:42:03,873 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2023-03-10 22:42:03,893 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn3_1    | 2023-03-10 22:42:03,897 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderStateImpl
dn3_1    | 2023-03-10 22:42:04,031 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-SegmentedRaftLogWorker: Starting segment from index:0
dn3_1    | 2023-03-10 22:42:04,217 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-LeaderElection2] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E: set configuration 0: [1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2023-03-10 22:42:04,221 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5089769692ns, electionTimeout:5089ms
dn3_1    | 2023-03-10 22:42:04,223 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState
dn3_1    | 2023-03-10 22:42:04,223 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn3_1    | 2023-03-10 22:42:04,223 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2023-03-10 22:42:04,223 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3
dn3_1    | 2023-03-10 22:42:04,236 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn3_1    | 2023-03-10 22:42:04,435 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn3_1    | 2023-03-10 22:42:04,435 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3] INFO impl.LeaderElection:   Response 0: 1a6d358d-6662-4447-914c-d709a67ff716<-3892a4e1-c878-42af-adb7-db66a90d61f4#0:FAIL-t2
dn3_1    | 2023-03-10 22:42:04,435 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3 ELECTION round 0: result REJECTED
dn3_1    | 2023-03-10 22:42:04,435 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
dn3_1    | 2023-03-10 22:42:04,436 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3
dn3_1    | 2023-03-10 22:42:04,436 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection3] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState
dn3_1    | 2023-03-10 22:42:04,438 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: receive requestVote(ELECTION, 3892a4e1-c878-42af-adb7-db66a90d61f4, group-5B98FDC36F00, 2, (t:0, i:0))
dn3_1    | 2023-03-10 22:42:04,459 [grpc-default-executor-1] INFO impl.VoteContext: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FOLLOWER: reject ELECTION from 3892a4e1-c878-42af-adb7-db66a90d61f4: already has voted for 1a6d358d-6662-4447-914c-d709a67ff716 at current term 2
dn3_1    | 2023-03-10 22:42:04,459 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00 replies to ELECTION vote request: 3892a4e1-c878-42af-adb7-db66a90d61f4<-1a6d358d-6662-4447-914c-d709a67ff716#0:FAIL-t2. Peer's state: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00:t2, leader=null, voted=1a6d358d-6662-4447-914c-d709a67ff716, raftlog=1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn3_1    | 2023-03-10 22:42:04,613 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: receive requestVote(ELECTION, 178b30e1-b74d-4f4d-a142-c930eee71455, group-5B98FDC36F00, 2, (t:0, i:0))
dn3_1    | 2023-03-10 22:42:04,614 [grpc-default-executor-1] INFO impl.VoteContext: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FOLLOWER: reject ELECTION from 178b30e1-b74d-4f4d-a142-c930eee71455: already has voted for 1a6d358d-6662-4447-914c-d709a67ff716 at current term 2
dn3_1    | 2023-03-10 22:42:04,614 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00 replies to ELECTION vote request: 178b30e1-b74d-4f4d-a142-c930eee71455<-1a6d358d-6662-4447-914c-d709a67ff716#0:FAIL-t2. Peer's state: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00:t2, leader=null, voted=1a6d358d-6662-4447-914c-d709a67ff716, raftlog=1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn3_1    | 2023-03-10 22:42:04,764 [1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-5C511402A23E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7572f4a9-8e86-407b-b624-5c511402a23e/current/log_inprogress_0
dn3_1    | 2023-03-10 22:42:08,837 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-0049FBBC23B3, 3, (t:0, i:0))
dn3_1    | 2023-03-10 22:42:08,840 [grpc-default-executor-1] INFO impl.VoteContext: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FOLLOWER: accept ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: our priority 0 <= candidate's priority 0
dn3_1    | 2023-03-10 22:42:08,841 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn3_1    | 2023-03-10 22:42:08,841 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState
dn3_1    | 2023-03-10 22:42:08,841 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState was interrupted: {}
dn3_1    | java.lang.InterruptedException: sleep interrupted
dn3_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn3_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn3_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn3_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn3_1    | 2023-03-10 22:42:08,845 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState
dn3_1    | 2023-03-10 22:42:08,851 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-1a6d358d-6662-4447-914c-d709a67ff716#0:OK-t3. Peer's state: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3:t3, leader=null, voted=e78c5ce1-46ab-4889-a0cd-5903ae46614d, raftlog=1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn3_1    | 2023-03-10 22:42:09,645 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5208757420ns, electionTimeout:5162ms
dn3_1    | 2023-03-10 22:42:09,645 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState
dn3_1    | 2023-03-10 22:42:09,645 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
dn3_1    | 2023-03-10 22:42:09,646 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2023-03-10 22:42:09,646 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4
dn3_1    | 2023-03-10 22:42:09,655 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4 ELECTION round 0: submit vote requests at term 3 for -1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn3_1    | 2023-03-10 22:42:09,707 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn3_1    | 2023-03-10 22:42:09,710 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4] INFO impl.LeaderElection:   Response 0: 1a6d358d-6662-4447-914c-d709a67ff716<-178b30e1-b74d-4f4d-a142-c930eee71455#0:OK-t3
dn3_1    | 2023-03-10 22:42:09,710 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4] INFO impl.LeaderElection:   Response 1: 1a6d358d-6662-4447-914c-d709a67ff716<-3892a4e1-c878-42af-adb7-db66a90d61f4#0:FAIL-t3
dn3_1    | 2023-03-10 22:42:09,711 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4] INFO impl.LeaderElection: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4 ELECTION round 0: result REJECTED
dn1_1    | 2023-03-10 22:41:58,798 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2023-03-10 22:41:58,798 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2023-03-10 22:41:58,799 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2023-03-10 22:41:58,809 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E: start as a follower, conf=-1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1], old=null
dn1_1    | 2023-03-10 22:41:58,817 [pool-22-thread-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn1_1    | 2023-03-10 22:41:58,818 [pool-22-thread-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-FollowerState
dn1_1    | 2023-03-10 22:41:58,824 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D0B7AA0D159E,id=e3e4587c-aa42-4e86-ae9a-d3e448365275
dn1_1    | 2023-03-10 22:41:58,885 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e
dn1_1    | 2023-03-10 22:41:58,890 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e.
dn1_1    | 2023-03-10 22:41:58,919 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: receive requestVote(ELECTION, 1a6d358d-6662-4447-914c-d709a67ff716, group-0049FBBC23B3, 1, (t:0, i:0))
dn1_1    | 2023-03-10 22:41:58,929 [grpc-default-executor-1] INFO impl.VoteContext: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FOLLOWER: reject ELECTION from 1a6d358d-6662-4447-914c-d709a67ff716: our priority 1 > candidate's priority 0
dn1_1    | 2023-03-10 22:41:58,931 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:1a6d358d-6662-4447-914c-d709a67ff716
dn1_1    | 2023-03-10 22:41:58,931 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:41:58,931 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState was interrupted: {}
dn1_1    | java.lang.InterruptedException: sleep interrupted
dn1_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn1_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn1_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn1_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn1_1    | 2023-03-10 22:41:58,949 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:41:58,952 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3 replies to ELECTION vote request: 1a6d358d-6662-4447-914c-d709a67ff716<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t1. Peer's state: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3:t1, leader=null, voted=null, raftlog=e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn1_1    | 2023-03-10 22:42:00,100 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CBC13A60F575 with new leaderId: 3892a4e1-c878-42af-adb7-db66a90d61f4
dn1_1    | 2023-03-10 22:42:00,100 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: change Leader from null to 3892a4e1-c878-42af-adb7-db66a90d61f4 at term 1 for appendEntries, leader elected after 2736ms
dn1_1    | 2023-03-10 22:42:00,295 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: set configuration 0: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn1_1    | 2023-03-10 22:42:00,351 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker: Starting segment from index:0
dn1_1    | 2023-03-10 22:42:00,694 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_inprogress_0
dn1_1    | 2023-03-10 22:42:03,719 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-0049FBBC23B3, 2, (t:0, i:0))
dn1_1    | 2023-03-10 22:42:03,719 [grpc-default-executor-1] INFO impl.VoteContext: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FOLLOWER: reject ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: our priority 1 > candidate's priority 0
dn1_1    | 2023-03-10 22:42:03,719 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn1_1    | 2023-03-10 22:42:03,719 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:42:03,720 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:42:03,720 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState was interrupted: {}
dn1_1    | java.lang.InterruptedException: sleep interrupted
dn1_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn1_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn1_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn1_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn3_1    | 2023-03-10 22:42:09,711 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
dn3_1    | 2023-03-10 22:42:09,711 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4
dn3_1    | 2023-03-10 22:42:09,711 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-LeaderElection4] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState
dn3_1    | 2023-03-10 22:42:13,977 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: receive requestVote(ELECTION, e3e4587c-aa42-4e86-ae9a-d3e448365275, group-0049FBBC23B3, 4, (t:0, i:0))
dn3_1    | 2023-03-10 22:42:13,977 [grpc-default-executor-1] INFO impl.VoteContext: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FOLLOWER: accept ELECTION from e3e4587c-aa42-4e86-ae9a-d3e448365275: our priority 0 <= candidate's priority 1
dn3_1    | 2023-03-10 22:42:13,978 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:e3e4587c-aa42-4e86-ae9a-d3e448365275
dn3_1    | 2023-03-10 22:42:13,978 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState
dn3_1    | 2023-03-10 22:42:13,978 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState
dn3_1    | 2023-03-10 22:42:13,978 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FollowerState was interrupted: {}
dn3_1    | java.lang.InterruptedException: sleep interrupted
dn3_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn3_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn3_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn3_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn3_1    | 2023-03-10 22:42:13,988 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3 replies to ELECTION vote request: e3e4587c-aa42-4e86-ae9a-d3e448365275<-1a6d358d-6662-4447-914c-d709a67ff716#0:OK-t4. Peer's state: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3:t4, leader=null, voted=e3e4587c-aa42-4e86-ae9a-d3e448365275, raftlog=1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn3_1    | 2023-03-10 22:42:14,043 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-0049FBBC23B3, 4, (t:0, i:0))
dn3_1    | 2023-03-10 22:42:14,044 [grpc-default-executor-1] INFO impl.VoteContext: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-FOLLOWER: reject ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: already has voted for e3e4587c-aa42-4e86-ae9a-d3e448365275 at current term 4
dn3_1    | 2023-03-10 22:42:14,044 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-1a6d358d-6662-4447-914c-d709a67ff716#0:FAIL-t4. Peer's state: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3:t4, leader=null, voted=e3e4587c-aa42-4e86-ae9a-d3e448365275, raftlog=1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn3_1    | 2023-03-10 22:42:14,391 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0049FBBC23B3 with new leaderId: e3e4587c-aa42-4e86-ae9a-d3e448365275
dn3_1    | 2023-03-10 22:42:14,391 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: change Leader from null to e3e4587c-aa42-4e86-ae9a-d3e448365275 at term 4 for appendEntries, leader elected after 22423ms
dn3_1    | 2023-03-10 22:42:14,462 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3: set configuration 0: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn3_1    | 2023-03-10 22:42:14,467 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLogWorker: Starting segment from index:0
dn3_1    | 2023-03-10 22:42:14,471 [1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-0049FBBC23B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3/current/log_inprogress_0
dn3_1    | 2023-03-10 22:42:14,875 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: receive requestVote(ELECTION, 3892a4e1-c878-42af-adb7-db66a90d61f4, group-5B98FDC36F00, 4, (t:0, i:0))
dn3_1    | 2023-03-10 22:42:14,876 [grpc-default-executor-1] INFO impl.VoteContext: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FOLLOWER: accept ELECTION from 3892a4e1-c878-42af-adb7-db66a90d61f4: our priority 0 <= candidate's priority 1
dn3_1    | 2023-03-10 22:42:14,876 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:3892a4e1-c878-42af-adb7-db66a90d61f4
dn3_1    | 2023-03-10 22:42:14,876 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: shutdown 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState
dn3_1    | 2023-03-10 22:42:14,876 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState] INFO impl.FollowerState: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState was interrupted: {}
dn3_1    | java.lang.InterruptedException: sleep interrupted
dn3_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn3_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn3_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn3_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn3_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn3_1    | 2023-03-10 22:42:14,877 [grpc-default-executor-1] INFO impl.RoleInfo: 1a6d358d-6662-4447-914c-d709a67ff716: start 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-FollowerState
dn3_1    | 2023-03-10 22:42:14,880 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00 replies to ELECTION vote request: 3892a4e1-c878-42af-adb7-db66a90d61f4<-1a6d358d-6662-4447-914c-d709a67ff716#0:OK-t4. Peer's state: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00:t4, leader=null, voted=3892a4e1-c878-42af-adb7-db66a90d61f4, raftlog=1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn3_1    | 2023-03-10 22:42:15,079 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5B98FDC36F00 with new leaderId: 3892a4e1-c878-42af-adb7-db66a90d61f4
dn3_1    | 2023-03-10 22:42:15,079 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: change Leader from null to 3892a4e1-c878-42af-adb7-db66a90d61f4 at term 4 for appendEntries, leader elected after 17999ms
dn3_1    | 2023-03-10 22:42:15,102 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00: set configuration 0: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn3_1    | 2023-03-10 22:42:15,102 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLogWorker: Starting segment from index:0
dn3_1    | 2023-03-10 22:42:15,120 [1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1a6d358d-6662-4447-914c-d709a67ff716@group-5B98FDC36F00-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00/current/log_inprogress_0
dn3_1    | 2023-03-10 22:42:38,043 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn3_1    | 2023-03-10 22:42:47,774 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn1_1    | 2023-03-10 22:42:03,725 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t2. Peer's state: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3:t2, leader=null, voted=null, raftlog=e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn1_1    | 2023-03-10 22:42:03,928 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-FollowerState] INFO impl.FollowerState: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5109860685ns, electionTimeout:5089ms
dn1_1    | 2023-03-10 22:42:03,928 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-FollowerState] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-FollowerState
dn1_1    | 2023-03-10 22:42:03,929 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-FollowerState] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn1_1    | 2023-03-10 22:42:03,932 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2023-03-10 22:42:03,932 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-FollowerState] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1
dn1_1    | 2023-03-10 22:42:03,938 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO impl.LeaderElection: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1], old=null
dn1_1    | 2023-03-10 22:42:03,946 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO impl.LeaderElection: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
dn1_1    | 2023-03-10 22:42:03,947 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1
dn1_1    | 2023-03-10 22:42:03,947 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn1_1    | 2023-03-10 22:42:03,948 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D0B7AA0D159E with new leaderId: e3e4587c-aa42-4e86-ae9a-d3e448365275
dn1_1    | 2023-03-10 22:42:03,948 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn1_1    | 2023-03-10 22:42:03,956 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E: change Leader from null to e3e4587c-aa42-4e86-ae9a-d3e448365275 at term 1 for becomeLeader, leader elected after 5264ms
dn1_1    | 2023-03-10 22:42:03,966 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn1_1    | 2023-03-10 22:42:03,987 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2023-03-10 22:42:03,993 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn1_1    | 2023-03-10 22:42:04,038 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn1_1    | 2023-03-10 22:42:04,039 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn1_1    | 2023-03-10 22:42:04,045 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn1_1    | 2023-03-10 22:42:04,058 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2023-03-10 22:42:04,063 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn1_1    | 2023-03-10 22:42:04,073 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderStateImpl
dn1_1    | 2023-03-10 22:42:04,088 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-SegmentedRaftLogWorker: Starting segment from index:0
dn1_1    | 2023-03-10 22:42:04,098 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e/current/log_inprogress_0
dn1_1    | 2023-03-10 22:42:04,118 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E-LeaderElection1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-D0B7AA0D159E: set configuration 0: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2023-03-10 22:42:05,704 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e3e4587c-aa42-4e86-ae9a-d3e448365275: Completed APPEND_ENTRIES, lastRequest: 3892a4e1-c878-42af-adb7-db66a90d61f4->e3e4587c-aa42-4e86-ae9a-d3e448365275#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
dn1_1    | 2023-03-10 22:42:05,723 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-CBC13A60F575, 2, (t:1, i:0))
dn1_1    | 2023-03-10 22:42:05,724 [grpc-default-executor-1] INFO impl.VoteContext: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FOLLOWER: accept ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: our priority 0 <= candidate's priority 1
dn1_1    | 2023-03-10 22:42:05,724 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: change Leader from 3892a4e1-c878-42af-adb7-db66a90d61f4 to null at term 2 for updateCurrentTerm
dn1_1    | 2023-03-10 22:42:05,724 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn1_1    | 2023-03-10 22:42:05,725 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FollowerState
dn1_1    | 2023-03-10 22:42:05,725 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FollowerState] INFO impl.FollowerState: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FollowerState was interrupted: {}
dn1_1    | java.lang.InterruptedException: sleep interrupted
dn1_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn1_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn1_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn1_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn1_1    | 2023-03-10 22:42:05,726 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-FollowerState
dn1_1    | 2023-03-10 22:42:05,732 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:OK-t2. Peer's state: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575:t2, leader=null, voted=e78c5ce1-46ab-4889-a0cd-5903ae46614d, raftlog=e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLog:OPENED:c0, conf=0: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn1_1    | 2023-03-10 22:42:06,155 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CBC13A60F575 with new leaderId: e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn1_1    | 2023-03-10 22:42:06,155 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: change Leader from null to e78c5ce1-46ab-4889-a0cd-5903ae46614d at term 2 for appendEntries, leader elected after 430ms
dn1_1    | 2023-03-10 22:42:06,156 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575: set configuration 1: [e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0], old=null
dn1_1    | 2023-03-10 22:42:06,158 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn1_1    | 2023-03-10 22:42:06,162 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_inprogress_0 to /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_0-0
dn1_1    | 2023-03-10 22:42:06,189 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-CBC13A60F575-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/78b03a88-75c1-4060-9962-cbc13a60f575/current/log_inprogress_1
dn1_1    | 2023-03-10 22:42:08,817 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-0049FBBC23B3, 3, (t:0, i:0))
dn1_1    | 2023-03-10 22:42:08,817 [grpc-default-executor-1] INFO impl.VoteContext: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FOLLOWER: reject ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: our priority 1 > candidate's priority 0
dn1_1    | 2023-03-10 22:42:08,817 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:e78c5ce1-46ab-4889-a0cd-5903ae46614d
dn1_1    | 2023-03-10 22:42:08,817 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:42:08,817 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState was interrupted: {}
dn1_1    | java.lang.InterruptedException: sleep interrupted
dn1_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn1_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
dn1_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
dn1_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
dn1_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
dn1_1    | 2023-03-10 22:42:08,817 [grpc-default-executor-1] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:42:08,834 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t3. Peer's state: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3:t3, leader=null, voted=null, raftlog=e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c-1, conf=-1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn1_1    | 2023-03-10 22:42:13,921 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState] INFO impl.FollowerState: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5103861066ns, electionTimeout:5072ms
dn1_1    | 2023-03-10 22:42:13,922 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState
dn1_1    | 2023-03-10 22:42:13,922 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn1_1    | 2023-03-10 22:42:13,923 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2023-03-10 22:42:13,923 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-FollowerState] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2
dn1_1    | 2023-03-10 22:42:13,927 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO impl.LeaderElection: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2 ELECTION round 0: submit vote requests at term 4 for -1: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn1_1    | 2023-03-10 22:42:14,038 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO impl.LeaderElection: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn1_1    | 2023-03-10 22:42:14,038 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO impl.LeaderElection:   Response 0: e3e4587c-aa42-4e86-ae9a-d3e448365275<-1a6d358d-6662-4447-914c-d709a67ff716#0:OK-t4
dn1_1    | 2023-03-10 22:42:14,039 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO impl.LeaderElection: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2 ELECTION round 0: result PASSED
dn1_1    | 2023-03-10 22:42:14,039 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: shutdown e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2
dn1_1    | 2023-03-10 22:42:14,039 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn1_1    | 2023-03-10 22:42:14,040 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0049FBBC23B3 with new leaderId: e3e4587c-aa42-4e86-ae9a-d3e448365275
dn1_1    | 2023-03-10 22:42:14,042 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn1_1    | 2023-03-10 22:42:14,042 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: change Leader from null to e3e4587c-aa42-4e86-ae9a-d3e448365275 at term 4 for becomeLeader, leader elected after 21709ms
dn1_1    | 2023-03-10 22:42:14,065 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn1_1    | 2023-03-10 22:42:14,065 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2023-03-10 22:42:14,066 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn1_1    | 2023-03-10 22:42:14,066 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn1_1    | 2023-03-10 22:42:14,066 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn1_1    | 2023-03-10 22:42:14,066 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn1_1    | 2023-03-10 22:42:14,066 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2023-03-10 22:42:14,066 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn1_1    | 2023-03-10 22:42:14,099 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: receive requestVote(ELECTION, e78c5ce1-46ab-4889-a0cd-5903ae46614d, group-0049FBBC23B3, 4, (t:0, i:0))
dn1_1    | 2023-03-10 22:42:14,125 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn1_1    | 2023-03-10 22:42:14,126 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2023-03-10 22:42:14,126 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn1_1    | 2023-03-10 22:42:14,189 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn1_1    | 2023-03-10 22:42:14,191 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2023-03-10 22:42:14,192 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2023-03-10 22:42:14,224 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn1_1    | 2023-03-10 22:42:14,233 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2023-03-10 22:42:14,234 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn1_1    | 2023-03-10 22:42:14,234 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn1_1    | 2023-03-10 22:42:14,235 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2023-03-10 22:42:14,235 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2023-03-10 22:42:14,236 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO impl.RoleInfo: e3e4587c-aa42-4e86-ae9a-d3e448365275: start e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderStateImpl
dn1_1    | 2023-03-10 22:42:14,245 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLogWorker: Starting segment from index:0
dn1_1    | 2023-03-10 22:42:14,248 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cf0cdca9-af45-4cc0-9366-0049fbbc23b3/current/log_inprogress_0
dn1_1    | 2023-03-10 22:42:14,295 [e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LeaderElection2] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3: set configuration 0: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn1_1    | 2023-03-10 22:42:14,301 [grpc-default-executor-1] INFO impl.VoteContext: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-LEADER: reject ELECTION from e78c5ce1-46ab-4889-a0cd-5903ae46614d: already has voted for e3e4587c-aa42-4e86-ae9a-d3e448365275 at current term 4
dn1_1    | 2023-03-10 22:42:14,301 [grpc-default-executor-1] INFO server.RaftServer$Division: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3 replies to ELECTION vote request: e78c5ce1-46ab-4889-a0cd-5903ae46614d<-e3e4587c-aa42-4e86-ae9a-d3e448365275#0:FAIL-t4. Peer's state: e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3:t4, leader=e3e4587c-aa42-4e86-ae9a-d3e448365275, voted=e3e4587c-aa42-4e86-ae9a-d3e448365275, raftlog=e3e4587c-aa42-4e86-ae9a-d3e448365275@group-0049FBBC23B3-SegmentedRaftLog:OPENED:c0, conf=0: [e78c5ce1-46ab-4889-a0cd-5903ae46614d|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, e3e4587c-aa42-4e86-ae9a-d3e448365275|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn1_1    | 2023-03-10 22:42:47,876 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
dn5_1    | 2023-03-10 22:42:14,838 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00 replies to ELECTION vote request: 3892a4e1-c878-42af-adb7-db66a90d61f4<-178b30e1-b74d-4f4d-a142-c930eee71455#0:OK-t4. Peer's state: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00:t4, leader=null, voted=3892a4e1-c878-42af-adb7-db66a90d61f4, raftlog=178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLog:OPENED:c-1, conf=-1: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0], old=null
dn5_1    | 2023-03-10 22:42:15,071 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5B98FDC36F00 with new leaderId: 3892a4e1-c878-42af-adb7-db66a90d61f4
dn5_1    | 2023-03-10 22:42:15,071 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: change Leader from null to 3892a4e1-c878-42af-adb7-db66a90d61f4 at term 4 for appendEntries, leader elected after 21753ms
dn5_1    | 2023-03-10 22:42:15,201 [grpc-default-executor-0] INFO server.RaftServer$Division: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00: set configuration 0: [178b30e1-b74d-4f4d-a142-c930eee71455|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0, 3892a4e1-c878-42af-adb7-db66a90d61f4|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 1a6d358d-6662-4447-914c-d709a67ff716|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0], old=null
dn5_1    | 2023-03-10 22:42:15,201 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLogWorker: Starting segment from index:0
dn5_1    | 2023-03-10 22:42:15,207 [178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 178b30e1-b74d-4f4d-a142-c930eee71455@group-5B98FDC36F00-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/54b523a6-4d1d-4f07-a057-5b98fdc36f00/current/log_inprogress_0
om2_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1    | 2023-03-10 22:40:56,870 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1    | /************************************************************
om2_1    | STARTUP_MSG: Starting OzoneManager
om2_1    | STARTUP_MSG:   host = 02cce6bd9936/10.9.0.12
om2_1    | STARTUP_MSG:   args = [--init]
om2_1    | STARTUP_MSG:   version = 1.2.1
om2_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar
om2_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:28Z
om2_1    | STARTUP_MSG:   java = 11.0.13
om2_1    | ************************************************************/
om2_1    | 2023-03-10 22:40:56,922 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1    | 2023-03-10 22:41:09,392 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om2_1    | 2023-03-10 22:41:10,253 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1    | 2023-03-10 22:41:10,254 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om2: om2
om2_1    | 2023-03-10 22:41:10,310 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2023-03-10 22:41:17,200 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:19,201 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:21,203 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:23,207 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:25,208 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:27,210 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:29,214 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:31,216 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:33,218 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:35,220 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:37,222 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:39,224 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2023-03-10 22:41:41,226 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 02cce6bd9936/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-d8d7fcf8-04e0-4b43-9ae2-eefeb561683b;layoutVersion=0
om2_1    | 2023-03-10 22:41:45,942 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1    | /************************************************************
om2_1    | SHUTDOWN_MSG: Shutting down OzoneManager at 02cce6bd9936/10.9.0.12
om2_1    | ************************************************************/
om2_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1    | 2023-03-10 22:41:54,887 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1    | /************************************************************
om2_1    | STARTUP_MSG: Starting OzoneManager
om2_1    | STARTUP_MSG:   host = 02cce6bd9936/10.9.0.12
om2_1    | STARTUP_MSG:   args = [--]
om2_1    | STARTUP_MSG:   version = 1.2.1
om2_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar
om2_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:28Z
om2_1    | STARTUP_MSG:   java = 11.0.13
om2_1    | ************************************************************/
om2_1    | 2023-03-10 22:41:54,963 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1    | 2023-03-10 22:42:02,757 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om2_1    | 2023-03-10 22:42:03,070 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1    | 2023-03-10 22:42:03,070 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om2: om2
om2_1    | 2023-03-10 22:42:03,086 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2023-03-10 22:42:03,178 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om2_1    | 2023-03-10 22:42:04,583 [main] INFO reflections.Reflections: Reflections took 1267 ms to scan 1 urls, producing 95 keys and 258 values [using 2 cores]
om2_1    | 2023-03-10 22:42:04,739 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2023-03-10 22:42:09,060 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2023-03-10 22:42:09,824 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1    | 2023-03-10 22:42:09,829 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1    | 2023-03-10 22:42:11,021 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om2_1    | 2023-03-10 22:42:11,202 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1    | 2023-03-10 22:42:11,204 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1    | 2023-03-10 22:42:11,292 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1    | 2023-03-10 22:42:12,109 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1    | 2023-03-10 22:42:12,124 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1    | 2023-03-10 22:42:12,289 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om2:9872, om1:9872, om3:9872
om2_1    | 2023-03-10 22:42:12,352 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1    | 2023-03-10 22:42:12,391 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1    | 2023-03-10 22:42:12,562 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1    | 2023-03-10 22:42:12,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1    | 2023-03-10 22:42:12,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1    | 2023-03-10 22:42:12,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1    | 2023-03-10 22:42:12,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1    | 2023-03-10 22:42:12,568 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1    | 2023-03-10 22:42:12,587 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1    | 2023-03-10 22:42:12,587 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1    | 2023-03-10 22:42:12,588 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1    | 2023-03-10 22:42:13,899 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1    | 2023-03-10 22:42:13,915 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1    | 2023-03-10 22:42:13,916 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1    | 2023-03-10 22:42:14,071 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1    | 2023-03-10 22:42:14,135 [main] INFO server.RaftServer: om2: addNew group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@157d3a45[Not completed]
om2_1    | 2023-03-10 22:42:14,135 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1    | 2023-03-10 22:42:14,366 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1    | 2023-03-10 22:42:14,426 [pool-23-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1    | 2023-03-10 22:42:14,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1    | 2023-03-10 22:42:14,475 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1    | 2023-03-10 22:42:14,498 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1    | 2023-03-10 22:42:14,498 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1    | 2023-03-10 22:42:14,498 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1    | 2023-03-10 22:42:14,499 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1    | 2023-03-10 22:42:14,499 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1    | 2023-03-10 22:42:14,500 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1    | 2023-03-10 22:42:14,533 [pool-23-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1    | 2023-03-10 22:42:14,534 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1    | 2023-03-10 22:42:14,540 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1    | 2023-03-10 22:42:14,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1    | 2023-03-10 22:42:14,574 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c does not exist. Creating ...
om2_1    | 2023-03-10 22:42:14,616 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 7@02cce6bd9936
om2_1    | 2023-03-10 22:42:14,764 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c has been successfully formatted.
om2_1    | 2023-03-10 22:42:14,776 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1    | 2023-03-10 22:42:14,822 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1    | 2023-03-10 22:42:14,856 [Listener at om2/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om2_1    | 2023-03-10 22:42:14,970 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1    | 2023-03-10 22:42:14,970 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1    | 2023-03-10 22:42:15,342 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1    | 2023-03-10 22:42:15,432 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1    | 2023-03-10 22:42:15,432 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1    | 2023-03-10 22:42:15,486 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om2_1    | 2023-03-10 22:42:15,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1    | 2023-03-10 22:42:15,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1    | 2023-03-10 22:42:15,488 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1    | 2023-03-10 22:42:15,488 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1    | 2023-03-10 22:42:15,505 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1    | 2023-03-10 22:42:15,515 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1    | 2023-03-10 22:42:15,526 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1    | 2023-03-10 22:42:15,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1    | 2023-03-10 22:42:15,612 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1    | 2023-03-10 22:42:15,617 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1    | 2023-03-10 22:42:15,664 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1    | 2023-03-10 22:42:15,682 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1    | 2023-03-10 22:42:15,716 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1    | 2023-03-10 22:42:15,725 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1    | 2023-03-10 22:42:15,732 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
recon_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1  | 2023-03-10 22:40:52,324 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1  | /************************************************************
recon_1  | STARTUP_MSG: Starting ReconServer
recon_1  | STARTUP_MSG:   host = 3a915c20833c/10.9.0.20
recon_1  | STARTUP_MSG:   args = []
recon_1  | STARTUP_MSG:   version = 1.2.1
recon_1  | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.2.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.2.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.2.1.jar
recon_1  | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:28Z
recon_1  | STARTUP_MSG:   java = 11.0.13
recon_1  | ************************************************************/
recon_1  | 2023-03-10 22:40:52,437 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1  | WARNING: An illegal reflective access operation has occurred
recon_1  | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1  | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1  | WARNING: All illegal access operations will be denied in a future release
recon_1  | 2023-03-10 22:40:59,719 [main] INFO reflections.Reflections: Reflections took 589 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1  | 2023-03-10 22:41:03,838 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1  | 2023-03-10 22:41:05,499 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1  | 2023-03-10 22:41:17,067 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2023-03-10 22:41:19,696 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1  | 2023-03-10 22:41:19,983 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2023-03-10 22:41:20,000 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1  | 2023-03-10 22:41:27,746 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1  | 2023-03-10 22:41:28,002 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1  | 2023-03-10 22:41:28,131 [main] INFO util.log: Logging initialized @44117ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1  | 2023-03-10 22:41:29,483 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1  | 2023-03-10 22:41:29,520 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1  | 2023-03-10 22:41:29,567 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1  | 2023-03-10 22:41:29,646 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1  | 2023-03-10 22:41:29,653 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1  | 2023-03-10 22:41:29,653 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1  | 2023-03-10 22:41:30,874 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1  | 2023-03-10 22:41:32,439 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1  | 2023-03-10 22:41:32,519 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
om2_1    | 2023-03-10 22:42:15,737 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1    | 2023-03-10 22:42:15,748 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1    | 2023-03-10 22:42:15,757 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1    | 2023-03-10 22:42:15,761 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1    | 2023-03-10 22:42:15,885 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1    | 2023-03-10 22:42:15,893 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1    | 2023-03-10 22:42:16,260 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/10.9.0.12:9862
om2_1    | 2023-03-10 22:42:16,262 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1    | 2023-03-10 22:42:16,266 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-D66704EFC61C: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1    | 2023-03-10 22:42:16,282 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1    | 2023-03-10 22:42:16,287 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-FollowerState
om2_1    | 2023-03-10 22:42:16,299 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om2
om2_1    | 2023-03-10 22:42:16,337 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1    | 2023-03-10 22:42:16,720 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1    | 2023-03-10 22:42:16,758 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1    | 2023-03-10 22:42:16,760 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$383/0x000000084050f040@5aa76ad2] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1    | 2023-03-10 22:42:16,902 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1    | 2023-03-10 22:42:16,904 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om2_1    | 2023-03-10 22:42:17,080 [Listener at om2/9862] INFO util.log: Logging initialized @29882ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1    | 2023-03-10 22:42:17,780 [Listener at om2/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om2_1    | 2023-03-10 22:42:17,792 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1    | 2023-03-10 22:42:17,803 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1    | 2023-03-10 22:42:17,822 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om2_1    | 2023-03-10 22:42:17,823 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1  | 2023-03-10 22:41:32,554 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1  | 2023-03-10 22:41:32,722 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1  | 2023-03-10 22:41:32,760 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'omservice'.
recon_1  | 2023-03-10 22:41:35,759 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2023-03-10 22:41:37,097 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2023-03-10 22:41:37,161 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/opt/hadoop/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar!/network-topology-default.xml]
recon_1  | 2023-03-10 22:41:37,164 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
om3_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1    | 2023-03-10 22:40:55,985 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1    | /************************************************************
om3_1    | STARTUP_MSG: Starting OzoneManager
om3_1    | STARTUP_MSG:   host = 7664c3bab220/10.9.0.13
om3_1    | STARTUP_MSG:   args = [--init]
om3_1    | STARTUP_MSG:   version = 1.2.1
om2_1    | 2023-03-10 22:42:17,823 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om2_1    | 2023-03-10 22:42:18,134 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1    | 2023-03-10 22:42:18,143 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
om2_1    | 2023-03-10 22:42:18,260 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1    | 2023-03-10 22:42:18,261 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1    | 2023-03-10 22:42:18,266 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1    | 2023-03-10 22:42:18,292 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7741ae1b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1    | 2023-03-10 22:42:18,294 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2d4a3e13{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar!/webapps/static,AVAILABLE}
om2_1    | 2023-03-10 22:42:19,180 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1144a02b{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_1_jar-_-any-1489865968127776751/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar!/webapps/ozoneManager}
om2_1    | 2023-03-10 22:42:19,201 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@6af87130{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1    | 2023-03-10 22:42:19,201 [Listener at om2/9862] INFO server.Server: Started @32003ms
om2_1    | 2023-03-10 22:42:19,207 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1    | 2023-03-10 22:42:19,207 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1    | 2023-03-10 22:42:19,210 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1    | 2023-03-10 22:42:19,215 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1    | 2023-03-10 22:42:19,239 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1    | 2023-03-10 22:42:19,503 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1    | 2023-03-10 22:42:19,538 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@589fb74d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1    | 2023-03-10 22:42:20,802 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 1, (t:0, i:~))
om2_1    | 2023-03-10 22:42:20,808 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-D66704EFC61C-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1    | 2023-03-10 22:42:20,809 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:om1
om2_1    | 2023-03-10 22:42:20,809 [grpc-default-executor-0] INFO impl.RoleInfo: om2: shutdown om2@group-D66704EFC61C-FollowerState
om2_1    | 2023-03-10 22:42:20,820 [om2@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om2@group-D66704EFC61C-FollowerState was interrupted: {}
om2_1    | java.lang.InterruptedException: sleep interrupted
om2_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1    | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
om2_1    | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om2_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om2_1    | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om2_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om2_1    | 2023-03-10 22:42:20,825 [grpc-default-executor-0] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-FollowerState
om2_1    | 2023-03-10 22:42:20,870 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C replies to ELECTION vote request: om1<-om2#0:OK-t1. Peer's state: om2@group-D66704EFC61C:t1, leader=null, voted=om1, raftlog=om2@group-D66704EFC61C-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1    | 2023-03-10 22:42:21,333 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: change Leader from null to om1 at term 1 for appendEntries, leader elected after 6557ms
om2_1    | 2023-03-10 22:42:21,477 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2023-03-10 22:42:21,503 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: Starting segment from index:0
om2_1    | 2023-03-10 22:42:21,735 [om2@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_0
om2_1    | 2023-03-10 22:42:21,917 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: receive requestVote(ELECTION, om3, group-D66704EFC61C, 1, (t:0, i:~))
om2_1    | 2023-03-10 22:42:21,918 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-D66704EFC61C-FOLLOWER: reject ELECTION from om3: already has voted for om1 at current term 1
om2_1    | 2023-03-10 22:42:21,918 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-D66704EFC61C:t1, leader=om1, voted=om1, raftlog=om2@group-D66704EFC61C-SegmentedRaftLog:OPENED:c-1, conf=0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2023-03-10 22:42:24,395 [om2@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1    | [id: "om1"
om2_1    | address: "om1:9872"
om2_1    | , id: "om3"
om2_1    | address: "om3:9872"
om2_1    | , id: "om2"
om2_1    | address: "om2:9872"
om2_1    | ]
om2_1    | 2023-03-10 22:42:29,220 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:old1-volume for user:hadoop
om2_1    | 2023-03-10 22:42:51,801 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:old1-bucket in volume:s3v
om2_1    | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1    | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om2_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:248)
om2_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1    | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar
om3_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:28Z
om3_1    | STARTUP_MSG:   java = 11.0.13
om3_1    | ************************************************************/
om3_1    | 2023-03-10 22:40:56,093 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1    | 2023-03-10 22:41:08,990 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om3_1    | 2023-03-10 22:41:09,779 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1    | 2023-03-10 22:41:09,779 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om3: om3
om3_1    | 2023-03-10 22:41:09,823 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2023-03-10 22:41:16,242 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:18,243 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:20,247 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:22,249 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:24,254 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:26,258 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:28,259 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:30,262 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:32,286 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:34,296 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:36,298 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:38,300 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:40,302 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2023-03-10 22:41:42,311 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 7664c3bab220/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-d8d7fcf8-04e0-4b43-9ae2-eefeb561683b;layoutVersion=0
om3_1    | 2023-03-10 22:41:46,000 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1    | /************************************************************
om3_1    | SHUTDOWN_MSG: Shutting down OzoneManager at 7664c3bab220/10.9.0.13
om3_1    | ************************************************************/
om3_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1    | 2023-03-10 22:41:55,172 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1    | /************************************************************
om3_1    | STARTUP_MSG: Starting OzoneManager
om3_1    | STARTUP_MSG:   host = 7664c3bab220/10.9.0.13
om3_1    | STARTUP_MSG:   args = [--]
om3_1    | STARTUP_MSG:   version = 1.2.1
recon_1  | 2023-03-10 22:41:37,513 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2023-03-10 22:41:37,877 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
recon_1  | 2023-03-10 22:41:38,266 [main] INFO reflections.Reflections: Reflections took 371 ms to scan 3 urls, producing 103 keys and 211 values 
recon_1  | 2023-03-10 22:41:38,433 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1  | 2023-03-10 22:41:38,461 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1  | 2023-03-10 22:41:38,472 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1  | 2023-03-10 22:41:38,484 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1  | 2023-03-10 22:41:38,583 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1  | 2023-03-10 22:41:38,658 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1  | 2023-03-10 22:41:38,736 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1  | 2023-03-10 22:41:38,837 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1  | 2023-03-10 22:41:38,837 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1  | 2023-03-10 22:41:38,988 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1  | 2023-03-10 22:41:39,038 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1  | 2023-03-10 22:41:39,038 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1  | 2023-03-10 22:41:39,564 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1  | 2023-03-10 22:41:39,570 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
recon_1  | 2023-03-10 22:41:39,668 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1  | 2023-03-10 22:41:39,677 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1  | 2023-03-10 22:41:39,683 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1  | 2023-03-10 22:41:39,709 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6da4feeb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1  | 2023-03-10 22:41:39,711 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@498a612d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.2.1.jar!/webapps/static,AVAILABLE}
recon_1  | 2023-03-10 22:41:44,482 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7e764e5c{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_2_1_jar-_-any-2483297399723756468/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.2.1.jar!/webapps/recon}
recon_1  | 2023-03-10 22:41:44,498 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@1e98b788{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1  | 2023-03-10 22:41:44,506 [Listener at 0.0.0.0/9891] INFO server.Server: Started @60493ms
recon_1  | 2023-03-10 22:41:44,513 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1  | 2023-03-10 22:41:44,513 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1  | 2023-03-10 22:41:44,516 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1  | 2023-03-10 22:41:44,516 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1  | 2023-03-10 22:41:44,536 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1  | 2023-03-10 22:41:44,551 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1  | 2023-03-10 22:41:44,555 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1  | 2023-03-10 22:41:44,556 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2023-03-10 22:41:44,557 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1  | 2023-03-10 22:41:44,578 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1  | 2023-03-10 22:41:47,840 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1  | 2023-03-10 22:41:47,853 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1  | 2023-03-10 22:41:47,853 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1  | 2023-03-10 22:41:47,878 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1  | 2023-03-10 22:41:47,878 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1  | 2023-03-10 22:41:48,243 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1  | 2023-03-10 22:41:48,244 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1  | 2023-03-10 22:41:48,317 [IPC Server handler 9 on default port 9891] INFO ipc.Server: IPC Server handler 9 on default port 9891: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.16:38570
recon_1  | 2023-03-10 22:41:48,322 [IPC Server handler 3 on default port 9891] INFO ipc.Server: IPC Server handler 3 on default port 9891: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.19:35734
recon_1  | 2023-03-10 22:41:48,322 [IPC Server handler 5 on default port 9891] INFO ipc.Server: IPC Server handler 5 on default port 9891: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.15:47580
recon_1  | 2023-03-10 22:41:48,322 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.17:58772
recon_1  | 2023-03-10 22:41:48,322 [IPC Server handler 8 on default port 9891] INFO ipc.Server: IPC Server handler 8 on default port 9891: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.18:40602
recon_1  | 2023-03-10 22:41:48,349 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1  | 2023-03-10 22:41:48,365 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1  | 2023-03-10 22:41:48,559 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1  | 2023-03-10 22:41:48,629 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=b1358d3e-7575-4e13-af6d-8e287caccc68 from SCM.
recon_1  | 2023-03-10 22:41:48,901 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 519 milliseconds to process 0 existing database records.
recon_1  | 2023-03-10 22:41:49,162 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b1358d3e-7575-4e13-af6d-8e287caccc68, Nodes: 178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:47.904Z[UTC]].
recon_1  | 2023-03-10 22:41:49,301 [PipelineSyncTask] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 514770.806us
recon_1  | 2023-03-10 22:41:49,370 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 1037 milliseconds.
recon_1  | 2023-03-10 22:41:49,500 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 595 milliseconds for processing 0 containers.
recon_1  | 2023-03-10 22:41:49,832 [IPC Server handler 1 on default port 9891] WARN ipc.Server: IPC Server handler 1 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.15:54516: output error
recon_1  | 2023-03-10 22:41:49,833 [IPC Server handler 2 on default port 9891] WARN ipc.Server: IPC Server handler 2 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.17:39596: output error
recon_1  | 2023-03-10 22:41:49,834 [IPC Server handler 7 on default port 9891] WARN ipc.Server: IPC Server handler 7 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.19:52122: output error
recon_1  | 2023-03-10 22:41:49,843 [IPC Server handler 10 on default port 9891] WARN ipc.Server: IPC Server handler 10 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.18:33806: output error
recon_1  | 2023-03-10 22:41:49,852 [IPC Server handler 10 on default port 9891] INFO ipc.Server: IPC Server handler 10 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2023-03-10 22:41:49,861 [IPC Server handler 7 on default port 9891] INFO ipc.Server: IPC Server handler 7 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2023-03-10 22:41:49,861 [IPC Server handler 2 on default port 9891] INFO ipc.Server: IPC Server handler 2 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2023-03-10 22:41:49,864 [IPC Server handler 1 on default port 9891] INFO ipc.Server: IPC Server handler 1 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2023-03-10 22:41:49,869 [IPC Server handler 4 on default port 9891] WARN ipc.Server: IPC Server handler 4 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.16:40926: output error
recon_1  | 2023-03-10 22:41:49,870 [IPC Server handler 4 on default port 9891] INFO ipc.Server: IPC Server handler 4 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2023-03-10 22:41:49,926 [IPC Server handler 14 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1a6d358d-6662-4447-914c-d709a67ff716
recon_1  | 2023-03-10 22:41:49,937 [IPC Server handler 14 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:49,986 [IPC Server handler 27 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e78c5ce1-46ab-4889-a0cd-5903ae46614d
recon_1  | 2023-03-10 22:41:50,038 [IPC Server handler 27 on default port 9891] INFO node.SCMNodeManager: Registered Data node : e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:50,037 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 1a6d358d-6662-4447-914c-d709a67ff716 to Node DB.
recon_1  | 2023-03-10 22:41:50,052 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node e78c5ce1-46ab-4889-a0cd-5903ae46614d to Node DB.
recon_1  | 2023-03-10 22:41:50,065 [IPC Server handler 96 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e3e4587c-aa42-4e86-ae9a-d3e448365275
recon_1  | 2023-03-10 22:41:50,065 [IPC Server handler 96 on default port 9891] INFO node.SCMNodeManager: Registered Data node : e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:50,066 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node e3e4587c-aa42-4e86-ae9a-d3e448365275 to Node DB.
recon_1  | 2023-03-10 22:41:50,439 [IPC Server handler 9 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3892a4e1-c878-42af-adb7-db66a90d61f4
recon_1  | 2023-03-10 22:41:50,440 [IPC Server handler 9 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:50,440 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575. Trying to get from SCM.
recon_1  | 2023-03-10 22:41:50,441 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 3892a4e1-c878-42af-adb7-db66a90d61f4 to Node DB.
recon_1  | 2023-03-10 22:41:50,468 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 78b03a88-75c1-4060-9962-cbc13a60f575, Nodes: 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.637Z[UTC]] to Recon pipeline metadata.
recon_1  | 2023-03-10 22:41:50,472 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 78b03a88-75c1-4060-9962-cbc13a60f575, Nodes: 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.637Z[UTC]].
recon_1  | 2023-03-10 22:41:50,472 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 1174.205us
recon_1  | 2023-03-10 22:41:50,473 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575 reported by 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:51,098 [IPC Server handler 96 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/178b30e1-b74d-4f4d-a142-c930eee71455
recon_1  | 2023-03-10 22:41:51,099 [IPC Server handler 96 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:51,100 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 178b30e1-b74d-4f4d-a142-c930eee71455 to Node DB.
recon_1  | 2023-03-10 22:41:51,101 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=b1358d3e-7575-4e13-af6d-8e287caccc68 reported by 178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:51,101 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b1358d3e-7575-4e13-af6d-8e287caccc68, Nodes: 178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:178b30e1-b74d-4f4d-a142-c930eee71455, CreationTimestamp2023-03-10T22:41:47.904Z[UTC]] moved to OPEN state
recon_1  | 2023-03-10 22:41:51,103 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 1338.706us
recon_1  | 2023-03-10 22:41:52,000 [IPC Server handler 27 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn3_1.ha_net
recon_1  | 2023-03-10 22:41:52,002 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3. Trying to get from SCM.
recon_1  | 2023-03-10 22:41:52,093 [IPC Server handler 96 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn4_1.ha_net
recon_1  | 2023-03-10 22:41:52,099 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: cf0cdca9-af45-4cc0-9366-0049fbbc23b3, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.535Z[UTC]] to Recon pipeline metadata.
recon_1  | 2023-03-10 22:41:52,101 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cf0cdca9-af45-4cc0-9366-0049fbbc23b3, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.535Z[UTC]].
recon_1  | 2023-03-10 22:41:52,108 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 7691.537us
recon_1  | 2023-03-10 22:41:52,115 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:52,117 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:52,462 [IPC Server handler 97 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn1_1.ha_net
om3_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar
om3_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:28Z
om3_1    | STARTUP_MSG:   java = 11.0.13
om3_1    | ************************************************************/
om3_1    | 2023-03-10 22:41:55,233 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1    | 2023-03-10 22:42:02,798 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om3_1    | 2023-03-10 22:42:03,078 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1    | 2023-03-10 22:42:03,081 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om3: om3
om3_1    | 2023-03-10 22:42:03,109 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2023-03-10 22:42:03,283 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om3_1    | 2023-03-10 22:42:04,922 [main] INFO reflections.Reflections: Reflections took 1436 ms to scan 1 urls, producing 95 keys and 258 values [using 2 cores]
om3_1    | 2023-03-10 22:42:05,206 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2023-03-10 22:42:09,880 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2023-03-10 22:42:10,371 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1    | 2023-03-10 22:42:10,377 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1    | 2023-03-10 22:42:11,371 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om3_1    | 2023-03-10 22:42:11,526 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1    | 2023-03-10 22:42:11,526 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1    | 2023-03-10 22:42:11,570 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1    | 2023-03-10 22:42:12,127 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1    | 2023-03-10 22:42:12,259 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1    | 2023-03-10 22:42:12,369 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om3:9872, om1:9872, om2:9872
om3_1    | 2023-03-10 22:42:12,399 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1    | 2023-03-10 22:42:12,496 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1    | 2023-03-10 22:42:12,769 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1    | 2023-03-10 22:42:12,769 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1    | 2023-03-10 22:42:12,770 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1    | 2023-03-10 22:42:12,770 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1    | 2023-03-10 22:42:12,770 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1    | 2023-03-10 22:42:12,771 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1    | 2023-03-10 22:42:12,788 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1    | 2023-03-10 22:42:12,797 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1    | 2023-03-10 22:42:12,798 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1    | 2023-03-10 22:42:13,672 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1    | 2023-03-10 22:42:13,674 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1    | 2023-03-10 22:42:13,674 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1    | 2023-03-10 22:42:13,743 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1    | 2023-03-10 22:42:13,788 [main] INFO server.RaftServer: om3: addNew group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@2b73bd6b[Not completed]
om3_1    | 2023-03-10 22:42:13,788 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1    | 2023-03-10 22:42:13,944 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1    | 2023-03-10 22:42:13,942 [pool-23-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1    | 2023-03-10 22:42:13,976 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1    | 2023-03-10 22:42:13,985 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1    | 2023-03-10 22:42:13,989 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1    | 2023-03-10 22:42:13,993 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1    | 2023-03-10 22:42:14,002 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1    | 2023-03-10 22:42:14,003 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1    | 2023-03-10 22:42:14,009 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1    | 2023-03-10 22:42:14,015 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1    | 2023-03-10 22:42:14,090 [pool-23-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1    | 2023-03-10 22:42:14,094 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
recon_1  | 2023-03-10 22:41:52,489 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:53,275 [IPC Server handler 6 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn5_1.ha_net
recon_1  | 2023-03-10 22:41:53,276 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00. Trying to get from SCM.
recon_1  | 2023-03-10 22:41:53,283 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 54b523a6-4d1d-4f07-a057-5b98fdc36f00, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.739Z[UTC]] to Recon pipeline metadata.
recon_1  | 2023-03-10 22:41:53,284 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 54b523a6-4d1d-4f07-a057-5b98fdc36f00, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.739Z[UTC]].
recon_1  | 2023-03-10 22:41:53,288 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 4979.024us
recon_1  | 2023-03-10 22:41:53,288 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:57,133 [IPC Server handler 95 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn3_1.ha_net
recon_1  | 2023-03-10 22:41:57,136 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:57,136 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:57,366 [IPC Server handler 3 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn1_1.ha_net
recon_1  | 2023-03-10 22:41:57,369 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:57,370 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575 reported by e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,192 [IPC Server handler 6 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn5_1.ha_net
recon_1  | 2023-03-10 22:41:58,193 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,278 [IPC Server handler 3 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn2_1.ha_net
recon_1  | 2023-03-10 22:41:58,279 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,279 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575 reported by 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1    | 2023-03-10 22:40:59,318 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1    | /************************************************************
scm_1    | STARTUP_MSG: Starting StorageContainerManager
scm_1    | STARTUP_MSG:   host = 0a66bbb20f63/10.9.0.14
scm_1    | STARTUP_MSG:   args = [--init]
scm_1    | STARTUP_MSG:   version = 1.2.1
recon_1  | 2023-03-10 22:41:58,335 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,335 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,335 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=7572f4a9-8e86-407b-b624-5c511402a23e. Trying to get from SCM.
recon_1  | 2023-03-10 22:41:58,338 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 7572f4a9-8e86-407b-b624-5c511402a23e, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.729Z[UTC]] to Recon pipeline metadata.
recon_1  | 2023-03-10 22:41:58,339 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 7572f4a9-8e86-407b-b624-5c511402a23e, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.729Z[UTC]].
recon_1  | 2023-03-10 22:41:58,340 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 757.703us
recon_1  | 2023-03-10 22:41:58,340 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=7572f4a9-8e86-407b-b624-5c511402a23e reported by 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,341 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7572f4a9-8e86-407b-b624-5c511402a23e, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1a6d358d-6662-4447-914c-d709a67ff716, CreationTimestamp2023-03-10T22:41:48.729Z[UTC]] moved to OPEN state
recon_1  | 2023-03-10 22:41:58,341 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 346.901us
recon_1  | 2023-03-10 22:41:58,593 [IPC Server handler 27 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn2_1.ha_net
recon_1  | 2023-03-10 22:41:58,594 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,594 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575 reported by 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,719 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,719 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e. Trying to get from SCM.
recon_1  | 2023-03-10 22:41:58,723 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e, Nodes: e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.597Z[UTC]] to Recon pipeline metadata.
recon_1  | 2023-03-10 22:41:58,724 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e, Nodes: e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.597Z[UTC]].
recon_1  | 2023-03-10 22:41:58,724 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 720.103us
scm_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar
scm_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
scm_1    | STARTUP_MSG:   java = 11.0.13
scm_1    | ************************************************************/
scm_1    | 2023-03-10 22:40:59,448 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1    | 2023-03-10 22:41:00,759 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2023-03-10 22:41:01,392 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1    | 2023-03-10 22:41:01,449 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1    | 2023-03-10 22:41:03,080 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-d8d7fcf8-04e0-4b43-9ae2-eefeb561683b; layoutVersion=2; scmId=af9b2ba2-ce52-4d43-bbf2-6c00e161fbdb
scm_1    | 2023-03-10 22:41:03,277 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1    | /************************************************************
scm_1    | SHUTDOWN_MSG: Shutting down StorageContainerManager at 0a66bbb20f63/10.9.0.14
scm_1    | ************************************************************/
scm_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1    | 2023-03-10 22:41:28,086 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1    | /************************************************************
scm_1    | STARTUP_MSG: Starting StorageContainerManager
scm_1    | STARTUP_MSG:   host = 0a66bbb20f63/10.9.0.14
scm_1    | STARTUP_MSG:   args = []
scm_1    | STARTUP_MSG:   version = 1.2.1
recon_1  | 2023-03-10 22:41:58,724 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e reported by e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:58,725 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e, Nodes: e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e3e4587c-aa42-4e86-ae9a-d3e448365275, CreationTimestamp2023-03-10T22:41:48.597Z[UTC]] moved to OPEN state
recon_1  | 2023-03-10 22:41:58,725 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 379.102us
recon_1  | 2023-03-10 22:41:58,727 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575 reported by e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:59,029 [IPC Server handler 95 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn4_1.ha_net
recon_1  | 2023-03-10 22:41:59,030 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:59,031 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575 reported by e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:59,032 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 78b03a88-75c1-4060-9962-cbc13a60f575, Nodes: 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3892a4e1-c878-42af-adb7-db66a90d61f4, CreationTimestamp2023-03-10T22:41:48.637Z[UTC]] moved to OPEN state
recon_1  | 2023-03-10 22:41:59,037 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 681.503us
recon_1  | 2023-03-10 22:41:59,673 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:59,673 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=2d4f1397-2cdc-4336-a562-676bab171c02. Trying to get from SCM.
recon_1  | 2023-03-10 22:41:59,681 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 2d4f1397-2cdc-4336-a562-676bab171c02, Nodes: 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3892a4e1-c878-42af-adb7-db66a90d61f4, CreationTimestamp2023-03-10T22:41:48.902Z[UTC]] to Recon pipeline metadata.
recon_1  | 2023-03-10 22:41:59,682 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 2d4f1397-2cdc-4336-a562-676bab171c02, Nodes: 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3892a4e1-c878-42af-adb7-db66a90d61f4, CreationTimestamp2023-03-10T22:41:48.902Z[UTC]].
recon_1  | 2023-03-10 22:41:59,683 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 1617.207us
recon_1  | 2023-03-10 22:41:59,849 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:59,849 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=8581ae3d-c50a-4a49-9d70-d98e5419b7a9. Trying to get from SCM.
scm_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar
scm_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
scm_1    | STARTUP_MSG:   java = 11.0.13
scm_1    | ************************************************************/
scm_1    | 2023-03-10 22:41:28,210 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1    | 2023-03-10 22:41:29,528 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1    | 2023-03-10 22:41:29,541 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1    | 2023-03-10 22:41:31,043 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2023-03-10 22:41:31,388 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm_1    | 2023-03-10 22:41:36,826 [main] INFO reflections.Reflections: Reflections took 2492 ms to scan 3 urls, producing 103 keys and 211 values 
scm_1    | 2023-03-10 22:41:39,132 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2023-03-10 22:41:39,466 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2023-03-10 22:41:39,896 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/opt/hadoop/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar!/network-topology-default.xml]
scm_1    | 2023-03-10 22:41:39,898 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1    | 2023-03-10 22:41:40,011 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1    | 2023-03-10 22:41:40,028 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
scm_1    | 2023-03-10 22:41:40,029 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm_1    | 2023-03-10 22:41:40,031 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm_1    | 2023-03-10 22:41:40,032 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm_1    | 2023-03-10 22:41:40,117 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1    | 2023-03-10 22:41:40,133 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1    | 2023-03-10 22:41:40,148 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm_1    | 2023-03-10 22:41:40,203 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm_1    | 2023-03-10 22:41:40,210 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm_1    | 2023-03-10 22:41:40,213 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm_1    | 2023-03-10 22:41:40,260 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1    | 2023-03-10 22:41:40,314 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm_1    | 2023-03-10 22:41:40,361 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm_1    | 2023-03-10 22:41:40,363 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1    | 2023-03-10 22:41:40,505 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 77 milliseconds for processing 0 containers.
scm_1    | 2023-03-10 22:41:40,555 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm_1    | 2023-03-10 22:41:40,566 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1    | 2023-03-10 22:41:40,575 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1    | 2023-03-10 22:41:42,713 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2023-03-10 22:41:42,870 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1    | 2023-03-10 22:41:43,011 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2023-03-10 22:41:43,022 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
s3g_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1    | 2023-03-10 22:40:56,329 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1    | 2023-03-10 22:40:56,330 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1    | 2023-03-10 22:40:56,546 [main] INFO util.log: Logging initialized @12245ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1    | 2023-03-10 22:40:57,963 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1    | 2023-03-10 22:40:58,204 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1    | 2023-03-10 22:40:58,267 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1    | 2023-03-10 22:40:58,291 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1    | 2023-03-10 22:40:58,292 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1    | 2023-03-10 22:40:58,309 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1    | 2023-03-10 22:40:58,755 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1    | /************************************************************
s3g_1    | STARTUP_MSG: Starting Gateway
s3g_1    | STARTUP_MSG:   host = ddd5c89d7a13/10.9.0.21
s3g_1    | STARTUP_MSG:   args = []
s3g_1    | STARTUP_MSG:   version = 1.2.1
s3g_1    | STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.1.jar
s3g_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:28Z
s3g_1    | STARTUP_MSG:   java = 11.0.13
s3g_1    | ************************************************************/
s3g_1    | 2023-03-10 22:40:58,793 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1    | 2023-03-10 22:40:59,309 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1    | 2023-03-10 22:40:59,387 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1    | 2023-03-10 22:40:59,460 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
s3g_1    | 2023-03-10 22:40:59,882 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1    | 2023-03-10 22:40:59,882 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1    | 2023-03-10 22:40:59,896 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1    | 2023-03-10 22:41:00,040 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1    | 2023-03-10 22:41:00,049 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@723e88f9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.1.jar!/webapps/static,AVAILABLE}
s3g_1    | WARNING: An illegal reflective access operation has occurred
s3g_1    | WARNING: Illegal reflective access by org.jboss.classfilewriter.ClassFile$1 (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
s3g_1    | WARNING: Please consider reporting this to the maintainers of org.jboss.classfilewriter.ClassFile$1
s3g_1    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1    | WARNING: All illegal access operations will be denied in a future release
s3g_1    | Mar 10, 2023 10:41:33 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1    | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1    | 
s3g_1    | 2023-03-10 22:41:34,088 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@19b5214b{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_2_1_jar-_-any-4932258068177637390/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.1.jar!/webapps/s3gateway}
s3g_1    | 2023-03-10 22:41:34,347 [main] INFO server.AbstractConnector: Started ServerConnector@5495333e{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1    | 2023-03-10 22:41:34,347 [main] INFO server.Server: Started @50046ms
s3g_1    | 2023-03-10 22:41:34,370 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1    | 2023-03-10 22:42:51,761 [qtp9797126-18] INFO rpc.RpcClient: Creating Bucket: s3v/old1-bucket, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1    | 2023-03-10 22:42:51,797 [qtp9797126-18] INFO endpoint.BucketEndpoint: Location is /old1-bucket
s3g_1    | 2023-03-10 22:42:53,285 [qtp9797126-15] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1    | 2023-03-10 22:42:53,305 [qtp9797126-15] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1    | 2023-03-10 22:42:53,306 [qtp9797126-15] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1    | 2023-03-10 22:42:53,309 [qtp9797126-15] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1    | 2023-03-10 22:42:53,309 [qtp9797126-15] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1    | 2023-03-10 22:42:53,595 [qtp9797126-15] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1    | 2023-03-10 22:42:14,139 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1    | 2023-03-10 22:42:14,172 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1    | 2023-03-10 22:42:14,202 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c does not exist. Creating ...
om3_1    | 2023-03-10 22:42:14,305 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 7@7664c3bab220
om3_1    | 2023-03-10 22:42:14,413 [Listener at om3/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om3_1    | 2023-03-10 22:42:14,551 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c has been successfully formatted.
om3_1    | 2023-03-10 22:42:14,562 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1    | 2023-03-10 22:42:14,567 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1    | 2023-03-10 22:42:14,625 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1    | 2023-03-10 22:42:14,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1    | 2023-03-10 22:42:14,737 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1    | 2023-03-10 22:42:14,801 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1    | 2023-03-10 22:42:14,811 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1    | 2023-03-10 22:42:14,882 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om3_1    | 2023-03-10 22:42:14,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1    | 2023-03-10 22:42:14,892 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1    | 2023-03-10 22:42:14,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1    | 2023-03-10 22:42:14,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1    | 2023-03-10 22:42:14,908 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1    | 2023-03-10 22:42:14,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1    | 2023-03-10 22:42:14,923 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1    | 2023-03-10 22:42:14,927 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1    | 2023-03-10 22:42:14,986 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1    | 2023-03-10 22:42:14,987 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1    | 2023-03-10 22:42:15,027 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1    | 2023-03-10 22:42:15,029 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1    | 2023-03-10 22:42:15,043 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1    | 2023-03-10 22:42:15,045 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1    | 2023-03-10 22:42:15,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1    | 2023-03-10 22:42:15,050 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1    | 2023-03-10 22:42:15,053 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1    | 2023-03-10 22:42:15,055 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1    | 2023-03-10 22:42:15,236 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1    | 2023-03-10 22:42:15,391 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1    | 2023-03-10 22:42:15,394 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1    | 2023-03-10 22:42:15,679 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/10.9.0.13:9862
om3_1    | 2023-03-10 22:42:15,680 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1    | 2023-03-10 22:42:15,705 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-D66704EFC61C: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1    | 2023-03-10 22:42:15,706 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1    | 2023-03-10 22:42:15,717 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-FollowerState
om3_1    | 2023-03-10 22:42:15,726 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om3
om3_1    | 2023-03-10 22:42:15,744 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1    | 2023-03-10 22:42:16,005 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1    | 2023-03-10 22:42:16,036 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1    | 2023-03-10 22:42:16,040 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$383/0x0000000840502840@26e8ff8c] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1    | 2023-03-10 22:42:16,158 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1    | 2023-03-10 22:42:16,162 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om3_1    | 2023-03-10 22:42:16,217 [Listener at om3/9862] INFO util.log: Logging initialized @28850ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1    | 2023-03-10 22:42:16,619 [Listener at om3/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om3_1    | 2023-03-10 22:42:16,642 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1    | 2023-03-10 22:42:16,664 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1  | 2023-03-10 22:41:59,855 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 8581ae3d-c50a-4a49-9d70-d98e5419b7a9, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.781Z[UTC]] to Recon pipeline metadata.
recon_1  | 2023-03-10 22:41:59,857 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8581ae3d-c50a-4a49-9d70-d98e5419b7a9, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.781Z[UTC]].
recon_1  | 2023-03-10 22:41:59,857 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 1899.308us
recon_1  | 2023-03-10 22:41:59,858 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=8581ae3d-c50a-4a49-9d70-d98e5419b7a9 reported by e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:41:59,858 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8581ae3d-c50a-4a49-9d70-d98e5419b7a9, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e78c5ce1-46ab-4889-a0cd-5903ae46614d, CreationTimestamp2023-03-10T22:41:48.781Z[UTC]] moved to OPEN state
recon_1  | 2023-03-10 22:41:59,859 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 375.302us
recon_1  | 2023-03-10 22:42:03,674 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:42:03,675 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:42:03,955 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:42:04,935 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:42:05,146 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:42:05,820 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:42:14,101 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 reported by e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:42:14,102 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cf0cdca9-af45-4cc0-9366-0049fbbc23b3, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:e3e4587c-aa42-4e86-ae9a-d3e448365275, CreationTimestamp2023-03-10T22:41:48.535Z[UTC]] moved to OPEN state
recon_1  | 2023-03-10 22:42:14,102 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 506.803us
recon_1  | 2023-03-10 22:42:14,865 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 reported by 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2023-03-10 22:42:14,866 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 54b523a6-4d1d-4f07-a057-5b98fdc36f00, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3892a4e1-c878-42af-adb7-db66a90d61f4, CreationTimestamp2023-03-10T22:41:48.739Z[UTC]] moved to OPEN state
recon_1  | 2023-03-10 22:42:14,867 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 605.403us
recon_1  | 2023-03-10 22:42:37,931 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ha_dn2_1.ha_net.
recon_1  | 2023-03-10 22:42:37,976 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 15399.462us
recon_1  | 2023-03-10 22:42:37,976 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1  | 2023-03-10 22:42:44,578 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2023-03-10 22:42:44,579 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1  | 2023-03-10 22:42:45,054 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1678488164579
recon_1  | 2023-03-10 22:42:45,061 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2023-03-10 22:42:45,062 [pool-16-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1  | 2023-03-10 22:42:45,156 [pool-16-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1678488164579.
recon_1  | 2023-03-10 22:42:45,185 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1  | 2023-03-10 22:42:45,188 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a reprocess run of NSSummaryTask
recon_1  | 2023-03-10 22:42:45,478 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
recon_1  | 2023-03-10 22:42:45,480 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1  | 2023-03-10 22:42:45,644 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1  | 2023-03-10 22:42:45,644 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.163 seconds to process 1 keys.
recon_1  | 2023-03-10 22:42:45,672 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
recon_1  | 2023-03-10 22:42:45,693 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1  | 2023-03-10 22:42:47,779 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ha_dn3_1.ha_net.
recon_1  | 2023-03-10 22:42:47,792 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@12426529, cost 3100.513us
recon_1  | 2023-03-10 22:42:47,792 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
om3_1    | 2023-03-10 22:42:16,670 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om3_1    | 2023-03-10 22:42:16,670 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om3_1    | 2023-03-10 22:42:16,670 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om3_1    | 2023-03-10 22:42:16,861 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1    | 2023-03-10 22:42:16,875 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
om3_1    | 2023-03-10 22:42:17,054 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1    | 2023-03-10 22:42:17,054 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1    | 2023-03-10 22:42:17,056 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1    | 2023-03-10 22:42:17,111 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@49c1e294{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1    | 2023-03-10 22:42:17,114 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10817f46{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar!/webapps/static,AVAILABLE}
om3_1    | 2023-03-10 22:42:18,514 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1894fa9f{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_1_jar-_-any-2367091166471002177/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.1.jar!/webapps/ozoneManager}
om3_1    | 2023-03-10 22:42:18,548 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@7f22687e{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1    | 2023-03-10 22:42:18,559 [Listener at om3/9862] INFO server.Server: Started @31181ms
om3_1    | 2023-03-10 22:42:18,576 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1    | 2023-03-10 22:42:18,576 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1    | 2023-03-10 22:42:18,578 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1    | 2023-03-10 22:42:18,586 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1    | 2023-03-10 22:42:18,610 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1    | 2023-03-10 22:42:18,670 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1    | 2023-03-10 22:42:18,742 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7f12094d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1    | 2023-03-10 22:42:20,935 [om3@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om3@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5221291853ns, electionTimeout:5139ms
om3_1    | 2023-03-10 22:42:20,946 [om3@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-D66704EFC61C-FollowerState
om3_1    | 2023-03-10 22:42:20,951 [om3@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1    | 2023-03-10 22:42:20,957 [om3@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1    | 2023-03-10 22:42:20,959 [om3@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-LeaderElection1
om3_1    | 2023-03-10 22:42:21,011 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1    | 2023-03-10 22:42:21,024 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 1, (t:0, i:~))
om3_1    | 2023-03-10 22:42:21,040 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-D66704EFC61C-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1    | 2023-03-10 22:42:21,058 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-D66704EFC61C replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-D66704EFC61C:t1, leader=null, voted=om3, raftlog=om3@group-D66704EFC61C-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1    | 2023-03-10 22:42:21,407 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
om3_1    | 2023-03-10 22:42:21,407 [grpc-default-executor-0] INFO impl.RoleInfo: om3: shutdown om3@group-D66704EFC61C-LeaderElection1
om3_1    | 2023-03-10 22:42:21,408 [grpc-default-executor-0] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-FollowerState
om3_1    | 2023-03-10 22:42:21,434 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-D66704EFC61C: change Leader from null to om1 at term 1 for appendEntries, leader elected after 6871ms
om3_1    | 2023-03-10 22:42:21,645 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2023-03-10 22:42:21,746 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: Starting segment from index:0
om3_1    | 2023-03-10 22:42:21,958 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
om3_1    | 2023-03-10 22:42:21,959 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om2#0:FAIL-t1
om3_1    | 2023-03-10 22:42:21,960 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection1 ELECTION round 0: result REJECTED
om3_1    | 2023-03-10 22:42:22,083 [om3@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_0
om3_1    | 2023-03-10 22:42:24,803 [om3@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1    | [id: "om1"
om3_1    | address: "om1:9872"
om3_1    | , id: "om3"
om3_1    | address: "om3:9872"
om3_1    | , id: "om2"
om3_1    | address: "om2:9872"
om3_1    | ]
om3_1    | 2023-03-10 22:42:29,193 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:old1-volume for user:hadoop
om3_1    | 2023-03-10 22:42:51,795 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:old1-bucket in volume:s3v
om3_1    | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1    | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
scm_1    | 2023-03-10 22:41:43,108 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2023-03-10 22:41:43,135 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1    | 2023-03-10 22:41:43,367 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1    | 2023-03-10 22:41:43,371 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm_1    | Container Balancer status:
scm_1    | Key                            Value
scm_1    | Running                        false
scm_1    | Container Balancer Configuration values:
scm_1    | Key                                                Value
scm_1    | Threshold                                          0.1
scm_1    | Max Datanodes to Involve per Iteration(ratio)      0.2
scm_1    | Max Size to Move per Iteration                     32212254720B
scm_1    | 
scm_1    | 2023-03-10 22:41:43,371 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2023-03-10 22:41:43,371 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm_1    | 2023-03-10 22:41:43,374 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1    | 2023-03-10 22:41:43,858 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1    | 2023-03-10 22:41:43,953 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1    | 2023-03-10 22:41:43,954 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1    | 2023-03-10 22:41:44,778 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1    | 2023-03-10 22:41:44,785 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2023-03-10 22:41:44,807 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1    | 2023-03-10 22:41:45,028 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1    | 2023-03-10 22:41:45,029 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1    | 2023-03-10 22:41:45,029 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1    | 2023-03-10 22:41:45,030 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2023-03-10 22:41:45,080 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1    | 2023-03-10 22:41:45,081 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1    | 2023-03-10 22:41:45,088 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2023-03-10 22:41:45,088 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1    | 2023-03-10 22:41:45,285 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e7bf7b7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1    | 2023-03-10 22:41:45,341 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1    | 2023-03-10 22:41:45,342 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1    | 2023-03-10 22:41:45,414 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @37893ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1    | 2023-03-10 22:41:47,130 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1    | 2023-03-10 22:41:47,246 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1    | 2023-03-10 22:41:47,392 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1    | 2023-03-10 22:41:47,414 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1    | 2023-03-10 22:41:47,428 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1    | 2023-03-10 22:41:47,428 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1    | 2023-03-10 22:41:47,414 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3892a4e1-c878-42af-adb7-db66a90d61f4
scm_1    | 2023-03-10 22:41:47,442 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2023-03-10 22:41:47,692 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1    | 2023-03-10 22:41:47,642 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/178b30e1-b74d-4f4d-a142-c930eee71455
scm_1    | 2023-03-10 22:41:47,752 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2023-03-10 22:41:47,721 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1    | 2023-03-10 22:41:47,752 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2023-03-10 22:41:47,755 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2023-03-10 22:41:47,762 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1    | 2023-03-10 22:41:47,813 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2023-03-10 22:41:47,919 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b1358d3e-7575-4e13-af6d-8e287caccc68 to datanode:178b30e1-b74d-4f4d-a142-c930eee71455
scm_1    | 2023-03-10 22:41:47,959 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
om3_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:248)
om3_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1    | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1    | 2023-03-10 22:41:47,973 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
scm_1    | 2023-03-10 22:41:48,044 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1a6d358d-6662-4447-914c-d709a67ff716
scm_1    | 2023-03-10 22:41:48,045 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2023-03-10 22:41:48,047 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2023-03-10 22:41:48,128 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e78c5ce1-46ab-4889-a0cd-5903ae46614d
scm_1    | 2023-03-10 22:41:48,133 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e3e4587c-aa42-4e86-ae9a-d3e448365275
scm_1    | 2023-03-10 22:41:48,133 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2023-03-10 22:41:48,135 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2023-03-10 22:41:48,135 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2023-03-10 22:41:48,135 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2023-03-10 22:41:48,137 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1    | 2023-03-10 22:41:48,138 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1    | 2023-03-10 22:41:48,139 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1    | 2023-03-10 22:41:48,082 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b1358d3e-7575-4e13-af6d-8e287caccc68, Nodes: 178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:47.904Z[UTC]].
scm_1    | 2023-03-10 22:41:48,139 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2023-03-10 22:41:48,170 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm_1    | 2023-03-10 22:41:48,200 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2023-03-10 22:41:48,535 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 to datanode:e78c5ce1-46ab-4889-a0cd-5903ae46614d
scm_1    | 2023-03-10 22:41:48,569 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 to datanode:e3e4587c-aa42-4e86-ae9a-d3e448365275
scm_1    | 2023-03-10 22:41:48,570 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cf0cdca9-af45-4cc0-9366-0049fbbc23b3 to datanode:1a6d358d-6662-4447-914c-d709a67ff716
scm_1    | 2023-03-10 22:41:48,586 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cf0cdca9-af45-4cc0-9366-0049fbbc23b3, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.535Z[UTC]].
scm_1    | 2023-03-10 22:41:48,597 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e to datanode:e3e4587c-aa42-4e86-ae9a-d3e448365275
scm_1    | 2023-03-10 22:41:48,628 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e, Nodes: e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.597Z[UTC]].
scm_1    | 2023-03-10 22:41:48,637 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575 to datanode:3892a4e1-c878-42af-adb7-db66a90d61f4
scm_1    | 2023-03-10 22:41:48,649 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575 to datanode:e3e4587c-aa42-4e86-ae9a-d3e448365275
scm_1    | 2023-03-10 22:41:48,649 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=78b03a88-75c1-4060-9962-cbc13a60f575 to datanode:e78c5ce1-46ab-4889-a0cd-5903ae46614d
scm_1    | 2023-03-10 22:41:48,658 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 78b03a88-75c1-4060-9962-cbc13a60f575, Nodes: 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.637Z[UTC]].
scm_1    | 2023-03-10 22:41:48,729 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7572f4a9-8e86-407b-b624-5c511402a23e to datanode:1a6d358d-6662-4447-914c-d709a67ff716
scm_1    | 2023-03-10 22:41:48,730 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 7572f4a9-8e86-407b-b624-5c511402a23e, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.729Z[UTC]].
scm_1    | 2023-03-10 22:41:48,739 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 to datanode:1a6d358d-6662-4447-914c-d709a67ff716
scm_1    | 2023-03-10 22:41:48,748 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 to datanode:178b30e1-b74d-4f4d-a142-c930eee71455
scm_1    | 2023-03-10 22:41:48,756 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=54b523a6-4d1d-4f07-a057-5b98fdc36f00 to datanode:3892a4e1-c878-42af-adb7-db66a90d61f4
scm_1    | 2023-03-10 22:41:48,762 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 54b523a6-4d1d-4f07-a057-5b98fdc36f00, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.739Z[UTC]].
scm_1    | 2023-03-10 22:41:48,781 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8581ae3d-c50a-4a49-9d70-d98e5419b7a9 to datanode:e78c5ce1-46ab-4889-a0cd-5903ae46614d
scm_1    | 2023-03-10 22:41:48,796 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8581ae3d-c50a-4a49-9d70-d98e5419b7a9, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.781Z[UTC]].
scm_1    | 2023-03-10 22:41:48,804 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1    | 2023-03-10 22:41:48,845 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1    | 2023-03-10 22:41:48,847 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1    | 2023-03-10 22:41:48,902 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2d4f1397-2cdc-4336-a562-676bab171c02 to datanode:3892a4e1-c878-42af-adb7-db66a90d61f4
scm_1    | 2023-03-10 22:41:48,919 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 2d4f1397-2cdc-4336-a562-676bab171c02, Nodes: 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-10T22:41:48.902Z[UTC]].
scm_1    | 2023-03-10 22:41:49,253 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b8137c5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1    | 2023-03-10 22:41:49,257 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@25ffd826{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar!/webapps/static,AVAILABLE}
scm_1    | 2023-03-10 22:41:51,462 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b1358d3e-7575-4e13-af6d-8e287caccc68, Nodes: 178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:178b30e1-b74d-4f4d-a142-c930eee71455, CreationTimestamp2023-03-10T22:41:47.904Z[UTC]] moved to OPEN state
scm_1    | 2023-03-10 22:41:51,654 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2023-03-10 22:41:51,852 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3cc053{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_1_jar-_-any-3766579560575797316/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar!/webapps/scm}
scm_1    | 2023-03-10 22:41:52,060 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@3d40a3b4{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1    | 2023-03-10 22:41:52,074 [Listener at 0.0.0.0/9860] INFO server.Server: Started @44552ms
scm_1    | 2023-03-10 22:41:52,129 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1    | 2023-03-10 22:41:52,132 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1    | 2023-03-10 22:41:52,192 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1    | 2023-03-10 22:41:53,321 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2023-03-10 22:41:58,193 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2023-03-10 22:41:58,360 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7572f4a9-8e86-407b-b624-5c511402a23e, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1a6d358d-6662-4447-914c-d709a67ff716, CreationTimestamp2023-03-10T22:41:48.729Z[UTC]] moved to OPEN state
scm_1    | 2023-03-10 22:41:58,375 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2023-03-10 22:41:58,743 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d1fa3d0d-6abe-48bc-b456-d0b7aa0d159e, Nodes: e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e3e4587c-aa42-4e86-ae9a-d3e448365275, CreationTimestamp2023-03-10T22:41:48.597Z[UTC]] moved to OPEN state
scm_1    | 2023-03-10 22:41:58,769 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2023-03-10 22:41:59,011 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 78b03a88-75c1-4060-9962-cbc13a60f575, Nodes: 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3892a4e1-c878-42af-adb7-db66a90d61f4, CreationTimestamp2023-03-10T22:41:48.637Z[UTC]] moved to OPEN state
scm_1    | 2023-03-10 22:41:59,024 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1    | 2023-03-10 22:41:59,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1    | 2023-03-10 22:41:59,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1    | 2023-03-10 22:41:59,046 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1    | 2023-03-10 22:41:59,054 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2023-03-10 22:41:59,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm_1    | 2023-03-10 22:41:59,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm_1    | 2023-03-10 22:41:59,058 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm_1    | 2023-03-10 22:41:59,647 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 2d4f1397-2cdc-4336-a562-676bab171c02, Nodes: 3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3892a4e1-c878-42af-adb7-db66a90d61f4, CreationTimestamp2023-03-10T22:41:48.902Z[UTC]] moved to OPEN state
scm_1    | 2023-03-10 22:41:59,879 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8581ae3d-c50a-4a49-9d70-d98e5419b7a9, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e78c5ce1-46ab-4889-a0cd-5903ae46614d, CreationTimestamp2023-03-10T22:41:48.781Z[UTC]] moved to OPEN state
scm_1    | 2023-03-10 22:42:14,166 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cf0cdca9-af45-4cc0-9366-0049fbbc23b3, Nodes: e78c5ce1-46ab-4889-a0cd-5903ae46614d{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e3e4587c-aa42-4e86-ae9a-d3e448365275{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:e3e4587c-aa42-4e86-ae9a-d3e448365275, CreationTimestamp2023-03-10T22:41:48.535Z[UTC]] moved to OPEN state
scm_1    | 2023-03-10 22:42:14,879 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 54b523a6-4d1d-4f07-a057-5b98fdc36f00, Nodes: 1a6d358d-6662-4447-914c-d709a67ff716{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}178b30e1-b74d-4f4d-a142-c930eee71455{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3892a4e1-c878-42af-adb7-db66a90d61f4{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3892a4e1-c878-42af-adb7-db66a90d61f4, CreationTimestamp2023-03-10T22:41:48.739Z[UTC]] moved to OPEN state
scm_1    | 2023-03-10 22:42:35,093 [IPC Server handler 77 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm_1    | 2023-03-10 22:42:35,113 [IPC Server handler 77 on default port 9863] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
scm_1    | 2023-03-10 22:42:35,114 [IPC Server handler 77 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
