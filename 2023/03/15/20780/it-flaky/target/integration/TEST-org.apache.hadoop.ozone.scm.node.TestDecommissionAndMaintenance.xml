<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="281.601" tests="7" errors="1" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.86.Final/netty-codec-http2-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.86.Final/netty-common-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.86.Final/netty-buffer-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.86.Final/netty-codec-http-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.86.Final/netty-handler-proxy-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.86.Final/netty-codec-socks-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.54.Final/netty-tcnative-classes-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-managed-rocksdb/1.4.0-SNAPSHOT/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.49.v20220914/jetty-client-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.13/httpcore-nio-4.4.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.86.Final/netty-transport-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.86.Final/netty-resolver-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.86.Final/netty-transport-native-epoll-4.1.86.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.86.Final/netty-transport-classes-epoll-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.86.Final/netty-transport-native-unix-common-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.86.Final/netty-codec-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.86.Final/netty-handler-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="java.vm.vendor" value="Temurin"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://adoptium.net/"/>
    <property name="user.timezone" value="Etc/UTC"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter4366525350353617218.jar /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire 2023-03-15T02-12-06_981-jvmRun1 surefire5579366905322179374tmp surefire_76227848612297220444tmp"/>
    <property name="surefire.test.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.86.Final/netty-codec-http2-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.86.Final/netty-common-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.86.Final/netty-buffer-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.86.Final/netty-codec-http-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.86.Final/netty-handler-proxy-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.86.Final/netty-codec-socks-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.54.Final/netty-tcnative-classes-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-managed-rocksdb/1.4.0-SNAPSHOT/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.49.v20220914/jetty-client-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.13/httpcore-nio-4.4.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.86.Final/netty-transport-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.86.Final/netty-resolver-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.86.Final/netty-transport-native-epoll-4.1.86.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.86.Final/netty-transport-classes-epoll-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.86.Final/netty-transport-native-unix-common-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.86.Final/netty-codec-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.86.Final/netty-handler-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/runner"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="skip.installnpx" value="true"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.fork.timeout" value="3600"/>
    <property name="surefire.real.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter4366525350353617218.jar:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_362-b09"/>
    <property name="skip.npx" value="true"/>
    <property name="user.name" value="runner"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="5.15.0-1034-azure"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/runner/.m2/repository"/>
    <property name="jetty.git.hash" value="4231a3b2e4cb8548a412a789936d640a97b1aa0a"/>
    <property name="java.vendor.url.bug" value="https://github.com/adoptium/adoptium-support/issues"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="java.version" value="1.8.0_362"/>
    <property name="surefire.rerunFailingTestsCount" value="5"/>
    <property name="user.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="test.build.classes" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="org.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads" value="false"/>
    <property name="hadoop.tmp.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vendor" value="Temurin"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.362-b09"/>
    <property name="java.specification.maintenance.version" value="4"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testNodeWithOpenPipelineCanBeDecommissionedAndRecommissioned" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="53.831"/>
  <testcase name="testContainerIsReplicatedWhenAllNodesGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="44.426"/>
  <testcase name="testMaintenanceEndsAutomaticallyAtTimeout" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="35.423"/>
  <testcase name="testSingleNodeWithOpenPipelineCanGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="42.23"/>
  <testcase name="testSCMHandlesRestartForMaintenanceNode" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="48.619">
    <error type="java.util.concurrent.TimeoutException"><![CDATA[java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2023-03-15 02:22:51,208

"BlockDeletingService#3" daemon prio=5 tid=6354 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1804-thread-1"  prio=5 tid=4302 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3859 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 44419" daemon prio=5 tid=5455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=6327 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5823 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 35751" daemon prio=5 tid=5409 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 12 on default port 36109" daemon prio=5 tid=4546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=4222 runnable
java.lang.Thread.State: RUNNABLE
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1762625636-3652" daemon prio=5 tid=3652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3708 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6a4dbde0-2827-4051-b593-1eb8ab0ee225@group-CF73E13F09DA-FollowerState" daemon prio=5 tid=5089 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=4223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-SegmentedRaftLogWorker"  prio=5 tid=6094 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3673 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp68594061-3560" daemon prio=5 tid=3560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 41473" daemon prio=5 tid=6298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server idle connection scanner for port 44419" daemon prio=5 tid=5379 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-SegmentedRaftLogWorker"  prio=5 tid=6102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 37433" daemon prio=5 tid=5531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=5913 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"1847c06b-5456-44fe-a2e2-332407f19896-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5809 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 33213" daemon prio=5 tid=4296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870->42380981-9e90-41f5-811d-3bbbf08d47d9-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 41473" daemon prio=5 tid=6296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=4213 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"ChunkWriter-3-0" daemon prio=5 tid=5940 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1682214758-4309" daemon prio=5 tid=4309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5841 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6a4dbde0-2827-4051-b593-1eb8ab0ee225@group-5F588D3E4CA0-LeaderStateImpl" daemon prio=5 tid=5060 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Periodic HDDS volume checker" daemon prio=5 tid=3676 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=6212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1520-thread-1" daemon prio=5 tid=3549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@55bf5cee" daemon prio=5 tid=3543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"cdc3fd6e-e759-42d4-8e19-947196a05030-server-thread2" daemon prio=5 tid=5158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 40195" daemon prio=5 tid=4276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-0"  prio=5 tid=5403 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4722 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44419 - 0 "  prio=5 tid=5936 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-2"  prio=5 tid=5490 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp531720972-3518" daemon prio=5 tid=3518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3579 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3787 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5753 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"480de393-893d-4d82-b81f-696ceb757cb1@group-9BBA42843B5D-SegmentedRaftLogWorker"  prio=5 tid=4988 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=3613 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ChunkReader-ELG-0" daemon prio=5 tid=4902 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4646 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=4176 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44419 - 0 "  prio=5 tid=5842 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c86f293d-b980-46b7-b4bb-ca602f6dc485-impl-thread1"  prio=5 tid=5630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5918 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"9b1f5799-4694-44ac-95a8-dde5d0689021@group-006A9A69ACB7-LeaderStateImpl" daemon prio=5 tid=5054 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ChunkWriter-0-0" daemon prio=5 tid=5882 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 33991" daemon prio=5 tid=6282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=3861 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-StateMachineUpdater" daemon prio=5 tid=6107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-StateMachineUpdater" daemon prio=5 tid=6116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3761 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4762 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2641-thread-1"  prio=5 tid=5812 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer3" daemon prio=5 tid=540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp712213994-5608" daemon prio=5 tid=5608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"59495bd3-eca8-4664-a537-a989ac7b0d80@group-CF73E13F09DA->6a4dbde0-2827-4051-b593-1eb8ab0ee225-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5092 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-2285DC16387D-StateMachineUpdater" daemon prio=5 tid=3972 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-0" daemon prio=5 tid=474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-3"  prio=5 tid=5494 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137087653-4849" daemon prio=5 tid=4849 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3118 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2175-thread-1"  prio=5 tid=4817 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@407e21c7" daemon prio=5 tid=4765 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 33213" daemon prio=5 tid=4282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=4214 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"BlockDeletingService#1" daemon prio=5 tid=5855 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5309 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor46" daemon prio=5 tid=4941 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp823157585-5522" daemon prio=5 tid=5522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4946 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2094-thread-1" daemon prio=5 tid=4731 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp368409287-3625" daemon prio=5 tid=3625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp136986031-4590-acceptor-0@61bec753-ServerConnector@33bec79d{HTTP/1.1, (http/1.1)}{0.0.0.0:46503}" daemon prio=3 tid=4590 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp177859206-5816" daemon prio=5 tid=5816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-8"  prio=5 tid=5710 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@750a3ded" daemon prio=5 tid=5601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5162 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 36109" daemon prio=5 tid=4552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"9b1f5799-4694-44ac-95a8-dde5d0689021@group-9BBA42843B5D-SegmentedRaftLogWorker"  prio=5 tid=4979 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 37571" daemon prio=5 tid=6260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1018617286-4822" daemon prio=5 tid=4822 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2482-thread-1" daemon prio=5 tid=5597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5381 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server handler 6 on default port 36109" daemon prio=5 tid=4540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 39711" daemon prio=5 tid=5438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"9f4b8ec3-f353-4948-b4fc-413f1dfec88e@group-16937DA64123-StateMachineUpdater" daemon prio=5 tid=5050 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 41473" daemon prio=5 tid=6288 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp368409287-3623" daemon prio=5 tid=3623 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor40" daemon prio=5 tid=3886 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=704 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5853 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4215 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"EndpointStateMachine task thread for /0.0.0.0:33213 - 0 "  prio=5 tid=4917 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 36109" daemon prio=5 tid=4536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp659628497-5765" daemon prio=5 tid=5765 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4924 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp531720972-3515-acceptor-0@2d01b553-ServerConnector@576db38e{HTTP/1.1, (http/1.1)}{0.0.0.0:35493}" daemon prio=3 tid=3515 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderStateImpl" daemon prio=5 tid=6174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Session-HouseKeeper-2c94c051-1"  prio=5 tid=4826 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cdc3fd6e-e759-42d4-8e19-947196a05030@group-42F8EC9463AC-LeaderStateImpl" daemon prio=5 tid=5056 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 7 on default port 37433" daemon prio=5 tid=5533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp849456214-5702" daemon prio=5 tid=5702 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderStateImpl" daemon prio=5 tid=6147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Parameter Sending Thread #1" daemon prio=5 tid=693 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4802 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1762625636-3657" daemon prio=5 tid=3657 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"9b1f5799-4694-44ac-95a8-dde5d0689021@group-9BBA42843B5D-StateMachineUpdater" daemon prio=5 tid=4981 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=4221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-2"  prio=5 tid=5491 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3877 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5175 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp136986031-4593" daemon prio=5 tid=4593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Timer-5"  prio=5 tid=4513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 17 on default port 33213" daemon prio=5 tid=4297 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1358372967-4892" daemon prio=5 tid=4892 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5183 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2455-thread-1"  prio=5 tid=5516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3267 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 44419" daemon prio=5 tid=5467 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp195362258-4679" daemon prio=5 tid=4679 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9-server-thread1" daemon prio=5 tid=6158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=4220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4948 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=3511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2112 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 33213" daemon prio=5 tid=4284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DatanodeAdminManager-0" daemon prio=5 tid=4205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 34223" daemon prio=5 tid=3541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 16 on default port 41473" daemon prio=5 tid=6302 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp849456214-5704" daemon prio=5 tid=5704 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 36135" daemon prio=5 tid=4242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 7 on default port 33213" daemon prio=5 tid=4287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5660 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=6326 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1018617286-4824" daemon prio=5 tid=4824 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLogWorker"  prio=5 tid=6080 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor51" daemon prio=5 tid=5509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 44419" daemon prio=5 tid=5466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=5848 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-62c05271-1"  prio=5 tid=4894 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 37433" daemon prio=5 tid=5545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 41473" daemon prio=5 tid=6286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5829 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 36109" daemon prio=5 tid=4537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=4506 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"pool-2413-thread-1"  prio=5 tid=5470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 33213" daemon prio=5 tid=4295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 15 on default port 37571" daemon prio=5 tid=6261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 1 on default port 36135" daemon prio=5 tid=4240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=5799 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp659628497-5769" daemon prio=5 tid=5769 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=5393 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-5"  prio=5 tid=5648 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3640 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=6057 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5844 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=5369 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3805 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 33991" daemon prio=5 tid=6274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 33213" daemon prio=5 tid=4293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1080956843-3688" daemon prio=5 tid=3688 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9-impl-thread1"  prio=5 tid=5600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4930 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6a4dbde0-2827-4051-b593-1eb8ab0ee225@group-CF73E13F09DA-SegmentedRaftLogWorker"  prio=5 tid=5007 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp68594061-3557-acceptor-0@60dfa95b-ServerConnector@6b5b03f3{HTTP/1.1, (http/1.1)}{0.0.0.0:45377}" daemon prio=3 tid=3557 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-3"  prio=5 tid=5492 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4791 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp712213994-5607" daemon prio=5 tid=5607 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3889 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3785 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp587286553-4743" daemon prio=5 tid=4743 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp823157585-5518" daemon prio=5 tid=5518 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5663 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c86f293d-b980-46b7-b4bb-ca602f6dc485-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5629 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=5391 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=5514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-impl-thread1"  prio=5 tid=5498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 36135" daemon prio=5 tid=4216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-StateMachineUpdater" daemon prio=5 tid=6062 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp88182619-4780" daemon prio=5 tid=4780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3275 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 37571" daemon prio=5 tid=6254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp368409287-3629" daemon prio=5 tid=3629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 44419" daemon prio=5 tid=5450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1682214758-4307" daemon prio=5 tid=4307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 37571" daemon prio=5 tid=6258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState" daemon prio=5 tid=6173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@2212c97e" daemon prio=5 tid=3735 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp659628497-5767" daemon prio=5 tid=5767 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@11b719cb" daemon prio=5 tid=3765 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp68594061-3561" daemon prio=5 tid=3561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5822 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp849456214-5703" daemon prio=5 tid=5703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLogWorker"  prio=5 tid=6060 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5380 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"480de393-893d-4d82-b81f-696ceb757cb1@group-9BBA42843B5D-LeaderStateImpl" daemon prio=5 tid=5152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1535-thread-1"  prio=5 tid=3555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=5392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4942 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread #2" daemon prio=5 tid=5177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 41473" daemon prio=5 tid=6300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-StateMachineUpdater" daemon prio=5 tid=6089 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 35751" daemon prio=5 tid=5422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=4503 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5754 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1653-thread-1"  prio=5 tid=3976 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3705 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-56e50be6-1"  prio=5 tid=4786 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4899 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3871 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp68594061-3563" daemon prio=5 tid=3563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5884 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 39711" daemon prio=5 tid=5439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2105-thread-1"  prio=5 tid=4987 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4929 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4912 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5650ff5c-2f39-425b-bee4-adddfcfb793b-server-thread3" daemon prio=5 tid=4043 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5190 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5891 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3822 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1672-thread-1" daemon prio=5 tid=3770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5731 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4913 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1571-thread-1"  prio=5 tid=3934 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 34223" daemon prio=5 tid=3525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DatanodeAdminManager-0" daemon prio=5 tid=6219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=5513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp136986031-4596" daemon prio=5 tid=4596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-2285DC16387D-SegmentedRaftLogWorker"  prio=5 tid=3970 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4957 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3661 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp659628497-5768" daemon prio=5 tid=5768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=4922 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 44419" daemon prio=5 tid=5463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-5"  prio=5 tid=5645 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp195362258-4683" daemon prio=5 tid=4683 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5573 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3271 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 37571" daemon prio=5 tid=6257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1579-thread-1"  prio=5 tid=3622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp68594061-3559" daemon prio=5 tid=3559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3634 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 35751" daemon prio=5 tid=5410 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=5942 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 36135" daemon prio=5 tid=4237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=6242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server listener on 0" daemon prio=5 tid=5502 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"ChunkReader-ELG-0" daemon prio=5 tid=5930 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1755303688-6316" daemon prio=5 tid=6316 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-8"  prio=5 tid=5707 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4895 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp141780135-4526" daemon prio=5 tid=4526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1980139489-5476" daemon prio=5 tid=5476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 33213" daemon prio=5 tid=4280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp177859206-5817" daemon prio=5 tid=5817 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137087653-4848" daemon prio=5 tid=4848 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-14e6bc76-1"  prio=5 tid=3564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5921 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6342 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=5511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=701 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 36135" daemon prio=5 tid=4243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=5803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp88182619-4778" daemon prio=5 tid=4778 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4056 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5739 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5937 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1446142935-5868" daemon prio=5 tid=5868 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 39711" daemon prio=5 tid=5433 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp531720972-3519" daemon prio=5 tid=3519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5946 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1429ab0f" daemon prio=5 tid=5878 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-20c0a673-1"  prio=5 tid=5705 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6a4dbde0-2827-4051-b593-1eb8ab0ee225@group-5F588D3E4CA0-StateMachineUpdater" daemon prio=5 tid=5003 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=4508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1358372967-4887-acceptor-0@469b4957-ServerConnector@c02ff73{HTTP/1.1, (http/1.1)}{0.0.0.0:33361}" daemon prio=3 tid=4887 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4766 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3856 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2113 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@ddc9fe6" daemon prio=5 tid=5622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:33213 - 0 "  prio=5 tid=4949 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4911 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"480de393-893d-4d82-b81f-696ceb757cb1@group-8D7E7099420A-StateMachineUpdater" daemon prio=5 tid=4999 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5847 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4806 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1161646926-3783" daemon prio=5 tid=3783 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 41473" daemon prio=5 tid=6293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=6214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/1514067012.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3715 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1762625636-3653" daemon prio=5 tid=3653 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-7"  prio=5 tid=5655 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5185 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 41473" daemon prio=5 tid=6294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4868 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4b011a83" daemon prio=5 tid=4776 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=3509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4960 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1682214758-4303" daemon prio=5 tid=4303 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3717 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41473 - 0 "  prio=5 tid=3704 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 40195" daemon prio=5 tid=4268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp712213994-5609" daemon prio=5 tid=5609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 35751" daemon prio=5 tid=5415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 34223" daemon prio=5 tid=3537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1682214758-4308" daemon prio=5 tid=4308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2117-thread-1"  prio=5 tid=4738 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4956 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 37571" daemon prio=5 tid=6246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 36135" daemon prio=5 tid=4249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=5948 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2671-thread-1"  prio=5 tid=5861 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-StateMachineUpdater" daemon prio=5 tid=6059 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-1ea2bb52-1"  prio=5 tid=4531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5827 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3863 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp712213994-5603" daemon prio=5 tid=5603 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-1007-thread-1"  prio=5 tid=2366 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-7"  prio=5 tid=5657 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1018617286-4818" daemon prio=5 tid=4818 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5845 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp659628497-5762" daemon prio=5 tid=5762 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 36135" daemon prio=5 tid=4254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 37433" daemon prio=5 tid=5526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server handler 7 on default port 34223" daemon prio=5 tid=3530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"timer5" daemon prio=5 tid=551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp823157585-5519" daemon prio=5 tid=5519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2508-thread-1" daemon prio=5 tid=5627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3828 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=6306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1682214758-4306" daemon prio=5 tid=4306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4864 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-487d5fdb-1"  prio=5 tid=4684 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 35751" daemon prio=5 tid=5426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor58" daemon prio=5 tid=5941 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5676 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp712213994-5606" daemon prio=5 tid=5606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 36109" daemon prio=5 tid=4538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1080956843-3685-acceptor-0@19ebacea-ServerConnector@7f2e0f2b{HTTP/1.1, (http/1.1)}{0.0.0.0:38103}" daemon prio=3 tid=3685 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 37433" daemon prio=5 tid=5538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=3823 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5733 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4865 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 36109" daemon prio=5 tid=4548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"OMDoubleBufferFlushThread" daemon prio=5 tid=4405 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:614)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$546/495796856.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4969 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@540eec21" daemon prio=5 tid=5665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"9b1f5799-4694-44ac-95a8-dde5d0689021-server-thread1" daemon prio=5 tid=5155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4207 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"pool-1923-thread-1"  prio=5 tid=4520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4910 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=4201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/1514067012.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"f66a9549-37e5-4f01-8484-0c21eaa44150@group-CF73E13F09DA-SegmentedRaftLogWorker"  prio=5 tid=5030 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=5376 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5925 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4963 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=4919 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6348 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1080956843-3691" daemon prio=5 tid=3691 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp823157585-5520" daemon prio=5 tid=5520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=3510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-1" daemon prio=5 tid=6337 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6b109e20-fb43-4126-a2d0-e01a40c07237-server-thread2" daemon prio=5 tid=6206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-3"  prio=5 tid=5642 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=5397 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"480de393-893d-4d82-b81f-696ceb757cb1-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4734 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 37571" daemon prio=5 tid=6264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp157054014-5637" daemon prio=5 tid=5637 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=3502 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"qtp587286553-4741" daemon prio=5 tid=4741 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 40195" daemon prio=5 tid=4279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 9 on default port 37571" daemon prio=5 tid=6255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2453-thread-1"  prio=5 tid=5499 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5888 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1762625636-3656" daemon prio=5 tid=3656 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"prometheus" daemon prio=5 tid=6244 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5801 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 34223" daemon prio=5 tid=3526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3758 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3891 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 36135" daemon prio=5 tid=4241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=4962 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor43" daemon prio=5 tid=4862 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-5"  prio=5 tid=5650 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 34223" daemon prio=5 tid=3523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ReplicationMonitor" daemon prio=5 tid=5373 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:795)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$424/297895050.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 39711" daemon prio=5 tid=5443 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5840 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59495bd3-eca8-4664-a537-a989ac7b0d80@group-CF73E13F09DA-LeaderStateImpl" daemon prio=5 tid=5090 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Command processor thread" daemon prio=5 tid=5877 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3632 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137087653-4845" daemon prio=5 tid=4845 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1018617286-4821" daemon prio=5 tid=4821 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3659 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 44419" daemon prio=5 tid=5457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5189 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1980139489-5471" daemon prio=5 tid=5471 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-5" daemon prio=5 tid=547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4804 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 37571"  prio=5 tid=6229 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"qtp587286553-4744" daemon prio=5 tid=4744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 33213" daemon prio=5 tid=4289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4788 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1080956843-3689" daemon prio=5 tid=3689 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"132d3d80-0103-4f41-b942-b9d80c35d5a5@group-082D0680124B-SegmentedRaftLogWorker"  prio=5 tid=3989 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 41473" daemon prio=5 tid=6299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 41473" daemon prio=5 tid=6292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 9 on default port 36109" daemon prio=5 tid=4543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=708 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5386 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server handler 5 on default port 33213" daemon prio=5 tid=4285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3660 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 40195" daemon prio=5 tid=4275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-StateMachineUpdater" daemon prio=5 tid=3949 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-4" daemon prio=5 tid=545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp141780135-4524-acceptor-0@6bfe276b-ServerConnector@591631e5{HTTP/1.1, (http/1.1)}{0.0.0.0:35903}" daemon prio=3 tid=4524 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->5650ff5c-2f39-425b-bee4-adddfcfb793b-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=4037 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=2092 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-3251b0b7-1"  prio=5 tid=3631 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4938 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp136986031-4594" daemon prio=5 tid=4594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5377 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"DirectoryDeletingService#0" daemon prio=5 tid=4515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=6235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5732 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-23AD5C6690D5-StateMachineUpdater" daemon prio=5 tid=3995 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"process reaper" daemon prio=10 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5828 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-LeaderStateImpl" daemon prio=5 tid=4022 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"timer6" daemon prio=5 tid=682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"JvmPauseMonitor54" daemon prio=5 tid=5851 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3718 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=4921 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp849456214-5699" daemon prio=5 tid=5699 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1755303688-6313" daemon prio=5 tid=6313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 37571" daemon prio=5 tid=6256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=4965 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4898 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=4226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4789 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6330 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-2"  prio=5 tid=5243 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 41473" daemon prio=5 tid=6289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor39" daemon prio=5 tid=3872 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4640 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1080956843-3690" daemon prio=5 tid=3690 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:33213 - 0 "  prio=5 tid=4961 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 36109" daemon prio=5 tid=4550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-8ee1315-1"  prio=5 tid=4853 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3268 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 37571" daemon prio=5 tid=6253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1137087653-4851" daemon prio=5 tid=4851 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp376997535-3742" daemon prio=5 tid=3742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44419 - 0 "  prio=5 tid=5902 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor48" daemon prio=5 tid=4966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5945 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4758 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 35751" daemon prio=5 tid=5418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp587286553-4740-acceptor-0@7fc2a9d-ServerConnector@45d47dbc{HTTP/1.1, (http/1.1)}{0.0.0.0:35807}" daemon prio=3 tid=4740 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3710 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5938 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-SegmentedRaftLogWorker"  prio=5 tid=3986 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5943 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-9"  prio=5 tid=5712 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:33213 - 0 "  prio=5 tid=4855 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 33213" daemon prio=5 tid=4292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 37571" daemon prio=5 tid=6228 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=6241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2239-thread-1"  prio=5 tid=4885 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 37571" daemon prio=5 tid=6248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"OMDoubleBufferFlushThread" daemon prio=5 tid=5497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:614)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$546/495796856.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=5390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3723 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4719 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137087653-4847" daemon prio=5 tid=4847 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-StateMachineUpdater" daemon prio=5 tid=6084 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 35751" daemon prio=5 tid=5421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 33213" daemon prio=5 tid=4290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=3788 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@6178d698" daemon prio=5 tid=5811 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp531720972-3517" daemon prio=5 tid=3517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 39711" daemon prio=5 tid=5429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ed5356af-2dee-4266-b55e-559e8c0d6889@group-F3AF78373E13-StateMachineUpdater" daemon prio=5 tid=3925 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 37571" daemon prio=5 tid=6247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-6"  prio=5 tid=5653 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3865 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp136986031-4589" daemon prio=5 tid=4589 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp68594061-3556" daemon prio=5 tid=3556 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6331 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 39711" daemon prio=5 tid=5441 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"9b1f5799-4694-44ac-95a8-dde5d0689021-server-thread2" daemon prio=5 tid=5157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-48f3e54f-1"  prio=5 tid=4747 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 37571" daemon prio=5 tid=6230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ChunkWriter-2-0" daemon prio=5 tid=4801 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=4219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp849456214-5697" daemon prio=5 tid=5697 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-2031-thread-1"  prio=5 tid=4982 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1018617286-4819-acceptor-0@69b3a09e-ServerConnector@1edf82b5{HTTP/1.1, (http/1.1)}{0.0.0.0:37459}" daemon prio=3 tid=4819 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=4173 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-9"  prio=5 tid=5708 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=4204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:147)
        at java.lang.Thread.run(Thread.java:750)
"qtp88182619-4779-acceptor-0@2710b702-ServerConnector@61b58237{HTTP/1.1, (http/1.1)}{0.0.0.0:36343}" daemon prio=3 tid=4779 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5-server-thread1" daemon prio=5 tid=6159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 44419" daemon prio=5 tid=5461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp195362258-4678" daemon prio=5 tid=4678 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=4225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@708ea59f" daemon prio=5 tid=4587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5928 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cdc3fd6e-e759-42d4-8e19-947196a05030-server-thread1" daemon prio=5 tid=5156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2497-thread-1"  prio=5 tid=5602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1358372967-4890" daemon prio=5 tid=4890 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 40195" daemon prio=5 tid=4277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1601-thread-1"  prio=5 tid=3649 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@69c72879" daemon prio=5 tid=5760 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4729 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=6238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3646 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-1476-thread-1"  prio=5 tid=3453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 40195" daemon prio=5 tid=4263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 17 on default port 41473" daemon prio=5 tid=6303 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-StateMachineUpdater" daemon prio=5 tid=6132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4867 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5806 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=5396 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=6329 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=5398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4874 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2134-thread-1" daemon prio=5 tid=4772 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5666 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6a4dbde0-2827-4051-b593-1eb8ab0ee225@group-5F588D3E4CA0-SegmentedRaftLogWorker"  prio=5 tid=5001 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4211 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"EndpointStateMachine task thread for /0.0.0.0:33213 - 0 "  prio=5 tid=4936 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4055 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2785-thread-1"  prio=5 tid=6308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-6"  prio=5 tid=5652 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5922 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4859 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1755303688-6315" daemon prio=5 tid=6315 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 39711" daemon prio=5 tid=5440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-StateMachineUpdater" daemon prio=5 tid=6082 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5920 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cdc3fd6e-e759-42d4-8e19-947196a05030@group-9BBA42843B5D-SegmentedRaftLogWorker"  prio=5 tid=4983 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp376997535-3741" daemon prio=5 tid=3741 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp376997535-3740" daemon prio=5 tid=3740 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4971 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=4920 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3635 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f66a9549-37e5-4f01-8484-0c21eaa44150-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4841 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1358372967-4893" daemon prio=5 tid=4893 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=4511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3724 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=6217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:147)
        at java.lang.Thread.run(Thread.java:750)
"1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderStateImpl" daemon prio=5 tid=6199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server idle connection scanner for port 35751" daemon prio=5 tid=5387 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"480de393-893d-4d82-b81f-696ceb757cb1@group-8D7E7099420A-LeaderStateImpl" daemon prio=5 tid=5058 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Periodic HDDS volume checker" daemon prio=5 tid=3729 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 33991" daemon prio=5 tid=6281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp368409287-3624-acceptor-0@69397925-ServerConnector@7e2c3f9d{HTTP/1.1, (http/1.1)}{0.0.0.0:42413}" daemon prio=3 tid=3624 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=4218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=6234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp376997535-3738-acceptor-0@49114988-ServerConnector@32d8a593{HTTP/1.1, (http/1.1)}{0.0.0.0:46247}" daemon prio=3 tid=3738 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp531720972-3514" daemon prio=5 tid=3514 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 37571" daemon prio=5 tid=6265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=5887 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 35751" daemon prio=5 tid=5417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=4799 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=3503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2160-thread-1" daemon prio=5 tid=4812 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5740 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4943 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"480de393-893d-4d82-b81f-696ceb757cb1@group-9BBA42843B5D->cdc3fd6e-e759-42d4-8e19-947196a05030-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1446142935-5862" daemon prio=5 tid=5862 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 35751" daemon prio=5 tid=5414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderStateImpl" daemon prio=5 tid=6208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=6240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-4"  prio=5 tid=3507 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Command processor thread" daemon prio=5 tid=5737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3794 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41473 - 0 "  prio=5 tid=3867 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3766 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4915 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3709 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 44419" daemon prio=5 tid=5449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5794 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"646e529a-a01f-4b15-a31a-2706cdf8d47d-server-thread2" daemon prio=5 tid=6180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1308394587-5557" daemon prio=5 tid=5557 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 44419" daemon prio=5 tid=5453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=709 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"71dc2d0c-c132-482e-adc3-0da69386d6d8-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5693 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3790 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6341 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2596-thread-1" daemon prio=5 tid=5755 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp823157585-5523" daemon prio=5 tid=5523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"cdc3fd6e-e759-42d4-8e19-947196a05030@group-42F8EC9463AC-StateMachineUpdater" daemon prio=5 tid=4996 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 36135" daemon prio=5 tid=4258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 16 on default port 37571" daemon prio=5 tid=6262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5932 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9b1f5799-4694-44ac-95a8-dde5d0689021-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4583 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 36109" daemon prio=5 tid=4547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4790 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7c12cad" daemon prio=5 tid=5631 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-0"  prio=5 tid=5401 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4959 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3974a42" daemon prio=5 tid=4673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"pool-2489-thread-1"  prio=5 tid=6068 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5163 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1755303688-6314" daemon prio=5 tid=6314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-478cb8-1"  prio=5 tid=5611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp136986031-4591" daemon prio=5 tid=4591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5889 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1682214758-4310" daemon prio=5 tid=4310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3854 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1308394587-5563" daemon prio=5 tid=5563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 33213" daemon prio=5 tid=4299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp141780135-4530" daemon prio=5 tid=4530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-3e710e44-1"  prio=5 tid=5564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9b1f5799-4694-44ac-95a8-dde5d0689021@group-006A9A69ACB7-StateMachineUpdater" daemon prio=5 tid=4978 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"b83605a3-0dba-4f7c-9b88-55eff2caaffe-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3772 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp157054014-5634-acceptor-0@7fe64cf-ServerConnector@7a3657df{HTTP/1.1, (http/1.1)}{0.0.0.0:41905}" daemon prio=3 tid=5634 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 39711" daemon prio=5 tid=5446 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-SegmentedRaftLogWorker"  prio=5 tid=3947 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4805 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5876 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 36109" daemon prio=5 tid=4505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-StateMachineUpdater" daemon prio=5 tid=3988 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 37571" daemon prio=5 tid=6251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->132d3d80-0103-4f41-b942-b9d80c35d5a5-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=4036 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1687-thread-1"  prio=5 tid=3775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6b109e20-fb43-4126-a2d0-e01a40c07237-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5758 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-1817-thread-1"  prio=5 tid=4365 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp368409287-3626" daemon prio=5 tid=3626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 44419" daemon prio=5 tid=5459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"SCMBlockDeletingService#0" daemon prio=5 tid=4300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-287-thread-1"  prio=5 tid=694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 33991" daemon prio=5 tid=6273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=5915 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3707 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp659628497-5763-acceptor-0@20ae9b53-ServerConnector@90fe933{HTTP/1.1, (http/1.1)}{0.0.0.0:42577}" daemon prio=3 tid=5763 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4810 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=5394 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3870 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1446142935-5869" daemon prio=5 tid=5869 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2149-thread-1"  prio=5 tid=4777 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B-SegmentedRaftLogWorker"  prio=5 tid=3973 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1755303688-6310-acceptor-0@31b2c0ab-ServerConnector@6e70861{HTTP/1.1, (http/1.1)}{0.0.0.0:33917}" daemon prio=3 tid=6310 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5914 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 36109" daemon prio=5 tid=4544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4873 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-8"  prio=5 tid=5706 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6231 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=5372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/1514067012.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"132d3d80-0103-4f41-b942-b9d80c35d5a5@group-A3695F9F7B6B-FollowerState" daemon prio=5 tid=4034 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server idle connection scanner for port 40195" daemon prio=5 tid=4212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-2566-thread-1"  prio=5 tid=6101 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5750 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 37571" daemon prio=5 tid=6252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderStateImpl" daemon prio=5 tid=6210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"EndpointStateMachine task thread for /0.0.0.0:44419 - 0 "  prio=5 tid=5741 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1308394587-5562" daemon prio=5 tid=5562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 39711" daemon prio=5 tid=5427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"646e529a-a01f-4b15-a31a-2706cdf8d47d-server-thread3" daemon prio=5 tid=6181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp712213994-5604" daemon prio=5 tid=5604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (140648931) connection to 0.0.0.0/0.0.0.0:44419 from runner" daemon prio=5 tid=5742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"IPC Server handler 6 on default port 33213" daemon prio=5 tid=4286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-SegmentedRaftLogWorker"  prio=5 tid=3982 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5568 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp177859206-5820" daemon prio=5 tid=5820 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3858 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4869 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fcf6611" daemon prio=5 tid=3582 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4724 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4832 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4795 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState" daemon prio=5 tid=6198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Socket Reader #1 for port 0"  prio=5 tid=4504 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"SnapshotDeletingService#0" daemon prio=5 tid=3512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"71dc2d0c-c132-482e-adc3-0da69386d6d8-server-thread3" daemon prio=5 tid=6204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 39711" daemon prio=5 tid=5445 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLogWorker"  prio=5 tid=6114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 36135" daemon prio=5 tid=4245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 37571" daemon prio=5 tid=6250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp368409287-3627" daemon prio=5 tid=3627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 37433" daemon prio=5 tid=5542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=4837 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5832 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 37433" daemon prio=5 tid=5529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5651 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5617 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5161 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-StateMachineUpdater" daemon prio=5 tid=6096 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp849456214-5700" daemon prio=5 tid=5700 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 35751" daemon prio=5 tid=5406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-2e8eafb2-1"  prio=5 tid=6317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2611-thread-1"  prio=5 tid=5761 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 39711" daemon prio=5 tid=5434 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4054 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5595 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5184 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=4200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/1514067012.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@619099e3" daemon prio=5 tid=3639 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5880 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb24641f-ac05-4a48-a34b-331e584b8427-impl-thread1"  prio=5 tid=5859 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp177859206-5813" daemon prio=5 tid=5813 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-1178880-1"  prio=5 tid=5770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5187 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3722 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1564-thread-1" daemon prio=5 tid=3617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 34223" daemon prio=5 tid=3535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5934 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-6" daemon prio=5 tid=1345 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp136986031-4595" daemon prio=5 tid=4595 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1308394587-5561" daemon prio=5 tid=5561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-4"  prio=5 tid=5646 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4951 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137087653-4850" daemon prio=5 tid=4850 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44419 - 0 "  prio=5 tid=5807 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-11c5a0ce-1"  prio=5 tid=3692 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2652-thread-1" daemon prio=5 tid=5846 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderStateImpl" daemon prio=5 tid=6245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4906 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5662 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-1"  prio=5 tid=5405 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 35751" daemon prio=5 tid=5412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6355 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 33991" daemon prio=5 tid=6278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 39711" daemon prio=5 tid=5431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"59495bd3-eca8-4664-a537-a989ac7b0d80@group-CF73E13F09DA->f66a9549-37e5-4f01-8484-0c21eaa44150-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5091 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6346 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 33991" daemon prio=5 tid=6276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2197-thread-1"  prio=5 tid=4844 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5186 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"1847c06b-5456-44fe-a2e2-332407f19896-impl-thread1"  prio=5 tid=5810 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=475 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3802 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4939 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp195362258-4682" daemon prio=5 tid=4682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 36109" daemon prio=5 tid=4545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=2103 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 39711" daemon prio=5 tid=5442 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"f66a9549-37e5-4f01-8484-0c21eaa44150-server-thread3" daemon prio=5 tid=5096 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6352 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5919 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=4973 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=140 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 44419" daemon prio=5 tid=5462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4830 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 35751" daemon prio=5 tid=5411 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=4955 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp823157585-5524" daemon prio=5 tid=5524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1762625636-3655" daemon prio=5 tid=3655 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5879 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 33991" daemon prio=5 tid=6266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"null-request--thread1" daemon prio=5 tid=5400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4940 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6a4dbde0-2827-4051-b593-1eb8ab0ee225-server-thread1" daemon prio=5 tid=5097 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-17c5bb51-1"  prio=5 tid=3745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5796 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=5159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=473 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager" daemon prio=5 tid=6334 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 41473" daemon prio=5 tid=6297 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 37433" daemon prio=5 tid=5532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 37433" daemon prio=5 tid=5540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 36109" daemon prio=5 tid=4553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1661-thread-1"  prio=5 tid=3736 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"71dc2d0c-c132-482e-adc3-0da69386d6d8-impl-thread1"  prio=5 tid=5694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-7"  prio=5 tid=5658 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-23AD5C6690D5-LeaderStateImpl" daemon prio=5 tid=4050 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3829 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3796 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp531720972-3521" daemon prio=5 tid=3521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3825 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41473 - 0 "  prio=5 tid=3819 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp88182619-4784" daemon prio=5 tid=4784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3880 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5385 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"qtp88182619-4781" daemon prio=5 tid=4781 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp712213994-5605-acceptor-0@84c477f-ServerConnector@1655ebc7{HTTP/1.1, (http/1.1)}{0.0.0.0:34279}" daemon prio=3 tid=5605 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 36135" daemon prio=5 tid=4255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=5180 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4863 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-4"  prio=5 tid=5647 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 44419" daemon prio=5 tid=5451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1620-thread-1" daemon prio=5 tid=3678 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 41473"  prio=5 tid=6221 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4935 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3760 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-SegmentedRaftLogWorker"  prio=5 tid=6134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=6218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:147)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4927 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6351 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 36135" daemon prio=5 tid=4252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=3869 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125->646e529a-a01f-4b15-a31a-2706cdf8d47d-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor42" daemon prio=5 tid=4803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1980139489-5475" daemon prio=5 tid=5475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 40195" daemon prio=5 tid=4273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870->dda7196a-19a1-4ef5-a6eb-ce99792637b5-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-SegmentedRaftLogWorker"  prio=5 tid=6064 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3873 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E->6b109e20-fb43-4126-a2d0-e01a40c07237-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"9b1f5799-4694-44ac-95a8-dde5d0689021@group-9BBA42843B5D-FollowerState" daemon prio=5 tid=5150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-FollowerState" daemon prio=5 tid=4038 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 12 on default port 35751" daemon prio=5 tid=5419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp368409287-3628" daemon prio=5 tid=3628 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4763 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3703 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"646e529a-a01f-4b15-a31a-2706cdf8d47d-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3619 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5-impl-thread1"  prio=5 tid=5553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=6319 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 44419" daemon prio=5 tid=5454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"59495bd3-eca8-4664-a537-a989ac7b0d80-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4814 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 33991" daemon prio=5 tid=6269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:44419 - 0 "  prio=5 tid=5881 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 35751" daemon prio=5 tid=5420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 35751" daemon prio=5 tid=5413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"71dc2d0c-c132-482e-adc3-0da69386d6d8-server-thread2" daemon prio=5 tid=6203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2182-thread-1" daemon prio=5 tid=4839 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=3500 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=6322 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor47" daemon prio=5 tid=4954 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 36135" daemon prio=5 tid=4247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3583 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5873 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1446142935-5867" daemon prio=5 tid=5867 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:33213 - 0 "  prio=5 tid=4797 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@2039c6c7" daemon prio=5 tid=3804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=5893 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=5375 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:147)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=4516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5253 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3762 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 37433" daemon prio=5 tid=5536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 33991" daemon prio=5 tid=6270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"null-request--thread1" daemon prio=5 tid=5340 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp659628497-5766" daemon prio=5 tid=5766 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 127.0.0.1/37433"  prio=5 tid=14 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:353)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$createClusters$1(MiniOzoneClusterProvider.java:237)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$342/532677950.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"cdc3fd6e-e759-42d4-8e19-947196a05030@group-9BBA42843B5D-FollowerState" daemon prio=5 tid=5151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"ReplicationMonitor" daemon prio=5 tid=6216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:795)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$424/297895050.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=5508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-2429-thread-1"  prio=5 tid=5496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=6328 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=5894 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@45952b5c" daemon prio=5 tid=4843 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4721 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-SegmentedRaftLogWorker"  prio=5 tid=6109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-StateMachineUpdater" daemon prio=5 tid=6066 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp88182619-4785" daemon prio=5 tid=4785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5650ff5c-2f39-425b-bee4-adddfcfb793b-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3680 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5620 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6223 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"f66a9549-37e5-4f01-8484-0c21eaa44150-server-thread2" daemon prio=5 tid=5094 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5566 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3789 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3798 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer2" daemon prio=5 tid=539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"SnapshotDeletingService#0" daemon prio=5 tid=5515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"480de393-893d-4d82-b81f-696ceb757cb1@group-9BBA42843B5D-StateMachineUpdater" daemon prio=5 tid=4990 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 34223" daemon prio=5 tid=3533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=4958 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor41" daemon prio=5 tid=4512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4761 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-LeaderStateImpl" daemon prio=5 tid=4046 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3511c408" daemon prio=5 tid=3648 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f0a48a" daemon prio=5 tid=5800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp368409287-3630" daemon prio=5 tid=3630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4635 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1161646926-3778-acceptor-0@1c88534-ServerConnector@6f91c08d{HTTP/1.1, (http/1.1)}{0.0.0.0:36689}" daemon prio=3 tid=3778 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 41473" daemon prio=5 tid=6304 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-StateMachineUpdater" daemon prio=5 tid=6099 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5935 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4827 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=5892 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9f4b8ec3-f353-4948-b4fc-413f1dfec88e-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4882 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41473 - 0 "  prio=5 tid=3855 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3577 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4860 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5746 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4861 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 40195" daemon prio=5 tid=4269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor56" daemon prio=5 tid=5917 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=6321 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4800 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 35751" daemon prio=5 tid=5423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4727 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4964 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 40195" daemon prio=5 tid=4270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=4224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6333 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=5468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3883 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-8" daemon prio=5 tid=3132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2475-thread-1"  prio=5 tid=5555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp849456214-5698-acceptor-0@16b56833-ServerConnector@2a5d4a84{HTTP/1.1, (http/1.1)}{0.0.0.0:41919}" daemon prio=3 tid=5698 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4944 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5-server-thread2" daemon prio=5 tid=6161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 35751" daemon prio=5 tid=5424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=5897 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5885 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1358372967-4888" daemon prio=5 tid=4888 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 44419" daemon prio=5 tid=5452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-2bc0b9e-1"  prio=5 tid=5870 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5c500d63-1"  prio=5 tid=3522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9b1f5799-4694-44ac-95a8-dde5d0689021@group-006A9A69ACB7-SegmentedRaftLogWorker"  prio=5 tid=4976 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-9" daemon prio=5 tid=3133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 34223" daemon prio=5 tid=3538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5235 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5749 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3637 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 36109" daemon prio=5 tid=4549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 17 on default port 36135" daemon prio=5 tid=4256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4be1fddf" daemon prio=5 tid=4816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5503 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server idle connection scanner for port 41473" daemon prio=5 tid=6222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"BlockDeletingService#0" daemon prio=5 tid=5931 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1682214758-4304-acceptor-0@1e985048-ServerConnector@648f8750{HTTP/1.1, (http/1.1)}{0.0.0.0:43027}" daemon prio=3 tid=4304 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5883 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp157054014-5639" daemon prio=5 tid=5639 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1980139489-5477" daemon prio=5 tid=5477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"cdc3fd6e-e759-42d4-8e19-947196a05030-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4669 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@570c05fb" daemon prio=5 tid=5469 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 37433" daemon prio=5 tid=5541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4871 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6227 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"f66a9549-37e5-4f01-8484-0c21eaa44150@group-8A523D200D03-StateMachineUpdater" daemon prio=5 tid=5046 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 34223" daemon prio=5 tid=3524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 33991" daemon prio=5 tid=6272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1627-thread-1"  prio=5 tid=3981 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4872 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-9"  prio=5 tid=5711 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6347 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1018617286-4820" daemon prio=5 tid=4820 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-SegmentedRaftLogWorker"  prio=5 tid=6105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5849 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3875 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp659628497-5764" daemon prio=5 tid=5764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5927 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@31374835" daemon prio=5 tid=3713 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp157054014-5636" daemon prio=5 tid=5636 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp157054014-5638" daemon prio=5 tid=5638 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5241 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5dd50d3d" daemon prio=5 tid=5738 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"pool-1963-thread-1"  prio=5 tid=4974 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5735 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4907 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1679-thread-1"  prio=5 tid=3992 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 35751" daemon prio=5 tid=5408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor37" daemon prio=5 tid=3824 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5837 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor36" daemon prio=5 tid=3791 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"6b109e20-fb43-4126-a2d0-e01a40c07237-impl-thread1"  prio=5 tid=5759 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1980139489-5474" daemon prio=5 tid=5474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp157054014-5633" daemon prio=5 tid=5633 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp88182619-4783" daemon prio=5 tid=4783 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 36135" daemon prio=5 tid=4244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1161646926-3780" daemon prio=5 tid=3780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4937 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2167-thread-1"  prio=5 tid=5036 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4808 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 33991" daemon prio=5 tid=6268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderStateImpl" daemon prio=5 tid=6155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 9 on default port 39711" daemon prio=5 tid=5436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 34223" daemon prio=5 tid=3527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 5 on default port 34223" daemon prio=5 tid=3528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@37389935" daemon prio=5 tid=4884 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp1161646926-3782" daemon prio=5 tid=3782 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 0.0.0.0/37571"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
        at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:583)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
        at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
        at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$164/2001223946.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall$$Lambda$165/794075965.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$$Lambda$322/1706099897.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$1229/1379186202.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/20853837.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/1158258131.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/252277567.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/510276116.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/20853837.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/1158258131.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/252277567.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/510276116.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/20853837.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/1158258131.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/252277567.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$220/262445056.accept(Unknown Source)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
        at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
"qtp195362258-4676" daemon prio=5 tid=4676 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1755303688-6309" daemon prio=5 tid=6309 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor38" daemon prio=5 tid=3860 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 40195" daemon prio=5 tid=4265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125->ed5356af-2dee-4266-b55e-559e8c0d6889-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 36135" daemon prio=5 tid=4248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1682214758-4305" daemon prio=5 tid=4305 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5570 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 39711" daemon prio=5 tid=5437 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3120 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3636 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3326 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 40195" daemon prio=5 tid=4271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"OMDoubleBufferFlushThread" daemon prio=5 tid=3493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:614)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$546/495796856.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5310 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1762625636-3650" daemon prio=5 tid=3650 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"9f4b8ec3-f353-4948-b4fc-413f1dfec88e@group-16937DA64123-SegmentedRaftLogWorker"  prio=5 tid=5048 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3720 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3792 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"59495bd3-eca8-4664-a537-a989ac7b0d80@group-8DB1F0EA65EE-StateMachineUpdater" daemon prio=5 tid=5043 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 40195" daemon prio=5 tid=4264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 37433" daemon prio=5 tid=5539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=4807 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3890 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4720 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3667 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp376997535-3739" daemon prio=5 tid=3739 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp88182619-4782" daemon prio=5 tid=4782 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor34" daemon prio=5 tid=3719 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=5160 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 39711" daemon prio=5 tid=5444 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=5371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/1514067012.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"bb24641f-ac05-4a48-a34b-331e584b8427-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5858 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=6325 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 36109" daemon prio=5 tid=4541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"6b109e20-fb43-4126-a2d0-e01a40c07237-server-thread1" daemon prio=5 tid=6205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@215de8c9" daemon prio=5 tid=5839 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=5506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5263 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5569 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6349 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp587286553-4739" daemon prio=5 tid=4739 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp141780135-4525" daemon prio=5 tid=4525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 36135" daemon prio=5 tid=4259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5856 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@2a36de1d" daemon prio=5 tid=4834 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"timer4" daemon prio=5 tid=542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp68594061-3562" daemon prio=5 tid=3562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3885 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5661 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3827 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3714 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4641 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp177859206-5814-acceptor-0@406dd5c8-ServerConnector@5dddbb19{HTTP/1.1, (http/1.1)}{0.0.0.0:39849}" daemon prio=3 tid=5814 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-2663-thread-1"  prio=5 tid=6133 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 37571" daemon prio=5 tid=6249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerReplicationThread-0" daemon prio=5 tid=6335 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 34223" daemon prio=5 tid=3531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"9f4b8ec3-f353-4948-b4fc-413f1dfec88e@group-16937DA64123-LeaderStateImpl" daemon prio=5 tid=5132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ChunkWriter-1-0" daemon prio=5 tid=3821 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1446142935-5865" daemon prio=5 tid=5865 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor53" daemon prio=5 tid=5826 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@27885a52" daemon prio=5 tid=4875 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 40195" daemon prio=5 tid=4267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp531720972-3520" daemon prio=5 tid=3520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"59495bd3-eca8-4664-a537-a989ac7b0d80@group-CF73E13F09DA-StateMachineUpdater" daemon prio=5 tid=5039 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor52" daemon prio=5 tid=5747 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5736 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 39711" daemon prio=5 tid=5430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=3884 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@48b6ff85" daemon prio=5 tid=4645 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState" daemon prio=5 tid=6197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"pool-2633-thread-1"  prio=5 tid=6108 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp195362258-4681" daemon prio=5 tid=4681 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1527-thread-1"  prio=5 tid=3921 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 44419" daemon prio=5 tid=5458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=3857 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-StateMachineUpdater" daemon prio=5 tid=6136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@503c1115" daemon prio=5 tid=3774 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3663 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1762625636-3651-acceptor-0@5eacec96-ServerConnector@589f8be4{HTTP/1.1, (http/1.1)}{0.0.0.0:41805}" daemon prio=3 tid=3651 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3642 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1308394587-5559" daemon prio=5 tid=5559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=3508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1308394587-5558" daemon prio=5 tid=5558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6332 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3581 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4792 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ed5356af-2dee-4266-b55e-559e8c0d6889-server-thread1" daemon prio=5 tid=6178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4835 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@4959ee8e" daemon prio=5 tid=5572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 37433" daemon prio=5 tid=5527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=4926 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5619 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-78752b1-1"  prio=5 tid=5641 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 37433" daemon prio=5 tid=5543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1980139489-5472-acceptor-0@363427c9-ServerConnector@1091f516{HTTP/1.1, (http/1.1)}{0.0.0.0:35533}" daemon prio=3 tid=5472 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5384 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3664 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp195362258-4677-acceptor-0@431182cb-ServerConnector@4b2ad938{HTTP/1.1, (http/1.1)}{0.0.0.0:40489}" daemon prio=3 tid=4677 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4642 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1080956843-3684" daemon prio=5 tid=3684 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4950 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4932 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Mini-Cluster-Provider-Reap"  prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$reapClusters$0(MiniOzoneClusterProvider.java:199)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$343/688593710.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"59495bd3-eca8-4664-a537-a989ac7b0d80@group-8DB1F0EA65EE-LeaderStateImpl" daemon prio=5 tid=5100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Command processor thread" daemon prio=5 tid=4725 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2460-thread-1" daemon prio=5 tid=5550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 41473" daemon prio=5 tid=6295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1586-thread-1" daemon prio=5 tid=3644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5825 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 35751" daemon prio=5 tid=5425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp587286553-4742" daemon prio=5 tid=4742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 37433" daemon prio=5 tid=5535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-2285DC16387D-LeaderStateImpl" daemon prio=5 tid=4024 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 11 on default port 34223" daemon prio=5 tid=3534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5795 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4925 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@70be5ebf" daemon prio=5 tid=4554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 33213" daemon prio=5 tid=4283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor57" daemon prio=5 tid=5929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 37433" daemon prio=5 tid=5534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Socket Reader #1 for port 0"  prio=5 tid=5378 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3711 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6a4dbde0-2827-4051-b593-1eb8ab0ee225@group-CF73E13F09DA-StateMachineUpdater" daemon prio=5 tid=5021 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3882 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer7" daemon prio=5 tid=683 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@55b78dad" daemon prio=5 tid=6307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 37433" daemon prio=5 tid=5530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=4833 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2123 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-StateMachineUpdater" daemon prio=5 tid=6071 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker"  prio=5 tid=6078 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1446142935-5864" daemon prio=5 tid=5864 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4900 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4796 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=6320 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5188 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3576 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4187 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6350 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5852 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4814a15c" daemon prio=5 tid=3621 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6340 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4933 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=3499 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=5614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Session-HouseKeeper-720f7f27-1"  prio=5 tid=5821 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1358372967-4889" daemon prio=5 tid=4889 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1980139489-5478" daemon prio=5 tid=5478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4897 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6343 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5756 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 40195" daemon prio=5 tid=4261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7529d19d" daemon prio=5 tid=4914 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5176 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3874 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4866 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4953 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41473 - 0 "  prio=5 tid=3881 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@f9263f3" daemon prio=5 tid=5554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 40195" daemon prio=5 tid=4262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6353 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4967 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 37571" daemon prio=5 tid=6259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1308394587-5560" daemon prio=5 tid=5560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp712213994-5610" daemon prio=5 tid=5610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=4514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp157054014-5635" daemon prio=5 tid=5635 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"timer0" daemon prio=5 tid=686 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 2 on default port 37433" daemon prio=5 tid=5528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2231-thread-1"  prio=5 tid=5047 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=6323 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"646e529a-a01f-4b15-a31a-2706cdf8d47d-server-thread1" daemon prio=5 tid=6177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5835 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 39711" daemon prio=5 tid=5432 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=4209 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@38ec0945" daemon prio=5 tid=4794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4664 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B-LeaderStateImpl" daemon prio=5 tid=4035 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp136986031-4592" daemon prio=5 tid=4592 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4186 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5552 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1080956843-3686" daemon prio=5 tid=3686 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3820 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4968 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3662 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59495bd3-eca8-4664-a537-a989ac7b0d80@group-CF73E13F09DA-SegmentedRaftLogWorker"  prio=5 tid=5037 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ed5356af-2dee-4266-b55e-559e8c0d6889-server-thread2" daemon prio=5 tid=6179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=4975 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f66a9549-37e5-4f01-8484-0c21eaa44150@group-8A523D200D03-LeaderStateImpl" daemon prio=5 tid=5107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"132d3d80-0103-4f41-b942-b9d80c35d5a5-server-thread2" daemon prio=5 tid=4042 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-StateMachineUpdater" daemon prio=5 tid=3984 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"132d3d80-0103-4f41-b942-b9d80c35d5a5@group-A3695F9F7B6B-StateMachineUpdater" daemon prio=5 tid=3979 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-4"  prio=5 tid=5644 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer1" daemon prio=5 tid=538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3580 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState" daemon prio=5 tid=6172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 1 on default port 41473" daemon prio=5 tid=6287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01-client-thread1" daemon prio=5 tid=5399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5836 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"59495bd3-eca8-4664-a537-a989ac7b0d80@group-8DB1F0EA65EE-SegmentedRaftLogWorker"  prio=5 tid=5041 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=5512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5872 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=4202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:795)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$424/297895050.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState" daemon prio=5 tid=6154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3674 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6a4dbde0-2827-4051-b593-1eb8ab0ee225-server-thread3" daemon prio=5 tid=5098 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6338 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor44" daemon prio=5 tid=4901 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 34223" daemon prio=5 tid=3536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4909 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5901 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=6236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4916 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=4199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$414/140620007.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=6232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-d829a19-1"  prio=5 tid=3658 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6339 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5240 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2045-thread-1"  prio=5 tid=4675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 40195" daemon prio=5 tid=4274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp157054014-5640" daemon prio=5 tid=5640 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 33213" daemon prio=5 tid=4291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=3716 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3633 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4970 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor45" daemon prio=5 tid=4928 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7356e519" daemon prio=5 tid=3554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"pool-1515-thread-1"  prio=5 tid=3513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 34223" daemon prio=5 tid=3501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1358372967-4886" daemon prio=5 tid=4886 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (140648931) connection to 0.0.0.0/0.0.0.0:41473 from runner" daemon prio=5 tid=6318 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-StateMachineUpdater" daemon prio=5 tid=6120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"SnapshotDeletingService#0" daemon prio=5 tid=4518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4854 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-693b4a70-1"  prio=5 tid=3784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 44419" daemon prio=5 tid=5465 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1161646926-3779" daemon prio=5 tid=3779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5623 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f66a9549-37e5-4f01-8484-0c21eaa44150@group-CF73E13F09DA-StateMachineUpdater" daemon prio=5 tid=5034 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6345 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1755303688-6311" daemon prio=5 tid=6311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1137087653-4846-acceptor-0@71419159-ServerConnector@7fe6ee83{HTTP/1.1, (http/1.1)}{0.0.0.0:46333}" daemon prio=3 tid=4846 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 34223" daemon prio=5 tid=3542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@337a7d9a" daemon prio=5 tid=4726 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"5650ff5c-2f39-425b-bee4-adddfcfb793b-server-thread2" daemon prio=5 tid=4044 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5926 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5874 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"71dc2d0c-c132-482e-adc3-0da69386d6d8-server-thread1" daemon prio=5 tid=6202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4832ba7d" daemon prio=5 tid=4737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5748 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-2141-thread-1"  prio=5 tid=5000 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4931 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=765 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 37433" daemon prio=5 tid=5537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 1 on default port 44419" daemon prio=5 tid=5448 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=5389 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-245c4eda-1"  prio=5 tid=4597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6344 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2626-thread-1" daemon prio=5 tid=5805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2574-thread-1"  prio=5 tid=5696 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3bdcc317" daemon prio=5 tid=3682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5743 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 44419" daemon prio=5 tid=5460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=5395 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5656 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-1"  prio=5 tid=5404 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5164 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp141780135-4529" daemon prio=5 tid=4529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cdc3fd6e-e759-42d4-8e19-947196a05030@group-42F8EC9463AC-SegmentedRaftLogWorker"  prio=5 tid=4994 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp195362258-4680" daemon prio=5 tid=4680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5854 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9-server-thread2" daemon prio=5 tid=6160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 41473" daemon prio=5 tid=6291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=4206 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"ChunkWriter-2-0" daemon prio=5 tid=5939 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4639 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 33991" daemon prio=5 tid=6284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3131dc0f" daemon prio=5 tid=4301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"pool-2189-thread-1"  prio=5 tid=5027 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 41473" daemon prio=5 tid=6220 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server Responder" daemon prio=5 tid=4217 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"pool-2024-thread-1" daemon prio=5 tid=4666 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2523-thread-1"  prio=5 tid=5632 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 36109" daemon prio=5 tid=4535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1080956843-3687" daemon prio=5 tid=3687 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4904 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-6"  prio=5 tid=5510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3818 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp376997535-3737" daemon prio=5 tid=3737 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4a10f34d" daemon prio=5 tid=5860 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 39711" daemon prio=5 tid=5435 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=5933 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4858 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp141780135-4523" daemon prio=5 tid=4523 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 36135" daemon prio=5 tid=4246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3864 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=4517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1358372967-4891" daemon prio=5 tid=4891 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ed5356af-2dee-4266-b55e-559e8c0d6889@group-F3AF78373E13-LeaderStateImpl" daemon prio=5 tid=4016 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BlockDeletingService#0" daemon prio=5 tid=3862 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 35751" daemon prio=5 tid=5416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-6"  prio=5 tid=5654 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@6846331b" daemon prio=5 tid=5546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4945 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@6bd17b9e" daemon prio=5 tid=5695 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"f66a9549-37e5-4f01-8484-0c21eaa44150@group-8A523D200D03-SegmentedRaftLogWorker"  prio=5 tid=5044 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fe82170" daemon prio=5 tid=3666 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"pool-681-thread-1"  prio=5 tid=1538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 33213" daemon prio=5 tid=4208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EndpointStateMachine task thread for /0.0.0.0:41473 - 0 "  prio=5 tid=3786 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4057 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4829 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=4972 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=6239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 36135" daemon prio=5 tid=4253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=4198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 33991" daemon prio=5 tid=6285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 40195" daemon prio=5 tid=4266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5833 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 37433" daemon prio=5 tid=5504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4643 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 36109" daemon prio=5 tid=4539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 17 on default port 36109" daemon prio=5 tid=4551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-SegmentedRaftLogWorker"  prio=5 tid=6130 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4903 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1635-thread-1"  prio=5 tid=3683 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp531720972-3516" daemon prio=5 tid=3516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 37433" daemon prio=5 tid=5544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 1 on default port 33213" daemon prio=5 tid=4281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3800 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5751 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"480de393-893d-4d82-b81f-696ceb757cb1@group-8D7E7099420A-SegmentedRaftLogWorker"  prio=5 tid=4997 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (140648931) connection to 0.0.0.0/0.0.0.0:33213 from runner" daemon prio=5 tid=4798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"pool-1950-thread-1" daemon prio=5 tid=4573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor55" daemon prio=5 tid=5886 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-33-thread-1"  prio=5 tid=125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderStateImpl" daemon prio=5 tid=6187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4870 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3578 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=4650 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-SegmentedRaftLogWorker"  prio=5 tid=6097 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 33991" daemon prio=5 tid=6226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ChunkWriter-2-0" daemon prio=5 tid=4952 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B-StateMachineUpdater" daemon prio=5 tid=3975 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1762625636-3654" daemon prio=5 tid=3654 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState" daemon prio=5 tid=6153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5565 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 41473" daemon prio=5 tid=6290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5923 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-SegmentedRaftLogWorker"  prio=5 tid=6087 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-0" daemon prio=5 tid=6336 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 37571" daemon prio=5 tid=6263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=3888 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"132d3d80-0103-4f41-b942-b9d80c35d5a5-server-thread3" daemon prio=5 tid=4041 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-SegmentedRaftLogWorker"  prio=5 tid=6056 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"cdc3fd6e-e759-42d4-8e19-947196a05030@group-9BBA42843B5D-StateMachineUpdater" daemon prio=5 tid=4985 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"132d3d80-0103-4f41-b942-b9d80c35d5a5@group-A3695F9F7B6B-SegmentedRaftLogWorker"  prio=5 tid=3977 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3119 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 33991" daemon prio=5 tid=6283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 1 on default port 39711" daemon prio=5 tid=5428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=3795 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 33213" daemon prio=5 tid=4288 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5944 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp141780135-4527" daemon prio=5 tid=4527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 41473" daemon prio=5 tid=6305 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1137087653-4852" daemon prio=5 tid=4852 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5850 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at org.apache.maven.surefire.api.util.internal.Channels$3.readImpl(Channels.java:214)
        at org.apache.maven.surefire.api.util.internal.AbstractNoninterruptibleReadableChannel.read(AbstractNoninterruptibleReadableChannel.java:54)
        at org.apache.maven.surefire.booter.spi.LegacyMasterProcessChannelDecoder.decode(LegacyMasterProcessChannelDecoder.java:80)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:343)
        at java.lang.Thread.run(Thread.java:750)
"pool-2224-thread-1" daemon prio=5 tid=4880 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3721 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5834 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-27e5c395-1"  prio=5 tid=5525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=5947 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp177859206-5819" daemon prio=5 tid=5819 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2549-thread-1" daemon prio=5 tid=5677 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp587286553-4745" daemon prio=5 tid=4745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp177859206-5815" daemon prio=5 tid=5815 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5382 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"qtp1755303688-6312" daemon prio=5 tid=6312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-2"  prio=5 tid=5489 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"132d3d80-0103-4f41-b942-b9d80c35d5a5-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3733 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 41473" daemon prio=5 tid=6301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"132d3d80-0103-4f41-b942-b9d80c35d5a5@group-082D0680124B-LeaderStateImpl" daemon prio=5 tid=4048 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"grpc-default-executor-1" daemon prio=5 tid=524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 33991" daemon prio=5 tid=6277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1446142935-5866" daemon prio=5 tid=5866 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=5370 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$414/140620007.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 36109" daemon prio=5 tid=4533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=6237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderStateImpl" daemon prio=5 tid=6185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BlockDeletingService#1" daemon prio=5 tid=5890 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1161646926-3777" daemon prio=5 tid=3777 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=4227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 33991" daemon prio=5 tid=6271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 36109" daemon prio=5 tid=4542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1446142935-5863-acceptor-0@2c33c66a-ServerConnector@355532b7{HTTP/1.1, (http/1.1)}{0.0.0.0:45831}" daemon prio=3 tid=5863 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5599 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5618 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3638 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3887 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1018617286-4825" daemon prio=5 tid=4825 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-494a1a28-1"  prio=5 tid=4311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-SegmentedRaftLogWorker"  prio=5 tid=6118 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 34223" daemon prio=5 tid=3529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=5664 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4723 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=5895 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 44419" daemon prio=5 tid=5456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-StateMachineUpdater" daemon prio=5 tid=6104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 33991" daemon prio=5 tid=6279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-StateMachineUpdater" daemon prio=5 tid=6111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"6a4dbde0-2827-4051-b593-1eb8ab0ee225-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4774 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4905 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ed5356af-2dee-4266-b55e-559e8c0d6889@group-F3AF78373E13-SegmentedRaftLogWorker"  prio=5 tid=3923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4878 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5734 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1161646926-3781" daemon prio=5 tid=3781 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 33991" daemon prio=5 tid=6275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=3826 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp177859206-5818" daemon prio=5 tid=5818 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5797 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 33213" daemon prio=5 tid=4298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3801 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5875 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1876-thread-1"  prio=5 tid=4407 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3575 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5388 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"IPC Server handler 14 on default port 33213" daemon prio=5 tid=4294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=5896 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=5374 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:147)
        at java.lang.Thread.run(Thread.java:750)
"qtp376997535-3743" daemon prio=5 tid=3743 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2603-thread-1"  prio=5 tid=6113 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3868 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3712 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 40195" daemon prio=5 tid=4260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"f66a9549-37e5-4f01-8484-0c21eaa44150@group-CF73E13F09DA-FollowerState" daemon prio=5 tid=5088 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3763 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=6233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1593-thread-1"  prio=5 tid=3969 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2467-thread-1"  prio=5 tid=6054 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 33991"  prio=5 tid=6225 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"JvmPauseMonitor33" daemon prio=5 tid=3506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$752/561326331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5824 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3799 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 33991" daemon prio=5 tid=6280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ed5356af-2dee-4266-b55e-559e8c0d6889-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3551 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp141780135-4528" daemon prio=5 tid=4528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3866 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 44419" daemon prio=5 tid=5447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=6215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$417/1514067012.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp376997535-3744" daemon prio=5 tid=3744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44419 - 0 "  prio=5 tid=5924 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5838 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5505 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"qtp1161646926-3776" daemon prio=5 tid=3776 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$480/955971071.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5745 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 33991" daemon prio=5 tid=6224 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"Session-HouseKeeper-4b06b2cd-1"  prio=5 tid=5479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 36135" daemon prio=5 tid=4250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1980139489-5473" daemon prio=5 tid=5473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 36135" daemon prio=5 tid=4251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=5621 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:649)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/194916966.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"480de393-893d-4d82-b81f-696ceb757cb1@group-9BBA42843B5D->9b1f5799-4694-44ac-95a8-dde5d0689021-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1513-thread-1"  prio=5 tid=3496 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5830 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1018617286-4823" daemon prio=5 tid=4823 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLogWorker"  prio=5 tid=6069 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=3505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 40195" daemon prio=5 tid=4278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=4210 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"ChunkWriter-3-0" daemon prio=5 tid=5916 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1646-thread-1" daemon prio=5 tid=3731 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp823157585-5517-acceptor-0@66d0325c-ServerConnector@62863dd6{HTTP/1.1, (http/1.1)}{0.0.0.0:38997}" daemon prio=3 tid=5517 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=4923 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp823157585-5521" daemon prio=5 tid=5521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1308394587-5556-acceptor-0@63599fd1-ServerConnector@4bcb020f{HTTP/1.1, (http/1.1)}{0.0.0.0:42955}" daemon prio=3 tid=5556 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp587286553-4746" daemon prio=5 tid=4746 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1971-thread-1"  prio=5 tid=4588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3672 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderStateImpl" daemon prio=5 tid=6183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5871 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$841/1208233030.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 34223" daemon prio=5 tid=3539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=5744 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=4918 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp68594061-3558" daemon prio=5 tid=3558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 40195" daemon prio=5 tid=4272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-23AD5C6690D5-SegmentedRaftLogWorker"  prio=5 tid=3993 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$711/1947140013.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3876 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 34223" daemon prio=5 tid=3540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-1"  prio=5 tid=5407 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=4203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:147)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 33991" daemon prio=5 tid=6267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:33213 - 0 "  prio=5 tid=4896 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 34223" daemon prio=5 tid=3532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-6172db30-ce81-4dfa-a1f1-a3695f9f7b6b-0"  prio=5 tid=5402 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"132d3d80-0103-4f41-b942-b9d80c35d5a5@group-082D0680124B-StateMachineUpdater" daemon prio=5 tid=3991 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=6213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$414/140620007.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E->71dc2d0c-c132-482e-adc3-0da69386d6d8-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1111/1802814653.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2515-thread-1"  prio=5 tid=6063 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4908 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 39711" daemon prio=5 tid=5383 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp849456214-5701" daemon prio=5 tid=5701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)


	at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:583)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
    <system-out><![CDATA[2023-03-15 02:22:02,725 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 36633
2023-03-15 02:22:02,735 [Listener at 127.0.0.1/36109] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:02,738 [Listener at 127.0.0.1/36109] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:02,739 [Listener at 127.0.0.1/36109] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-15 02:22:02,739 [Listener at 127.0.0.1/36109] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-15 02:22:02,752 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-15 02:22:02,752 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:02,758 [Listener at 127.0.0.1/36109] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:02,758 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-03-15 02:22:02,758 [Listener at 127.0.0.1/36109] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:02,765 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:02,765 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-03-15 02:22:02,765 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-03-15 02:22:02,766 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-03-15 02:22:02,766 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:02,780 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:02,817 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(476)) - Creating Volume: vol1, with user38966 as owner and space quota set to -1 bytes, counts quota set to -1
2023-03-15 02:22:02,823 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 168
2023-03-15 02:22:02,824 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:168)
2023-03-15 02:22:02,834 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(195)) - created volume:vol1 for user:user38966
2023-03-15 02:22:02,852 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(698)) - Creating Bucket: vol1/bucket1, with bucket layout LEGACY, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2023-03-15 02:22:02,855 [OM StateMachine ApplyTransaction Thread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(263)) - created bucket: bucket1 of layout LEGACY in volume: vol1
2023-03-15 02:22:02,895 [IPC Server handler 12 on default port 33991] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2023-03-15 02:22:02,896 [IPC Server handler 12 on default port 33991] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(237)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-03-15 02:22:02,896 [IPC Server handler 12 on default port 33991] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
2023-03-15 02:22:02,932 [Listener at 127.0.0.1/36109] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-15 02:22:02,933 [Listener at 127.0.0.1/36109] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-15 02:22:02,936 [Listener at 127.0.0.1/36109] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:02,936 [Listener at 127.0.0.1/36109] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:02,936 [Listener at 127.0.0.1/36109] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:02,948 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 168
2023-03-15 02:22:02,955 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 168
2023-03-15 02:22:02,955 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-15 02:22:02,955 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(540)) - Stopping OMDoubleBuffer flush thread
2023-03-15 02:22:02,955 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(625)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-03-15 02:22:02,957 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 168
2023-03-15 02:22:02,957 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:02,958 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-03-15 02:22:02,958 [JvmPauseMonitor25] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-03-15 02:22:02,959 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-15 02:22:02,959 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(549)) - OMDoubleBuffer flush thread is not running.
2023-03-15 02:22:02,959 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-03-15 02:22:02,959 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-03-15 02:22:02,959 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-03-15 02:22:02,960 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-03-15 02:22:02,960 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SnapshotDeletingService
2023-03-15 02:22:02,961 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@29925f5b{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-15 02:22:02,961 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@71d3eb2c{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:02,961 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:02,961 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@17a3cdc6{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-15 02:22:02,962 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@60ef2630{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:02,966 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(524)) - Stopping the HddsDatanodes
2023-03-15 02:22:03,017 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:03,018 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: close
2023-03-15 02:22:03,019 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D: shutdown
2023-03-15 02:22:03,020 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-40224524692D,id=ba703dd0-9123-40b7-b53b-b3e9bbb37b8e
2023-03-15 02:22:03,020 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: shutdown ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-LeaderStateImpl
2023-03-15 02:22:03,020 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:03,021 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-40224524692D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-4/data/ratis/e23b3f27-6f65-49a3-bcd3-40224524692d/sm/snapshot.1_0
2023-03-15 02:22:03,021 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:03,026 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:03,041 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:03,047 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 49ec7792-09fe-4082-843c-e0901275937b: close
2023-03-15 02:22:03,047 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 49ec7792-09fe-4082-843c-e0901275937b: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:03,048 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-40224524692D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-4/data/ratis/e23b3f27-6f65-49a3-bcd3-40224524692d/sm/snapshot.1_0 took: 27 ms
2023-03-15 02:22:03,048 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:03,048 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:03,049 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D: closes. applyIndex: 0
2023-03-15 02:22:03,055 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:03,054 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 49ec7792-09fe-4082-843c-e0901275937b: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:03,057 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-40224524692D-SegmentedRaftLogWorker close()
2023-03-15 02:22:03,057 [49ec7792-09fe-4082-843c-e0901275937b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x7e63c80d, L:/0:0:0:0:0:0:0:0:38865] CLOSE
2023-03-15 02:22:03,057 [49ec7792-09fe-4082-843c-e0901275937b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x7e63c80d, L:/0:0:0:0:0:0:0:0:38865] INACTIVE
2023-03-15 02:22:03,057 [49ec7792-09fe-4082-843c-e0901275937b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x7e63c80d, L:/0:0:0:0:0:0:0:0:38865] UNREGISTERED
2023-03-15 02:22:03,058 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-15 02:22:03,058 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:03,058 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-15 02:22:03,058 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 32 -> 31
2023-03-15 02:22:03,058 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-15 02:22:03,058 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x4047d52c, L:/0:0:0:0:0:0:0:0:44563] CLOSE
2023-03-15 02:22:03,058 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 31 -> 30
2023-03-15 02:22:03,059 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x4047d52c, L:/0:0:0:0:0:0:0:0:44563] INACTIVE
2023-03-15 02:22:03,059 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x4047d52c, L:/0:0:0:0:0:0:0:0:44563] UNREGISTERED
2023-03-15 02:22:03,058 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: installSnapshot onError, lastRequest: dff27167-0db1-43de-a597-ad7d66669fa4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e#185-t1,previous=(t:1, i:30),leaderCommit=29,initializing? true,entries: size=1, first=(t:1, i:31), METADATAENTRY(c:29): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-15 02:22:03,105 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4: shutdown
2023-03-15 02:22:03,105 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2798F6AD2DD4,id=ba703dd0-9123-40b7-b53b-b3e9bbb37b8e
2023-03-15 02:22:03,105 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: shutdown ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-FollowerState
2023-03-15 02:22:03,108 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:03,108 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 31 -> 30
2023-03-15 02:22:03,110 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:03,110 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 30 -> 29
2023-03-15 02:22:03,142 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-StateMachineUpdater: set stopIndex = 31
2023-03-15 02:22:03,142 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-FollowerState was interrupted
2023-03-15 02:22:03,143 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-2798F6AD2DD4: Taking a snapshot at:(t:1, i:31) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-4/data/ratis/7822455f-27f0-4240-bfdb-2798f6ad2dd4/sm/snapshot.1_31
2023-03-15 02:22:03,161 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-2798F6AD2DD4: Finished taking a snapshot at:(t:1, i:31) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-4/data/ratis/7822455f-27f0-4240-bfdb-2798f6ad2dd4/sm/snapshot.1_31 took: 18 ms
2023-03-15 02:22:03,161 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-StateMachineUpdater: Took a snapshot at index 31
2023-03-15 02:22:03,161 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 31
2023-03-15 02:22:03,166 [JvmPauseMonitor50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-49ec7792-09fe-4082-843c-e0901275937b: Stopped
2023-03-15 02:22:03,177 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4: closes. applyIndex: 31
2023-03-15 02:22:03,177 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:03,177 [ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e@group-2798F6AD2DD4-SegmentedRaftLogWorker close()
2023-03-15 02:22:03,189 [JvmPauseMonitor30] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: Stopped
2023-03-15 02:22:03,204 [Listener at 127.0.0.1/36109] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 267 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:03,206 [Listener at 127.0.0.1/36109] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(349)) - upgrade localId to 111677748019200000
2023-03-15 02:22:03,206 [Listener at 127.0.0.1/36109] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(359)) - upgrade delTxnId to 0
2023-03-15 02:22:03,206 [Listener at 127.0.0.1/36109] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(376)) - upgrade containerId to 0
2023-03-15 02:22:03,206 [Listener at 127.0.0.1/36109] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-15 02:22:03,207 [Listener at 127.0.0.1/36109] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-15 02:22:03,207 [Listener at 127.0.0.1/36109] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-15 02:22:03,207 [Listener at 127.0.0.1/36109] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-15 02:22:03,207 [Listener at 127.0.0.1/36109] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2023-03-15 02:22:03,207 [Listener at 127.0.0.1/36109] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-15 02:22:03,208 [Listener at 127.0.0.1/36109] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-15 02:22:03,208 [Listener at 127.0.0.1/36109] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-15 02:22:03,208 [Listener at 127.0.0.1/36109] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-15 02:22:03,208 [Listener at 127.0.0.1/36109] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-15 02:22:03,208 [Listener at 127.0.0.1/36109] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-15 02:22:03,208 [Listener at 127.0.0.1/36109] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-15 02:22:03,209 [Listener at 127.0.0.1/36109] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-15 02:22:03,209 [Listener at 127.0.0.1/36109] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-15 02:22:03,210 [Listener at 127.0.0.1/36109] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-15 02:22:03,210 [Listener at 127.0.0.1/36109] INFO  replication.ReplicationManager (ReplicationManager.java:start(271)) - Starting Replication Monitor Thread.
2023-03-15 02:22:03,211 [Listener at 127.0.0.1/36109] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-15 02:22:03,211 [Listener at 127.0.0.1/36109] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2023-03-15 02:22:03,212 [Listener at 127.0.0.1/36109] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2023-03-15 02:22:03,212 [Listener at 127.0.0.1/36109] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-03-15 02:22:03,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:03,217 [Listener at 127.0.0.1/36109] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(392)) - SCM start with adminUsers: [runner]
2023-03-15 02:22:03,217 [Listener at 127.0.0.1/36109] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:03,221 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-15 02:22:03,222 [Listener at 0.0.0.0/44419] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:03,237 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-15 02:22:03,238 [Listener at 0.0.0.0/39711] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:03,249 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-15 02:22:03,277 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:03,277 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:03,278 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:03,284 [Listener at 0.0.0.0/35751] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-15 02:22:03,284 [Listener at 0.0.0.0/35751] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(407)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-15 02:22:03,284 [Listener at 0.0.0.0/35751] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-15 02:22:03,284 [Listener at 0.0.0.0/35751] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1437)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35751
2023-03-15 02:22:03,284 [Listener at 0.0.0.0/35751] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2023-03-15 02:22:03,285 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:03,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:03,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2023-03-15 02:22:03,298 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:03,321 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1148)) - Container #1 is over replicated. Expected replica count is 3, but found 4.
2023-03-15 02:22:03,322 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1477)) - Sending delete container command for container #1 to datanode a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:03,322 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1148)) - Container #3 is over replicated. Expected replica count is 3, but found 4.
2023-03-15 02:22:03,322 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1477)) - Sending delete container command for container #3 to datanode a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:03,322 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1148)) - Container #4 is over replicated. Expected replica count is 3, but found 4.
2023-03-15 02:22:03,322 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1477)) - Sending delete container command for container #4 to datanode a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:03,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 12 containers.
2023-03-15 02:22:03,323 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:03,347 [Listener at 0.0.0.0/35751] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(194)) - RPC server for Client  is listening at /0.0.0.0:35751
2023-03-15 02:22:03,353 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:03,356 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-15 02:22:03,371 [Listener at 0.0.0.0/35751] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1451)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:39711
2023-03-15 02:22:03,372 [Listener at 0.0.0.0/35751] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:39711
2023-03-15 02:22:03,372 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:03,372 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-15 02:22:03,373 [Listener at 0.0.0.0/35751] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:44419
2023-03-15 02:22:03,374 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:03,374 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-15 02:22:03,402 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@570c05fb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:03,407 [Listener at 0.0.0.0/35751] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:0
2023-03-15 02:22:03,408 [Listener at 0.0.0.0/35751] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:03,413 [Listener at 0.0.0.0/35751] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:03,415 [Listener at 0.0.0.0/35751] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:03,416 [Listener at 0.0.0.0/35751] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:03,416 [Listener at 0.0.0.0/35751] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-15 02:22:03,416 [Listener at 0.0.0.0/35751] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:03,416 [Listener at 0.0.0.0/35751] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:03,433 [Listener at 0.0.0.0/35751] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/ozone-meta/webserver
2023-03-15 02:22:03,433 [Listener at 0.0.0.0/35751] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 35533
2023-03-15 02:22:03,433 [Listener at 0.0.0.0/35751] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:03,435 [Listener at 0.0.0.0/35751] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:03,435 [Listener at 0.0.0.0/35751] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:03,435 [Listener at 0.0.0.0/35751] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-15 02:22:03,436 [Listener at 0.0.0.0/35751] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@293e132a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:03,436 [Listener at 0.0.0.0/35751] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7d94e28c{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-15 02:22:03,441 [Listener at 0.0.0.0/35751] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@208747b2{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-15 02:22:03,446 [Listener at 0.0.0.0/35751] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1091f516{HTTP/1.1, (http/1.1)}{0.0.0.0:35533}
2023-03-15 02:22:03,446 [Listener at 0.0.0.0/35751] INFO  server.Server (Server.java:doStart(415)) - Started @178324ms
2023-03-15 02:22:03,447 [Listener at 0.0.0.0/35751] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:03,448 [Listener at 0.0.0.0/35751] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:35533
2023-03-15 02:22:03,448 [Listener at 0.0.0.0/35751] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:03,485 [Listener at 0.0.0.0/35751] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-03-15 02:22:03,487 [Listener at 0.0.0.0/35751] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2023-03-15 02:22:03,487 [Listener at 0.0.0.0/35751] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-03-15 02:22:03,487 [Listener at 0.0.0.0/35751] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2023-03-15 02:22:03,487 [Listener at 0.0.0.0/35751] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:03,499 [Listener at 0.0.0.0/35751] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2023-03-15 02:22:03,585 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:03,586 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 29 -> 28
2023-03-15 02:22:03,586 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:03,605 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 28 -> 27
2023-03-15 02:22:03,611 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:03,612 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 28 -> 27
2023-03-15 02:22:03,612 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:03,612 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 27 -> 26
2023-03-15 02:22:03,744 [Listener at 0.0.0.0/35751] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 233 ms to scan 2 urls, producing 167 keys and 464 values [using 2 cores]
2023-03-15 02:22:03,744 [Listener at 0.0.0.0/35751] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2023-03-15 02:22:03,744 [Listener at 0.0.0.0/35751] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:03,745 [Listener at 0.0.0.0/35751] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:39711]
2023-03-15 02:22:03,746 [Listener at 0.0.0.0/35751] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:39711]
2023-03-15 02:22:03,764 [Listener at 0.0.0.0/35751] INFO  om.OzoneManager (OzoneManager.java:<init>(620)) - OM start with adminUsers: [runner]
2023-03-15 02:22:03,765 [Listener at 0.0.0.0/35751] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:03,765 [Listener at 0.0.0.0/35751] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2023-03-15 02:22:03,765 [Listener at 0.0.0.0/35751] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2023-03-15 02:22:04,020 [Listener at 0.0.0.0/35751] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(750)) - S3 Multi-Tenancy is disabled
2023-03-15 02:22:04,021 [Listener at 0.0.0.0/35751] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:04,037 [Listener at 0.0.0.0/35751] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4228)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2023-03-15 02:22:04,037 [Listener at 0.0.0.0/35751] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-15 02:22:04,037 [Listener at 0.0.0.0/35751] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(439)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2023-03-15 02:22:04,038 [Listener at 0.0.0.0/35751] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:04,038 [Listener at 0.0.0.0/35751] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:04,038 [Listener at 0.0.0.0/35751] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-03-15 02:22:04,039 [Listener at 0.0.0.0/35751] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(164)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:45611
2023-03-15 02:22:04,039 [Listener at 0.0.0.0/35751] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(636)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2023-03-15 02:22:04,039 [Listener at 0.0.0.0/35751] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-15 02:22:04,039 [Listener at 0.0.0.0/35751] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:04,039 [Listener at 0.0.0.0/35751] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 45611 (fallback to raft.grpc.server.port)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 45611 (fallback to raft.grpc.server.port)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 45611 (custom)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-15 02:22:04,040 [Listener at 0.0.0.0/35751] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-15 02:22:04,041 [Listener at 0.0.0.0/35751] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2023-03-15 02:22:04,042 [Listener at 0.0.0.0/35751] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-15 02:22:04,042 [Listener at 0.0.0.0/35751] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-15 02:22:04,042 [Listener at 0.0.0.0/35751] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-15 02:22:04,042 [Listener at 0.0.0.0/35751] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:04,042 [Listener at 0.0.0.0/35751] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/ozone-meta/ratis] (custom)
2023-03-15 02:22:04,044 [Listener at 0.0.0.0/35751] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:45611|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@6987378f[Not completed]
2023-03-15 02:22:04,045 [Listener at 0.0.0.0/35751] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2107)) - OzoneManager Ratis server initialized at port 45611
2023-03-15 02:22:04,045 [Listener at 0.0.0.0/35751] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1134)) - Creating RPC Server
2023-03-15 02:22:04,046 [pool-2453-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:45611|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
2023-03-15 02:22:04,046 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2023-03-15 02:22:04,046 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2023-03-15 02:22:04,046 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:04,046 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-03-15 02:22:04,046 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:04,046 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:04,046 [pool-2453-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:localhost:45611|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:04,046 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/ozone-meta/ratis] (custom)
2023-03-15 02:22:04,047 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:04,047 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:04,047 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2023-03-15 02:22:04,047 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2023-03-15 02:22:04,047 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:04,049 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:04,049 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:04,049 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:04,049 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:04,049 [pool-2453-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:04,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:04,277 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:04,278 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [deleteContainerCommand: containerID: 7, replicaIndex: 2, force: true] for container ContainerInfo{id=#7, state=CLOSED, pipelineID=PipelineID=acd51a91-9a06-4d0e-9c02-534add183928, stateEnterTime=2023-03-15T02:21:23.693Z, owner=om1} to 49ec7792-09fe-4082-843c-e0901275937b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848544278 and scm deadline 1678848724278
2023-03-15 02:22:04,278 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [deleteContainerCommand: containerID: 10, replicaIndex: 5, force: true] for container ContainerInfo{id=#10, state=CLOSED, pipelineID=PipelineID=71355d29-0f5b-4e6e-86cc-8aae260a911c, stateEnterTime=2023-03-15T02:21:24.833Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848544278 and scm deadline 1678848724278
2023-03-15 02:22:04,278 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [deleteContainerCommand: containerID: 11, replicaIndex: 1, force: true] for container ContainerInfo{id=#11, state=CLOSED, pipelineID=PipelineID=252bb837-2b85-4c58-9ec8-22393c5ca3db, stateEnterTime=2023-03-15T02:21:25.317Z, owner=om1} to c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848544278 and scm deadline 1678848724278
2023-03-15 02:22:04,278 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [deleteContainerCommand: containerID: 12, replicaIndex: 4, force: true] for container ContainerInfo{id=#12, state=CLOSED, pipelineID=PipelineID=7ce0591d-f406-4473-a1cb-56d802685ccf, stateEnterTime=2023-03-15T02:21:26.591Z, owner=om1} to 49ec7792-09fe-4082-843c-e0901275937b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848544278 and scm deadline 1678848724278
2023-03-15 02:22:04,278 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 4 containers with health state counts {OVER_REPLICATED=4},failed processing 0
2023-03-15 02:22:04,280 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:04,293 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:04,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:04,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 4 containers.
2023-03-15 02:22:04,298 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:04,323 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 12 containers.
2023-03-15 02:22:04,323 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:04,525 [Listener at 0.0.0.0/35751] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 479 ms to scan 19 urls, producing 68 keys and 4936 values [using 2 cores]
2023-03-15 02:22:04,526 [Listener at 0.0.0.0/35751] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:04,527 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-03-15 02:22:04,572 [Listener at 127.0.0.1/37433] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2023-03-15 02:22:04,586 [Listener at 127.0.0.1/37433] INFO  om.OzoneManager (OzoneManager.java:start(1564)) - OzoneManager RPC server is listening at localhost/127.0.0.1:37433
2023-03-15 02:22:04,586 [Listener at 127.0.0.1/37433] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(559)) - Starting OzoneManagerRatisServer om1 at port 45611
2023-03-15 02:22:04,586 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2023-03-15 02:22:04,587 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:04,589 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2023-03-15 02:22:04,589 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:04,589 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:04,589 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:04,589 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:04,590 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:04,590 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-15 02:22:04,590 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:04,590 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:04,590 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2023-03-15 02:22:04,590 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-03-15 02:22:04,590 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2023-03-15 02:22:04,590 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-03-15 02:22:04,591 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2023-03-15 02:22:04,591 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:04,591 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:04,591 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:04,591 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:04,592 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-03-15 02:22:04,592 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:04,598 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:04,598 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:04,598 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2023-03-15 02:22:04,598 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:04,598 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:04,598 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:localhost:45611|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:04,598 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:04,598 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2023-03-15 02:22:04,601 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-03-15 02:22:04,601 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:04,601 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2023-03-15 02:22:04,601 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2023-03-15 02:22:04,601 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2023-03-15 02:22:04,602 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:04,602 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:04,602 [Listener at 127.0.0.1/37433] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - om1: start RPC server
2023-03-15 02:22:04,602 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - om1: GrpcService started, listening on 45611
2023-03-15 02:22:04,605 [Listener at 127.0.0.1/37433] INFO  om.OzoneManager (OzoneManager.java:start(1580)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2023-03-15 02:22:04,606 [JvmPauseMonitor51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-om1: Started
2023-03-15 02:22:04,614 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2023-03-15 02:22:04,614 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:04,615 [Listener at 127.0.0.1/37433] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:04,616 [Listener at 127.0.0.1/37433] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:04,617 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:04,617 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2023-03-15 02:22:04,617 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:04,617 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:04,618 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/ozone-meta/webserver
2023-03-15 02:22:04,618 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 38997
2023-03-15 02:22:04,618 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:04,636 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:04,636 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:04,636 [Listener at 127.0.0.1/37433] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-15 02:22:04,641 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@fdded0d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:04,641 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@158ded3e{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-15 02:22:04,643 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@226d5359{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-15 02:22:04,648 [Listener at 127.0.0.1/37433] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@62863dd6{HTTP/1.1, (http/1.1)}{0.0.0.0:38997}
2023-03-15 02:22:04,648 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(415)) - Started @179526ms
2023-03-15 02:22:04,649 [Listener at 127.0.0.1/37433] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:04,650 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of ozoneManager listening at http://0.0.0.0:38997
2023-03-15 02:22:04,651 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:04,651 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-03-15 02:22:04,653 [Listener at 127.0.0.1/37433] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2051)) - Trash Interval set to 0. Files deleted won't move to trash
2023-03-15 02:22:04,724 [Finalizer] WARN  managed.ManagedRocksObjectUtils (ManagedRocksObjectUtils.java:assertClosed(54)) - RocksIterator is not closed properly
2023-03-15 02:22:04,748 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6846331b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:04,765 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:04,766 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:04,766 [Listener at 127.0.0.1/37433] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-15 02:22:04,782 [Listener at 127.0.0.1/37433] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(229)) - HddsDatanodeService host:fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net ip:10.1.0.23
2023-03-15 02:22:04,810 [Listener at 127.0.0.1/37433] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:04,836 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:04,837 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 26 -> 25
2023-03-15 02:22:04,836 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:04,838 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 25 -> 24
2023-03-15 02:22:04,848 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:04,848 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:04,849 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 25 -> 24
2023-03-15 02:22:04,850 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 24 -> 23
2023-03-15 02:22:04,878 [Listener at 127.0.0.1/37433] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 66 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:04,879 [Listener at 127.0.0.1/37433] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-15 02:22:04,885 [Listener at 127.0.0.1/37433] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-15 02:22:04,886 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data-0/containers/hdds to VolumeSet
2023-03-15 02:22:04,886 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data-0/containers/hdds
2023-03-15 02:22:04,888 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data-0/containers/hdds
2023-03-15 02:22:04,902 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis to VolumeSet
2023-03-15 02:22:04,903 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis
2023-03-15 02:22:04,903 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis
2023-03-15 02:22:04,925 [Thread-3207] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data-0/containers/hdds
2023-03-15 02:22:04,925 [Listener at 127.0.0.1/37433] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-15 02:22:04,927 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-15 02:22:04,930 [Listener at 127.0.0.1/37433] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-15 02:22:04,931 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-15 02:22:04,931 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-15 02:22:04,931 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-15 02:22:04,931 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-15 02:22:04,931 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-15 02:22:04,931 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-15 02:22:04,932 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-15 02:22:04,932 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-15 02:22:04,932 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-15 02:22:04,932 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-15 02:22:04,933 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-15 02:22:04,933 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-15 02:22:04,933 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:04,933 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:04,933 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis] (custom)
2023-03-15 02:22:04,934 [dda7196a-19a1-4ef5-a6eb-ce99792637b5-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3c63546c] REGISTERED
2023-03-15 02:22:04,934 [dda7196a-19a1-4ef5-a6eb-ce99792637b5-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3c63546c] BIND: 0.0.0.0/0.0.0.0:0
2023-03-15 02:22:04,934 [dda7196a-19a1-4ef5-a6eb-ce99792637b5-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3c63546c, L:/0:0:0:0:0:0:0:0:46287] ACTIVE
2023-03-15 02:22:04,935 [Listener at 127.0.0.1/37433] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-15 02:22:04,938 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-15 02:22:04,938 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:04,939 [Listener at 127.0.0.1/37433] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:04,941 [Listener at 127.0.0.1/37433] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:04,942 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:04,942 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-15 02:22:04,942 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:04,942 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:04,942 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/meta/webserver
2023-03-15 02:22:04,942 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 42955
2023-03-15 02:22:04,943 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:04,949 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:04,949 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:04,949 [Listener at 127.0.0.1/37433] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-15 02:22:04,950 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7e12ef9b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:04,950 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@349cec8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-15 02:22:05,202 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6e896e20{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/meta/webserver/jetty-0_0_0_0-42955-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-3600306387653639900/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:05,207 [Listener at 127.0.0.1/37433] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4bcb020f{HTTP/1.1, (http/1.1)}{0.0.0.0:42955}
2023-03-15 02:22:05,207 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(415)) - Started @180085ms
2023-03-15 02:22:05,207 [Listener at 127.0.0.1/37433] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:05,208 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:42955
2023-03-15 02:22:05,209 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:05,209 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:05,209 [Listener at 127.0.0.1/37433] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-15 02:22:05,216 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-15 02:22:05,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:05,223 [Listener at 127.0.0.1/37433] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(229)) - HddsDatanodeService host:fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net ip:10.1.0.23
2023-03-15 02:22:05,230 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4959ee8e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:05,233 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/meta/datanode.id
2023-03-15 02:22:05,265 [Listener at 127.0.0.1/37433] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:05,272 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-4/data-0/containers/hdds/926a3f87-e453-428c-b155-4688bf5536ac/DS-516b8220-8370-4bc8-b9b0-8f932c0a9880/container.db for volume DS-516b8220-8370-4bc8-b9b0-8f932c0a9880
2023-03-15 02:22:05,272 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-15 02:22:05,272 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-15 02:22:05,274 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-15 02:22:05,277 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:05,288 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:05,293 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:05,298 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-1/data-0/containers/hdds/926a3f87-e453-428c-b155-4688bf5536ac/DS-63b8f07c-9cd2-451d-b695-7b4a8e3119d9/container.db for volume DS-63b8f07c-9cd2-451d-b695-7b4a8e3119d9
2023-03-15 02:22:05,300 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-15 02:22:05,301 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-15 02:22:05,301 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:05,306 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:05,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 4 containers.
2023-03-15 02:22:05,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:05,325 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:05,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 12 containers.
2023-03-15 02:22:05,337 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1013c325{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:05,338 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-15 02:22:05,341 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@61f06ea{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:05,341 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:05,349 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@25865ee0{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-15 02:22:05,355 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5d979ed1{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:05,393 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@c3114ea{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:05,397 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5ead245{HTTP/1.1, (http/1.1)}{0.0.0.0:43023}
2023-03-15 02:22:05,397 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:05,399 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5b0d480c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-15 02:22:05,402 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5ab06829{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:05,425 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:05,425 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:05,429 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - a2e38771-97ec-4c41-9533-82a103767b0b: close
2023-03-15 02:22:05,429 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469: shutdown
2023-03-15 02:22:05,429 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FC918C320469,id=a2e38771-97ec-4c41-9533-82a103767b0b
2023-03-15 02:22:05,430 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - a2e38771-97ec-4c41-9533-82a103767b0b: shutdown a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-LeaderStateImpl
2023-03-15 02:22:05,430 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:05,430 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:05,430 [a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-FC918C320469: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-2/data/ratis/2ab7e996-f10a-469a-8408-fc918c320469/sm/snapshot.1_0
2023-03-15 02:22:05,431 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - a2e38771-97ec-4c41-9533-82a103767b0b: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:05,431 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE: shutdown
2023-03-15 02:22:05,431 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5E30A3BFDCFE,id=a2e38771-97ec-4c41-9533-82a103767b0b
2023-03-15 02:22:05,431 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - a2e38771-97ec-4c41-9533-82a103767b0b: shutdown a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-LeaderStateImpl
2023-03-15 02:22:05,435 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b Close channels
2023-03-15 02:22:05,435 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:05,435 [a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->6cc283c3-90e9-4b51-9f1a-a0029c7c549b-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->6cc283c3-90e9-4b51-9f1a-a0029c7c549b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-15 02:22:05,435 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - c0541761-aa68-4214-a339-56b9b1ec7b43: close
2023-03-15 02:22:05,436 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b: Completed APPEND_ENTRIES, lastRequest: a2e38771-97ec-4c41-9533-82a103767b0b->6cc283c3-90e9-4b51-9f1a-a0029c7c549b#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "6cc283c3-90e9-4b51-9f1a-a0029c7c549b"
address: "10.1.0.23:35419"
dataStreamAddress: "10.1.0.23:35885"
clientAddress: "10.1.0.23:35419"
adminAddress: "10.1.0.23:35419"
startupRole: FOLLOWER
,id: "2e577448-b8d8-48ce-8745-caa267c5872e"
address: "10.1.0.23:45807"
dataStreamAddress: "10.1.0.23:34803"
clientAddress: "10.1.0.23:45807"
adminAddress: "10.1.0.23:45807"
startupRole: FOLLOWER
,id: "a2e38771-97ec-4c41-9533-82a103767b0b"
address: "10.1.0.23:37399"
priority: 1
dataStreamAddress: "10.1.0.23:41773"
clientAddress: "10.1.0.23:37399"
adminAddress: "10.1.0.23:37399"
startupRole: FOLLOWER
, old:)
2023-03-15 02:22:05,436 [a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->2e577448-b8d8-48ce-8745-caa267c5872e-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->2e577448-b8d8-48ce-8745-caa267c5872e-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-15 02:22:05,436 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->6cc283c3-90e9-4b51-9f1a-a0029c7c549b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-15 02:22:05,437 [grpc-default-executor-0] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->6cc283c3-90e9-4b51-9f1a-a0029c7c549b-GrpcLogAppender: Failed to getClient for 6cc283c3-90e9-4b51-9f1a-a0029c7c549b
org.apache.ratis.protocol.exceptions.AlreadyClosedException: a2e38771-97ec-4c41-9533-82a103767b0b is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-15 02:22:05,437 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:05,437 [a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-5E30A3BFDCFE: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-2/data/ratis/c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe/sm/snapshot.1_0
2023-03-15 02:22:05,437 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 2e577448-b8d8-48ce-8745-caa267c5872e: Completed APPEND_ENTRIES, lastRequest: a2e38771-97ec-4c41-9533-82a103767b0b->2e577448-b8d8-48ce-8745-caa267c5872e#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "6cc283c3-90e9-4b51-9f1a-a0029c7c549b"
address: "10.1.0.23:35419"
dataStreamAddress: "10.1.0.23:35885"
clientAddress: "10.1.0.23:35419"
adminAddress: "10.1.0.23:35419"
startupRole: FOLLOWER
,id: "2e577448-b8d8-48ce-8745-caa267c5872e"
address: "10.1.0.23:45807"
dataStreamAddress: "10.1.0.23:34803"
clientAddress: "10.1.0.23:45807"
adminAddress: "10.1.0.23:45807"
startupRole: FOLLOWER
,id: "a2e38771-97ec-4c41-9533-82a103767b0b"
address: "10.1.0.23:37399"
priority: 1
dataStreamAddress: "10.1.0.23:41773"
clientAddress: "10.1.0.23:37399"
adminAddress: "10.1.0.23:37399"
startupRole: FOLLOWER
, old:)
2023-03-15 02:22:05,438 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b: Completed APPEND_ENTRIES, lastRequest: null
2023-03-15 02:22:05,438 [a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-5E30A3BFDCFE: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-2/data/ratis/c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe/sm/snapshot.1_0 took: 1 ms
2023-03-15 02:22:05,438 [grpc-default-executor-9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->6cc283c3-90e9-4b51-9f1a-a0029c7c549b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-15 02:22:05,438 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->6cc283c3-90e9-4b51-9f1a-a0029c7c549b-GrpcLogAppender: Failed to getClient for 6cc283c3-90e9-4b51-9f1a-a0029c7c549b
org.apache.ratis.protocol.exceptions.AlreadyClosedException: a2e38771-97ec-4c41-9533-82a103767b0b is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:432)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:465)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-03-15 02:22:05,438 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->2e577448-b8d8-48ce-8745-caa267c5872e-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-15 02:22:05,438 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 2e577448-b8d8-48ce-8745-caa267c5872e: Completed APPEND_ENTRIES, lastRequest: null
2023-03-15 02:22:05,438 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->2e577448-b8d8-48ce-8745-caa267c5872e: nextIndex: updateUnconditionally 1 -> 0
2023-03-15 02:22:05,438 [a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:05,438 [a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:05,439 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE: closes. applyIndex: 0
2023-03-15 02:22:05,440 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - c0541761-aa68-4214-a339-56b9b1ec7b43: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:05,440 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4: shutdown
2023-03-15 02:22:05,441 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2798F6AD2DD4,id=c0541761-aa68-4214-a339-56b9b1ec7b43
2023-03-15 02:22:05,441 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c0541761-aa68-4214-a339-56b9b1ec7b43: shutdown c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-FollowerState
2023-03-15 02:22:05,441 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-FollowerState was interrupted
2023-03-15 02:22:05,441 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-2798F6AD2DD4: Taking a snapshot at:(t:1, i:31) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-3/data/ratis/7822455f-27f0-4240-bfdb-2798f6ad2dd4/sm/snapshot.1_31
2023-03-15 02:22:05,441 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-StateMachineUpdater: set stopIndex = 31
2023-03-15 02:22:05,442 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-2798F6AD2DD4: Finished taking a snapshot at:(t:1, i:31) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-3/data/ratis/7822455f-27f0-4240-bfdb-2798f6ad2dd4/sm/snapshot.1_31 took: 1 ms
2023-03-15 02:22:05,442 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-StateMachineUpdater: Took a snapshot at index 31
2023-03-15 02:22:05,442 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 31
2023-03-15 02:22:05,443 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4: closes. applyIndex: 31
2023-03-15 02:22:05,445 [a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-FC918C320469: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-2/data/ratis/2ab7e996-f10a-469a-8408-fc918c320469/sm/snapshot.1_0 took: 14 ms
2023-03-15 02:22:05,445 [a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:05,445 [a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:05,445 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469: closes. applyIndex: 0
2023-03-15 02:22:05,446 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:05,446 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-2798F6AD2DD4-SegmentedRaftLogWorker close()
2023-03-15 02:22:05,448 [a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:05,449 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-FC918C320469-SegmentedRaftLogWorker close()
2023-03-15 02:22:05,449 [a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:05,461 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->2e577448-b8d8-48ce-8745-caa267c5872e-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-15 02:22:05,461 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE->2e577448-b8d8-48ce-8745-caa267c5872e: nextIndex: updateUnconditionally 0 -> 0
2023-03-15 02:22:05,461 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - dff27167-0db1-43de-a597-ad7d66669fa4 Close channels
2023-03-15 02:22:05,461 [a2e38771-97ec-4c41-9533-82a103767b0b-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - a2e38771-97ec-4c41-9533-82a103767b0b@group-5E30A3BFDCFE-SegmentedRaftLogWorker close()
2023-03-15 02:22:05,469 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C: shutdown
2023-03-15 02:22:05,469 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-56F9F413B02C,id=c0541761-aa68-4214-a339-56b9b1ec7b43
2023-03-15 02:22:05,470 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c0541761-aa68-4214-a339-56b9b1ec7b43: shutdown c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-LeaderStateImpl
2023-03-15 02:22:05,471 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:05,469 [grpc-default-executor-0] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - c0541761-aa68-4214-a339-56b9b1ec7b43: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-15 02:22:05,469 [grpc-default-executor-1] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - c0541761-aa68-4214-a339-56b9b1ec7b43: installSnapshot onError, lastRequest: dff27167-0db1-43de-a597-ad7d66669fa4->c0541761-aa68-4214-a339-56b9b1ec7b43#190-t1,previous=(t:1, i:30),leaderCommit=29,initializing? true,entries: size=1, first=(t:1, i:31), METADATAENTRY(c:29): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-15 02:22:05,475 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 2e577448-b8d8-48ce-8745-caa267c5872e Close channels
2023-03-15 02:22:05,470 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e Close channels
2023-03-15 02:22:05,477 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-15 02:22:05,495 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 32 -> 31
2023-03-15 02:22:05,495 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-56F9F413B02C: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-3/data/ratis/c79eb4e6-51eb-416c-bf8f-56f9f413b02c/sm/snapshot.1_0
2023-03-15 02:22:05,493 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:05,490 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - a2e38771-97ec-4c41-9533-82a103767b0b: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:05,481 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-15 02:22:05,481 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - c0541761-aa68-4214-a339-56b9b1ec7b43: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:05,496 [a2e38771-97ec-4c41-9533-82a103767b0b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa29ddbf0, L:/0:0:0:0:0:0:0:0:41773] CLOSE
2023-03-15 02:22:05,496 [c0541761-aa68-4214-a339-56b9b1ec7b43-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x97b21d3d, L:/0:0:0:0:0:0:0:0:39973] CLOSE
2023-03-15 02:22:05,496 [a2e38771-97ec-4c41-9533-82a103767b0b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa29ddbf0, L:/0:0:0:0:0:0:0:0:41773] INACTIVE
2023-03-15 02:22:05,497 [c0541761-aa68-4214-a339-56b9b1ec7b43-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x97b21d3d, L:/0:0:0:0:0:0:0:0:39973] INACTIVE
2023-03-15 02:22:05,497 [c0541761-aa68-4214-a339-56b9b1ec7b43-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x97b21d3d, L:/0:0:0:0:0:0:0:0:39973] UNREGISTERED
2023-03-15 02:22:05,496 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 31 -> 30
2023-03-15 02:22:05,497 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-56F9F413B02C: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-3/data/ratis/c79eb4e6-51eb-416c-bf8f-56f9f413b02c/sm/snapshot.1_0 took: 1 ms
2023-03-15 02:22:05,497 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:05,497 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:05,497 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C: closes. applyIndex: 0
2023-03-15 02:22:05,497 [a2e38771-97ec-4c41-9533-82a103767b0b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa29ddbf0, L:/0:0:0:0:0:0:0:0:41773] UNREGISTERED
2023-03-15 02:22:05,503 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:05,503 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 31 -> 30
2023-03-15 02:22:05,503 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:05,504 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 30 -> 29
2023-03-15 02:22:05,510 [c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:05,510 [c0541761-aa68-4214-a339-56b9b1ec7b43-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c0541761-aa68-4214-a339-56b9b1ec7b43@group-56F9F413B02C-SegmentedRaftLogWorker close()
2023-03-15 02:22:05,521 [JvmPauseMonitor28] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-a2e38771-97ec-4c41-9533-82a103767b0b: Stopped
2023-03-15 02:22:05,524 [JvmPauseMonitor29] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-c0541761-aa68-4214-a339-56b9b1ec7b43: Stopped
2023-03-15 02:22:05,536 [Listener at 127.0.0.1/37433] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 267 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:05,538 [Listener at 127.0.0.1/37433] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-15 02:22:05,539 [Listener at 127.0.0.1/37433] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-15 02:22:05,539 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data-0/containers/hdds to VolumeSet
2023-03-15 02:22:05,540 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data-0/containers/hdds
2023-03-15 02:22:05,540 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data-0/containers/hdds
2023-03-15 02:22:05,545 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) moved to stale state. Finalizing its pipelines [PipelineID=e23b3f27-6f65-49a3-bcd3-40224524692d, PipelineID=7822455f-27f0-4240-bfdb-2798f6ad2dd4, PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212]
2023-03-15 02:22:05,545 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: e23b3f27-6f65-49a3-bcd3-40224524692d, Nodes: ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:ba703dd0-9123-40b7-b53b-b3e9bbb37b8e, CreationTimestamp2023-03-15T02:20:13.472Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:05,546 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #2 closed for pipeline=PipelineID=7822455f-27f0-4240-bfdb-2798f6ad2dd4
2023-03-15 02:22:05,546 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #5 closed for pipeline=PipelineID=7822455f-27f0-4240-bfdb-2798f6ad2dd4
2023-03-15 02:22:05,546 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #6 closed for pipeline=PipelineID=7822455f-27f0-4240-bfdb-2798f6ad2dd4
2023-03-15 02:22:05,546 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 7822455f-27f0-4240-bfdb-2798f6ad2dd4, Nodes: c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dff27167-0db1-43de-a597-ad7d66669fa4, CreationTimestamp2023-03-15T02:20:14.145Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:05,546 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #9 closed for pipeline=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212
2023-03-15 02:22:05,547 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, Nodes: 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: EC{rs-3-2-1048576}, State:OPEN, leaderId:, CreationTimestamp2023-03-15T02:21:24.495Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:05,547 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #2, current state: CLOSING
2023-03-15 02:22:05,547 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #5, current state: CLOSING
2023-03-15 02:22:05,547 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #6, current state: CLOSING
2023-03-15 02:22:05,547 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #9, current state: CLOSING
2023-03-15 02:22:05,553 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis to VolumeSet
2023-03-15 02:22:05,553 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis
2023-03-15 02:22:05,553 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis
2023-03-15 02:22:05,569 [Thread-3239] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data-0/containers/hdds
2023-03-15 02:22:05,569 [Listener at 127.0.0.1/37433] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-15 02:22:05,573 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:05,574 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:05,574 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-15 02:22:05,574 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-15 02:22:05,575 [Listener at 127.0.0.1/37433] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-15 02:22:05,575 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-15 02:22:05,576 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-15 02:22:05,576 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-15 02:22:05,576 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-15 02:22:05,576 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-15 02:22:05,576 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-15 02:22:05,576 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-15 02:22:05,576 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-15 02:22:05,576 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-15 02:22:05,577 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-15 02:22:05,577 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-15 02:22:05,577 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-15 02:22:05,577 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:05,577 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:05,577 [42380981-9e90-41f5-811d-3bbbf08d47d9-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf6256e47] REGISTERED
2023-03-15 02:22:05,577 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis] (custom)
2023-03-15 02:22:05,577 [42380981-9e90-41f5-811d-3bbbf08d47d9-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf6256e47] BIND: 0.0.0.0/0.0.0.0:0
2023-03-15 02:22:05,578 [42380981-9e90-41f5-811d-3bbbf08d47d9-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf6256e47, L:/0:0:0:0:0:0:0:0:35043] ACTIVE
2023-03-15 02:22:05,579 [Listener at 127.0.0.1/37433] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-15 02:22:05,590 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-15 02:22:05,590 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:05,591 [Listener at 127.0.0.1/37433] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:05,592 [Listener at 127.0.0.1/37433] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:05,593 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:05,593 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-15 02:22:05,593 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:05,593 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:05,593 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/meta/webserver
2023-03-15 02:22:05,594 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34279
2023-03-15 02:22:05,594 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:05,609 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:05,610 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:05,610 [Listener at 127.0.0.1/37433] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-15 02:22:05,610 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4707ecc7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:05,610 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@701d3bfd{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-15 02:22:05,745 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 49ec7792-09fe-4082-843c-e0901275937b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) moved to stale state. Finalizing its pipelines [PipelineID=cb21bf1f-fbd8-4662-b4d4-a5fceea3c264]
2023-03-15 02:22:05,745 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: cb21bf1f-fbd8-4662-b4d4-a5fceea3c264, Nodes: 49ec7792-09fe-4082-843c-e0901275937b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:00.832Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:05,794 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1195532703ns, electionTimeout:1192ms
2023-03-15 02:22:05,794 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2023-03-15 02:22:05,794 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:05,794 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:05,794 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection91
2023-03-15 02:22:05,795 [om1@group-C5BA1605619E-LeaderElection91] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection91 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|rpc:localhost:45611|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:05,795 [om1@group-C5BA1605619E-LeaderElection91] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection91 PRE_VOTE round 0: result PASSED (term=0)
2023-03-15 02:22:05,797 [om1@group-C5BA1605619E-LeaderElection91] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection91 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:localhost:45611|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:05,798 [om1@group-C5BA1605619E-LeaderElection91] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection91 ELECTION round 0: result PASSED (term=1)
2023-03-15 02:22:05,798 [om1@group-C5BA1605619E-LeaderElection91] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection91
2023-03-15 02:22:05,798 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:05,798 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1751ms
2023-03-15 02:22:05,798 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:05,798 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-15 02:22:05,798 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-03-15 02:22:05,799 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2023-03-15 02:22:05,799 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:05,799 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:05,799 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-03-15 02:22:05,799 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:05,799 [om1@group-C5BA1605619E-LeaderElection91] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2023-03-15 02:22:05,800 [om1@group-C5BA1605619E-LeaderElection91] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:05,813 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2023-03-15 02:22:05,814 [om1@group-C5BA1605619E-LeaderElection91] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:localhost:45611|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:05,815 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:45611"
startupRole: FOLLOWER
]
2023-03-15 02:22:05,875 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1e626428{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/meta/webserver/jetty-0_0_0_0-34279-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-5608564694575521999/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:05,879 [Listener at 127.0.0.1/37433] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1655ebc7{HTTP/1.1, (http/1.1)}{0.0.0.0:34279}
2023-03-15 02:22:05,879 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(415)) - Started @180757ms
2023-03-15 02:22:05,879 [Listener at 127.0.0.1/37433] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:05,880 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34279
2023-03-15 02:22:05,880 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-15 02:22:05,880 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:05,881 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:05,881 [Listener at 127.0.0.1/37433] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-15 02:22:05,893 [Listener at 127.0.0.1/37433] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(229)) - HddsDatanodeService host:fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net ip:10.1.0.23
2023-03-15 02:22:05,896 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@ddc9fe6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:05,898 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/meta/datanode.id
2023-03-15 02:22:05,919 [Listener at 127.0.0.1/37433] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:05,971 [Listener at 127.0.0.1/37433] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 51 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:05,972 [Listener at 127.0.0.1/37433] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-15 02:22:05,974 [Listener at 127.0.0.1/37433] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-15 02:22:05,974 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data-0/containers/hdds to VolumeSet
2023-03-15 02:22:05,974 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data-0/containers/hdds
2023-03-15 02:22:05,974 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data-0/containers/hdds
2023-03-15 02:22:05,987 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis to VolumeSet
2023-03-15 02:22:05,987 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis
2023-03-15 02:22:05,987 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis
2023-03-15 02:22:06,003 [Thread-3255] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data-0/containers/hdds
2023-03-15 02:22:06,004 [Listener at 127.0.0.1/37433] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-15 02:22:06,005 [Listener at 127.0.0.1/37433] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-15 02:22:06,005 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-15 02:22:06,006 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-15 02:22:06,009 [Listener at 127.0.0.1/37433] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-15 02:22:06,009 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-15 02:22:06,010 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-15 02:22:06,011 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-15 02:22:06,011 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-15 02:22:06,012 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-15 02:22:06,012 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-15 02:22:06,013 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-15 02:22:06,013 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-15 02:22:06,013 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-15 02:22:06,013 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-15 02:22:06,014 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-15 02:22:06,014 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-15 02:22:06,014 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:06,014 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:06,014 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis] (custom)
2023-03-15 02:22:06,014 [c86f293d-b980-46b7-b4bb-ca602f6dc485-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x4e3c045e] REGISTERED
2023-03-15 02:22:06,014 [c86f293d-b980-46b7-b4bb-ca602f6dc485-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x4e3c045e] BIND: 0.0.0.0/0.0.0.0:0
2023-03-15 02:22:06,014 [c86f293d-b980-46b7-b4bb-ca602f6dc485-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x4e3c045e, L:/0:0:0:0:0:0:0:0:33749] ACTIVE
2023-03-15 02:22:06,016 [Listener at 127.0.0.1/37433] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-15 02:22:06,018 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-15 02:22:06,019 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:06,019 [Listener at 127.0.0.1/37433] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:06,020 [Listener at 127.0.0.1/37433] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:06,021 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:06,021 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-15 02:22:06,021 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:06,021 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:06,021 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/meta/webserver
2023-03-15 02:22:06,022 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 41905
2023-03-15 02:22:06,022 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:06,023 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:06,024 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:06,024 [Listener at 127.0.0.1/37433] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-15 02:22:06,025 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7ef761fe{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:06,025 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@413132c1{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-15 02:22:06,062 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,062 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,063 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 29 -> 28
2023-03-15 02:22:06,063 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 28 -> 27
2023-03-15 02:22:06,074 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,074 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 28 -> 27
2023-03-15 02:22:06,075 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,075 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 27 -> 26
2023-03-15 02:22:06,086 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,087 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 23 -> 22
2023-03-15 02:22:06,088 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,088 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 22 -> 21
2023-03-15 02:22:06,097 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,097 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 22 -> 21
2023-03-15 02:22:06,098 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,099 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 21 -> 20
2023-03-15 02:22:06,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:06,277 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:06,289 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:06,293 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:06,301 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:06,306 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:06,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 5 containers.
2023-03-15 02:22:06,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-15 02:22:06,325 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:06,329 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:06,329 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:06,329 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:06,329 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:06,329 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:06,329 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:06,329 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:06,330 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:06,330 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:06,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848546330 and scm deadline 1678848726330
2023-03-15 02:22:06,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848546330 and scm deadline 1678848726330
2023-03-15 02:22:06,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to 6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848546330 and scm deadline 1678848726330
2023-03-15 02:22:06,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848546330 and scm deadline 1678848726330
2023-03-15 02:22:06,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848546330 and scm deadline 1678848726330
2023-03-15 02:22:06,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 12 containers.
2023-03-15 02:22:06,354 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@50dc61ec{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/meta/webserver/jetty-0_0_0_0-41905-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-8962980151333182033/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:06,362 [Listener at 127.0.0.1/37433] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7a3657df{HTTP/1.1, (http/1.1)}{0.0.0.0:41905}
2023-03-15 02:22:06,362 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(415)) - Started @181239ms
2023-03-15 02:22:06,362 [Listener at 127.0.0.1/37433] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:06,364 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41905
2023-03-15 02:22:06,376 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-15 02:22:06,377 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:06,377 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:06,377 [Listener at 127.0.0.1/37433] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-15 02:22:06,400 [Listener at 127.0.0.1/37433] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(229)) - HddsDatanodeService host:fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net ip:10.1.0.23
2023-03-15 02:22:06,409 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@540eec21] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:06,430 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/meta/datanode.id
2023-03-15 02:22:06,449 [Listener at 127.0.0.1/37433] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:06,527 [Listener at 127.0.0.1/37433] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 76 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:06,530 [Listener at 127.0.0.1/37433] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-15 02:22:06,532 [Listener at 127.0.0.1/37433] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-15 02:22:06,534 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data-0/containers/hdds to VolumeSet
2023-03-15 02:22:06,534 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data-0/containers/hdds
2023-03-15 02:22:06,540 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data-0/containers/hdds
2023-03-15 02:22:06,575 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis to VolumeSet
2023-03-15 02:22:06,575 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis
2023-03-15 02:22:06,578 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis
2023-03-15 02:22:06,617 [Thread-3270] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data-0/containers/hdds
2023-03-15 02:22:06,617 [Listener at 127.0.0.1/37433] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:06,619 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-15 02:22:06,620 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-15 02:22:06,621 [Listener at 127.0.0.1/37433] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-15 02:22:06,621 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-15 02:22:06,621 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-15 02:22:06,621 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-15 02:22:06,621 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-15 02:22:06,621 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-15 02:22:06,621 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-15 02:22:06,622 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-15 02:22:06,622 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-15 02:22:06,622 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-15 02:22:06,622 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-15 02:22:06,623 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-15 02:22:06,623 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-15 02:22:06,623 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:06,623 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:06,623 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis] (custom)
2023-03-15 02:22:06,623 [71dc2d0c-c132-482e-adc3-0da69386d6d8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x15931a60] REGISTERED
2023-03-15 02:22:06,623 [71dc2d0c-c132-482e-adc3-0da69386d6d8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x15931a60] BIND: 0.0.0.0/0.0.0.0:0
2023-03-15 02:22:06,624 [71dc2d0c-c132-482e-adc3-0da69386d6d8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x15931a60, L:/0:0:0:0:0:0:0:0:36025] ACTIVE
2023-03-15 02:22:06,625 [Listener at 127.0.0.1/37433] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-15 02:22:06,627 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-15 02:22:06,627 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:06,628 [Listener at 127.0.0.1/37433] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:06,629 [Listener at 127.0.0.1/37433] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:06,630 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:06,630 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-15 02:22:06,630 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:06,630 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:06,630 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/meta/webserver
2023-03-15 02:22:06,631 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 41919
2023-03-15 02:22:06,631 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:06,633 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:06,633 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:06,633 [Listener at 127.0.0.1/37433] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-15 02:22:06,634 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@568ea8c4{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:06,634 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@70d1133{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-15 02:22:06,740 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,740 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,741 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,741 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 21 -> 20
2023-03-15 02:22:06,741 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 27 -> 26
2023-03-15 02:22:06,741 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 20 -> 19
2023-03-15 02:22:06,742 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:06,742 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 26 -> 25
2023-03-15 02:22:07,022 [IPC Server handler 3 on default port 37571] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(366)) - Starting Maintenance for node 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:07,025 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) moved to HEALTHY state.
2023-03-15 02:22:07,025 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:07,029 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-15 02:22:07,151 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@852b5e1{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/meta/webserver/jetty-0_0_0_0-41919-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-4848554537700157410/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:07,156 [Listener at 127.0.0.1/37433] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2a5d4a84{HTTP/1.1, (http/1.1)}{0.0.0.0:41919}
2023-03-15 02:22:07,157 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(415)) - Started @182034ms
2023-03-15 02:22:07,157 [Listener at 127.0.0.1/37433] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:07,157 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41919
2023-03-15 02:22:07,158 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:07,158 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:07,158 [Listener at 127.0.0.1/37433] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-15 02:22:07,164 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-15 02:22:07,172 [Listener at 127.0.0.1/37433] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(229)) - HddsDatanodeService host:fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net ip:10.1.0.23
2023-03-15 02:22:07,174 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5dd50d3d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:07,176 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/meta/datanode.id
2023-03-15 02:22:07,203 [Listener at 127.0.0.1/37433] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:07,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:07,278 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:07,285 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-6e078747-2a67-438b-a46c-c71e4112ab09/container.db to cache
2023-03-15 02:22:07,285 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-6e078747-2a67-438b-a46c-c71e4112ab09/container.db for volume DS-6e078747-2a67-438b-a46c-c71e4112ab09
2023-03-15 02:22:07,285 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-15 02:22:07,285 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-15 02:22:07,286 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 37663
2023-03-15 02:22:07,290 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:07,290 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis dda7196a-19a1-4ef5-a6eb-ce99792637b5
2023-03-15 02:22:07,295 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: start RPC server
2023-03-15 02:22:07,296 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:07,297 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: GrpcService started, listening on 32909
2023-03-15 02:22:07,297 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis dda7196a-19a1-4ef5-a6eb-ce99792637b5 is started using port 32909 for RATIS
2023-03-15 02:22:07,297 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis dda7196a-19a1-4ef5-a6eb-ce99792637b5 is started using port 32909 for RATIS_ADMIN
2023-03-15 02:22:07,297 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis dda7196a-19a1-4ef5-a6eb-ce99792637b5 is started using port 32909 for RATIS_SERVER
2023-03-15 02:22:07,297 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis dda7196a-19a1-4ef5-a6eb-ce99792637b5 is started using port 46287 for RATIS_DATASTREAM
2023-03-15 02:22:07,297 [JvmPauseMonitor52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-dda7196a-19a1-4ef5-a6eb-ce99792637b5: Started
2023-03-15 02:22:07,297 [Listener at 127.0.0.1/37433] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 92 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:07,298 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc dda7196a-19a1-4ef5-a6eb-ce99792637b5 is started using port 45749
2023-03-15 02:22:07,298 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:07,299 [Listener at 127.0.0.1/37433] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-15 02:22:07,300 [Listener at 127.0.0.1/37433] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-15 02:22:07,300 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data-0/containers/hdds to VolumeSet
2023-03-15 02:22:07,300 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data-0/containers/hdds
2023-03-15 02:22:07,301 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data-0/containers/hdds
2023-03-15 02:22:07,304 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:07,306 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:07,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-15 02:22:07,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:07,313 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:07,313 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:07,314 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 25 -> 24
2023-03-15 02:22:07,315 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 24 -> 23
2023-03-15 02:22:07,324 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:07,324 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:07,324 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 24 -> 23
2023-03-15 02:22:07,326 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 23 -> 22
2023-03-15 02:22:07,326 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:07,328 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis to VolumeSet
2023-03-15 02:22:07,328 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis
2023-03-15 02:22:07,329 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848547331 and scm deadline 1678848727331
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to 6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848547331 and scm deadline 1678848727331
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848547331 and scm deadline 1678848727331
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848547331 and scm deadline 1678848727331
2023-03-15 02:22:07,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSING, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848547331 and scm deadline 1678848727331
2023-03-15 02:22:07,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 2 milliseconds for processing 12 containers.
2023-03-15 02:22:07,337 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:07,337 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 19 -> 18
2023-03-15 02:22:07,337 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:07,338 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 18 -> 17
2023-03-15 02:22:07,347 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:07,347 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:07,348 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 18 -> 17
2023-03-15 02:22:07,348 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 17 -> 16
2023-03-15 02:22:07,355 [Thread-3298] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data-0/containers/hdds
2023-03-15 02:22:07,355 [Listener at 127.0.0.1/37433] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-15 02:22:07,357 [Listener at 127.0.0.1/37433] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-15 02:22:07,358 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-15 02:22:07,360 [Listener at 127.0.0.1/37433] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-15 02:22:07,360 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-15 02:22:07,360 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-15 02:22:07,360 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-15 02:22:07,360 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-15 02:22:07,360 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-15 02:22:07,360 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-15 02:22:07,360 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-15 02:22:07,361 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-15 02:22:07,361 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-15 02:22:07,361 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-15 02:22:07,361 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-15 02:22:07,361 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-15 02:22:07,362 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:07,362 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:07,362 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis] (custom)
2023-03-15 02:22:07,362 [6b109e20-fb43-4126-a2d0-e01a40c07237-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x7605bfc3] REGISTERED
2023-03-15 02:22:07,363 [6b109e20-fb43-4126-a2d0-e01a40c07237-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x7605bfc3] BIND: 0.0.0.0/0.0.0.0:0
2023-03-15 02:22:07,363 [6b109e20-fb43-4126-a2d0-e01a40c07237-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x7605bfc3, L:/0:0:0:0:0:0:0:0:34799] ACTIVE
2023-03-15 02:22:07,365 [Listener at 127.0.0.1/37433] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-15 02:22:07,368 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-15 02:22:07,369 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:07,369 [Listener at 127.0.0.1/37433] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:07,370 [Listener at 127.0.0.1/37433] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:07,375 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:07,376 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-15 02:22:07,377 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:07,377 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:07,377 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 9 is synced with bcsId 0.
2023-03-15 02:22:07,377 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 9 is synced with bcsId 0.
2023-03-15 02:22:07,378 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/meta/webserver
2023-03-15 02:22:07,379 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 42577
2023-03-15 02:22:07,379 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:07,379 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 9 is closed with bcsId 0.
2023-03-15 02:22:07,380 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(292)) - Moving container #9 to CLOSED state, datanode 6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) reported CLOSED replica.
2023-03-15 02:22:07,381 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:07,381 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:07,381 [Listener at 127.0.0.1/37433] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-15 02:22:07,382 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6ea4bc02{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:07,382 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7a8abf64{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-15 02:22:07,426 [IPC Server handler 14 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-03-15 02:22:07,491 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 9 is synced with bcsId 0.
2023-03-15 02:22:07,491 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 9 is synced with bcsId 0.
2023-03-15 02:22:07,493 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 9 is closed with bcsId 0.
2023-03-15 02:22:07,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(326)) - Waiting for pipelines to close for 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). There are 2 pipelines
2023-03-15 02:22:07,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:07,529 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Finalizing its pipelines [PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb, PipelineID=1a4b26ce-8fbb-4f60-9299-e897810e2042]
2023-03-15 02:22:07,540 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #1 closed for pipeline=PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb
2023-03-15 02:22:07,540 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #1, current state: CLOSING
2023-03-15 02:22:07,540 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #3 closed for pipeline=PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb
2023-03-15 02:22:07,540 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #6 closed for pipeline=PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb
2023-03-15 02:22:07,549 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 567e773f-eefb-46cf-b9d9-1c9295bea5bb, Nodes: ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:ed5356af-2dee-4266-b55e-559e8c0d6889, CreationTimestamp2023-03-15T02:20:52.873Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:07,549 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb close command to datanode ed5356af-2dee-4266-b55e-559e8c0d6889
2023-03-15 02:22:07,549 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb close command to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6
2023-03-15 02:22:07,549 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb close command to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d
2023-03-15 02:22:07,553 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 567e773f-eefb-46cf-b9d9-1c9295bea5bb, Nodes: ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:ed5356af-2dee-4266-b55e-559e8c0d6889, CreationTimestamp2023-03-15T02:20:52.873Z[Etc/UTC]] removed.
2023-03-15 02:22:07,553 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #3, current state: CLOSING
2023-03-15 02:22:07,553 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) moved to stale state. Finalizing its pipelines [PipelineID=c79eb4e6-51eb-416c-bf8f-56f9f413b02c, PipelineID=7822455f-27f0-4240-bfdb-2798f6ad2dd4, PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8]
2023-03-15 02:22:07,553 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 1a4b26ce-8fbb-4f60-9299-e897810e2042, Nodes: 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:13b63f14-21ce-4492-9d02-d9a6b9e153c6, CreationTimestamp2023-03-15T02:20:52.406Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:07,554 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: c79eb4e6-51eb-416c-bf8f-56f9f413b02c, Nodes: c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:c0541761-aa68-4214-a339-56b9b1ec7b43, CreationTimestamp2023-03-15T02:20:12.937Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:07,554 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #8 closed for pipeline=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8
2023-03-15 02:22:07,554 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=1a4b26ce-8fbb-4f60-9299-e897810e2042 close command to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6
2023-03-15 02:22:07,554 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 1a4b26ce-8fbb-4f60-9299-e897810e2042, Nodes: 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:13b63f14-21ce-4492-9d02-d9a6b9e153c6, CreationTimestamp2023-03-15T02:20:52.406Z[Etc/UTC]] removed.
2023-03-15 02:22:07,554 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: aa94b31b-70f4-4343-8e73-d14ceea2ddc8, Nodes: dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: EC{rs-3-2-1048576}, State:OPEN, leaderId:, CreationTimestamp2023-03-15T02:21:24.193Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:07,555 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #8, current state: CLOSING
2023-03-15 02:22:07,558 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(78)) - Close container Event triggered for container : #6, current state: CLOSING
2023-03-15 02:22:07,566 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-2/data-0/containers/hdds/926a3f87-e453-428c-b155-4688bf5536ac/DS-5ba02818-e7b9-49f9-8a7d-0c6437bca2b1/container.db for volume DS-5ba02818-e7b9-49f9-8a7d-0c6437bca2b1
2023-03-15 02:22:07,566 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-15 02:22:07,567 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-3/data-0/containers/hdds/926a3f87-e453-428c-b155-4688bf5536ac/DS-c03d1da7-72ef-41ae-be73-78af58b25357/container.db for volume DS-c03d1da7-72ef-41ae-be73-78af58b25357
2023-03-15 02:22:07,567 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-15 02:22:07,567 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-15 02:22:07,569 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-15 02:22:07,582 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-15 02:22:07,588 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-15 02:22:07,609 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@515bdac4{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:07,610 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5efcd4e1{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:07,610 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:07,614 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@13b05c2{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-15 02:22:07,617 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5469076b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:07,627 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@143dff12{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:07,628 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:07,628 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6363e52a{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:07,628 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:07,629 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 2e577448-b8d8-48ce-8745-caa267c5872e: close
2023-03-15 02:22:07,635 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE: shutdown
2023-03-15 02:22:07,636 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5E30A3BFDCFE,id=2e577448-b8d8-48ce-8745-caa267c5872e
2023-03-15 02:22:07,636 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2e577448-b8d8-48ce-8745-caa267c5872e: shutdown 2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-FollowerState
2023-03-15 02:22:07,636 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 2e577448-b8d8-48ce-8745-caa267c5872e: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:07,639 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3f161de1{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-15 02:22:07,639 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@bedab3c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:07,641 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A: shutdown
2023-03-15 02:22:07,641 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8195E871A18A,id=2e577448-b8d8-48ce-8745-caa267c5872e
2023-03-15 02:22:07,641 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 2e577448-b8d8-48ce-8745-caa267c5872e: shutdown 2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-LeaderStateImpl
2023-03-15 02:22:07,641 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:07,642 [2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-FollowerState was interrupted
2023-03-15 02:22:07,642 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:07,643 [2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-5E30A3BFDCFE: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-6/data/ratis/c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe/sm/snapshot.1_0
2023-03-15 02:22:07,644 [2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-8195E871A18A: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-6/data/ratis/2eb2382e-cff8-440f-960d-8195e871a18a/sm/snapshot.1_0
2023-03-15 02:22:07,644 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:07,646 [2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-5E30A3BFDCFE: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-6/data/ratis/c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe/sm/snapshot.1_0 took: 3 ms
2023-03-15 02:22:07,646 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 2e577448-b8d8-48ce-8745-caa267c5872e: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:07,647 [2e577448-b8d8-48ce-8745-caa267c5872e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa4fe89e2, L:/0:0:0:0:0:0:0:0:34803] CLOSE
2023-03-15 02:22:07,647 [2e577448-b8d8-48ce-8745-caa267c5872e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa4fe89e2, L:/0:0:0:0:0:0:0:0:34803] INACTIVE
2023-03-15 02:22:07,648 [2e577448-b8d8-48ce-8745-caa267c5872e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa4fe89e2, L:/0:0:0:0:0:0:0:0:34803] UNREGISTERED
2023-03-15 02:22:07,647 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:07,646 [2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-8195E871A18A: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-6/data/ratis/2eb2382e-cff8-440f-960d-8195e871a18a/sm/snapshot.1_0 took: 3 ms
2023-03-15 02:22:07,648 [2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:07,648 [2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:07,646 [2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:07,648 [2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:07,649 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE: closes. applyIndex: 0
2023-03-15 02:22:07,649 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A: closes. applyIndex: 0
2023-03-15 02:22:07,670 [2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:07,670 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-5E30A3BFDCFE-SegmentedRaftLogWorker close()
2023-03-15 02:22:07,670 [2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:07,681 [2e577448-b8d8-48ce-8745-caa267c5872e-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 2e577448-b8d8-48ce-8745-caa267c5872e@group-8195E871A18A-SegmentedRaftLogWorker close()
2023-03-15 02:22:07,681 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b: close
2023-03-15 02:22:07,682 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3: shutdown
2023-03-15 02:22:07,682 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-12A902955AF3,id=6cc283c3-90e9-4b51-9f1a-a0029c7c549b
2023-03-15 02:22:07,683 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b: shutdown 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-LeaderStateImpl
2023-03-15 02:22:07,683 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:07,683 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-12A902955AF3: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-0/data/ratis/96066cba-aadf-4fa4-9f1b-12a902955af3/sm/snapshot.1_0
2023-03-15 02:22:07,684 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:07,684 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:07,684 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 49ec7792-09fe-4082-843c-e0901275937b Close channels
2023-03-15 02:22:07,684 [JvmPauseMonitor32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-2e577448-b8d8-48ce-8745-caa267c5872e: Stopped
2023-03-15 02:22:07,684 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-12A902955AF3: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-0/data/ratis/96066cba-aadf-4fa4-9f1b-12a902955af3/sm/snapshot.1_0 took: 1 ms
2023-03-15 02:22:07,685 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:07,685 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:07,685 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE: shutdown
2023-03-15 02:22:07,692 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 2e577448-b8d8-48ce-8745-caa267c5872e Close channels
2023-03-15 02:22:07,693 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - a2e38771-97ec-4c41-9533-82a103767b0b Close channels
2023-03-15 02:22:07,693 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:07,693 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3: closes. applyIndex: 0
2023-03-15 02:22:07,693 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5E30A3BFDCFE,id=6cc283c3-90e9-4b51-9f1a-a0029c7c549b
2023-03-15 02:22:07,693 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b: shutdown 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-FollowerState
2023-03-15 02:22:07,693 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-FollowerState was interrupted
2023-03-15 02:22:07,693 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd6688c5c, L:/0:0:0:0:0:0:0:0:35885] CLOSE
2023-03-15 02:22:07,693 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:07,693 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd6688c5c, L:/0:0:0:0:0:0:0:0:35885] INACTIVE
2023-03-15 02:22:07,693 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-5E30A3BFDCFE: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-0/data/ratis/c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe/sm/snapshot.1_0
2023-03-15 02:22:07,694 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd6688c5c, L:/0:0:0:0:0:0:0:0:35885] UNREGISTERED
2023-03-15 02:22:07,694 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-5E30A3BFDCFE: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-0/data/ratis/c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe/sm/snapshot.1_0 took: 1 ms
2023-03-15 02:22:07,694 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:07,694 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:07,695 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE: closes. applyIndex: 0
2023-03-15 02:22:07,697 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:07,697 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-5E30A3BFDCFE-SegmentedRaftLogWorker close()
2023-03-15 02:22:07,698 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:07,698 [6cc283c3-90e9-4b51-9f1a-a0029c7c549b-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 6cc283c3-90e9-4b51-9f1a-a0029c7c549b@group-12A902955AF3-SegmentedRaftLogWorker close()
2023-03-15 02:22:07,701 [JvmPauseMonitor26] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-6cc283c3-90e9-4b51-9f1a-a0029c7c549b: Stopped
2023-03-15 02:22:07,771 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@fb5e663{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/meta/webserver/jetty-0_0_0_0-42577-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-5552671951667276185/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:07,775 [Listener at 127.0.0.1/37433] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@90fe933{HTTP/1.1, (http/1.1)}{0.0.0.0:42577}
2023-03-15 02:22:07,775 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(415)) - Started @182653ms
2023-03-15 02:22:07,776 [Listener at 127.0.0.1/37433] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:07,776 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:42577
2023-03-15 02:22:07,777 [Listener at 127.0.0.1/37433] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-15 02:22:07,783 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-15 02:22:07,790 [Listener at 127.0.0.1/37433] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(229)) - HddsDatanodeService host:fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net ip:10.1.0.23
2023-03-15 02:22:07,804 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f0a48a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:07,807 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/meta/datanode.id
2023-03-15 02:22:07,825 [Listener at 127.0.0.1/37433] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:07,888 [Listener at 127.0.0.1/37433] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 61 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:07,890 [Listener at 127.0.0.1/37433] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-15 02:22:07,891 [Listener at 127.0.0.1/37433] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-15 02:22:07,892 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data-0/containers/hdds to VolumeSet
2023-03-15 02:22:07,892 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data-0/containers/hdds
2023-03-15 02:22:07,892 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data-0/containers/hdds
2023-03-15 02:22:07,907 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis to VolumeSet
2023-03-15 02:22:07,907 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis
2023-03-15 02:22:07,907 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis
2023-03-15 02:22:07,922 [Thread-3332] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data-0/containers/hdds
2023-03-15 02:22:07,922 [Listener at 127.0.0.1/37433] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-15 02:22:07,924 [Listener at 127.0.0.1/37433] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-15 02:22:07,925 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-15 02:22:07,927 [Listener at 127.0.0.1/37433] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-15 02:22:07,927 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-15 02:22:07,928 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-15 02:22:07,928 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-15 02:22:07,928 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-15 02:22:07,928 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-15 02:22:07,928 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-15 02:22:07,928 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-15 02:22:07,928 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-15 02:22:07,929 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-15 02:22:07,929 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-15 02:22:07,929 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-15 02:22:07,929 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-15 02:22:07,929 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:07,929 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:07,929 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis] (custom)
2023-03-15 02:22:07,930 [1847c06b-5456-44fe-a2e2-332407f19896-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x126e2b9a] REGISTERED
2023-03-15 02:22:07,931 [Listener at 127.0.0.1/37433] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-15 02:22:07,934 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-15 02:22:07,934 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:07,934 [1847c06b-5456-44fe-a2e2-332407f19896-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x126e2b9a] BIND: 0.0.0.0/0.0.0.0:0
2023-03-15 02:22:07,935 [1847c06b-5456-44fe-a2e2-332407f19896-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x126e2b9a, L:/0:0:0:0:0:0:0:0:41099] ACTIVE
2023-03-15 02:22:07,936 [Listener at 127.0.0.1/37433] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:07,936 [Listener at 127.0.0.1/37433] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:07,937 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:07,938 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-15 02:22:07,938 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:07,938 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:07,938 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/meta/webserver
2023-03-15 02:22:07,938 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 39849
2023-03-15 02:22:07,938 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:07,942 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:07,942 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:07,943 [Listener at 127.0.0.1/37433] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-15 02:22:07,943 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3826aa73{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:07,943 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6f6f955e{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-15 02:22:07,950 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-3029babd-53f9-49fa-9170-97aa11e15302/container.db to cache
2023-03-15 02:22:07,950 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-3029babd-53f9-49fa-9170-97aa11e15302/container.db for volume DS-3029babd-53f9-49fa-9170-97aa11e15302
2023-03-15 02:22:07,951 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-15 02:22:07,951 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-15 02:22:07,951 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 36435
2023-03-15 02:22:07,955 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 42380981-9e90-41f5-811d-3bbbf08d47d9
2023-03-15 02:22:07,956 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) moved to stale state. Finalizing its pipelines [PipelineID=2ab7e996-f10a-469a-8408-fc918c320469, PipelineID=c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe, PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8]
2023-03-15 02:22:07,957 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 2ab7e996-f10a-469a-8408-fc918c320469, Nodes: a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:a2e38771-97ec-4c41-9533-82a103767b0b, CreationTimestamp2023-03-15T02:20:12.533Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:07,957 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe, Nodes: 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a2e38771-97ec-4c41-9533-82a103767b0b, CreationTimestamp2023-03-15T02:21:33.955Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:07,967 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: start RPC server
2023-03-15 02:22:07,968 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: GrpcService started, listening on 40377
2023-03-15 02:22:07,968 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 42380981-9e90-41f5-811d-3bbbf08d47d9 is started using port 40377 for RATIS
2023-03-15 02:22:07,968 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 42380981-9e90-41f5-811d-3bbbf08d47d9 is started using port 40377 for RATIS_ADMIN
2023-03-15 02:22:07,968 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 42380981-9e90-41f5-811d-3bbbf08d47d9 is started using port 40377 for RATIS_SERVER
2023-03-15 02:22:07,968 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 42380981-9e90-41f5-811d-3bbbf08d47d9 is started using port 35043 for RATIS_DATASTREAM
2023-03-15 02:22:07,969 [JvmPauseMonitor53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-42380981-9e90-41f5-811d-3bbbf08d47d9: Started
2023-03-15 02:22:07,969 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 42380981-9e90-41f5-811d-3bbbf08d47d9 is started using port 45555
2023-03-15 02:22:07,970 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:08,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:08,278 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:08,290 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:08,297 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:08,304 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:08,306 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:08,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:08,326 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:08,328 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7f4485d4{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/meta/webserver/jetty-0_0_0_0-39849-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-1959532471846584630/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:08,333 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,333 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,333 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,333 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,333 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848548334 and scm deadline 1678848728334
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848548334 and scm deadline 1678848728334
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848548334 and scm deadline 1678848728334
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to 6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848548334 and scm deadline 1678848728334
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848548334 and scm deadline 1678848728334
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848548334 and scm deadline 1678848728334
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848548334 and scm deadline 1678848728334
2023-03-15 02:22:08,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848548334 and scm deadline 1678848728334
2023-03-15 02:22:08,335 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 2 milliseconds for processing 12 containers.
2023-03-15 02:22:08,340 [Listener at 127.0.0.1/37433] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5dddbb19{HTTP/1.1, (http/1.1)}{0.0.0.0:39849}
2023-03-15 02:22:08,340 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(415)) - Started @183217ms
2023-03-15 02:22:08,340 [Listener at 127.0.0.1/37433] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:08,341 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:39849
2023-03-15 02:22:08,341 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-15 02:22:08,341 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:08,341 [Listener at 127.0.0.1/37433] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-03-15 02:22:08,341 [Listener at 127.0.0.1/37433] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-03-15 02:22:08,358 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@215de8c9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:08,361 [Listener at 127.0.0.1/37433] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(229)) - HddsDatanodeService host:fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net ip:10.1.0.23
2023-03-15 02:22:08,366 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/meta/datanode.id
2023-03-15 02:22:08,393 [Listener at 127.0.0.1/37433] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:08,425 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb is not found
2023-03-15 02:22:08,426 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb is not found
2023-03-15 02:22:08,426 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=1a4b26ce-8fbb-4f60-9299-e897810e2042 is not found
2023-03-15 02:22:08,463 [Listener at 127.0.0.1/37433] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 69 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:08,464 [Listener at 127.0.0.1/37433] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-03-15 02:22:08,465 [Listener at 127.0.0.1/37433] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-03-15 02:22:08,466 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data-0/containers/hdds to VolumeSet
2023-03-15 02:22:08,466 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data-0/containers/hdds
2023-03-15 02:22:08,467 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data-0/containers/hdds
2023-03-15 02:22:08,469 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-7a51d141-e611-49d3-8a34-f5ce4abb8905/container.db to cache
2023-03-15 02:22:08,469 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-7a51d141-e611-49d3-8a34-f5ce4abb8905/container.db for volume DS-7a51d141-e611-49d3-8a34-f5ce4abb8905
2023-03-15 02:22:08,469 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-15 02:22:08,469 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-15 02:22:08,470 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 42263
2023-03-15 02:22:08,476 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:08,478 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:08,478 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=e23b3f27-6f65-49a3-bcd3-40224524692d close command to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e
2023-03-15 02:22:08,478 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: e23b3f27-6f65-49a3-bcd3-40224524692d, Nodes: ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:ba703dd0-9123-40b7-b53b-b3e9bbb37b8e, CreationTimestamp2023-03-15T02:20:13.472Z[Etc/UTC]] removed.
2023-03-15 02:22:08,478 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=7822455f-27f0-4240-bfdb-2798f6ad2dd4 close command to datanode c0541761-aa68-4214-a339-56b9b1ec7b43
2023-03-15 02:22:08,478 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=7822455f-27f0-4240-bfdb-2798f6ad2dd4 close command to datanode ba703dd0-9123-40b7-b53b-b3e9bbb37b8e
2023-03-15 02:22:08,478 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=7822455f-27f0-4240-bfdb-2798f6ad2dd4 close command to datanode dff27167-0db1-43de-a597-ad7d66669fa4
2023-03-15 02:22:08,478 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 7822455f-27f0-4240-bfdb-2798f6ad2dd4, Nodes: c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:dff27167-0db1-43de-a597-ad7d66669fa4, CreationTimestamp2023-03-15T02:20:14.145Z[Etc/UTC]] removed.
2023-03-15 02:22:08,478 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, Nodes: 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)ba703dd0-9123-40b7-b53b-b3e9bbb37b8e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: EC{rs-3-2-1048576}, State:CLOSED, leaderId:, CreationTimestamp2023-03-15T02:21:24.495Z[Etc/UTC]] removed.
2023-03-15 02:22:08,479 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/ba703dd0-9123-40b7-b53b-b3e9bbb37b8e
2023-03-15 02:22:08,497 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: start RPC server
2023-03-15 02:22:08,498 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: GrpcService started, listening on 38675
2023-03-15 02:22:08,499 [Listener at 127.0.0.1/37433] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis to VolumeSet
2023-03-15 02:22:08,499 [Listener at 127.0.0.1/37433] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis
2023-03-15 02:22:08,499 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c86f293d-b980-46b7-b4bb-ca602f6dc485 is started using port 38675 for RATIS
2023-03-15 02:22:08,499 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c86f293d-b980-46b7-b4bb-ca602f6dc485 is started using port 38675 for RATIS_ADMIN
2023-03-15 02:22:08,499 [Listener at 127.0.0.1/37433] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis
2023-03-15 02:22:08,499 [JvmPauseMonitor54] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-c86f293d-b980-46b7-b4bb-ca602f6dc485: Started
2023-03-15 02:22:08,499 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c86f293d-b980-46b7-b4bb-ca602f6dc485 is started using port 38675 for RATIS_SERVER
2023-03-15 02:22:08,506 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis c86f293d-b980-46b7-b4bb-ca602f6dc485 is started using port 33749 for RATIS_DATASTREAM
2023-03-15 02:22:08,507 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc c86f293d-b980-46b7-b4bb-ca602f6dc485 is started using port 42377
2023-03-15 02:22:08,507 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:08,515 [Thread-3356] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data-0/containers/hdds
2023-03-15 02:22:08,515 [Listener at 127.0.0.1/37433] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(307)) - Build ContainerSet costs 0s
2023-03-15 02:22:08,516 [Listener at 127.0.0.1/37433] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-03-15 02:22:08,516 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-03-15 02:22:08,517 [Listener at 127.0.0.1/37433] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-03-15 02:22:08,518 [Listener at 127.0.0.1/37433] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-03-15 02:22:08,519 [Listener at 127.0.0.1/37433] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-03-15 02:22:08,520 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-03-15 02:22:08,520 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-03-15 02:22:08,520 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:08,520 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:08,520 [Listener at 127.0.0.1/37433] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis] (custom)
2023-03-15 02:22:08,520 [bb24641f-ac05-4a48-a34b-331e584b8427-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x483e5333] REGISTERED
2023-03-15 02:22:08,521 [bb24641f-ac05-4a48-a34b-331e584b8427-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x483e5333] BIND: 0.0.0.0/0.0.0.0:0
2023-03-15 02:22:08,521 [bb24641f-ac05-4a48-a34b-331e584b8427-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x483e5333, L:/0:0:0:0:0:0:0:0:39219] ACTIVE
2023-03-15 02:22:08,522 [Listener at 127.0.0.1/37433] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-03-15 02:22:08,524 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-03-15 02:22:08,525 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:08,525 [Listener at 127.0.0.1/37433] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:08,526 [Listener at 127.0.0.1/37433] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:08,526 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:08,527 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-03-15 02:22:08,527 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:08,527 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:08,527 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/meta/webserver
2023-03-15 02:22:08,527 [Listener at 127.0.0.1/37433] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 45831
2023-03-15 02:22:08,528 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:08,529 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:08,529 [Listener at 127.0.0.1/37433] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:08,529 [Listener at 127.0.0.1/37433] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-15 02:22:08,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-15 02:22:08,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-15 02:22:08,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #1 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=38, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=38, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=38, keyCount=4, bytesUsed=76}}
2023-03-15 02:22:08,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #1 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=38, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=38, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=38, keyCount=4, bytesUsed=76}}
2023-03-15 02:22:08,530 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #3 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-15 02:22:08,530 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #3 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-15 02:22:08,530 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) has 0 sufficientlyReplicated, 3 underReplicated and 3 unhealthy containers
2023-03-15 02:22:08,530 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:08,533 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2c3a6ba0{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:08,533 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@58b8980b{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-03-15 02:22:08,564 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:08,564 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:08,565 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 22 -> 21
2023-03-15 02:22:08,566 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 21 -> 20
2023-03-15 02:22:08,575 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:08,575 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 21 -> 20
2023-03-15 02:22:08,575 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:08,576 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43: nextIndex: updateUnconditionally 20 -> 19
2023-03-15 02:22:08,587 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:08,588 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 16 -> 15
2023-03-15 02:22:08,588 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:08,588 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 15 -> 14
2023-03-15 02:22:08,598 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:08,598 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 15 -> 14
2023-03-15 02:22:08,598 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:08,598 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->ba703dd0-9123-40b7-b53b-b3e9bbb37b8e: nextIndex: updateUnconditionally 14 -> 13
2023-03-15 02:22:08,778 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 49ec7792-09fe-4082-843c-e0901275937b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:08,778 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=cb21bf1f-fbd8-4662-b4d4-a5fceea3c264 close command to datanode 49ec7792-09fe-4082-843c-e0901275937b
2023-03-15 02:22:08,778 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: cb21bf1f-fbd8-4662-b4d4-a5fceea3c264, Nodes: 49ec7792-09fe-4082-843c-e0901275937b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:, CreationTimestamp2023-03-15T02:22:00.832Z[Etc/UTC]] removed.
2023-03-15 02:22:08,779 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/49ec7792-09fe-4082-843c-e0901275937b
2023-03-15 02:22:08,792 [Listener at 127.0.0.1/37433] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6168afd1{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/meta/webserver/jetty-0_0_0_0-45831-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-3767460090940284479/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:08,797 [Listener at 127.0.0.1/37433] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@355532b7{HTTP/1.1, (http/1.1)}{0.0.0.0:45831}
2023-03-15 02:22:08,797 [Listener at 127.0.0.1/37433] INFO  server.Server (Server.java:doStart(415)) - Started @183674ms
2023-03-15 02:22:08,797 [Listener at 127.0.0.1/37433] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:08,798 [Listener at 127.0.0.1/37433] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45831
2023-03-15 02:22:08,798 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(517)) - Ozone container server started.
2023-03-15 02:22:08,798 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-15 02:22:08,799 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:08,799 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:08,801 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1429ab0f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:08,801 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/meta/datanode.id
2023-03-15 02:22:09,211 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-85136513-0baa-4754-8726-437fc55fecf4/container.db to cache
2023-03-15 02:22:09,211 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-85136513-0baa-4754-8726-437fc55fecf4/container.db for volume DS-85136513-0baa-4754-8726-437fc55fecf4
2023-03-15 02:22:09,211 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-15 02:22:09,212 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-15 02:22:09,212 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 38751
2023-03-15 02:22:09,217 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 71dc2d0c-c132-482e-adc3-0da69386d6d8
2023-03-15 02:22:09,219 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: start RPC server
2023-03-15 02:22:09,219 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: GrpcService started, listening on 33845
2023-03-15 02:22:09,221 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 71dc2d0c-c132-482e-adc3-0da69386d6d8 is started using port 33845 for RATIS
2023-03-15 02:22:09,221 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 71dc2d0c-c132-482e-adc3-0da69386d6d8 is started using port 33845 for RATIS_ADMIN
2023-03-15 02:22:09,221 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 71dc2d0c-c132-482e-adc3-0da69386d6d8 is started using port 33845 for RATIS_SERVER
2023-03-15 02:22:09,221 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 71dc2d0c-c132-482e-adc3-0da69386d6d8 is started using port 36025 for RATIS_DATASTREAM
2023-03-15 02:22:09,222 [JvmPauseMonitor55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-71dc2d0c-c132-482e-adc3-0da69386d6d8: Started
2023-03-15 02:22:09,222 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 71dc2d0c-c132-482e-adc3-0da69386d6d8 is started using port 40175
2023-03-15 02:22:09,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:09,225 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:09,232 [IPC Server handler 13 on default port 44419] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/dda7196a-19a1-4ef5-a6eb-ce99792637b5
2023-03-15 02:22:09,232 [IPC Server handler 13 on default port 44419] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : dda7196a-19a1-4ef5-a6eb-ce99792637b5{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=37663, RATIS=32909, RATIS_ADMIN=32909, RATIS_SERVER=32909, RATIS_DATASTREAM=46287, STANDALONE=45749], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:09,244 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-15 02:22:09,244 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-15 02:22:09,247 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-15 02:22:09,251 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:09,251 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=78ab6313-1582-4821-a408-d59eff0a6f52 to datanode:dda7196a-19a1-4ef5-a6eb-ce99792637b5
2023-03-15 02:22:09,252 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 78ab6313-1582-4821-a408-d59eff0a6f52, Nodes: dda7196a-19a1-4ef5-a6eb-ce99792637b5(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:09.251Z[Etc/UTC]].
2023-03-15 02:22:09,278 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:09,290 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:09,297 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:09,304 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:09,307 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-15 02:22:09,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:09,326 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:09,335 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #1 is under replicated. Expected replica count is 3, but found 1.
2023-03-15 02:22:09,335 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:09,335 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL to 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:09,335 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,335 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,335 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2023-03-15 02:22:09,335 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId: 3, replicaIndex: 0, sourceNodes: [6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #4 is under replicated. Expected replica count is 3, but found 2.
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId: 4, replicaIndex: 0, sourceNodes: [6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL to 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848549336 and scm deadline 1678848729336
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848549336 and scm deadline 1678848729336
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848549336 and scm deadline 1678848729336
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to 6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848549336 and scm deadline 1678848729336
2023-03-15 02:22:09,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848549336 and scm deadline 1678848729336
2023-03-15 02:22:09,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848549337 and scm deadline 1678848729337
2023-03-15 02:22:09,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848549337 and scm deadline 1678848729337
2023-03-15 02:22:09,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 2 milliseconds for processing 12 containers.
2023-03-15 02:22:09,409 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:09,433 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb is not found
2023-03-15 02:22:09,531 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-15 02:22:09,531 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-03-15 02:22:09,531 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #1 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=38, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=38, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=38, keyCount=4, bytesUsed=76}}
2023-03-15 02:22:09,531 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #1 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=38, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=38, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=38, keyCount=4, bytesUsed=76}}
2023-03-15 02:22:09,531 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #3 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-15 02:22:09,532 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #3 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=646e529a-a01f-4b15-a31a-2706cdf8d47d, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=ed5356af-2dee-4266-b55e-559e8c0d6889, sequenceId=30, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=13b63f14-21ce-4492-9d02-d9a6b9e153c6, sequenceId=30, keyCount=3, bytesUsed=57}}
2023-03-15 02:22:09,532 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) has 0 sufficientlyReplicated, 3 underReplicated and 3 unhealthy containers
2023-03-15 02:22:09,532 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:09,734 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-6/data-0/containers/hdds/926a3f87-e453-428c-b155-4688bf5536ac/DS-77590b61-12b8-4eac-a1d4-d9f6f3408ca0/container.db for volume DS-77590b61-12b8-4eac-a1d4-d9f6f3408ca0
2023-03-15 02:22:09,734 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-15 02:22:09,737 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-0/data-0/containers/hdds/926a3f87-e453-428c-b155-4688bf5536ac/DS-c33de470-c75d-4a16-9f68-4cf7c0079b65/container.db for volume DS-c33de470-c75d-4a16-9f68-4cf7c0079b65
2023-03-15 02:22:09,737 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-15 02:22:09,749 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-15 02:22:09,750 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-15 02:22:09,750 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=7822455f-27f0-4240-bfdb-2798f6ad2dd4 is not found
2023-03-15 02:22:09,754 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-15 02:22:09,757 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-15 02:22:09,781 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@12ba7c5f{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:09,783 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@7434957{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:09,783 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:09,783 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@cd9426f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-15 02:22:09,783 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1d3e4e3e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:09,788 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@f069753{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:09,789 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1a4ebe4c{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:09,789 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:09,794 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@205ca4ae{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-15 02:22:09,798 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4620886b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:09,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 1 of 7 DN Heartbeats.
2023-03-15 02:22:09,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:09,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:09,833 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:09,834 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - dff27167-0db1-43de-a597-ad7d66669fa4: close
2023-03-15 02:22:09,835 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(133)) - Can't close container #2
java.io.IOException
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:631)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:105)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:642)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.InterruptedException
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:347)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1928)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:626)
	... 4 more
2023-03-15 02:22:09,835 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4: shutdown
2023-03-15 02:22:09,836 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2798F6AD2DD4,id=dff27167-0db1-43de-a597-ad7d66669fa4
2023-03-15 02:22:09,836 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - dff27167-0db1-43de-a597-ad7d66669fa4: shutdown dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-LeaderStateImpl
2023-03-15 02:22:09,836 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - dff27167-0db1-43de-a597-ad7d66669fa4: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:09,836 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - ba703dd0-9123-40b7-b53b-b3e9bbb37b8e Close channels
2023-03-15 02:22:09,836 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - c0541761-aa68-4214-a339-56b9b1ec7b43 Close channels
2023-03-15 02:22:09,836 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - dff27167-0db1-43de-a597-ad7d66669fa4: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:09,837 [grpc-default-executor-5] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-15 02:22:09,837 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68: shutdown
2023-03-15 02:22:09,838 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-99095AA9DD68,id=dff27167-0db1-43de-a597-ad7d66669fa4
2023-03-15 02:22:09,838 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - dff27167-0db1-43de-a597-ad7d66669fa4: shutdown dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-LeaderStateImpl
2023-03-15 02:22:09,838 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:09,838 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:09,839 [dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-99095AA9DD68: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-5/data/ratis/2c84acba-82dd-4eaa-aa98-99095aa9dd68/sm/snapshot.1_0
2023-03-15 02:22:09,843 [dff27167-0db1-43de-a597-ad7d66669fa4-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x935a9dcd, L:/0:0:0:0:0:0:0:0:42117] CLOSE
2023-03-15 02:22:09,843 [dff27167-0db1-43de-a597-ad7d66669fa4-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x935a9dcd, L:/0:0:0:0:0:0:0:0:42117] INACTIVE
2023-03-15 02:22:09,844 [dff27167-0db1-43de-a597-ad7d66669fa4-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x935a9dcd, L:/0:0:0:0:0:0:0:0:42117] UNREGISTERED
2023-03-15 02:22:09,844 [dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-99095AA9DD68: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-5/data/ratis/2c84acba-82dd-4eaa-aa98-99095aa9dd68/sm/snapshot.1_0 took: 5 ms
2023-03-15 02:22:09,845 [dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:09,845 [dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:09,845 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68: closes. applyIndex: 0
2023-03-15 02:22:09,845 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:09,846 [dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-GrpcLogAppender-LogAppenderDaemon] ERROR leader.LogAppenderDaemon (LogAppenderDaemon.java:run(87)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4->c0541761-aa68-4214-a339-56b9b1ec7b43-GrpcLogAppender-LogAppenderDaemon failed
org.apache.ratis.protocol.exceptions.AlreadyClosedException: dff27167-0db1-43de-a597-ad7d66669fa4 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:280)
	at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:168)
	at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
	at java.lang.Thread.run(Thread.java:750)
2023-03-15 02:22:09,860 [dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:09,860 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-99095AA9DD68-SegmentedRaftLogWorker close()
2023-03-15 02:22:09,873 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-StateMachineUpdater: set stopIndex = 31
2023-03-15 02:22:09,873 [dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-2798F6AD2DD4: Taking a snapshot at:(t:1, i:31) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-5/data/ratis/7822455f-27f0-4240-bfdb-2798f6ad2dd4/sm/snapshot.1_31
2023-03-15 02:22:09,875 [dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-2798F6AD2DD4: Finished taking a snapshot at:(t:1, i:31) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-5/data/ratis/7822455f-27f0-4240-bfdb-2798f6ad2dd4/sm/snapshot.1_31 took: 1 ms
2023-03-15 02:22:09,875 [dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-StateMachineUpdater: Took a snapshot at index 31
2023-03-15 02:22:09,875 [dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 31
2023-03-15 02:22:09,877 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4: closes. applyIndex: 31
2023-03-15 02:22:09,877 [dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:09,878 [dff27167-0db1-43de-a597-ad7d66669fa4-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - dff27167-0db1-43de-a597-ad7d66669fa4@group-2798F6AD2DD4-SegmentedRaftLogWorker close()
2023-03-15 02:22:09,879 [JvmPauseMonitor31] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-dff27167-0db1-43de-a597-ad7d66669fa4: Stopped
2023-03-15 02:22:09,895 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-b4452cd6-f11b-4267-a512-7b28d4d1422b/container.db to cache
2023-03-15 02:22:09,895 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-b4452cd6-f11b-4267-a512-7b28d4d1422b/container.db for volume DS-b4452cd6-f11b-4267-a512-7b28d4d1422b
2023-03-15 02:22:09,896 [IPC Server handler 15 on default port 44419] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/42380981-9e90-41f5-811d-3bbbf08d47d9
2023-03-15 02:22:09,896 [IPC Server handler 15 on default port 44419] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 42380981-9e90-41f5-811d-3bbbf08d47d9{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=36435, RATIS=40377, RATIS_ADMIN=40377, RATIS_SERVER=40377, RATIS_DATASTREAM=35043, STANDALONE=45555], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:09,896 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:09,900 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=6e97b4b9-43b0-4c2a-bb40-3e24f2997de1 to datanode:42380981-9e90-41f5-811d-3bbbf08d47d9
2023-03-15 02:22:09,900 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-15 02:22:09,901 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 6e97b4b9-43b0-4c2a-bb40-3e24f2997de1, Nodes: 42380981-9e90-41f5-811d-3bbbf08d47d9(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:09.900Z[Etc/UTC]].
2023-03-15 02:22:09,902 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-15 02:22:09,902 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-15 02:22:09,902 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 36927
2023-03-15 02:22:09,906 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 6b109e20-fb43-4126-a2d0-e01a40c07237
2023-03-15 02:22:09,911 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: start RPC server
2023-03-15 02:22:09,911 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: GrpcService started, listening on 44885
2023-03-15 02:22:09,912 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 6b109e20-fb43-4126-a2d0-e01a40c07237 is started using port 44885 for RATIS
2023-03-15 02:22:09,912 [JvmPauseMonitor56] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-6b109e20-fb43-4126-a2d0-e01a40c07237: Started
2023-03-15 02:22:09,912 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 6b109e20-fb43-4126-a2d0-e01a40c07237 is started using port 44885 for RATIS_ADMIN
2023-03-15 02:22:09,912 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 6b109e20-fb43-4126-a2d0-e01a40c07237 is started using port 44885 for RATIS_SERVER
2023-03-15 02:22:09,912 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 6b109e20-fb43-4126-a2d0-e01a40c07237 is started using port 34799 for RATIS_DATASTREAM
2023-03-15 02:22:09,913 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 6b109e20-fb43-4126-a2d0-e01a40c07237 is started using port 33553
2023-03-15 02:22:09,914 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:10,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:10,279 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #10, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 2. Available sources are: {3=(ContainerReplica{containerID=#10, state=CLOSED, datanodeDetails=6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=6cc283c3-90e9-4b51-9f1a-a0029c7c549b, sequenceId=0, keyCount=1, bytesUsed=0,replicaIndex=3},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0), 4=(ContainerReplica{containerID=#10, state=CLOSED, datanodeDetails=2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=2e577448-b8d8-48ce-8745-caa267c5872e, sequenceId=0, keyCount=1, bytesUsed=19,replicaIndex=4},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-03-15 02:22:10,279 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(218)) - Container #10 is under replicated, but no commands were created to correct it
2023-03-15 02:22:10,279 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(212)) - Exception while processing for creating the EC reconstruction container commands for container #11.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No enough datanodes to choose. TotalNode = 5 AvailableNode = 1 RequiredNode = 2 ExcludedNode = 4
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter.chooseDatanodesInternal(SCMContainerPlacementRackScatter.java:238)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.getTargetDatanodes(ECUnderReplicationHandler.java:271)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.processMissingIndexes(ECUnderReplicationHandler.java:300)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.processAndCreateCommands(ECUnderReplicationHandler.java:172)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processUnderReplicatedContainer(ReplicationManager.java:665)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.getDatanodeCommands(UnderReplicatedProcessor.java:58)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.getDatanodeCommands(UnderReplicatedProcessor.java:32)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processContainer(UnhealthyReplicationProcessor.java:129)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processAll(UnhealthyReplicationProcessor.java:97)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:143)
	at java.lang.Thread.run(Thread.java:750)
2023-03-15 02:22:10,279 [Under Replicated Processor] ERROR replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(102)) - Error processing Health result of class: class org.apache.hadoop.hdds.scm.container.replication.ContainerHealthResult$UnderReplicatedHealthResult for container ContainerInfo{id=#11, state=CLOSED, pipelineID=PipelineID=252bb837-2b85-4c58-9ec8-22393c5ca3db, stateEnterTime=2023-03-15T02:21:25.317Z, owner=om1}
org.apache.hadoop.hdds.scm.exceptions.SCMException: No enough datanodes to choose. TotalNode = 5 AvailableNode = 1 RequiredNode = 2 ExcludedNode = 4
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter.chooseDatanodesInternal(SCMContainerPlacementRackScatter.java:238)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.getTargetDatanodes(ECUnderReplicationHandler.java:271)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.processMissingIndexes(ECUnderReplicationHandler.java:300)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.processAndCreateCommands(ECUnderReplicationHandler.java:172)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processUnderReplicatedContainer(ReplicationManager.java:665)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.getDatanodeCommands(UnderReplicatedProcessor.java:58)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.getDatanodeCommands(UnderReplicatedProcessor.java:32)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processContainer(UnhealthyReplicationProcessor.java:129)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processAll(UnhealthyReplicationProcessor.java:97)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:143)
	at java.lang.Thread.run(Thread.java:750)
2023-03-15 02:22:10,280 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #9, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 2. Available sources are: {1=(ContainerReplica{containerID=#9, state=CLOSED, datanodeDetails=2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=2e577448-b8d8-48ce-8745-caa267c5872e, sequenceId=0, keyCount=7, bytesUsed=133,replicaIndex=1},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0), 2=(ContainerReplica{containerID=#9, state=CLOSED, datanodeDetails=6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=6cc283c3-90e9-4b51-9f1a-a0029c7c549b, sequenceId=0, keyCount=7, bytesUsed=0,replicaIndex=2},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-03-15 02:22:10,280 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(218)) - Container #9 is under replicated, but no commands were created to correct it
2023-03-15 02:22:10,280 [Under Replicated Processor] WARN  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(653)) - No available node in (scope="/default-rack" excludedScope="null" excludedNodes="[6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)]"  ancestorGen="0").
2023-03-15 02:22:10,280 [Under Replicated Processor] WARN  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(653)) - No available node in (scope="/default-rack" excludedScope="null" excludedNodes="[6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)]"  ancestorGen="0").
2023-03-15 02:22:10,280 [Under Replicated Processor] WARN  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(653)) - No available node in (scope="/default-rack" excludedScope="null" excludedNodes="[6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)]"  ancestorGen="0").
2023-03-15 02:22:10,280 [Under Replicated Processor] WARN  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(653)) - No available node in (scope="/default-rack" excludedScope="null" excludedNodes="[6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)]"  ancestorGen="0").
2023-03-15 02:22:10,280 [Under Replicated Processor] INFO  algorithms.SCMContainerPlacementRackScatter (SCMContainerPlacementRackScatter.java:chooseNode(421)) - No satisfied datanode to meet the constraints. Metadatadata size required: 0 Data size required: 5368709120, scope /default-rack, excluded nodes [6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)]
2023-03-15 02:22:10,280 [Under Replicated Processor] WARN  algorithms.SCMContainerPlacementRackScatter (SCMContainerPlacementRackScatter.java:chooseDatanodesInternal(317)) - Placement policy could not choose the enough nodes from available racks. Chosen nodes size from Unique Racks: 0, but required nodes to choose from Unique Racks: 1 do not match. Available racks count: 1, Excluded nodes count: 4
2023-03-15 02:22:10,281 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(212)) - Exception while processing for creating the EC reconstruction container commands for container #7.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Chosen nodes size from Unique Racks: 0, but required nodes to choose from Unique Racks: 1 do not match.
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter.chooseDatanodesInternal(SCMContainerPlacementRackScatter.java:321)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.getTargetDatanodes(ECUnderReplicationHandler.java:271)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.processMissingIndexes(ECUnderReplicationHandler.java:300)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.processAndCreateCommands(ECUnderReplicationHandler.java:172)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processUnderReplicatedContainer(ReplicationManager.java:665)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.getDatanodeCommands(UnderReplicatedProcessor.java:58)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.getDatanodeCommands(UnderReplicatedProcessor.java:32)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processContainer(UnhealthyReplicationProcessor.java:129)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processAll(UnhealthyReplicationProcessor.java:97)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:143)
	at java.lang.Thread.run(Thread.java:750)
2023-03-15 02:22:10,281 [Under Replicated Processor] ERROR replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(102)) - Error processing Health result of class: class org.apache.hadoop.hdds.scm.container.replication.ContainerHealthResult$UnderReplicatedHealthResult for container ContainerInfo{id=#7, state=CLOSED, pipelineID=PipelineID=acd51a91-9a06-4d0e-9c02-534add183928, stateEnterTime=2023-03-15T02:21:23.693Z, owner=om1}
org.apache.hadoop.hdds.scm.exceptions.SCMException: Chosen nodes size from Unique Racks: 0, but required nodes to choose from Unique Racks: 1 do not match.
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter.chooseDatanodesInternal(SCMContainerPlacementRackScatter.java:321)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.getTargetDatanodes(ECUnderReplicationHandler.java:271)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.processMissingIndexes(ECUnderReplicationHandler.java:300)
	at org.apache.hadoop.hdds.scm.container.replication.ECUnderReplicationHandler.processAndCreateCommands(ECUnderReplicationHandler.java:172)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processUnderReplicatedContainer(ReplicationManager.java:665)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.getDatanodeCommands(UnderReplicatedProcessor.java:58)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.getDatanodeCommands(UnderReplicatedProcessor.java:32)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processContainer(UnhealthyReplicationProcessor.java:129)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processAll(UnhealthyReplicationProcessor.java:97)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:143)
	at java.lang.Thread.run(Thread.java:750)
2023-03-15 02:22:10,281 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #12, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 2. Available sources are: {2=(ContainerReplica{containerID=#12, state=CLOSED, datanodeDetails=6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=6cc283c3-90e9-4b51-9f1a-a0029c7c549b, sequenceId=0, keyCount=2, bytesUsed=0,replicaIndex=2},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0), 3=(ContainerReplica{containerID=#12, state=CLOSED, datanodeDetails=2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=2e577448-b8d8-48ce-8745-caa267c5872e, sequenceId=0, keyCount=2, bytesUsed=0,replicaIndex=3},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-03-15 02:22:10,281 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(218)) - Container #12 is under replicated, but no commands were created to correct it
2023-03-15 02:22:10,281 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 3 containers with health state counts {UNDER_REPLICATED=3},failed processing 2
2023-03-15 02:22:10,291 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:10,297 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:10,304 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:10,307 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:10,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,308 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-15 02:22:10,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:10,326 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:10,337 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,337 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,337 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848550338 and scm deadline 1678848730338
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848550338 and scm deadline 1678848730338
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848550338 and scm deadline 1678848730338
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to 6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848550338 and scm deadline 1678848730338
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848550338 and scm deadline 1678848730338
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848550338 and scm deadline 1678848730338
2023-03-15 02:22:10,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848550338 and scm deadline 1678848730338
2023-03-15 02:22:10,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 2 milliseconds for processing 12 containers.
2023-03-15 02:22:10,398 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-dd688290-e122-4414-894f-4c7006a1337d/container.db to cache
2023-03-15 02:22:10,398 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-dd688290-e122-4414-894f-4c7006a1337d/container.db for volume DS-dd688290-e122-4414-894f-4c7006a1337d
2023-03-15 02:22:10,398 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-15 02:22:10,398 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-15 02:22:10,399 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 45549
2023-03-15 02:22:10,403 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:10,412 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 1847c06b-5456-44fe-a2e2-332407f19896: start RPC server
2023-03-15 02:22:10,412 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 1847c06b-5456-44fe-a2e2-332407f19896: GrpcService started, listening on 43143
2023-03-15 02:22:10,413 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1847c06b-5456-44fe-a2e2-332407f19896 is started using port 43143 for RATIS
2023-03-15 02:22:10,413 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1847c06b-5456-44fe-a2e2-332407f19896 is started using port 43143 for RATIS_ADMIN
2023-03-15 02:22:10,413 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1847c06b-5456-44fe-a2e2-332407f19896 is started using port 43143 for RATIS_SERVER
2023-03-15 02:22:10,413 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 1847c06b-5456-44fe-a2e2-332407f19896 is started using port 41099 for RATIS_DATASTREAM
2023-03-15 02:22:10,414 [IPC Server handler 19 on default port 44419] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:10,414 [IPC Server handler 19 on default port 44419] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : c86f293d-b980-46b7-b4bb-ca602f6dc485{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=42263, RATIS=38675, RATIS_ADMIN=38675, RATIS_SERVER=38675, RATIS_DATASTREAM=33749, STANDALONE=42377], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:10,414 [JvmPauseMonitor57] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-1847c06b-5456-44fe-a2e2-332407f19896: Started
2023-03-15 02:22:10,414 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:10,414 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 1847c06b-5456-44fe-a2e2-332407f19896 is started using port 36671
2023-03-15 02:22:10,415 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=3157bed6-4585-40be-9dc3-9f23a9ff9cac to datanode:c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:10,415 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 3157bed6-4585-40be-9dc3-9f23a9ff9cac, Nodes: c86f293d-b980-46b7-b4bb-ca602f6dc485(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:10.415Z[Etc/UTC]].
2023-03-15 02:22:10,419 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-15 02:22:10,419 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-15 02:22:10,419 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-15 02:22:10,419 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-15 02:22:10,419 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:10,419 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:10,420 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=2c7edc49-dfb9-414e-a54e-d9c9687c9870 to datanode:c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:10,420 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=2c7edc49-dfb9-414e-a54e-d9c9687c9870 to datanode:42380981-9e90-41f5-811d-3bbbf08d47d9
2023-03-15 02:22:10,420 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=2c7edc49-dfb9-414e-a54e-d9c9687c9870 to datanode:dda7196a-19a1-4ef5-a6eb-ce99792637b5
2023-03-15 02:22:10,420 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 2c7edc49-dfb9-414e-a54e-d9c9687c9870, Nodes: c86f293d-b980-46b7-b4bb-ca602f6dc485(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)42380981-9e90-41f5-811d-3bbbf08d47d9(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)dda7196a-19a1-4ef5-a6eb-ce99792637b5(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:10.420Z[Etc/UTC]].
2023-03-15 02:22:10,420 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-15 02:22:10,424 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: remove  FOLLOWER 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB:t1, leader=ed5356af-2dee-4266-b55e-559e8c0d6889, voted=ed5356af-2dee-4266-b55e-559e8c0d6889, raftlog=Memoized:646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-SegmentedRaftLog:OPENED:c39, conf=0: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:1|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, 13b63f14-21ce-4492-9d02-d9a6b9e153c6|rpc:10.1.0.23:45547|dataStream:10.1.0.23:46243|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-15 02:22:10,424 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB: shutdown
2023-03-15 02:22:10,424 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1C9295BEA5BB,id=646e529a-a01f-4b15-a31a-2706cdf8d47d
2023-03-15 02:22:10,424 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: shutdown 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-FollowerState
2023-03-15 02:22:10,424 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-StateMachineUpdater: set stopIndex = 39
2023-03-15 02:22:10,424 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb is not found
2023-03-15 02:22:10,424 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-FollowerState was interrupted
2023-03-15 02:22:10,424 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-1C9295BEA5BB: Taking a snapshot at:(t:1, i:39) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/567e773f-eefb-46cf-b9d9-1c9295bea5bb/sm/snapshot.1_39
2023-03-15 02:22:10,425 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6: remove  FOLLOWER 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB:t1, leader=ed5356af-2dee-4266-b55e-559e8c0d6889, voted=ed5356af-2dee-4266-b55e-559e8c0d6889, raftlog=Memoized:13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-SegmentedRaftLog:OPENED:c39, conf=0: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:1|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, 13b63f14-21ce-4492-9d02-d9a6b9e153c6|rpc:10.1.0.23:45547|dataStream:10.1.0.23:46243|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-15 02:22:10,425 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB: shutdown
2023-03-15 02:22:10,425 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1C9295BEA5BB,id=13b63f14-21ce-4492-9d02-d9a6b9e153c6
2023-03-15 02:22:10,425 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6: shutdown 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-FollowerState
2023-03-15 02:22:10,425 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-StateMachineUpdater: set stopIndex = 39
2023-03-15 02:22:10,426 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-FollowerState was interrupted
2023-03-15 02:22:10,426 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-1C9295BEA5BB: Taking a snapshot at:(t:1, i:39) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-1/data/ratis/567e773f-eefb-46cf-b9d9-1c9295bea5bb/sm/snapshot.1_39
2023-03-15 02:22:10,427 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb is not found
2023-03-15 02:22:10,427 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=1a4b26ce-8fbb-4f60-9299-e897810e2042 is not found
2023-03-15 02:22:10,428 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-1C9295BEA5BB: Finished taking a snapshot at:(t:1, i:39) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-1/data/ratis/567e773f-eefb-46cf-b9d9-1c9295bea5bb/sm/snapshot.1_39 took: 2 ms
2023-03-15 02:22:10,428 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-1C9295BEA5BB: Finished taking a snapshot at:(t:1, i:39) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/567e773f-eefb-46cf-b9d9-1c9295bea5bb/sm/snapshot.1_39 took: 4 ms
2023-03-15 02:22:10,428 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-StateMachineUpdater: Took a snapshot at index 39
2023-03-15 02:22:10,428 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 39
2023-03-15 02:22:10,430 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB: closes. applyIndex: 39
2023-03-15 02:22:10,430 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:10,430 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB-SegmentedRaftLogWorker close()
2023-03-15 02:22:10,431 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-StateMachineUpdater: Took a snapshot at index 39
2023-03-15 02:22:10,431 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 39
2023-03-15 02:22:10,432 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB: closes. applyIndex: 39
2023-03-15 02:22:10,432 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:10,432 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB-SegmentedRaftLogWorker close()
2023-03-15 02:22:10,433 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - ed5356af-2dee-4266-b55e-559e8c0d6889: remove    LEADER ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB:t1, leader=ed5356af-2dee-4266-b55e-559e8c0d6889, voted=ed5356af-2dee-4266-b55e-559e8c0d6889, raftlog=Memoized:ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-SegmentedRaftLog:OPENED:c39, conf=0: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:1|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, 13b63f14-21ce-4492-9d02-d9a6b9e153c6|rpc:10.1.0.23:45547|dataStream:10.1.0.23:46243|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-15 02:22:10,433 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB: shutdown
2023-03-15 02:22:10,434 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1C9295BEA5BB,id=ed5356af-2dee-4266-b55e-559e8c0d6889
2023-03-15 02:22:10,434 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - ed5356af-2dee-4266-b55e-559e8c0d6889: shutdown ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-LeaderStateImpl
2023-03-15 02:22:10,434 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:10,434 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->13b63f14-21ce-4492-9d02-d9a6b9e153c6-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->13b63f14-21ce-4492-9d02-d9a6b9e153c6-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-15 02:22:10,434 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->646e529a-a01f-4b15-a31a-2706cdf8d47d-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->646e529a-a01f-4b15-a31a-2706cdf8d47d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-03-15 02:22:10,444 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6: Completed APPEND_ENTRIES, lastRequest: null
2023-03-15 02:22:10,445 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: Completed APPEND_ENTRIES, lastRequest: null
2023-03-15 02:22:10,445 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6: Completed APPEND_ENTRIES, lastRequest: ed5356af-2dee-4266-b55e-559e8c0d6889->13b63f14-21ce-4492-9d02-d9a6b9e153c6#406-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), METADATAENTRY(c:38)
2023-03-15 02:22:10,445 [grpc-default-executor-9] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: Completed APPEND_ENTRIES, lastRequest: ed5356af-2dee-4266-b55e-559e8c0d6889->646e529a-a01f-4b15-a31a-2706cdf8d47d#406-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), METADATAENTRY(c:38)
2023-03-15 02:22:10,445 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->13b63f14-21ce-4492-9d02-d9a6b9e153c6-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-15 02:22:10,445 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->646e529a-a01f-4b15-a31a-2706cdf8d47d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-15 02:22:10,446 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->13b63f14-21ce-4492-9d02-d9a6b9e153c6: nextIndex: updateUnconditionally 40 -> 39
2023-03-15 02:22:10,446 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->646e529a-a01f-4b15-a31a-2706cdf8d47d: nextIndex: updateUnconditionally 40 -> 39
2023-03-15 02:22:10,454 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->13b63f14-21ce-4492-9d02-d9a6b9e153c6-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-15 02:22:10,454 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->13b63f14-21ce-4492-9d02-d9a6b9e153c6: nextIndex: updateUnconditionally 39 -> 38
2023-03-15 02:22:10,455 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->646e529a-a01f-4b15-a31a-2706cdf8d47d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-03-15 02:22:10,455 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB->646e529a-a01f-4b15-a31a-2706cdf8d47d: nextIndex: updateUnconditionally 39 -> 38
2023-03-15 02:22:10,455 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-StateMachineUpdater: set stopIndex = 39
2023-03-15 02:22:10,455 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-1C9295BEA5BB: Taking a snapshot at:(t:1, i:39) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-0/data/ratis/567e773f-eefb-46cf-b9d9-1c9295bea5bb/sm/snapshot.1_39
2023-03-15 02:22:10,457 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-1C9295BEA5BB: Finished taking a snapshot at:(t:1, i:39) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-0/data/ratis/567e773f-eefb-46cf-b9d9-1c9295bea5bb/sm/snapshot.1_39 took: 1 ms
2023-03-15 02:22:10,457 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-StateMachineUpdater: Took a snapshot at index 39
2023-03-15 02:22:10,457 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 39
2023-03-15 02:22:10,458 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB: closes. applyIndex: 39
2023-03-15 02:22:10,458 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:10,458 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB-SegmentedRaftLogWorker close()
2023-03-15 02:22:10,481 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) moved to stale state. Finalizing its pipelines [PipelineID=96066cba-aadf-4fa4-9f1b-12a902955af3, PipelineID=c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe, PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8]
2023-03-15 02:22:10,481 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 96066cba-aadf-4fa4-9f1b-12a902955af3, Nodes: 6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:6cc283c3-90e9-4b51-9f1a-a0029c7c549b, CreationTimestamp2023-03-15T02:20:11.318Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:10,482 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:10,482 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:10,486 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #1 to QUASI_CLOSED state, datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) reported QUASI_CLOSED replica.
2023-03-15 02:22:10,486 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:10,487 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:10,489 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #3 to QUASI_CLOSED state, datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) reported QUASI_CLOSED replica.
2023-03-15 02:22:10,491 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:10,491 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:10,494 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-1C9295BEA5BB: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/567e773f-eefb-46cf-b9d9-1c9295bea5bb
2023-03-15 02:22:10,494 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb command on datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d.
2023-03-15 02:22:10,495 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #6 to QUASI_CLOSED state, datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) reported QUASI_CLOSED replica.
2023-03-15 02:22:10,513 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:10,513 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:10,519 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:10,519 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:10,523 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:10,523 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:10,526 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-1C9295BEA5BB: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-0/data/ratis/567e773f-eefb-46cf-b9d9-1c9295bea5bb
2023-03-15 02:22:10,526 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb command on datanode ed5356af-2dee-4266-b55e-559e8c0d6889.
2023-03-15 02:22:10,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) has 3 sufficientlyReplicated, 0 underReplicated and 0 unhealthy containers
2023-03-15 02:22:10,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(422)) - Datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) has entered maintenance
2023-03-15 02:22:10,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:10,529 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) moved to HEALTHY state.
2023-03-15 02:22:10,529 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:10,530 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=e2467591-d6d0-4055-98f0-b57df5c92125 to datanode:b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:10,530 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=e2467591-d6d0-4055-98f0-b57df5c92125 to datanode:ed5356af-2dee-4266-b55e-559e8c0d6889
2023-03-15 02:22:10,530 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=e2467591-d6d0-4055-98f0-b57df5c92125 to datanode:646e529a-a01f-4b15-a31a-2706cdf8d47d
2023-03-15 02:22:10,530 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: e2467591-d6d0-4055-98f0-b57df5c92125, Nodes: b83605a3-0dba-4f7c-9b88-55eff2caaffe(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:10.530Z[Etc/UTC]].
2023-03-15 02:22:10,530 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-15 02:22:10,535 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:10,535 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:10,537 [IPC Server handler 18 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-03-15 02:22:10,539 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:10,540 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:10,540 [IPC Server handler 17 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-03-15 02:22:10,542 [IPC Server handler 15 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-03-15 02:22:10,544 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:10,544 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:10,544 [IPC Server handler 14 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-03-15 02:22:10,546 [IPC Server handler 19 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(565)) - Scheduling a command to update the operationalState persisted on 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-03-15 02:22:10,547 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-1C9295BEA5BB: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-1/data/ratis/567e773f-eefb-46cf-b9d9-1c9295bea5bb
2023-03-15 02:22:10,547 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=567e773f-eefb-46cf-b9d9-1c9295bea5bb command on datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6.
2023-03-15 02:22:10,547 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6: remove    LEADER 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042:t1, leader=13b63f14-21ce-4492-9d02-d9a6b9e153c6, voted=13b63f14-21ce-4492-9d02-d9a6b9e153c6, raftlog=Memoized:13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-SegmentedRaftLog:OPENED:c0, conf=0: peers:[13b63f14-21ce-4492-9d02-d9a6b9e153c6|rpc:10.1.0.23:45547|dataStream:10.1.0.23:46243|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-03-15 02:22:10,547 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042: shutdown
2023-03-15 02:22:10,547 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E897810E2042,id=13b63f14-21ce-4492-9d02-d9a6b9e153c6
2023-03-15 02:22:10,547 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6: shutdown 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-LeaderStateImpl
2023-03-15 02:22:10,547 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:10,550 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:10,550 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-E897810E2042: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-1/data/ratis/1a4b26ce-8fbb-4f60-9299-e897810e2042/sm/snapshot.1_0
2023-03-15 02:22:10,551 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-E897810E2042: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-1/data/ratis/1a4b26ce-8fbb-4f60-9299-e897810e2042/sm/snapshot.1_0 took: 0 ms
2023-03-15 02:22:10,551 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:10,551 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:10,551 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042: closes. applyIndex: 0
2023-03-15 02:22:10,552 [13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:10,552 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042-SegmentedRaftLogWorker close()
2023-03-15 02:22:10,552 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6@group-E897810E2042: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-1/data/ratis/1a4b26ce-8fbb-4f60-9299-e897810e2042
2023-03-15 02:22:10,552 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=1a4b26ce-8fbb-4f60-9299-e897810e2042 command on datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6.
2023-03-15 02:22:10,581 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) moved to stale state. Finalizing its pipelines [PipelineID=c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe, PipelineID=2eb2382e-cff8-440f-960d-8195e871a18a, PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8]
2023-03-15 02:22:10,581 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 2eb2382e-cff8-440f-960d-8195e871a18a, Nodes: 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:2e577448-b8d8-48ce-8745-caa267c5872e, CreationTimestamp2023-03-15T02:20:14.906Z[Etc/UTC]] moved to CLOSED state
2023-03-15 02:22:10,581 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:10,582 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=c79eb4e6-51eb-416c-bf8f-56f9f413b02c close command to datanode c0541761-aa68-4214-a339-56b9b1ec7b43
2023-03-15 02:22:10,582 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: c79eb4e6-51eb-416c-bf8f-56f9f413b02c, Nodes: c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:c0541761-aa68-4214-a339-56b9b1ec7b43, CreationTimestamp2023-03-15T02:20:12.937Z[Etc/UTC]] removed.
2023-03-15 02:22:10,582 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: aa94b31b-70f4-4343-8e73-d14ceea2ddc8, Nodes: dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)c0541761-aa68-4214-a339-56b9b1ec7b43(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: EC{rs-3-2-1048576}, State:CLOSED, leaderId:, CreationTimestamp2023-03-15T02:21:24.193Z[Etc/UTC]] removed.
2023-03-15 02:22:10,582 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/c0541761-aa68-4214-a339-56b9b1ec7b43
2023-03-15 02:22:10,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 3 of 7 DN Heartbeats.
2023-03-15 02:22:10,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:10,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:10,844 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-ee52c2d7-fe73-40ee-8f5e-0b293c0f1f1e/container.db to cache
2023-03-15 02:22:10,844 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data-0/containers/hdds/d45f4060-1b89-4550-a4d1-dcd9394607ae/DS-ee52c2d7-fe73-40ee-8f5e-0b293c0f1f1e/container.db for volume DS-ee52c2d7-fe73-40ee-8f5e-0b293c0f1f1e
2023-03-15 02:22:10,845 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(401)) - Attempting to start container services.
2023-03-15 02:22:10,845 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(318)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-03-15 02:22:10,845 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 38323
2023-03-15 02:22:10,849 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis bb24641f-ac05-4a48-a34b-331e584b8427
2023-03-15 02:22:10,863 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - bb24641f-ac05-4a48-a34b-331e584b8427: start RPC server
2023-03-15 02:22:10,864 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - bb24641f-ac05-4a48-a34b-331e584b8427: GrpcService started, listening on 33913
2023-03-15 02:22:10,864 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis bb24641f-ac05-4a48-a34b-331e584b8427 is started using port 33913 for RATIS
2023-03-15 02:22:10,864 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis bb24641f-ac05-4a48-a34b-331e584b8427 is started using port 33913 for RATIS_ADMIN
2023-03-15 02:22:10,864 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis bb24641f-ac05-4a48-a34b-331e584b8427 is started using port 33913 for RATIS_SERVER
2023-03-15 02:22:10,864 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis bb24641f-ac05-4a48-a34b-331e584b8427 is started using port 39219 for RATIS_DATASTREAM
2023-03-15 02:22:10,864 [JvmPauseMonitor58] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-bb24641f-ac05-4a48-a34b-331e584b8427: Started
2023-03-15 02:22:10,869 [EndpointStateMachine task thread for /0.0.0.0:44419 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc bb24641f-ac05-4a48-a34b-331e584b8427 is started using port 37209
2023-03-15 02:22:10,870 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:10,981 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:10,981 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=2ab7e996-f10a-469a-8408-fc918c320469 close command to datanode a2e38771-97ec-4c41-9533-82a103767b0b
2023-03-15 02:22:10,982 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 2ab7e996-f10a-469a-8408-fc918c320469, Nodes: a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:a2e38771-97ec-4c41-9533-82a103767b0b, CreationTimestamp2023-03-15T02:20:12.533Z[Etc/UTC]] removed.
2023-03-15 02:22:10,982 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe close command to datanode 2e577448-b8d8-48ce-8745-caa267c5872e
2023-03-15 02:22:10,982 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe close command to datanode a2e38771-97ec-4c41-9533-82a103767b0b
2023-03-15 02:22:10,982 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe close command to datanode 6cc283c3-90e9-4b51-9f1a-a0029c7c549b
2023-03-15 02:22:10,982 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: c9528bd2-2f78-4293-ae7d-5e30a3bfdcfe, Nodes: 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)a2e38771-97ec-4c41-9533-82a103767b0b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:a2e38771-97ec-4c41-9533-82a103767b0b, CreationTimestamp2023-03-15T02:21:33.955Z[Etc/UTC]] removed.
2023-03-15 02:22:10,982 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/a2e38771-97ec-4c41-9533-82a103767b0b
2023-03-15 02:22:11,181 [IPC Server handler 13 on default port 44419] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/71dc2d0c-c132-482e-adc3-0da69386d6d8
2023-03-15 02:22:11,181 [IPC Server handler 13 on default port 44419] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 71dc2d0c-c132-482e-adc3-0da69386d6d8{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=38751, RATIS=33845, RATIS_ADMIN=33845, RATIS_SERVER=33845, RATIS_DATASTREAM=36025, STANDALONE=40175], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:11,182 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:11,182 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=e176a732-6e44-41d1-a762-784429324467 to datanode:71dc2d0c-c132-482e-adc3-0da69386d6d8
2023-03-15 02:22:11,182 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: e176a732-6e44-41d1-a762-784429324467, Nodes: 71dc2d0c-c132-482e-adc3-0da69386d6d8(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:11.182Z[Etc/UTC]].
2023-03-15 02:22:11,183 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-15 02:22:11,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:11,281 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #10, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 0. Available sources are: {}
2023-03-15 02:22:11,282 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(218)) - Container #10 is under replicated, but no commands were created to correct it
2023-03-15 02:22:11,282 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #11, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {4=(ContainerReplica{containerID=#11, state=CLOSED, datanodeDetails=dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=dff27167-0db1-43de-a597-ad7d66669fa4, sequenceId=0, keyCount=3, bytesUsed=57,replicaIndex=4},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-03-15 02:22:11,282 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(218)) - Container #11 is under replicated, but no commands were created to correct it
2023-03-15 02:22:11,282 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #9, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 0. Available sources are: {}
2023-03-15 02:22:11,282 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(218)) - Container #9 is under replicated, but no commands were created to correct it
2023-03-15 02:22:11,282 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #7, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {1=(ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), placeOfBirth=dff27167-0db1-43de-a597-ad7d66669fa4, sequenceId=0, keyCount=4, bytesUsed=76,replicaIndex=1},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-03-15 02:22:11,282 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(218)) - Container #7 is under replicated, but no commands were created to correct it
2023-03-15 02:22:11,282 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #12, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 0. Available sources are: {}
2023-03-15 02:22:11,282 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(218)) - Container #12 is under replicated, but no commands were created to correct it
2023-03-15 02:22:11,282 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 5 containers with health state counts {UNDER_REPLICATED=5},failed processing 0
2023-03-15 02:22:11,291 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:11,297 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:11,304 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:11,307 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:11,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1080)) - Force closing container #1 with BCSID 38, which is in QUASI_CLOSED state.
2023-03-15 02:22:11,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #1 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1080)) - Force closing container #3 with BCSID 30, which is in QUASI_CLOSED state.
2023-03-15 02:22:11,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,309 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #3 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,310 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1080)) - Force closing container #6 with BCSID 34, which is in QUASI_CLOSED state.
2023-03-15 02:22:11,310 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,310 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,310 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-15 02:22:11,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:11,326 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:11,339 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2228)) - Cannot replicate container #1, no healthy datanodes with replica found.
2023-03-15 02:22:11,339 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #2 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,339 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2228)) - Cannot replicate container #3, no healthy datanodes with replica found.
2023-03-15 02:22:11,339 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2228)) - Cannot replicate container #4, no healthy datanodes with replica found.
2023-03-15 02:22:11,339 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #5 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,339 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1403)) - Sending close container command for container #6 to datanode dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23).
2023-03-15 02:22:11,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to 2e577448-b8d8-48ce-8745-caa267c5872e(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848551340 and scm deadline 1678848731340
2023-03-15 02:22:11,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848551340 and scm deadline 1678848731340
2023-03-15 02:22:11,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, force: true] for container ContainerInfo{id=#8, state=CLOSING, pipelineID=PipelineID=aa94b31b-70f4-4343-8e73-d14ceea2ddc8, stateEnterTime=2023-03-15T02:21:24.194Z, owner=om1} to 6cc283c3-90e9-4b51-9f1a-a0029c7c549b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848551340 and scm deadline 1678848731340
2023-03-15 02:22:11,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(553)) - Sending command [closeContainerCommand: containerID: 9, pipelineID: PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=5a33e93c-08f6-4cdc-bfbe-d03d45dd9212, stateEnterTime=2023-03-15T02:21:24.497Z, owner=om1} to dff27167-0db1-43de-a597-ad7d66669fa4(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) with datanode deadline 1678848551340 and scm deadline 1678848731340
2023-03-15 02:22:11,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 12 containers.
2023-03-15 02:22:11,529 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:11,650 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(351)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-03-15 02:22:11,650 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1532)) - Container Balancer is not running.
2023-03-15 02:22:11,650 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1539)) - Stopping Replication Manager Service.
2023-03-15 02:22:11,651 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(304)) - Stopping Replication Monitor Thread.
2023-03-15 02:22:11,651 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(153)) - Under Replicated Processor interrupted. Exiting...
2023-03-15 02:22:11,651 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(153)) - Over Replicated Processor interrupted. Exiting...
2023-03-15 02:22:11,656 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1546)) - Stopping the Datanode Admin Monitor.
2023-03-15 02:22:11,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(799)) - Replication Monitor Thread is stopped
2023-03-15 02:22:11,656 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1553)) - Stopping datanode service RPC server
2023-03-15 02:22:11,657 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-03-15 02:22:11,660 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 41473
2023-03-15 02:22:11,671 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-15 02:22:11,672 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:11,681 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-03-15 02:22:11,682 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1561)) - Stopping block service RPC server
2023-03-15 02:22:11,682 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-03-15 02:22:11,685 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 33991
2023-03-15 02:22:11,691 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-15 02:22:11,700 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1568)) - Stopping the StorageContainerLocationProtocol RPC server
2023-03-15 02:22:11,700 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:11,700 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(203)) - Stopping the RPC server for Client Protocol
2023-03-15 02:22:11,703 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 37571
2023-03-15 02:22:11,708 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1575)) - Stopping Storage Container Manager HTTP server.
2023-03-15 02:22:11,708 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-15 02:22:11,708 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:11,713 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@6502dcc0{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-15 02:22:11,713 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4593036c{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:11,713 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:11,716 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@74216e44{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-15 02:22:11,719 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@22a7213{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:11,720 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1583)) - Stopping SCM LayoutVersionManager Service.
2023-03-15 02:22:11,721 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1591)) - Stopping Block Manager Service.
2023-03-15 02:22:11,721 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-15 02:22:11,721 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-15 02:22:11,721 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1613)) - Stopping SCM Event Queue.
2023-03-15 02:22:11,723 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1624)) - Stopping SCM HA services.
2023-03-15 02:22:11,723 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-03-15 02:22:11,724 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-03-15 02:22:11,725 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-03-15 02:22:11,725 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-03-15 02:22:11,725 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2023-03-15 02:22:11,729 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-03-15 02:22:11,733 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2023-03-15 02:22:11,734 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-03-15 02:22:11,734 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-03-15 02:22:11,734 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-03-15 02:22:11,734 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-15 02:22:11,734 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-03-15 02:22:11,734 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(314)) - Replication Monitor Thread is not running.
2023-03-15 02:22:11,735 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-03-15 02:22:11,735 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1642)) - Stopping SCM MetadataStore.
2023-03-15 02:22:11,736 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:11,737 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-15 02:22:11,737 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-15 02:22:11,737 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:11,737 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:11,772 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-15 02:22:11,772 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-15 02:22:11,775 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:11,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 4 of 7 DN Heartbeats.
2023-03-15 02:22:11,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:11,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:11,808 [IPC Server handler 15 on default port 44419] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/6b109e20-fb43-4126-a2d0-e01a40c07237
2023-03-15 02:22:11,808 [IPC Server handler 15 on default port 44419] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 6b109e20-fb43-4126-a2d0-e01a40c07237{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=36927, RATIS=44885, RATIS_ADMIN=44885, RATIS_SERVER=44885, RATIS_DATASTREAM=34799, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:11,808 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:11,809 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=e820d2a7-e73f-462b-b858-e8089850d28e to datanode:6b109e20-fb43-4126-a2d0-e01a40c07237
2023-03-15 02:22:11,809 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: e820d2a7-e73f-462b-b858-e8089850d28e, Nodes: 6b109e20-fb43-4126-a2d0-e01a40c07237(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:11.809Z[Etc/UTC]].
2023-03-15 02:22:11,809 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2023-03-15 02:22:11,846 [main] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 70 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:11,848 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-15 02:22:11,851 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-15 02:22:11,851 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-15 02:22:11,851 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-15 02:22:11,855 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-15 02:22:11,856 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-15 02:22:11,857 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-15 02:22:11,857 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-15 02:22:11,857 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-15 02:22:11,858 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-15 02:22:11,858 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-15 02:22:11,858 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-15 02:22:11,860 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-15 02:22:11,861 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-15 02:22:11,862 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(271)) - Starting Replication Monitor Thread.
2023-03-15 02:22:11,862 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-15 02:22:11,863 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-03-15 02:22:11,864 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 1, healthy pipeline threshold count is 1
2023-03-15 02:22:11,864 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 1, pipeline's with at least one datanode reported threshold count is 1
2023-03-15 02:22:11,864 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(392)) - SCM start with adminUsers: [runner]
2023-03-15 02:22:11,865 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:11,872 [Socket Reader #1 for port 41473] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 41473
2023-03-15 02:22:11,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:11,877 [Listener at 0.0.0.0/41473] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:11,878 [Socket Reader #1 for port 33991] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 33991
2023-03-15 02:22:11,885 [Listener at 0.0.0.0/33991] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:11,888 [Socket Reader #1 for port 37571] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 37571
2023-03-15 02:22:11,908 [Listener at 0.0.0.0/37571] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-15 02:22:11,908 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(407)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-15 02:22:11,909 [Listener at 0.0.0.0/37571] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-15 02:22:11,909 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1437)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:37571
2023-03-15 02:22:11,914 [Listener at 0.0.0.0/37571] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-03-15 02:22:11,915 [Listener at 0.0.0.0/37571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-03-15 02:22:11,916 [Listener at 0.0.0.0/37571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-03-15 02:22:11,953 [Listener at 0.0.0.0/37571] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-03-15 02:22:11,953 [Listener at 0.0.0.0/37571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-03-15 02:22:11,989 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-926a3f87-e453-428c-b155-4688bf5536ac/datanode-5/data-0/containers/hdds/926a3f87-e453-428c-b155-4688bf5536ac/DS-2e44a521-1f1e-4915-97e4-a80bed8a7e71/container.db for volume DS-2e44a521-1f1e-4915-97e4-a80bed8a7e71
2023-03-15 02:22:11,989 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-15 02:22:11,989 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-15 02:22:11,991 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-15 02:22:12,016 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@65da3527{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:12,017 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@39fcca25{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:12,017 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:12,024 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3302517d{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-15 02:22:12,028 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@10b221d5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:12,031 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(539)) - Stopping the StorageContainerManager
2023-03-15 02:22:12,032 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1532)) - Container Balancer is not running.
2023-03-15 02:22:12,032 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1539)) - Stopping Replication Manager Service.
2023-03-15 02:22:12,032 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(304)) - Stopping Replication Monitor Thread.
2023-03-15 02:22:12,032 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(153)) - Under Replicated Processor interrupted. Exiting...
2023-03-15 02:22:12,032 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(153)) - Over Replicated Processor interrupted. Exiting...
2023-03-15 02:22:12,033 [Listener at 0.0.0.0/37571] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(194)) - RPC server for Client  is listening at /0.0.0.0:37571
2023-03-15 02:22:12,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(799)) - Replication Monitor Thread is stopped
2023-03-15 02:22:12,037 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1546)) - Stopping the Datanode Admin Monitor.
2023-03-15 02:22:12,037 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:12,038 [IPC Server listener on 37571] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 37571: starting
2023-03-15 02:22:12,039 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1451)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33991
2023-03-15 02:22:12,039 [Listener at 0.0.0.0/37571] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:33991
2023-03-15 02:22:12,040 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:12,040 [IPC Server listener on 33991] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 33991: starting
2023-03-15 02:22:12,042 [Listener at 0.0.0.0/37571] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:41473
2023-03-15 02:22:12,042 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:12,043 [IPC Server listener on 41473] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 41473: starting
2023-03-15 02:22:12,044 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@222a7429] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:12,051 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1553)) - Stopping datanode service RPC server
2023-03-15 02:22:12,051 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-03-15 02:22:12,055 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42247
2023-03-15 02:22:12,057 [Listener at 0.0.0.0/37571] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:33917
2023-03-15 02:22:12,057 [Listener at 0.0.0.0/37571] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:12,058 [Listener at 0.0.0.0/37571] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:12,061 [Listener at 0.0.0.0/37571] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:12,062 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:12,063 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-15 02:22:12,063 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:12,063 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:12,064 [Listener at 0.0.0.0/37571] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/ozone-meta/webserver
2023-03-15 02:22:12,064 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 33917
2023-03-15 02:22:12,064 [Listener at 0.0.0.0/37571] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:12,067 [Listener at 0.0.0.0/37571] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:12,067 [Listener at 0.0.0.0/37571] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:12,067 [Listener at 0.0.0.0/37571] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-03-15 02:22:12,073 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-15 02:22:12,073 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@77604a86{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:12,074 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3a6409ec{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-15 02:22:12,076 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@438a65a7{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-15 02:22:12,082 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:12,086 [Listener at 0.0.0.0/37571] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5b4880b3{HTTP/1.1, (http/1.1)}{0.0.0.0:33917}
2023-03-15 02:22:12,086 [Listener at 0.0.0.0/37571] INFO  server.Server (Server.java:doStart(415)) - Started @186963ms
2023-03-15 02:22:12,086 [Listener at 0.0.0.0/37571] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:12,086 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-03-15 02:22:12,087 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1561)) - Stopping block service RPC server
2023-03-15 02:22:12,087 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-03-15 02:22:12,090 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 35597
2023-03-15 02:22:12,093 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-15 02:22:12,094 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:12,094 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1568)) - Stopping the StorageContainerLocationProtocol RPC server
2023-03-15 02:22:12,094 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(203)) - Stopping the RPC server for Client Protocol
2023-03-15 02:22:12,096 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 38883
2023-03-15 02:22:12,102 [Listener at 0.0.0.0/37571] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:33917
2023-03-15 02:22:12,103 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-03-15 02:22:12,107 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:12,110 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:12,107 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1575)) - Stopping Storage Container Manager HTTP server.
2023-03-15 02:22:12,110 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3db13f22{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-15 02:22:12,107 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:12,107 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-15 02:22:12,112 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@65045d8{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:12,112 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:12,112 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3bbd86e8{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-15 02:22:12,112 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@56aef053{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:12,114 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1583)) - Stopping SCM LayoutVersionManager Service.
2023-03-15 02:22:12,114 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1591)) - Stopping Block Manager Service.
2023-03-15 02:22:12,114 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-15 02:22:12,114 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-15 02:22:12,114 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1613)) - Stopping SCM Event Queue.
2023-03-15 02:22:12,116 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1624)) - Stopping SCM HA services.
2023-03-15 02:22:12,117 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-03-15 02:22:12,117 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-03-15 02:22:12,117 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-03-15 02:22:12,117 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-03-15 02:22:12,118 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2023-03-15 02:22:12,132 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-03-15 02:22:12,136 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2023-03-15 02:22:12,136 [Mini-Cluster-Provider-Reap] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-03-15 02:22:12,136 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-03-15 02:22:12,136 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-03-15 02:22:12,137 [Mini-Cluster-Provider-Reap] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-03-15 02:22:12,137 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-15 02:22:12,137 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(314)) - Replication Monitor Thread is not running.
2023-03-15 02:22:12,137 [Mini-Cluster-Provider-Reap] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-03-15 02:22:12,137 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1642)) - Stopping SCM MetadataStore.
2023-03-15 02:22:12,231 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: addNew group-D59EFF0A6F52:[dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:1|startupRole:FOLLOWER] returns group-D59EFF0A6F52:java.util.concurrent.CompletableFuture@58d05c58[Not completed]
2023-03-15 02:22:12,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: new RaftServerImpl for group-D59EFF0A6F52:[dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52: ConfigurationManager, init=-1: peers:[dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis] (custom)
2023-03-15 02:22:12,233 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:12,234 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:12,234 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:12,234 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:12,234 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:12,234 [EndpointStateMachine task thread for /0.0.0.0:41473 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:41473 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az260-852/10.1.0.23"; destination host is: "0.0.0.0":41473; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy56.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-03-15 02:22:12,236 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:12,250 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:12,250 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:12,250 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:12,250 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:12,250 [pool-2467-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/78ab6313-1582-4821-a408-d59eff0a6f52 does not exist. Creating ...
2023-03-15 02:22:12,250 [IPC Server handler 0 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 132d3d80-0103-4f41-b942-b9d80c35d5a5(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:12,250 [IPC Server handler 1 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 00dcba52-510b-4641-a1c5-22cfbaaa7f01(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:12,262 [pool-2467-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/78ab6313-1582-4821-a408-d59eff0a6f52/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:12,264 [pool-2467-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/78ab6313-1582-4821-a408-d59eff0a6f52 has been successfully formatted.
2023-03-15 02:22:12,264 [pool-2467-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-D59EFF0A6F52: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:12,264 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:12,264 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:12,264 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,265 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:12,265 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:12,265 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,265 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:12,265 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:12,265 [pool-2467-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/78ab6313-1582-4821-a408-d59eff0a6f52
2023-03-15 02:22:12,266 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:12,266 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:12,266 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,266 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:12,266 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:12,266 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:12,266 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:12,266 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:12,267 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:12,268 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,269 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 78ab6313-1582-4821-a408-d59eff0a6f52, Nodes: dda7196a-19a1-4ef5-a6eb-ce99792637b5(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:dda7196a-19a1-4ef5-a6eb-ce99792637b5, CreationTimestamp2023-03-15T02:22:09.251Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:12,278 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:12,287 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:12,287 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:12,287 [pool-2467-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,287 [pool-2467-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,282 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:12,287 [pool-2467-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52: start as a follower, conf=-1: peers:[dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:12,287 [pool-2467-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:12,287 [pool-2467-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: start dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState
2023-03-15 02:22:12,289 [pool-2467-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D59EFF0A6F52,id=dda7196a-19a1-4ef5-a6eb-ce99792637b5
2023-03-15 02:22:12,289 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:12,289 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:12,289 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:12,289 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:12,289 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:12,290 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:12,292 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:12,297 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=78ab6313-1582-4821-a408-d59eff0a6f52
2023-03-15 02:22:12,297 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=78ab6313-1582-4821-a408-d59eff0a6f52.
2023-03-15 02:22:12,297 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: addNew group-D9C9687C9870:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER] returns group-D9C9687C9870:java.util.concurrent.CompletableFuture@5cefd39a[Not completed]
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: new RaftServerImpl for group-D9C9687C9870:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: ConfigurationManager, init=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis] (custom)
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:12,298 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:12,299 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:12,299 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:12,299 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:12,300 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:12,300 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:12,300 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:12,300 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:12,301 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:12,301 [pool-2467-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870 does not exist. Creating ...
2023-03-15 02:22:12,302 [pool-2467-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:12,303 [pool-2467-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870 has been successfully formatted.
2023-03-15 02:22:12,304 [pool-2467-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-D9C9687C9870: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:12,304 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:12,304 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:12,304 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,304 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:12,304 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:12,304 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,305 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:12,305 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:12,305 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:12,305 [pool-2467-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870
2023-03-15 02:22:12,305 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:12,305 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:12,305 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,306 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:12,306 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:12,306 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:12,306 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:12,306 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:12,307 [IPC Server handler 2 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode b83605a3-0dba-4f7c-9b88-55eff2caaffe(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:12,307 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:12,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-15 02:22:12,314 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:12,315 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,320 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:12,321 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:12,321 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:12,321 [pool-2467-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,321 [pool-2467-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,321 [pool-2467-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: start as a follower, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:12,321 [pool-2467-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:12,321 [pool-2467-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: start dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState
2023-03-15 02:22:12,323 [pool-2467-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9C9687C9870,id=dda7196a-19a1-4ef5-a6eb-ce99792637b5
2023-03-15 02:22:12,323 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:12,324 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:12,324 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:12,324 [pool-2467-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:12,325 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:12,325 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:12,327 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=2c7edc49-dfb9-414e-a54e-d9c9687c9870
2023-03-15 02:22:12,334 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: addNew group-D9C9687C9870:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER] returns group-D9C9687C9870:java.util.concurrent.CompletableFuture@67cdb958[Not completed]
2023-03-15 02:22:12,335 [pool-2515-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: new RaftServerImpl for group-D9C9687C9870:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:12,335 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:12,335 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:12,335 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:12,335 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:12,335 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:12,336 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:12,336 [pool-2515-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870: ConfigurationManager, init=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:12,336 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis] (custom)
2023-03-15 02:22:12,336 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:12,336 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:12,336 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:12,336 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:12,336 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:12,338 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:12,338 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:12,338 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:12,338 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:12,338 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:12,338 [pool-2515-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870 does not exist. Creating ...
2023-03-15 02:22:12,340 [pool-2515-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:12,342 [pool-2515-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870 has been successfully formatted.
2023-03-15 02:22:12,342 [pool-2515-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-D9C9687C9870: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:12,342 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:12,342 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:12,342 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,343 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:12,343 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:12,343 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:12,344 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:12,345 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:12,346 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:12,347 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,352 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:12,352 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:12,353 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:12,353 [pool-2515-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,353 [pool-2515-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,353 [pool-2515-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870: start as a follower, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:12,353 [pool-2515-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:12,353 [pool-2515-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: start c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState
2023-03-15 02:22:12,354 [pool-2515-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9C9687C9870,id=c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:12,354 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:12,354 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:12,354 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:12,354 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:12,355 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:12,355 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:12,364 [IPC Server handler 9 on default port 44419] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:12,365 [IPC Server handler 9 on default port 44419] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 1847c06b-5456-44fe-a2e2-332407f19896{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=45549, RATIS=43143, RATIS_ADMIN=43143, RATIS_SERVER=43143, RATIS_DATASTREAM=41099, STANDALONE=36671], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:12,365 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:12,366 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=e8e306ef-b9aa-42ad-aa76-4773a172c6fd to datanode:1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:12,366 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: e8e306ef-b9aa-42ad-aa76-4773a172c6fd, Nodes: 1847c06b-5456-44fe-a2e2-332407f19896(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:12.366Z[Etc/UTC]].
2023-03-15 02:22:12,367 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=7afa3418-6f18-4a5c-9380-6685db77740e to datanode:1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:12,367 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=7afa3418-6f18-4a5c-9380-6685db77740e to datanode:6b109e20-fb43-4126-a2d0-e01a40c07237
2023-03-15 02:22:12,367 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=7afa3418-6f18-4a5c-9380-6685db77740e to datanode:71dc2d0c-c132-482e-adc3-0da69386d6d8
2023-03-15 02:22:12,367 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 7afa3418-6f18-4a5c-9380-6685db77740e, Nodes: 1847c06b-5456-44fe-a2e2-332407f19896(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)6b109e20-fb43-4126-a2d0-e01a40c07237(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)71dc2d0c-c132-482e-adc3-0da69386d6d8(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:12.367Z[Etc/UTC]].
2023-03-15 02:22:12,367 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-15 02:22:12,373 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: addNew group-D9C9687C9870:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER] returns group-D9C9687C9870:java.util.concurrent.CompletableFuture@521d836a[Not completed]
2023-03-15 02:22:12,377 [pool-2489-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: new RaftServerImpl for group-D9C9687C9870:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:12,377 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:12,377 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:12,377 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:12,377 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:12,377 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:12,377 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:12,377 [pool-2489-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: ConfigurationManager, init=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:12,378 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis] (custom)
2023-03-15 02:22:12,378 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:12,378 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:12,378 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:12,378 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:12,378 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:12,380 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:12,380 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:12,380 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:12,380 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:12,380 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:12,380 [pool-2489-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870 does not exist. Creating ...
2023-03-15 02:22:12,381 [pool-2489-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:12,382 [pool-2489-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870 has been successfully formatted.
2023-03-15 02:22:12,384 [pool-2489-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-D9C9687C9870: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:12,384 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:12,384 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:12,384 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,384 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:12,384 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:12,384 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:12,385 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:12,387 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:12,387 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,393 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:12,393 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:12,393 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:12,394 [pool-2489-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,394 [pool-2489-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,395 [pool-2489-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: start as a follower, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:12,395 [pool-2489-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:12,395 [pool-2489-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: start 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState
2023-03-15 02:22:12,399 [pool-2489-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9C9687C9870,id=42380981-9e90-41f5-811d-3bbbf08d47d9
2023-03-15 02:22:12,399 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:12,399 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:12,399 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:12,399 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:12,400 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:12,400 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:12,411 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=2c7edc49-dfb9-414e-a54e-d9c9687c9870.
2023-03-15 02:22:12,495 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: addNew group-B57DF5C92125:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER] returns group-B57DF5C92125:java.util.concurrent.CompletableFuture@5a2d7008[Not completed]
2023-03-15 02:22:12,495 [IPC Server handler 3 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:12,496 [pool-1571-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: new RaftServerImpl for group-B57DF5C92125:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:12,496 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:12,496 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:12,496 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:12,496 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:12,496 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:12,496 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:12,496 [pool-1571-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: ConfigurationManager, init=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:12,496 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis] (custom)
2023-03-15 02:22:12,497 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:12,497 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:12,497 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:12,497 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:12,497 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:12,498 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:12,498 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:12,498 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:12,498 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:12,498 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:12,499 [pool-1571-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125 does not exist. Creating ...
2023-03-15 02:22:12,500 [pool-1571-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:12,501 [pool-1571-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125 has been successfully formatted.
2023-03-15 02:22:12,502 [pool-1571-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-B57DF5C92125: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:12,502 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:12,502 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:12,502 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,502 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:12,502 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:12,503 [IPC Server handler 4 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/646e529a-a01f-4b15-a31a-2706cdf8d47d
2023-03-15 02:22:12,503 [IPC Server handler 4 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 646e529a-a01f-4b15-a31a-2706cdf8d47d{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=34565, RATIS=38099, RATIS_ADMIN=38099, RATIS_SERVER=38099, RATIS_DATASTREAM=36605, STANDALONE=43083], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:12,525 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-03-15 02:22:12,526 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-15 02:22:12,530 [IPC Server handler 5 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:12,530 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-15 02:22:12,533 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ed5356af-2dee-4266-b55e-559e8c0d6889: addNew group-B57DF5C92125:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER] returns group-B57DF5C92125:java.util.concurrent.CompletableFuture@76f8410a[Not completed]
2023-03-15 02:22:12,533 [pool-1527-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - ed5356af-2dee-4266-b55e-559e8c0d6889: new RaftServerImpl for group-B57DF5C92125:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:12,534 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:12,540 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-03-15 02:22:12,540 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125: ConfigurationManager, init=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-0/data/ratis] (custom)
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:12,541 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:12,541 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125
2023-03-15 02:22:12,542 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,542 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:12,542 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:12,546 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:12,557 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:12,565 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:12,565 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:12,565 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:12,565 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:12,557 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:12,566 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:12,566 [IPC Server handler 6 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:12,566 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,565 [pool-1527-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-0/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125 does not exist. Creating ...
2023-03-15 02:22:12,568 [pool-1527-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-0/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:12,569 [pool-1527-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-0/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125 has been successfully formatted.
2023-03-15 02:22:12,570 [pool-1527-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-B57DF5C92125: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:12,570 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:12,570 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:12,570 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,570 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:12,570 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:12,570 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-0/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:12,571 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:12,572 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:12,573 [IPC Server handler 7 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ed5356af-2dee-4266-b55e-559e8c0d6889
2023-03-15 02:22:12,573 [IPC Server handler 7 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : ed5356af-2dee-4266-b55e-559e8c0d6889{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=46635, RATIS=46587, RATIS_ADMIN=46587, RATIS_SERVER=46587, RATIS_DATASTREAM=45375, STANDALONE=46781], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:12,574 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:12,574 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,580 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:12,580 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:12,580 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:12,588 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-15 02:22:12,588 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-03-15 02:22:12,589 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:12,589 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:12,589 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:12,589 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:12,589 [pool-1571-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,589 [pool-1571-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,589 [pool-1527-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,589 [pool-1527-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,590 [pool-1571-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: start as a follower, conf=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:12,590 [pool-1571-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:12,590 [pool-1571-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: start 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState
2023-03-15 02:22:12,590 [pool-1571-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B57DF5C92125,id=646e529a-a01f-4b15-a31a-2706cdf8d47d
2023-03-15 02:22:12,590 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:12,590 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:12,590 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:12,590 [pool-1571-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:12,591 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:12,591 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:12,591 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=e2467591-d6d0-4055-98f0-b57df5c92125
2023-03-15 02:22:12,616 [pool-1527-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125: start as a follower, conf=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:12,616 [pool-1527-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:12,616 [pool-1527-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ed5356af-2dee-4266-b55e-559e8c0d6889: start ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState
2023-03-15 02:22:12,619 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:12,619 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:12,622 [pool-1527-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B57DF5C92125,id=ed5356af-2dee-4266-b55e-559e8c0d6889
2023-03-15 02:22:12,622 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:12,622 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:12,622 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:12,622 [pool-1527-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:12,622 [pool-1679-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe: new RaftServerImpl for group-B57DF5C92125:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125: ConfigurationManager, init=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-6/data/ratis] (custom)
2023-03-15 02:22:12,622 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe: addNew group-B57DF5C92125:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER] returns group-B57DF5C92125:java.util.concurrent.CompletableFuture@c8d434e[Not completed]
2023-03-15 02:22:12,622 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 1 is closed with bcsId 38.
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:12,623 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:12,623 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:12,624 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:12,624 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:12,624 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:12,624 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=e2467591-d6d0-4055-98f0-b57df5c92125
2023-03-15 02:22:12,625 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:12,625 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:12,625 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:12,625 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:12,625 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:12,626 [IPC Server handler 8 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/13b63f14-21ce-4492-9d02-d9a6b9e153c6
2023-03-15 02:22:12,626 [IPC Server handler 8 on default port 41473] INFO  node.NodeStateManager (NodeStateManager.java:newNodeStatus(338)) - Updating nodeOperationalState on registration as the datanode has a persisted state of IN_MAINTENANCE and expiry of 0
2023-03-15 02:22:12,626 [IPC Server handler 8 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 13b63f14-21ce-4492-9d02-d9a6b9e153c6{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=43943, RATIS=45547, RATIS_ADMIN=45547, RATIS_SERVER=45547, RATIS_DATASTREAM=46243, STANDALONE=45295], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:12,626 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:12,626 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #1 to CLOSED state, datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) reported CLOSED replica.
2023-03-15 02:22:12,626 [EventQueue-NewNodeForNewNodeHandler] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:continueAdminForNode(267)) - Continue admin for datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:12,627 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-15 02:22:12,627 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-03-15 02:22:12,627 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.ContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #3 to CLOSED state, datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) reported CLOSED replica.
2023-03-15 02:22:12,623 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:12,632 [pool-1679-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-6/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125 does not exist. Creating ...
2023-03-15 02:22:12,632 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 3 is closed with bcsId 30.
2023-03-15 02:22:12,632 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-15 02:22:12,640 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-15 02:22:12,640 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-15 02:22:12,641 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:12,640 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:12,641 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:12,641 [pool-1679-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-6/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:12,647 [pool-1679-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-6/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125 has been successfully formatted.
2023-03-15 02:22:12,648 [pool-1679-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-B57DF5C92125: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:12,648 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:12,648 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:12,648 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,648 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:12,648 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:12,648 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-6/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:12,649 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:12,650 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:12,651 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,653 [IPC Server handler 10 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:12,653 [IPC Server handler 10 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : b83605a3-0dba-4f7c-9b88-55eff2caaffe{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=37347, RATIS=46445, RATIS_ADMIN=46445, RATIS_SERVER=46445, RATIS_DATASTREAM=42333, STANDALONE=44263], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:12,653 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:12,653 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-03-15 02:22:12,654 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 6 is closed with bcsId 34.
2023-03-15 02:22:12,654 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:12,655 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #6 to CLOSED state, datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) reported CLOSED replica.
2023-03-15 02:22:12,664 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:12,664 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:12,664 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:12,664 [pool-1679-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,664 [pool-1679-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,664 [pool-1679-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125: start as a follower, conf=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:12,665 [pool-1679-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:12,665 [pool-1679-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe: start b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState
2023-03-15 02:22:12,665 [pool-1679-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B57DF5C92125,id=b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:12,665 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:12,665 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:12,665 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:12,665 [pool-1679-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:12,666 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:12,666 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:12,719 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=e2467591-d6d0-4055-98f0-b57df5c92125.
2023-03-15 02:22:12,726 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=e2467591-d6d0-4055-98f0-b57df5c92125.
2023-03-15 02:22:12,754 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:12,755 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:12,756 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 1 is closed with bcsId 38.
2023-03-15 02:22:12,757 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:12,757 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:12,758 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-03-15 02:22:12,758 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:12,759 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 3 is closed with bcsId 30.
2023-03-15 02:22:12,760 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:12,760 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:12,762 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 6 is closed with bcsId 34.
2023-03-15 02:22:12,782 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:12,782 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 1 is synced with bcsId 38.
2023-03-15 02:22:12,784 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 1 is closed with bcsId 38.
2023-03-15 02:22:12,784 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:12,784 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 3 is synced with bcsId 30.
2023-03-15 02:22:12,785 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-03-15 02:22:12,785 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:12,786 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 3 is closed with bcsId 30.
2023-03-15 02:22:12,786 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:12,787 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(444)) - Container 6 is synced with bcsId 34.
2023-03-15 02:22:12,788 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(359)) - Container 6 is closed with bcsId 34.
2023-03-15 02:22:12,800 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 6 of 7 DN Heartbeats.
2023-03-15 02:22:12,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:12,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:12,801 [IPC Server handler 16 on default port 44419] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/bb24641f-ac05-4a48-a34b-331e584b8427
2023-03-15 02:22:12,801 [IPC Server handler 16 on default port 44419] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : bb24641f-ac05-4a48-a34b-331e584b8427{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=38323, RATIS=33913, RATIS_ADMIN=33913, RATIS_SERVER=33913, RATIS_DATASTREAM=39219, STANDALONE=37209], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:12,801 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:12,802 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=ade2cb9d-27c1-4d81-af81-946ccaf7cd0a to datanode:bb24641f-ac05-4a48-a34b-331e584b8427
2023-03-15 02:22:12,802 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: ade2cb9d-27c1-4d81-af81-946ccaf7cd0a, Nodes: bb24641f-ac05-4a48-a34b-331e584b8427(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-03-15T02:22:12.802Z[Etc/UTC]].
2023-03-15 02:22:12,802 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-03-15 02:22:12,864 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:12,871 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Finalizing its pipelines []
2023-03-15 02:22:12,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:12,895 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: addNew group-3E24F2997DE1:[42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:1|startupRole:FOLLOWER] returns group-3E24F2997DE1:java.util.concurrent.CompletableFuture@13f6111e[Not completed]
2023-03-15 02:22:12,896 [pool-2489-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: new RaftServerImpl for group-3E24F2997DE1:[42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:12,896 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:12,896 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:12,896 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:12,896 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:12,896 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:12,896 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:12,896 [pool-2489-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1: ConfigurationManager, init=-1: peers:[42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:12,896 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis] (custom)
2023-03-15 02:22:12,897 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:12,897 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:12,897 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:12,897 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:12,897 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:12,898 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:12,898 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:12,898 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:12,898 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:12,899 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:12,899 [pool-2489-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/6e97b4b9-43b0-4c2a-bb40-3e24f2997de1 does not exist. Creating ...
2023-03-15 02:22:12,901 [pool-2489-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/6e97b4b9-43b0-4c2a-bb40-3e24f2997de1/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:12,902 [pool-2489-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/6e97b4b9-43b0-4c2a-bb40-3e24f2997de1 has been successfully formatted.
2023-03-15 02:22:12,903 [pool-2489-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-3E24F2997DE1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:12,903 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:12,903 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:12,903 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,903 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:12,903 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 6e97b4b9-43b0-4c2a-bb40-3e24f2997de1, Nodes: 42380981-9e90-41f5-811d-3bbbf08d47d9(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:42380981-9e90-41f5-811d-3bbbf08d47d9, CreationTimestamp2023-03-15T02:22:09.900Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:12,904 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:12,904 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:12,904 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,905 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:12,905 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:12,905 [pool-2489-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/6e97b4b9-43b0-4c2a-bb40-3e24f2997de1
2023-03-15 02:22:12,905 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:12,905 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:12,905 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:12,906 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:12,906 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:12,906 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:12,906 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:12,906 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:12,907 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:12,907 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:12,914 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:12,914 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:12,914 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:12,914 [pool-2489-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,914 [pool-2489-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:12,914 [pool-2489-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1: start as a follower, conf=-1: peers:[42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:12,914 [pool-2489-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:12,915 [pool-2489-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: start 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState
2023-03-15 02:22:12,918 [pool-2489-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3E24F2997DE1,id=42380981-9e90-41f5-811d-3bbbf08d47d9
2023-03-15 02:22:12,918 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:12,918 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:12,918 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:12,918 [pool-2489-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:12,919 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:12,919 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:12,920 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=6e97b4b9-43b0-4c2a-bb40-3e24f2997de1
2023-03-15 02:22:12,920 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=6e97b4b9-43b0-4c2a-bb40-3e24f2997de1.
2023-03-15 02:22:13,110 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 4 of 7 DN Heartbeats.
2023-03-15 02:22:13,110 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:13,110 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:13,295 [IPC Server handler 0 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 5650ff5c-2f39-425b-bee4-adddfcfb793b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:13,295 [IPC Server handler 1 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/132d3d80-0103-4f41-b942-b9d80c35d5a5
2023-03-15 02:22:13,295 [IPC Server handler 1 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 132d3d80-0103-4f41-b942-b9d80c35d5a5{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=40211, RATIS=46755, RATIS_ADMIN=46755, RATIS_SERVER=46755, RATIS_DATASTREAM=43593, STANDALONE=39053], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:13,296 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:13,296 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 1
2023-03-15 02:22:13,296 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-15 02:22:13,296 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:13,297 [IPC Server handler 3 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/00dcba52-510b-4641-a1c5-22cfbaaa7f01
2023-03-15 02:22:13,297 [IPC Server handler 3 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 00dcba52-510b-4641-a1c5-22cfbaaa7f01{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=33971, RATIS=42113, RATIS_ADMIN=42113, RATIS_SERVER=42113, RATIS_DATASTREAM=41049, STANDALONE=36357], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:13,297 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:13,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:13,301 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:13,300 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:13,309 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:13,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:13,314 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:13,413 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: addNew group-9F23A9FF9CAC:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER] returns group-9F23A9FF9CAC:java.util.concurrent.CompletableFuture@6ea5374[Not completed]
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: new RaftServerImpl for group-9F23A9FF9CAC:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC: ConfigurationManager, init=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis] (custom)
2023-03-15 02:22:13,414 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:13,415 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:13,415 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:13,415 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:13,415 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:13,419 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:13,419 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:13,419 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:13,419 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:13,419 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:13,419 [pool-2515-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/3157bed6-4585-40be-9dc3-9f23a9ff9cac does not exist. Creating ...
2023-03-15 02:22:13,425 [pool-2515-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/3157bed6-4585-40be-9dc3-9f23a9ff9cac/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:13,426 [pool-2515-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/3157bed6-4585-40be-9dc3-9f23a9ff9cac has been successfully formatted.
2023-03-15 02:22:13,426 [pool-2515-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-9F23A9FF9CAC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:13,426 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:13,427 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:13,427 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:13,427 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:13,427 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 3157bed6-4585-40be-9dc3-9f23a9ff9cac, Nodes: c86f293d-b980-46b7-b4bb-ca602f6dc485(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c86f293d-b980-46b7-b4bb-ca602f6dc485, CreationTimestamp2023-03-15T02:22:10.415Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:13,427 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:13,428 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:13,428 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/3157bed6-4585-40be-9dc3-9f23a9ff9cac
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:13,429 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:13,430 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:13,431 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:13,436 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:13,436 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:13,436 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:13,436 [pool-2515-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:13,436 [pool-2515-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:13,436 [pool-2515-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC: start as a follower, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:13,436 [pool-2515-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:13,437 [pool-2515-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: start c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState
2023-03-15 02:22:13,437 [pool-2515-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9F23A9FF9CAC,id=c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:13,437 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:13,437 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:13,437 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:13,437 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:13,437 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:13,437 [pool-2515-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:13,438 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=3157bed6-4585-40be-9dc3-9f23a9ff9cac
2023-03-15 02:22:13,438 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=3157bed6-4585-40be-9dc3-9f23a9ff9cac.
2023-03-15 02:22:13,649 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:13,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-15 02:22:13,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:13,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:13,864 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:13,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:13,903 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:14,111 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 6 of 7 DN Heartbeats.
2023-03-15 02:22:14,111 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:14,111 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:14,173 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: addNew group-784429324467:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:1|startupRole:FOLLOWER] returns group-784429324467:java.util.concurrent.CompletableFuture@4288ac7[Not completed]
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: new RaftServerImpl for group-784429324467:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467: ConfigurationManager, init=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis] (custom)
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:14,175 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:14,176 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:14,176 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:14,176 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:14,177 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:14,177 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:14,177 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:14,178 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:14,178 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:14,178 [pool-2566-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/e176a732-6e44-41d1-a762-784429324467 does not exist. Creating ...
2023-03-15 02:22:14,179 [pool-2566-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/e176a732-6e44-41d1-a762-784429324467/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:14,180 [pool-2566-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/e176a732-6e44-41d1-a762-784429324467 has been successfully formatted.
2023-03-15 02:22:14,181 [pool-2566-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-784429324467: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:14,181 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:14,181 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:14,181 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,181 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:14,181 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:14,181 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: e176a732-6e44-41d1-a762-784429324467, Nodes: 71dc2d0c-c132-482e-adc3-0da69386d6d8(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:71dc2d0c-c132-482e-adc3-0da69386d6d8, CreationTimestamp2023-03-15T02:22:11.182Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:14,182 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,182 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:14,182 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:14,182 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:14,182 [pool-2566-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/e176a732-6e44-41d1-a762-784429324467
2023-03-15 02:22:14,182 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:14,182 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:14,183 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,183 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:14,183 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:14,183 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:14,183 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:14,183 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:14,184 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:14,185 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,190 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:14,190 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:14,190 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:14,191 [pool-2566-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,191 [pool-2566-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,191 [pool-2566-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467: start as a follower, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:14,191 [pool-2566-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:14,191 [pool-2566-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: start 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState
2023-03-15 02:22:14,191 [pool-2566-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-784429324467,id=71dc2d0c-c132-482e-adc3-0da69386d6d8
2023-03-15 02:22:14,191 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:14,191 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:14,191 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:14,191 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:14,191 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:14,192 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:14,192 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=e176a732-6e44-41d1-a762-784429324467
2023-03-15 02:22:14,192 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=e176a732-6e44-41d1-a762-784429324467.
2023-03-15 02:22:14,193 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: addNew group-6685DB77740E:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER] returns group-6685DB77740E:java.util.concurrent.CompletableFuture@170e9a[Not completed]
2023-03-15 02:22:14,193 [pool-2566-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: new RaftServerImpl for group-6685DB77740E:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:14,193 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:14,193 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:14,193 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:14,193 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:14,194 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:14,194 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:14,194 [pool-2566-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: ConfigurationManager, init=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:14,194 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis] (custom)
2023-03-15 02:22:14,194 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:14,194 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:14,194 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:14,194 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:14,194 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:14,196 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:14,196 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:14,196 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:14,196 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:14,196 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:14,197 [pool-2566-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e does not exist. Creating ...
2023-03-15 02:22:14,198 [pool-2566-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:14,200 [pool-2566-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e has been successfully formatted.
2023-03-15 02:22:14,200 [pool-2566-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-6685DB77740E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:14,200 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:14,200 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:14,200 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,200 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:14,200 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:14,201 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:14,201 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:14,202 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:14,204 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:14,204 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,210 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:14,210 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:14,210 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:14,211 [pool-2566-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,211 [pool-2566-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,211 [pool-2566-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: start as a follower, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:14,211 [pool-2566-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:14,211 [pool-2566-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: start 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState
2023-03-15 02:22:14,211 [pool-2566-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6685DB77740E,id=71dc2d0c-c132-482e-adc3-0da69386d6d8
2023-03-15 02:22:14,211 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:14,211 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:14,211 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:14,212 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:14,212 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:14,212 [pool-2566-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:14,213 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=7afa3418-6f18-4a5c-9380-6685db77740e
2023-03-15 02:22:14,220 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 1847c06b-5456-44fe-a2e2-332407f19896: addNew group-6685DB77740E:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER] returns group-6685DB77740E:java.util.concurrent.CompletableFuture@78bf33de[Not completed]
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 1847c06b-5456-44fe-a2e2-332407f19896: new RaftServerImpl for group-6685DB77740E:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E: ConfigurationManager, init=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis] (custom)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:14,221 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:14,223 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:14,223 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:14,223 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:14,223 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:14,223 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:14,224 [pool-2633-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e does not exist. Creating ...
2023-03-15 02:22:14,225 [pool-2633-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:14,227 [pool-2633-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e has been successfully formatted.
2023-03-15 02:22:14,227 [pool-2633-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-6685DB77740E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:14,227 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:14,227 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:14,227 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,228 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:14,228 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:14,228 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,229 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:14,229 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:14,229 [pool-2633-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e
2023-03-15 02:22:14,229 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:14,230 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:14,230 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,230 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:14,230 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:14,230 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:14,230 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:14,230 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:14,231 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:14,231 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,232 [IPC Server handler 0 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/5650ff5c-2f39-425b-bee4-adddfcfb793b
2023-03-15 02:22:14,232 [IPC Server handler 0 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 5650ff5c-2f39-425b-bee4-adddfcfb793b{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=36691, RATIS=33051, RATIS_ADMIN=33051, RATIS_SERVER=33051, RATIS_DATASTREAM=43637, STANDALONE=36993], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:14,240 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-15 02:22:14,241 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-15 02:22:14,241 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-15 02:22:14,241 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-15 02:22:14,241 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-15 02:22:14,241 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-15 02:22:14,241 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-15 02:22:14,241 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-15 02:22:14,241 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1156)) - Service ReplicationManager transitions to RUNNING.
2023-03-15 02:22:14,241 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-15 02:22:14,241 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:14,242 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:14,242 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:14,242 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:14,242 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-15 02:22:14,244 [pool-2633-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,244 [pool-2633-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,244 [pool-2633-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E: start as a follower, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:14,244 [pool-2633-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:14,244 [pool-2633-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1847c06b-5456-44fe-a2e2-332407f19896: start 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState
2023-03-15 02:22:14,245 [pool-2633-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6685DB77740E,id=1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:14,245 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:14,245 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:14,245 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:14,245 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:14,246 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:14,246 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:14,258 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: addNew group-6685DB77740E:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER] returns group-6685DB77740E:java.util.concurrent.CompletableFuture@6322ea95[Not completed]
2023-03-15 02:22:14,259 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: new RaftServerImpl for group-6685DB77740E:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:14,259 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:14,259 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:14,259 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:14,259 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:14,259 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:14,260 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:14,260 [pool-2603-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E: ConfigurationManager, init=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:14,260 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis] (custom)
2023-03-15 02:22:14,260 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:14,260 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:14,260 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:14,260 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:14,260 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:14,262 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:14,262 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:14,262 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:14,262 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:14,262 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:14,262 [pool-2603-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e does not exist. Creating ...
2023-03-15 02:22:14,263 [pool-2603-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:14,265 [pool-2603-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e has been successfully formatted.
2023-03-15 02:22:14,265 [pool-2603-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-6685DB77740E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:14,265 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:14,266 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:14,266 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,266 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:14,266 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:14,266 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,266 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:14,267 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:14,268 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:14,269 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,275 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:14,275 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:14,275 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:14,275 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,275 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,275 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E: start as a follower, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:14,275 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:14,275 [pool-2603-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: start 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState
2023-03-15 02:22:14,276 [pool-2603-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6685DB77740E,id=6b109e20-fb43-4126-a2d0-e01a40c07237
2023-03-15 02:22:14,276 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:14,276 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:14,276 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:14,276 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:14,276 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:14,276 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:14,289 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=7afa3418-6f18-4a5c-9380-6685db77740e.
2023-03-15 02:22:14,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:14,302 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:14,314 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:14,316 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:14,427 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:14,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-15 02:22:14,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:14,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:14,804 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: addNew group-E8089850D28E:[6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:1|startupRole:FOLLOWER] returns group-E8089850D28E:java.util.concurrent.CompletableFuture@2830aa38[Not completed]
2023-03-15 02:22:14,804 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: new RaftServerImpl for group-E8089850D28E:[6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E: ConfigurationManager, init=-1: peers:[6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis] (custom)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:14,805 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:14,807 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:14,807 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:14,807 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:14,807 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:14,807 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:14,807 [pool-2603-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/e820d2a7-e73f-462b-b858-e8089850d28e does not exist. Creating ...
2023-03-15 02:22:14,808 [pool-2603-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/e820d2a7-e73f-462b-b858-e8089850d28e/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:14,810 [pool-2603-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/e820d2a7-e73f-462b-b858-e8089850d28e has been successfully formatted.
2023-03-15 02:22:14,810 [pool-2603-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-E8089850D28E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:14,810 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:14,811 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:14,811 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,811 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:14,811 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:14,811 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: e820d2a7-e73f-462b-b858-e8089850d28e, Nodes: 6b109e20-fb43-4126-a2d0-e01a40c07237(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:6b109e20-fb43-4126-a2d0-e01a40c07237, CreationTimestamp2023-03-15T02:22:11.809Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:14,812 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,812 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:14,812 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:14,812 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:14,812 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/e820d2a7-e73f-462b-b858-e8089850d28e
2023-03-15 02:22:14,812 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:14,813 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:14,813 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:14,813 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:14,813 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:14,813 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:14,813 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:14,813 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:14,814 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:14,815 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:14,821 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:14,821 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:14,821 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:14,822 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,822 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:14,825 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E: start as a follower, conf=-1: peers:[6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:14,825 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:14,825 [pool-2603-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: start 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState
2023-03-15 02:22:14,830 [pool-2603-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E8089850D28E,id=6b109e20-fb43-4126-a2d0-e01a40c07237
2023-03-15 02:22:14,830 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:14,830 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:14,830 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:14,830 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:14,831 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:14,831 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:14,831 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=e820d2a7-e73f-462b-b858-e8089850d28e
2023-03-15 02:22:14,832 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=e820d2a7-e73f-462b-b858-e8089850d28e.
2023-03-15 02:22:14,864 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:14,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:14,903 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:15,111 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-15 02:22:15,112 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Cluster exits safe mode
2023-03-15 02:22:15,112 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:15,115 [Listener at 0.0.0.0/37571] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:15,116 [Listener at 0.0.0.0/37571] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6: close
2023-03-15 02:22:15,116 [Listener at 0.0.0.0/37571] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:15,117 [Listener at 0.0.0.0/37571] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 13b63f14-21ce-4492-9d02-d9a6b9e153c6: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:15,118 [13b63f14-21ce-4492-9d02-d9a6b9e153c6-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x41d002c7, L:/0:0:0:0:0:0:0:0:46243] CLOSE
2023-03-15 02:22:15,118 [13b63f14-21ce-4492-9d02-d9a6b9e153c6-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x41d002c7, L:/0:0:0:0:0:0:0:0:46243] INACTIVE
2023-03-15 02:22:15,118 [13b63f14-21ce-4492-9d02-d9a6b9e153c6-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x41d002c7, L:/0:0:0:0:0:0:0:0:46243] UNREGISTERED
2023-03-15 02:22:15,128 [JvmPauseMonitor35] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-13b63f14-21ce-4492-9d02-d9a6b9e153c6: Stopped
2023-03-15 02:22:15,201 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:15,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:15,302 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:15,307 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:15,314 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:15,316 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:15,360 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 1847c06b-5456-44fe-a2e2-332407f19896: addNew group-4773A172C6FD:[1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER] returns group-4773A172C6FD:java.util.concurrent.CompletableFuture@71475e7d[Not completed]
2023-03-15 02:22:15,361 [pool-2633-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 1847c06b-5456-44fe-a2e2-332407f19896: new RaftServerImpl for group-4773A172C6FD:[1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:15,361 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:15,361 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:15,361 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:15,361 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:15,361 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:15,361 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:15,361 [pool-2633-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD: ConfigurationManager, init=-1: peers:[1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:15,361 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis] (custom)
2023-03-15 02:22:15,362 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:15,362 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:15,362 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:15,362 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:15,362 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:15,364 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:15,364 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:15,364 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:15,364 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:15,364 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:15,364 [pool-2633-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/e8e306ef-b9aa-42ad-aa76-4773a172c6fd does not exist. Creating ...
2023-03-15 02:22:15,365 [pool-2633-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/e8e306ef-b9aa-42ad-aa76-4773a172c6fd/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:15,367 [pool-2633-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/e8e306ef-b9aa-42ad-aa76-4773a172c6fd has been successfully formatted.
2023-03-15 02:22:15,367 [pool-2633-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-4773A172C6FD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:15,367 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:15,368 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:15,368 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:15,368 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: e8e306ef-b9aa-42ad-aa76-4773a172c6fd, Nodes: 1847c06b-5456-44fe-a2e2-332407f19896(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1847c06b-5456-44fe-a2e2-332407f19896, CreationTimestamp2023-03-15T02:22:12.366Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:15,368 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:15,368 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:15,368 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:15,369 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:15,369 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:15,369 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:15,369 [pool-2633-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/e8e306ef-b9aa-42ad-aa76-4773a172c6fd
2023-03-15 02:22:15,369 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:15,369 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:15,369 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:15,370 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:15,370 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:15,370 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:15,370 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:15,370 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:15,371 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:15,371 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:15,376 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:15,376 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:15,376 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:15,377 [pool-2633-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:15,377 [pool-2633-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:15,377 [pool-2633-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD: start as a follower, conf=-1: peers:[1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:15,377 [pool-2633-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:15,377 [pool-2633-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1847c06b-5456-44fe-a2e2-332407f19896: start 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState
2023-03-15 02:22:15,377 [pool-2633-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4773A172C6FD,id=1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:15,377 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:15,377 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:15,378 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:15,378 [pool-2633-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:15,378 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=e8e306ef-b9aa-42ad-aa76-4773a172c6fd
2023-03-15 02:22:15,378 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:15,378 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=e8e306ef-b9aa-42ad-aa76-4773a172c6fd.
2023-03-15 02:22:15,378 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:15,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-15 02:22:15,801 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:15,802 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:15,802 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - bb24641f-ac05-4a48-a34b-331e584b8427: addNew group-946CCAF7CD0A:[bb24641f-ac05-4a48-a34b-331e584b8427|rpc:10.1.0.23:33913|dataStream:10.1.0.23:39219|priority:1|startupRole:FOLLOWER] returns group-946CCAF7CD0A:java.util.concurrent.CompletableFuture@110a04f9[Not completed]
2023-03-15 02:22:15,803 [pool-2663-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - bb24641f-ac05-4a48-a34b-331e584b8427: new RaftServerImpl for group-946CCAF7CD0A:[bb24641f-ac05-4a48-a34b-331e584b8427|rpc:10.1.0.23:33913|dataStream:10.1.0.23:39219|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-03-15 02:22:15,804 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-03-15 02:22:15,804 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-03-15 02:22:15,804 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-03-15 02:22:15,804 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-03-15 02:22:15,804 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-03-15 02:22:15,804 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-03-15 02:22:15,804 [pool-2663-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A: ConfigurationManager, init=-1: peers:[bb24641f-ac05-4a48-a34b-331e584b8427|rpc:10.1.0.23:33913|dataStream:10.1.0.23:39219|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-03-15 02:22:15,804 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis] (custom)
2023-03-15 02:22:15,805 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-03-15 02:22:15,805 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-03-15 02:22:15,805 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-03-15 02:22:15,805 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-03-15 02:22:15,805 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-03-15 02:22:15,806 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:15,806 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-03-15 02:22:15,806 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-03-15 02:22:15,806 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-03-15 02:22:15,807 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-03-15 02:22:15,807 [pool-2663-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis/ade2cb9d-27c1-4d81-af81-946ccaf7cd0a does not exist. Creating ...
2023-03-15 02:22:15,808 [pool-2663-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis/ade2cb9d-27c1-4d81-af81-946ccaf7cd0a/in_use.lock acquired by nodename 15183@fv-az260-852
2023-03-15 02:22:15,810 [pool-2663-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis/ade2cb9d-27c1-4d81-af81-946ccaf7cd0a has been successfully formatted.
2023-03-15 02:22:15,810 [pool-2663-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-946CCAF7CD0A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-03-15 02:22:15,811 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-03-15 02:22:15,811 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-03-15 02:22:15,811 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:15,811 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:15,811 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-03-15 02:22:15,811 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-03-15 02:22:15,812 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:15,812 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: ade2cb9d-27c1-4d81-af81-946ccaf7cd0a, Nodes: bb24641f-ac05-4a48-a34b-331e584b8427(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:bb24641f-ac05-4a48-a34b-331e584b8427, CreationTimestamp2023-03-15T02:22:12.802Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:15,812 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis/ade2cb9d-27c1-4d81-af81-946ccaf7cd0a
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-03-15 02:22:15,813 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-03-15 02:22:15,814 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-03-15 02:22:15,815 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:15,820 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-03-15 02:22:15,820 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A: start as a follower, conf=-1: peers:[bb24641f-ac05-4a48-a34b-331e584b8427|rpc:10.1.0.23:33913|dataStream:10.1.0.23:39219|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bb24641f-ac05-4a48-a34b-331e584b8427: start bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-946CCAF7CD0A,id=bb24641f-ac05-4a48-a34b-331e584b8427
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-03-15 02:22:15,821 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-03-15 02:22:15,822 [pool-2663-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-03-15 02:22:15,822 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:15,822 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:15,822 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=ade2cb9d-27c1-4d81-af81-946ccaf7cd0a
2023-03-15 02:22:15,822 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=ade2cb9d-27c1-4d81-af81-946ccaf7cd0a.
2023-03-15 02:22:15,864 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:15,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:15,903 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:16,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:16,302 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:16,307 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:16,314 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:16,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-15 02:22:16,368 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:16,427 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:16,802 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-15 02:22:16,802 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-03-15 02:22:16,802 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:16,812 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:16,864 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:16,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:16,904 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:17,140 [Listener at 0.0.0.0/37571] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-1/data-0/containers/hdds/59b91c09-8b07-4c70-997f-cc8d5df695e6/DS-c37910e7-5522-464d-80f3-827efbfd3a63/container.db for volume DS-c37910e7-5522-464d-80f3-827efbfd3a63
2023-03-15 02:22:17,140 [Listener at 0.0.0.0/37571] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-03-15 02:22:17,140 [Listener at 0.0.0.0/37571] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-03-15 02:22:17,141 [Listener at 0.0.0.0/37571] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(601)) - Ozone container server stopped.
2023-03-15 02:22:17,161 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@132ca197{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-03-15 02:22:17,161 [Listener at 0.0.0.0/37571] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@78cdefc8{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:17,162 [Listener at 0.0.0.0/37571] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:17,162 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@31cbbb3a{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-03-15 02:22:17,162 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@ee11c6f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:17,201 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:17,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:17,302 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:17,315 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:17,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:17,368 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:17,427 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:17,458 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5136480283ns, electionTimeout:5133ms
2023-03-15 02:22:17,458 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5062860154ns, electionTimeout:5057ms
2023-03-15 02:22:17,458 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: shutdown dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState
2023-03-15 02:22:17,458 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:17,458 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: shutdown 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState
2023-03-15 02:22:17,458 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:17,458 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: start dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92
2023-03-15 02:22:17,458 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:17,459 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:17,459 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,459 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: start 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93
2023-03-15 02:22:17,460 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,460 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:17,463 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,463 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,463 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 42380981-9e90-41f5-811d-3bbbf08d47d9
2023-03-15 02:22:17,473 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870: receive requestVote(PRE_VOTE, dda7196a-19a1-4ef5-a6eb-ce99792637b5, group-D9C9687C9870, 0, (t:0, i:0))
2023-03-15 02:22:17,473 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FOLLOWER: reject PRE_VOTE from dda7196a-19a1-4ef5-a6eb-ce99792637b5: our priority 1 > candidate's priority 0
2023-03-15 02:22:17,473 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870 replies to PRE_VOTE vote request: dda7196a-19a1-4ef5-a6eb-ce99792637b5<-c86f293d-b980-46b7-b4bb-ca602f6dc485#0:FAIL-t0. Peer's state: c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870:t0, leader=null, voted=, raftlog=Memoized:c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,474 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2023-03-15 02:22:17,474 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: dda7196a-19a1-4ef5-a6eb-ce99792637b5<-c86f293d-b980-46b7-b4bb-ca602f6dc485#0:FAIL-t0
2023-03-15 02:22:17,474 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92 PRE_VOTE round 0: result REJECTED
2023-03-15 02:22:17,474 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-15 02:22:17,474 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: shutdown dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92
2023-03-15 02:22:17,474 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-LeaderElection92] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: start dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState
2023-03-15 02:22:17,474 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,474 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,477 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:17,478 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,478 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,480 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for dda7196a-19a1-4ef5-a6eb-ce99792637b5
2023-03-15 02:22:17,481 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5193554590ns, electionTimeout:5191ms
2023-03-15 02:22:17,481 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: shutdown dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState
2023-03-15 02:22:17,481 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:17,481 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:17,481 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: start dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94
2023-03-15 02:22:17,482 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,482 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94 PRE_VOTE round 0: result PASSED (term=0)
2023-03-15 02:22:17,486 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: receive requestVote(PRE_VOTE, dda7196a-19a1-4ef5-a6eb-ce99792637b5, group-D9C9687C9870, 0, (t:0, i:0))
2023-03-15 02:22:17,486 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-CANDIDATE: accept PRE_VOTE from dda7196a-19a1-4ef5-a6eb-ce99792637b5: our priority 0 <= candidate's priority 0
2023-03-15 02:22:17,486 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870 replies to PRE_VOTE vote request: dda7196a-19a1-4ef5-a6eb-ce99792637b5<-42380981-9e90-41f5-811d-3bbbf08d47d9#0:OK-t0. Peer's state: 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870:t0, leader=null, voted=, raftlog=Memoized:42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,487 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870: receive requestVote(PRE_VOTE, 42380981-9e90-41f5-811d-3bbbf08d47d9, group-D9C9687C9870, 0, (t:0, i:0))
2023-03-15 02:22:17,487 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FOLLOWER: reject PRE_VOTE from 42380981-9e90-41f5-811d-3bbbf08d47d9: our priority 1 > candidate's priority 0
2023-03-15 02:22:17,487 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870 replies to PRE_VOTE vote request: 42380981-9e90-41f5-811d-3bbbf08d47d9<-c86f293d-b980-46b7-b4bb-ca602f6dc485#0:FAIL-t0. Peer's state: c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870:t0, leader=null, voted=, raftlog=Memoized:c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,488 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2023-03-15 02:22:17,488 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 42380981-9e90-41f5-811d-3bbbf08d47d9<-c86f293d-b980-46b7-b4bb-ca602f6dc485#0:FAIL-t0
2023-03-15 02:22:17,488 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93 PRE_VOTE round 0: result REJECTED
2023-03-15 02:22:17,488 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-15 02:22:17,488 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: shutdown 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93
2023-03-15 02:22:17,488 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-LeaderElection93] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: start 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState
2023-03-15 02:22:17,491 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94 ELECTION round 0: submit vote requests at term 1 for -1: peers:[dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,491 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94 ELECTION round 0: result PASSED (term=1)
2023-03-15 02:22:17,491 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: shutdown dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94
2023-03-15 02:22:17,491 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:17,491 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-D59EFF0A6F52 with new leaderId: dda7196a-19a1-4ef5-a6eb-ce99792637b5
2023-03-15 02:22:17,491 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52: change Leader from null to dda7196a-19a1-4ef5-a6eb-ce99792637b5 at term 1 for becomeLeader, leader elected after 5257ms
2023-03-15 02:22:17,491 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:17,492 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:17,492 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:17,492 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: receive requestVote(PRE_VOTE, 42380981-9e90-41f5-811d-3bbbf08d47d9, group-D9C9687C9870, 0, (t:0, i:0))
2023-03-15 02:22:17,492 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FOLLOWER: accept PRE_VOTE from 42380981-9e90-41f5-811d-3bbbf08d47d9: our priority 0 <= candidate's priority 0
2023-03-15 02:22:17,492 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870 replies to PRE_VOTE vote request: 42380981-9e90-41f5-811d-3bbbf08d47d9<-dda7196a-19a1-4ef5-a6eb-ce99792637b5#0:OK-t0. Peer's state: dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870:t0, leader=null, voted=, raftlog=Memoized:dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,493 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:17,494 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:17,494 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:17,494 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:17,494 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:17,494 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:17,494 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: start dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderStateImpl
2023-03-15 02:22:17,494 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,495 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:17,495 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,506 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-LeaderElection94] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52: set configuration 0: peers:[dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,507 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D59EFF0A6F52-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/78ab6313-1582-4821-a408-d59eff0a6f52/current/log_inprogress_0
2023-03-15 02:22:17,508 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5154408404ns, electionTimeout:5152ms
2023-03-15 02:22:17,508 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: shutdown c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState
2023-03-15 02:22:17,508 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:17,508 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:17,508 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: start c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95
2023-03-15 02:22:17,511 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,513 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,513 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 42380981-9e90-41f5-811d-3bbbf08d47d9
2023-03-15 02:22:17,513 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for dda7196a-19a1-4ef5-a6eb-ce99792637b5
2023-03-15 02:22:17,513 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,523 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: receive requestVote(PRE_VOTE, c86f293d-b980-46b7-b4bb-ca602f6dc485, group-D9C9687C9870, 0, (t:0, i:0))
2023-03-15 02:22:17,523 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FOLLOWER: accept PRE_VOTE from c86f293d-b980-46b7-b4bb-ca602f6dc485: our priority 0 <= candidate's priority 1
2023-03-15 02:22:17,524 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870 replies to PRE_VOTE vote request: c86f293d-b980-46b7-b4bb-ca602f6dc485<-dda7196a-19a1-4ef5-a6eb-ce99792637b5#0:OK-t0. Peer's state: dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870:t0, leader=null, voted=, raftlog=Memoized:dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,529 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-15 02:22:17,529 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c86f293d-b980-46b7-b4bb-ca602f6dc485<-dda7196a-19a1-4ef5-a6eb-ce99792637b5#0:OK-t0
2023-03-15 02:22:17,530 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95 PRE_VOTE round 0: result PASSED
2023-03-15 02:22:17,531 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: receive requestVote(PRE_VOTE, c86f293d-b980-46b7-b4bb-ca602f6dc485, group-D9C9687C9870, 0, (t:0, i:0))
2023-03-15 02:22:17,531 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FOLLOWER: accept PRE_VOTE from c86f293d-b980-46b7-b4bb-ca602f6dc485: our priority 0 <= candidate's priority 1
2023-03-15 02:22:17,531 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870 replies to PRE_VOTE vote request: c86f293d-b980-46b7-b4bb-ca602f6dc485<-42380981-9e90-41f5-811d-3bbbf08d47d9#0:OK-t0. Peer's state: 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870:t0, leader=null, voted=, raftlog=Memoized:42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,531 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,532 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,532 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,533 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: receive requestVote(ELECTION, c86f293d-b980-46b7-b4bb-ca602f6dc485, group-D9C9687C9870, 1, (t:0, i:0))
2023-03-15 02:22:17,533 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FOLLOWER: accept ELECTION from c86f293d-b980-46b7-b4bb-ca602f6dc485: our priority 0 <= candidate's priority 1
2023-03-15 02:22:17,533 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:17,533 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: shutdown 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState
2023-03-15 02:22:17,533 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: start 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState
2023-03-15 02:22:17,533 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState was interrupted
2023-03-15 02:22:17,534 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: receive requestVote(ELECTION, c86f293d-b980-46b7-b4bb-ca602f6dc485, group-D9C9687C9870, 1, (t:0, i:0))
2023-03-15 02:22:17,534 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FOLLOWER: accept ELECTION from c86f293d-b980-46b7-b4bb-ca602f6dc485: our priority 0 <= candidate's priority 1
2023-03-15 02:22:17,534 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:17,534 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: shutdown dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState
2023-03-15 02:22:17,537 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5: start dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState
2023-03-15 02:22:17,537 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState was interrupted
2023-03-15 02:22:17,537 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,537 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,538 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870 replies to ELECTION vote request: c86f293d-b980-46b7-b4bb-ca602f6dc485<-42380981-9e90-41f5-811d-3bbbf08d47d9#0:OK-t1. Peer's state: 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870:t1, leader=null, voted=c86f293d-b980-46b7-b4bb-ca602f6dc485, raftlog=Memoized:42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,542 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-15 02:22:17,542 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c86f293d-b980-46b7-b4bb-ca602f6dc485<-42380981-9e90-41f5-811d-3bbbf08d47d9#0:OK-t1
2023-03-15 02:22:17,542 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95 ELECTION round 0: result PASSED
2023-03-15 02:22:17,542 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: shutdown c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95
2023-03-15 02:22:17,542 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:17,542 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-D9C9687C9870 with new leaderId: c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:17,542 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870: change Leader from null to c86f293d-b980-46b7-b4bb-ca602f6dc485 at term 1 for becomeLeader, leader elected after 5206ms
2023-03-15 02:22:17,542 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:17,542 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:17,543 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:17,543 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870 replies to ELECTION vote request: c86f293d-b980-46b7-b4bb-ca602f6dc485<-dda7196a-19a1-4ef5-a6eb-ce99792637b5#0:OK-t1. Peer's state: dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870:t1, leader=null, voted=c86f293d-b980-46b7-b4bb-ca602f6dc485, raftlog=Memoized:dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,543 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:17,543 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:17,543 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:17,543 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:17,543 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:17,544 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-15 02:22:17,544 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:17,544 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-15 02:22:17,544 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-15 02:22:17,544 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:17,544 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:17,545 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:17,545 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 2c7edc49-dfb9-414e-a54e-d9c9687c9870, Nodes: c86f293d-b980-46b7-b4bb-ca602f6dc485(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)42380981-9e90-41f5-811d-3bbbf08d47d9(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)dda7196a-19a1-4ef5-a6eb-ce99792637b5(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:c86f293d-b980-46b7-b4bb-ca602f6dc485, CreationTimestamp2023-03-15T02:22:10.420Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:17,546 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:17,546 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-15 02:22:17,548 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-15 02:22:17,548 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:17,548 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-15 02:22:17,548 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-15 02:22:17,548 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:17,548 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:17,548 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:17,548 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-15 02:22:17,548 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: start c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderStateImpl
2023-03-15 02:22:17,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-15 02:22:17,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-15 02:22:17,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-15 02:22:17,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-15 02:22:17,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-15 02:22:17,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-15 02:22:17,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-15 02:22:17,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-15 02:22:17,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1156)) - Service ReplicationManager transitions to RUNNING.
2023-03-15 02:22:17,550 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-15 02:22:17,550 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:17,551 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,551 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,551 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870/current/log_inprogress_0
2023-03-15 02:22:17,566 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870-LeaderElection95] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-D9C9687C9870: set configuration 0: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,572 [42380981-9e90-41f5-811d-3bbbf08d47d9-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-D9C9687C9870 with new leaderId: c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:17,572 [42380981-9e90-41f5-811d-3bbbf08d47d9-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: change Leader from null to c86f293d-b980-46b7-b4bb-ca602f6dc485 at term 1 for appendEntries, leader elected after 5193ms
2023-03-15 02:22:17,572 [dda7196a-19a1-4ef5-a6eb-ce99792637b5-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-D9C9687C9870 with new leaderId: c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:17,572 [dda7196a-19a1-4ef5-a6eb-ce99792637b5-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: change Leader from null to c86f293d-b980-46b7-b4bb-ca602f6dc485 at term 1 for appendEntries, leader elected after 5273ms
2023-03-15 02:22:17,575 [42380981-9e90-41f5-811d-3bbbf08d47d9-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870: set configuration 0: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,575 [42380981-9e90-41f5-811d-3bbbf08d47d9-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:17,576 [dda7196a-19a1-4ef5-a6eb-ce99792637b5-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870: set configuration 0: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER, 42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:0|startupRole:FOLLOWER, dda7196a-19a1-4ef5-a6eb-ce99792637b5|rpc:10.1.0.23:32909|dataStream:10.1.0.23:46287|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,576 [dda7196a-19a1-4ef5-a6eb-ce99792637b5-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:17,577 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-D9C9687C9870-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870/current/log_inprogress_0
2023-03-15 02:22:17,578 [dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - dda7196a-19a1-4ef5-a6eb-ce99792637b5@group-D9C9687C9870-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-0/data/ratis/2c7edc49-dfb9-414e-a54e-d9c9687c9870/current/log_inprogress_0
2023-03-15 02:22:17,622 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5032348008ns, electionTimeout:5031ms
2023-03-15 02:22:17,622 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: shutdown 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState
2023-03-15 02:22:17,623 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:17,623 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:17,623 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: start 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96
2023-03-15 02:22:17,623 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,624 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for ed5356af-2dee-4266-b55e-559e8c0d6889
2023-03-15 02:22:17,627 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,628 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,628 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:17,629 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125: receive requestVote(PRE_VOTE, 646e529a-a01f-4b15-a31a-2706cdf8d47d, group-B57DF5C92125, 0, (t:0, i:0))
2023-03-15 02:22:17,629 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FOLLOWER: accept PRE_VOTE from 646e529a-a01f-4b15-a31a-2706cdf8d47d: our priority 0 <= candidate's priority 0
2023-03-15 02:22:17,629 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125 replies to PRE_VOTE vote request: 646e529a-a01f-4b15-a31a-2706cdf8d47d<-ed5356af-2dee-4266-b55e-559e8c0d6889#0:OK-t0. Peer's state: ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125:t0, leader=null, voted=, raftlog=Memoized:ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,633 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125: receive requestVote(PRE_VOTE, 646e529a-a01f-4b15-a31a-2706cdf8d47d, group-B57DF5C92125, 0, (t:0, i:0))
2023-03-15 02:22:17,633 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FOLLOWER: reject PRE_VOTE from 646e529a-a01f-4b15-a31a-2706cdf8d47d: our priority 1 > candidate's priority 0
2023-03-15 02:22:17,633 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125 replies to PRE_VOTE vote request: 646e529a-a01f-4b15-a31a-2706cdf8d47d<-b83605a3-0dba-4f7c-9b88-55eff2caaffe#0:FAIL-t0. Peer's state: b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125:t0, leader=null, voted=, raftlog=Memoized:b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,634 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2023-03-15 02:22:17,634 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 646e529a-a01f-4b15-a31a-2706cdf8d47d<-ed5356af-2dee-4266-b55e-559e8c0d6889#0:OK-t0
2023-03-15 02:22:17,634 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 646e529a-a01f-4b15-a31a-2706cdf8d47d<-b83605a3-0dba-4f7c-9b88-55eff2caaffe#0:FAIL-t0
2023-03-15 02:22:17,634 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96 PRE_VOTE round 0: result REJECTED
2023-03-15 02:22:17,634 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-15 02:22:17,634 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: shutdown 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96
2023-03-15 02:22:17,634 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-LeaderElection96] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: start 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState
2023-03-15 02:22:17,635 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,635 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,665 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,665 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,707 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23) moved to stale state. Finalizing its pipelines []
2023-03-15 02:22:17,769 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5104630404ns, electionTimeout:5103ms
2023-03-15 02:22:17,770 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe: shutdown b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState
2023-03-15 02:22:17,770 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:17,770 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:17,770 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe: start b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97
2023-03-15 02:22:17,770 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,771 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for ed5356af-2dee-4266-b55e-559e8c0d6889
2023-03-15 02:22:17,771 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,771 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,772 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 646e529a-a01f-4b15-a31a-2706cdf8d47d
2023-03-15 02:22:17,777 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: receive requestVote(PRE_VOTE, b83605a3-0dba-4f7c-9b88-55eff2caaffe, group-B57DF5C92125, 0, (t:0, i:0))
2023-03-15 02:22:17,777 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FOLLOWER: accept PRE_VOTE from b83605a3-0dba-4f7c-9b88-55eff2caaffe: our priority 0 <= candidate's priority 1
2023-03-15 02:22:17,777 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125 replies to PRE_VOTE vote request: b83605a3-0dba-4f7c-9b88-55eff2caaffe<-646e529a-a01f-4b15-a31a-2706cdf8d47d#0:OK-t0. Peer's state: 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125:t0, leader=null, voted=, raftlog=Memoized:646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,778 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125: receive requestVote(PRE_VOTE, b83605a3-0dba-4f7c-9b88-55eff2caaffe, group-B57DF5C92125, 0, (t:0, i:0))
2023-03-15 02:22:17,778 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FOLLOWER: accept PRE_VOTE from b83605a3-0dba-4f7c-9b88-55eff2caaffe: our priority 0 <= candidate's priority 1
2023-03-15 02:22:17,779 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125 replies to PRE_VOTE vote request: b83605a3-0dba-4f7c-9b88-55eff2caaffe<-ed5356af-2dee-4266-b55e-559e8c0d6889#0:OK-t0. Peer's state: ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125:t0, leader=null, voted=, raftlog=Memoized:ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,779 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-15 02:22:17,779 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: b83605a3-0dba-4f7c-9b88-55eff2caaffe<-646e529a-a01f-4b15-a31a-2706cdf8d47d#0:OK-t0
2023-03-15 02:22:17,779 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97 PRE_VOTE round 0: result PASSED
2023-03-15 02:22:17,781 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,781 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,781 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,782 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: receive requestVote(ELECTION, b83605a3-0dba-4f7c-9b88-55eff2caaffe, group-B57DF5C92125, 1, (t:0, i:0))
2023-03-15 02:22:17,782 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FOLLOWER: accept ELECTION from b83605a3-0dba-4f7c-9b88-55eff2caaffe: our priority 0 <= candidate's priority 1
2023-03-15 02:22:17,782 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:17,782 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: shutdown 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState
2023-03-15 02:22:17,782 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: start 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState
2023-03-15 02:22:17,782 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125: receive requestVote(ELECTION, b83605a3-0dba-4f7c-9b88-55eff2caaffe, group-B57DF5C92125, 1, (t:0, i:0))
2023-03-15 02:22:17,782 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FOLLOWER: accept ELECTION from b83605a3-0dba-4f7c-9b88-55eff2caaffe: our priority 0 <= candidate's priority 1
2023-03-15 02:22:17,782 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState was interrupted
2023-03-15 02:22:17,782 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:17,782 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ed5356af-2dee-4266-b55e-559e8c0d6889: shutdown ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState
2023-03-15 02:22:17,783 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ed5356af-2dee-4266-b55e-559e8c0d6889: start ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState
2023-03-15 02:22:17,783 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState was interrupted
2023-03-15 02:22:17,783 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,783 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,784 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:17,784 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:17,784 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125 replies to ELECTION vote request: b83605a3-0dba-4f7c-9b88-55eff2caaffe<-646e529a-a01f-4b15-a31a-2706cdf8d47d#0:OK-t1. Peer's state: 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125:t1, leader=null, voted=b83605a3-0dba-4f7c-9b88-55eff2caaffe, raftlog=Memoized:646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,785 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125 replies to ELECTION vote request: b83605a3-0dba-4f7c-9b88-55eff2caaffe<-ed5356af-2dee-4266-b55e-559e8c0d6889#0:OK-t1. Peer's state: ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125:t1, leader=null, voted=b83605a3-0dba-4f7c-9b88-55eff2caaffe, raftlog=Memoized:ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: b83605a3-0dba-4f7c-9b88-55eff2caaffe<-646e529a-a01f-4b15-a31a-2706cdf8d47d#0:OK-t1
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97 ELECTION round 0: result PASSED
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe: shutdown b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-B57DF5C92125 with new leaderId: b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125: change Leader from null to b83605a3-0dba-4f7c-9b88-55eff2caaffe at term 1 for becomeLeader, leader elected after 5162ms
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:17,786 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:17,787 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:17,787 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:17,787 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:17,787 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:17,787 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:17,788 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-15 02:22:17,788 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:17,788 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-15 02:22:17,788 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-15 02:22:17,788 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:17,788 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:17,788 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:17,788 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-15 02:22:17,790 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: e2467591-d6d0-4055-98f0-b57df5c92125, Nodes: b83605a3-0dba-4f7c-9b88-55eff2caaffe(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:b83605a3-0dba-4f7c-9b88-55eff2caaffe, CreationTimestamp2023-03-15T02:22:11.853Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:17,792 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-15 02:22:17,792 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:17,792 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-15 02:22:17,792 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-15 02:22:17,792 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:17,793 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:17,795 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:17,795 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-15 02:22:17,795 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe: start b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderStateImpl
2023-03-15 02:22:17,796 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:17,797 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-LeaderElection97] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125: set configuration 0: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,797 [b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-6/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125/current/log_inprogress_0
2023-03-15 02:22:17,802 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-03-15 02:22:17,802 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Cluster exits safe mode
2023-03-15 02:22:17,802 [Listener at 127.0.0.1/37433] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-03-15 02:22:17,806 [ed5356af-2dee-4266-b55e-559e8c0d6889-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-B57DF5C92125 with new leaderId: b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:17,806 [ed5356af-2dee-4266-b55e-559e8c0d6889-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125: change Leader from null to b83605a3-0dba-4f7c-9b88-55eff2caaffe at term 1 for appendEntries, leader elected after 5264ms
2023-03-15 02:22:17,807 [646e529a-a01f-4b15-a31a-2706cdf8d47d-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-B57DF5C92125 with new leaderId: b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:17,807 [646e529a-a01f-4b15-a31a-2706cdf8d47d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: change Leader from null to b83605a3-0dba-4f7c-9b88-55eff2caaffe at term 1 for appendEntries, leader elected after 5308ms
2023-03-15 02:22:17,809 [646e529a-a01f-4b15-a31a-2706cdf8d47d-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: set configuration 0: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,810 [646e529a-a01f-4b15-a31a-2706cdf8d47d-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:17,810 [ed5356af-2dee-4266-b55e-559e8c0d6889-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125: set configuration 0: peers:[ed5356af-2dee-4266-b55e-559e8c0d6889|rpc:10.1.0.23:46587|dataStream:10.1.0.23:45375|priority:0|startupRole:FOLLOWER, 646e529a-a01f-4b15-a31a-2706cdf8d47d|rpc:10.1.0.23:38099|dataStream:10.1.0.23:36605|priority:0|startupRole:FOLLOWER, b83605a3-0dba-4f7c-9b88-55eff2caaffe|rpc:10.1.0.23:46445|dataStream:10.1.0.23:42333|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:17,810 [ed5356af-2dee-4266-b55e-559e8c0d6889-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:17,813 [ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - ed5356af-2dee-4266-b55e-559e8c0d6889@group-B57DF5C92125-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-0/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125/current/log_inprogress_0
2023-03-15 02:22:17,814 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125/current/log_inprogress_0
2023-03-15 02:22:17,863 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:17,864 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:17,872 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:17,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-15 02:22:18,025 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5110714006ns, electionTimeout:5106ms
2023-03-15 02:22:18,026 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: shutdown 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState
2023-03-15 02:22:18,026 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:18,026 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:18,026 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: start 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98
2023-03-15 02:22:18,026 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:18,027 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98 PRE_VOTE round 0: result PASSED (term=0)
2023-03-15 02:22:18,028 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98 ELECTION round 0: submit vote requests at term 1 for -1: peers:[42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:18,028 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98 ELECTION round 0: result PASSED (term=1)
2023-03-15 02:22:18,028 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: shutdown 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98
2023-03-15 02:22:18,028 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:18,028 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-3E24F2997DE1 with new leaderId: 42380981-9e90-41f5-811d-3bbbf08d47d9
2023-03-15 02:22:18,028 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1: change Leader from null to 42380981-9e90-41f5-811d-3bbbf08d47d9 at term 1 for becomeLeader, leader elected after 5131ms
2023-03-15 02:22:18,028 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:18,029 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:18,029 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:18,029 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:18,029 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:18,029 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:18,029 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:18,029 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:18,030 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 42380981-9e90-41f5-811d-3bbbf08d47d9: start 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderStateImpl
2023-03-15 02:22:18,030 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:18,031 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-LeaderElection98] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1: set configuration 0: peers:[42380981-9e90-41f5-811d-3bbbf08d47d9|rpc:10.1.0.23:40377|dataStream:10.1.0.23:35043|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:18,032 [42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 42380981-9e90-41f5-811d-3bbbf08d47d9@group-3E24F2997DE1-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-1/data/ratis/6e97b4b9-43b0-4c2a-bb40-3e24f2997de1/current/log_inprogress_0
2023-03-15 02:22:18,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:18,302 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:18,315 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:18,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:18,618 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5181677439ns, electionTimeout:5181ms
2023-03-15 02:22:18,619 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: shutdown c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState
2023-03-15 02:22:18,619 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:18,619 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:18,619 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: start c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99
2023-03-15 02:22:18,619 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:18,619 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99 PRE_VOTE round 0: result PASSED (term=0)
2023-03-15 02:22:18,621 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:18,621 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99 ELECTION round 0: result PASSED (term=1)
2023-03-15 02:22:18,621 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: shutdown c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99
2023-03-15 02:22:18,621 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:18,621 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-9F23A9FF9CAC with new leaderId: c86f293d-b980-46b7-b4bb-ca602f6dc485
2023-03-15 02:22:18,622 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC: change Leader from null to c86f293d-b980-46b7-b4bb-ca602f6dc485 at term 1 for becomeLeader, leader elected after 5206ms
2023-03-15 02:22:18,622 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:18,622 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:18,622 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:18,622 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:18,622 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:18,623 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:18,623 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:18,623 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:18,623 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c86f293d-b980-46b7-b4bb-ca602f6dc485: start c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderStateImpl
2023-03-15 02:22:18,623 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:18,623 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-LeaderElection99] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC: set configuration 0: peers:[c86f293d-b980-46b7-b4bb-ca602f6dc485|rpc:10.1.0.23:38675|dataStream:10.1.0.23:33749|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:18,624 [c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - c86f293d-b980-46b7-b4bb-ca602f6dc485@group-9F23A9FF9CAC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-2/data/ratis/3157bed6-4585-40be-9dc3-9f23a9ff9cac/current/log_inprogress_0
2023-03-15 02:22:18,863 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:18,864 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:18,872 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:18,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:19,242 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5050647618ns, electionTimeout:5050ms
2023-03-15 02:22:19,242 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: shutdown 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState
2023-03-15 02:22:19,242 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:19,242 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:19,242 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: start 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100
2023-03-15 02:22:19,243 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,243 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100 PRE_VOTE round 0: result PASSED (term=0)
2023-03-15 02:22:19,244 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100 ELECTION round 0: submit vote requests at term 1 for -1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,244 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100 ELECTION round 0: result PASSED (term=1)
2023-03-15 02:22:19,245 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: shutdown 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100
2023-03-15 02:22:19,245 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:19,245 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-784429324467 with new leaderId: 71dc2d0c-c132-482e-adc3-0da69386d6d8
2023-03-15 02:22:19,245 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467: change Leader from null to 71dc2d0c-c132-482e-adc3-0da69386d6d8 at term 1 for becomeLeader, leader elected after 5069ms
2023-03-15 02:22:19,245 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:19,245 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:19,245 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:19,246 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:19,246 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:19,246 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:19,246 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:19,246 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:19,246 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: start 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderStateImpl
2023-03-15 02:22:19,247 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:19,247 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-LeaderElection100] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467: set configuration 0: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,248 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-784429324467-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/e176a732-6e44-41d1-a762-784429324467/current/log_inprogress_0
2023-03-15 02:22:19,296 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5084552455ns, electionTimeout:5084ms
2023-03-15 02:22:19,296 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: shutdown 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState
2023-03-15 02:22:19,296 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:19,296 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:19,296 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: start 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101
2023-03-15 02:22:19,297 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:19,302 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:19,305 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:19,310 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:19,310 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:19,310 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 6b109e20-fb43-4126-a2d0-e01a40c07237
2023-03-15 02:22:19,315 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:19,318 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:19,319 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E: receive requestVote(PRE_VOTE, 71dc2d0c-c132-482e-adc3-0da69386d6d8, group-6685DB77740E, 0, (t:0, i:0))
2023-03-15 02:22:19,319 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FOLLOWER: reject PRE_VOTE from 71dc2d0c-c132-482e-adc3-0da69386d6d8: our priority 1 > candidate's priority 0
2023-03-15 02:22:19,319 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E replies to PRE_VOTE vote request: 71dc2d0c-c132-482e-adc3-0da69386d6d8<-1847c06b-5456-44fe-a2e2-332407f19896#0:FAIL-t0. Peer's state: 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E:t0, leader=null, voted=, raftlog=Memoized:1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,320 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E: receive requestVote(PRE_VOTE, 71dc2d0c-c132-482e-adc3-0da69386d6d8, group-6685DB77740E, 0, (t:0, i:0))
2023-03-15 02:22:19,320 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2023-03-15 02:22:19,320 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FOLLOWER: accept PRE_VOTE from 71dc2d0c-c132-482e-adc3-0da69386d6d8: our priority 0 <= candidate's priority 0
2023-03-15 02:22:19,320 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 71dc2d0c-c132-482e-adc3-0da69386d6d8<-1847c06b-5456-44fe-a2e2-332407f19896#0:FAIL-t0
2023-03-15 02:22:19,320 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E replies to PRE_VOTE vote request: 71dc2d0c-c132-482e-adc3-0da69386d6d8<-6b109e20-fb43-4126-a2d0-e01a40c07237#0:OK-t0. Peer's state: 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E:t0, leader=null, voted=, raftlog=Memoized:6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,320 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101 PRE_VOTE round 0: result REJECTED
2023-03-15 02:22:19,321 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2023-03-15 02:22:19,321 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: shutdown 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101
2023-03-15 02:22:19,321 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-LeaderElection101] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: start 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState
2023-03-15 02:22:19,321 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:19,321 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:19,345 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:19,345 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:19,418 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5173530582ns, electionTimeout:5172ms
2023-03-15 02:22:19,418 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1847c06b-5456-44fe-a2e2-332407f19896: shutdown 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState
2023-03-15 02:22:19,418 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:19,418 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:19,418 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1847c06b-5456-44fe-a2e2-332407f19896: start 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102
2023-03-15 02:22:19,419 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,421 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 71dc2d0c-c132-482e-adc3-0da69386d6d8
2023-03-15 02:22:19,422 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 6b109e20-fb43-4126-a2d0-e01a40c07237
2023-03-15 02:22:19,422 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:19,423 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:19,435 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: receive requestVote(PRE_VOTE, 1847c06b-5456-44fe-a2e2-332407f19896, group-6685DB77740E, 0, (t:0, i:0))
2023-03-15 02:22:19,435 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FOLLOWER: accept PRE_VOTE from 1847c06b-5456-44fe-a2e2-332407f19896: our priority 0 <= candidate's priority 1
2023-03-15 02:22:19,435 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E replies to PRE_VOTE vote request: 1847c06b-5456-44fe-a2e2-332407f19896<-71dc2d0c-c132-482e-adc3-0da69386d6d8#0:OK-t0. Peer's state: 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E:t0, leader=null, voted=, raftlog=Memoized:71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,436 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2023-03-15 02:22:19,436 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 1847c06b-5456-44fe-a2e2-332407f19896<-71dc2d0c-c132-482e-adc3-0da69386d6d8#0:OK-t0
2023-03-15 02:22:19,436 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102 PRE_VOTE round 0: result PASSED
2023-03-15 02:22:19,437 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E: receive requestVote(PRE_VOTE, 1847c06b-5456-44fe-a2e2-332407f19896, group-6685DB77740E, 0, (t:0, i:0))
2023-03-15 02:22:19,438 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FOLLOWER: accept PRE_VOTE from 1847c06b-5456-44fe-a2e2-332407f19896: our priority 0 <= candidate's priority 1
2023-03-15 02:22:19,438 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E replies to PRE_VOTE vote request: 1847c06b-5456-44fe-a2e2-332407f19896<-6b109e20-fb43-4126-a2d0-e01a40c07237#0:OK-t0. Peer's state: 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E:t0, leader=null, voted=, raftlog=Memoized:6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,438 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102 ELECTION round 0: submit vote requests at term 1 for -1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,439 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: receive requestVote(ELECTION, 1847c06b-5456-44fe-a2e2-332407f19896, group-6685DB77740E, 1, (t:0, i:0))
2023-03-15 02:22:19,439 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FOLLOWER: accept ELECTION from 1847c06b-5456-44fe-a2e2-332407f19896: our priority 0 <= candidate's priority 1
2023-03-15 02:22:19,439 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:19,439 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: shutdown 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState
2023-03-15 02:22:19,447 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:19,447 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:19,448 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E: receive requestVote(ELECTION, 1847c06b-5456-44fe-a2e2-332407f19896, group-6685DB77740E, 1, (t:0, i:0))
2023-03-15 02:22:19,448 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FOLLOWER: accept ELECTION from 1847c06b-5456-44fe-a2e2-332407f19896: our priority 0 <= candidate's priority 1
2023-03-15 02:22:19,448 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:19,448 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8: start 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState
2023-03-15 02:22:19,448 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState was interrupted
2023-03-15 02:22:19,448 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: shutdown 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState
2023-03-15 02:22:19,448 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: start 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState
2023-03-15 02:22:19,448 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState was interrupted
2023-03-15 02:22:19,449 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:19,449 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:19,452 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-03-15 02:22:19,452 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E replies to ELECTION vote request: 1847c06b-5456-44fe-a2e2-332407f19896<-71dc2d0c-c132-482e-adc3-0da69386d6d8#0:OK-t1. Peer's state: 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E:t1, leader=null, voted=1847c06b-5456-44fe-a2e2-332407f19896, raftlog=Memoized:71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,453 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-03-15 02:22:19,453 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E replies to ELECTION vote request: 1847c06b-5456-44fe-a2e2-332407f19896<-6b109e20-fb43-4126-a2d0-e01a40c07237#0:OK-t1. Peer's state: 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E:t1, leader=null, voted=1847c06b-5456-44fe-a2e2-332407f19896, raftlog=Memoized:6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,453 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-03-15 02:22:19,453 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 1847c06b-5456-44fe-a2e2-332407f19896<-71dc2d0c-c132-482e-adc3-0da69386d6d8#0:OK-t1
2023-03-15 02:22:19,453 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102 ELECTION round 0: result PASSED
2023-03-15 02:22:19,453 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 1847c06b-5456-44fe-a2e2-332407f19896: shutdown 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102
2023-03-15 02:22:19,453 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:19,453 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-6685DB77740E with new leaderId: 1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:19,454 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E: change Leader from null to 1847c06b-5456-44fe-a2e2-332407f19896 at term 1 for becomeLeader, leader elected after 5232ms
2023-03-15 02:22:19,454 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:19,454 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:19,454 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:19,454 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:19,454 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:19,454 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:19,454 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:19,454 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:19,454 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 7afa3418-6f18-4a5c-9380-6685db77740e, Nodes: 1847c06b-5456-44fe-a2e2-332407f19896(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)6b109e20-fb43-4126-a2d0-e01a40c07237(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)71dc2d0c-c132-482e-adc3-0da69386d6d8(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:1847c06b-5456-44fe-a2e2-332407f19896, CreationTimestamp2023-03-15T02:22:12.367Z[Etc/UTC]] moved to OPEN state
2023-03-15 02:22:19,455 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-15 02:22:19,455 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:19,455 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-15 02:22:19,456 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-15 02:22:19,456 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:19,456 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:19,456 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:19,456 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-15 02:22:19,459 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-03-15 02:22:19,459 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-03-15 02:22:19,459 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-03-15 02:22:19,459 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-03-15 02:22:19,460 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-03-15 02:22:19,460 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-03-15 02:22:19,460 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-03-15 02:22:19,460 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-03-15 02:22:19,460 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1847c06b-5456-44fe-a2e2-332407f19896: start 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderStateImpl
2023-03-15 02:22:19,461 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:19,462 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e/current/log_inprogress_0
2023-03-15 02:22:19,476 [1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E-LeaderElection102] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-6685DB77740E: set configuration 0: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,480 [71dc2d0c-c132-482e-adc3-0da69386d6d8-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-6685DB77740E with new leaderId: 1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:19,480 [71dc2d0c-c132-482e-adc3-0da69386d6d8-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: change Leader from null to 1847c06b-5456-44fe-a2e2-332407f19896 at term 1 for appendEntries, leader elected after 5285ms
2023-03-15 02:22:19,485 [6b109e20-fb43-4126-a2d0-e01a40c07237-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-6685DB77740E with new leaderId: 1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:19,485 [6b109e20-fb43-4126-a2d0-e01a40c07237-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E: change Leader from null to 1847c06b-5456-44fe-a2e2-332407f19896 at term 1 for appendEntries, leader elected after 5224ms
2023-03-15 02:22:19,485 [71dc2d0c-c132-482e-adc3-0da69386d6d8-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E: set configuration 0: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,485 [71dc2d0c-c132-482e-adc3-0da69386d6d8-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:19,490 [71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 71dc2d0c-c132-482e-adc3-0da69386d6d8@group-6685DB77740E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-3/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e/current/log_inprogress_0
2023-03-15 02:22:19,495 [6b109e20-fb43-4126-a2d0-e01a40c07237-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E: set configuration 0: peers:[71dc2d0c-c132-482e-adc3-0da69386d6d8|rpc:10.1.0.23:33845|dataStream:10.1.0.23:36025|priority:0|startupRole:FOLLOWER, 1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER, 6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,496 [6b109e20-fb43-4126-a2d0-e01a40c07237-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:19,497 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-6685DB77740E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/7afa3418-6f18-4a5c-9380-6685db77740e/current/log_inprogress_0
2023-03-15 02:22:19,863 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:19,864 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-03-15 02:22:19,873 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:19,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:19,937 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5112678354ns, electionTimeout:5106ms
2023-03-15 02:22:19,938 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: shutdown 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState
2023-03-15 02:22:19,938 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:19,938 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:19,938 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: start 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103
2023-03-15 02:22:19,939 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,939 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103 PRE_VOTE round 0: result PASSED (term=0)
2023-03-15 02:22:19,940 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103 ELECTION round 0: submit vote requests at term 1 for -1: peers:[6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,941 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103 ELECTION round 0: result PASSED (term=1)
2023-03-15 02:22:19,941 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: shutdown 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103
2023-03-15 02:22:19,941 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:19,941 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-E8089850D28E with new leaderId: 6b109e20-fb43-4126-a2d0-e01a40c07237
2023-03-15 02:22:19,941 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E: change Leader from null to 6b109e20-fb43-4126-a2d0-e01a40c07237 at term 1 for becomeLeader, leader elected after 5135ms
2023-03-15 02:22:19,941 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:19,941 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:19,941 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:19,942 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:19,942 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:19,942 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:19,942 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:19,942 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:19,942 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6b109e20-fb43-4126-a2d0-e01a40c07237: start 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderStateImpl
2023-03-15 02:22:19,943 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:19,943 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-LeaderElection103] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E: set configuration 0: peers:[6b109e20-fb43-4126-a2d0-e01a40c07237|rpc:10.1.0.23:44885|dataStream:10.1.0.23:34799|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:19,944 [6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 6b109e20-fb43-4126-a2d0-e01a40c07237@group-E8089850D28E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-4/data/ratis/e820d2a7-e73f-462b-b858-e8089850d28e/current/log_inprogress_0
2023-03-15 02:22:20,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:20,302 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:20,315 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:20,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:20,455 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5077510606ns, electionTimeout:5076ms
2023-03-15 02:22:20,455 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1847c06b-5456-44fe-a2e2-332407f19896: shutdown 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState
2023-03-15 02:22:20,455 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:20,455 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:20,455 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1847c06b-5456-44fe-a2e2-332407f19896: start 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104
2023-03-15 02:22:20,456 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:20,456 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104 PRE_VOTE round 0: result PASSED (term=0)
2023-03-15 02:22:20,462 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104 ELECTION round 0: submit vote requests at term 1 for -1: peers:[1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:20,462 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104 ELECTION round 0: result PASSED (term=1)
2023-03-15 02:22:20,462 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 1847c06b-5456-44fe-a2e2-332407f19896: shutdown 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104
2023-03-15 02:22:20,462 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:20,462 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-4773A172C6FD with new leaderId: 1847c06b-5456-44fe-a2e2-332407f19896
2023-03-15 02:22:20,462 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD: change Leader from null to 1847c06b-5456-44fe-a2e2-332407f19896 at term 1 for becomeLeader, leader elected after 5100ms
2023-03-15 02:22:20,462 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:20,463 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:20,463 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:20,464 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:20,464 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:20,464 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:20,464 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:20,464 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:20,464 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1847c06b-5456-44fe-a2e2-332407f19896: start 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderStateImpl
2023-03-15 02:22:20,464 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:20,465 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-LeaderElection104] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD: set configuration 0: peers:[1847c06b-5456-44fe-a2e2-332407f19896|rpc:10.1.0.23:43143|dataStream:10.1.0.23:41099|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:20,466 [1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 1847c06b-5456-44fe-a2e2-332407f19896@group-4773A172C6FD-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-5/data/ratis/e8e306ef-b9aa-42ad-aa76-4773a172c6fd/current/log_inprogress_0
2023-03-15 02:22:20,710 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 13b63f14-21ce-4492-9d02-d9a6b9e153c6(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:20,710 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/13b63f14-21ce-4492-9d02-d9a6b9e153c6
2023-03-15 02:22:20,771 [Listener at 0.0.0.0/37571] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(351)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-03-15 02:22:20,771 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1532)) - Container Balancer is not running.
2023-03-15 02:22:20,771 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1539)) - Stopping Replication Manager Service.
2023-03-15 02:22:20,771 [Listener at 0.0.0.0/37571] INFO  replication.ReplicationManager (ReplicationManager.java:stop(304)) - Stopping Replication Monitor Thread.
2023-03-15 02:22:20,771 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1546)) - Stopping the Datanode Admin Monitor.
2023-03-15 02:22:20,771 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(153)) - Over Replicated Processor interrupted. Exiting...
2023-03-15 02:22:20,771 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1553)) - Stopping datanode service RPC server
2023-03-15 02:22:20,772 [Listener at 0.0.0.0/37571] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-03-15 02:22:20,771 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(153)) - Under Replicated Processor interrupted. Exiting...
2023-03-15 02:22:20,772 [Listener at 0.0.0.0/37571] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 41473
2023-03-15 02:22:20,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(799)) - Replication Monitor Thread is stopped
2023-03-15 02:22:20,782 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:20,782 [IPC Server listener on 41473] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 41473
2023-03-15 02:22:20,795 [EndpointStateMachine task thread for /0.0.0.0:41473 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:41473 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az260-852/10.1.0.23"; destination host is: "0.0.0.0":41473; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy56.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-03-15 02:22:20,795 [EndpointStateMachine task thread for /0.0.0.0:41473 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:41473 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az260-852/10.1.0.23"; destination host is: "0.0.0.0":41473; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy56.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-03-15 02:22:20,810 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-03-15 02:22:20,810 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1561)) - Stopping block service RPC server
2023-03-15 02:22:20,810 [Listener at 0.0.0.0/37571] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-03-15 02:22:20,810 [Listener at 0.0.0.0/37571] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 33991
2023-03-15 02:22:20,811 [IPC Server listener on 33991] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 33991
2023-03-15 02:22:20,816 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:20,816 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1568)) - Stopping the StorageContainerLocationProtocol RPC server
2023-03-15 02:22:20,817 [Listener at 0.0.0.0/37571] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(203)) - Stopping the RPC server for Client Protocol
2023-03-15 02:22:20,817 [Listener at 0.0.0.0/37571] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 37571
2023-03-15 02:22:20,821 [IPC Server listener on 37571] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 37571
2023-03-15 02:22:20,821 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:20,830 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1575)) - Stopping Storage Container Manager HTTP server.
2023-03-15 02:22:20,831 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@438a65a7{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-15 02:22:20,831 [Listener at 0.0.0.0/37571] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5b4880b3{HTTP/1.1, (http/1.1)}{0.0.0.0:33917}
2023-03-15 02:22:20,832 [Listener at 0.0.0.0/37571] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:20,832 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3a6409ec{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-15 02:22:20,832 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@77604a86{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:20,833 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1583)) - Stopping SCM LayoutVersionManager Service.
2023-03-15 02:22:20,833 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1591)) - Stopping Block Manager Service.
2023-03-15 02:22:20,833 [Listener at 0.0.0.0/37571] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-15 02:22:20,834 [Listener at 0.0.0.0/37571] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-15 02:22:20,834 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1613)) - Stopping SCM Event Queue.
2023-03-15 02:22:20,845 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1624)) - Stopping SCM HA services.
2023-03-15 02:22:20,845 [Listener at 0.0.0.0/37571] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-03-15 02:22:20,845 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-03-15 02:22:20,846 [Listener at 0.0.0.0/37571] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-03-15 02:22:20,846 [Listener at 0.0.0.0/37571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - StorageContainerManager metrics system stopped (again)
2023-03-15 02:22:20,846 [Listener at 0.0.0.0/37571] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-03-15 02:22:20,846 [Listener at 0.0.0.0/37571] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-03-15 02:22:20,846 [Listener at 0.0.0.0/37571] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-03-15 02:22:20,846 [Listener at 0.0.0.0/37571] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-03-15 02:22:20,846 [Listener at 0.0.0.0/37571] INFO  replication.ReplicationManager (ReplicationManager.java:stop(314)) - Replication Monitor Thread is not running.
2023-03-15 02:22:20,847 [Listener at 0.0.0.0/37571] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-03-15 02:22:20,847 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1642)) - Stopping SCM MetadataStore.
2023-03-15 02:22:20,847 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-03-15 02:22:20,847 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-03-15 02:22:20,850 [Listener at 0.0.0.0/37571] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:20,850 [Listener at 0.0.0.0/37571] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-03-15 02:22:20,850 [Listener at 0.0.0.0/37571] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-03-15 02:22:20,851 [Listener at 0.0.0.0/37571] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:20,851 [Listener at 0.0.0.0/37571] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-03-15 02:22:20,887 [Listener at 0.0.0.0/37571] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-03-15 02:22:20,887 [Listener at 0.0.0.0/37571] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-03-15 02:22:20,891 [Listener at 0.0.0.0/37571] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-03-15 02:22:20,950 [Listener at 0.0.0.0/37571] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 58 ms to scan 7 urls, producing 155 keys and 368 values 
2023-03-15 02:22:20,951 [Listener at 0.0.0.0/37571] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-03-15 02:22:20,955 [Listener at 0.0.0.0/37571] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(156)) - Entering startup safe mode.
2023-03-15 02:22:20,956 [Listener at 0.0.0.0/37571] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-03-15 02:22:20,956 [Listener at 0.0.0.0/37571] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-15 02:22:20,957 [Listener at 0.0.0.0/37571] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-03-15 02:22:20,957 [Listener at 0.0.0.0/37571] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-03-15 02:22:20,958 [Listener at 0.0.0.0/37571] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-03-15 02:22:20,958 [Listener at 0.0.0.0/37571] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-03-15 02:22:20,958 [Listener at 0.0.0.0/37571] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-03-15 02:22:20,958 [Listener at 0.0.0.0/37571] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-03-15 02:22:20,959 [Listener at 0.0.0.0/37571] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-03-15 02:22:20,959 [Listener at 0.0.0.0/37571] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-03-15 02:22:20,962 [Listener at 0.0.0.0/37571] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-03-15 02:22:20,963 [Listener at 0.0.0.0/37571] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-03-15 02:22:20,963 [Listener at 0.0.0.0/37571] INFO  replication.ReplicationManager (ReplicationManager.java:start(271)) - Starting Replication Monitor Thread.
2023-03-15 02:22:20,964 [Listener at 0.0.0.0/37571] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-03-15 02:22:20,964 [Listener at 0.0.0.0/37571] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-03-15 02:22:20,964 [Listener at 0.0.0.0/37571] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 2, healthy pipeline threshold count is 1
2023-03-15 02:22:20,964 [Listener at 0.0.0.0/37571] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2023-03-15 02:22:20,966 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(392)) - SCM start with adminUsers: [runner]
2023-03-15 02:22:20,966 [Listener at 0.0.0.0/37571] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:20,967 [Socket Reader #1 for port 41473] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 41473
2023-03-15 02:22:20,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:20,972 [Listener at 0.0.0.0/41473] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:20,973 [Listener at 0.0.0.0/33991] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-03-15 02:22:20,974 [Socket Reader #1 for port 37571] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 37571
2023-03-15 02:22:20,974 [Socket Reader #1 for port 33991] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 33991
2023-03-15 02:22:20,976 [Listener at 0.0.0.0/37571] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-03-15 02:22:20,976 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(407)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-03-15 02:22:20,977 [Listener at 0.0.0.0/37571] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-03-15 02:22:20,977 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1437)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:37571
2023-03-15 02:22:20,978 [Listener at 0.0.0.0/37571] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-03-15 02:22:20,992 [Listener at 0.0.0.0/37571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-03-15 02:22:20,993 [Listener at 0.0.0.0/37571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-03-15 02:22:20,995 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5174296887ns, electionTimeout:5173ms
2023-03-15 02:22:20,996 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - bb24641f-ac05-4a48-a34b-331e584b8427: shutdown bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState
2023-03-15 02:22:20,996 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-03-15 02:22:20,996 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-03-15 02:22:20,996 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bb24641f-ac05-4a48-a34b-331e584b8427: start bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105
2023-03-15 02:22:21,004 [Listener at 0.0.0.0/37571] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-03-15 02:22:21,005 [Listener at 0.0.0.0/37571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-03-15 02:22:21,005 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[bb24641f-ac05-4a48-a34b-331e584b8427|rpc:10.1.0.23:33913|dataStream:10.1.0.23:39219|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:21,005 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105 PRE_VOTE round 0: result PASSED (term=0)
2023-03-15 02:22:21,008 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105 ELECTION round 0: submit vote requests at term 1 for -1: peers:[bb24641f-ac05-4a48-a34b-331e584b8427|rpc:10.1.0.23:33913|dataStream:10.1.0.23:39219|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:21,008 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105 ELECTION round 0: result PASSED (term=1)
2023-03-15 02:22:21,008 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - bb24641f-ac05-4a48-a34b-331e584b8427: shutdown bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105
2023-03-15 02:22:21,008 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-03-15 02:22:21,008 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-946CCAF7CD0A with new leaderId: bb24641f-ac05-4a48-a34b-331e584b8427
2023-03-15 02:22:21,008 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A: change Leader from null to bb24641f-ac05-4a48-a34b-331e584b8427 at term 1 for becomeLeader, leader elected after 5203ms
2023-03-15 02:22:21,008 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-03-15 02:22:21,009 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:21,009 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-03-15 02:22:21,011 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-03-15 02:22:21,011 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-03-15 02:22:21,011 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-03-15 02:22:21,011 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-03-15 02:22:21,011 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-03-15 02:22:21,011 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bb24641f-ac05-4a48-a34b-331e584b8427: start bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderStateImpl
2023-03-15 02:22:21,013 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-SegmentedRaftLogWorker: Starting segment from index:0
2023-03-15 02:22:21,015 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d45f4060-1b89-4550-a4d1-dcd9394607ae/datanode-6/data/ratis/ade2cb9d-27c1-4d81-af81-946ccaf7cd0a/current/log_inprogress_0
2023-03-15 02:22:21,020 [bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A-LeaderElection105] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - bb24641f-ac05-4a48-a34b-331e584b8427@group-946CCAF7CD0A: set configuration 0: peers:[bb24641f-ac05-4a48-a34b-331e584b8427|rpc:10.1.0.23:33913|dataStream:10.1.0.23:39219|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-03-15 02:22:21,039 [Listener at 0.0.0.0/37571] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(194)) - RPC server for Client  is listening at /0.0.0.0:37571
2023-03-15 02:22:21,039 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:21,041 [IPC Server listener on 37571] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 37571: starting
2023-03-15 02:22:21,068 [Listener at 0.0.0.0/37571] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1451)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:33991
2023-03-15 02:22:21,068 [Listener at 0.0.0.0/37571] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:33991
2023-03-15 02:22:21,069 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:21,069 [IPC Server listener on 33991] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 33991: starting
2023-03-15 02:22:21,076 [Listener at 0.0.0.0/37571] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:41473
2023-03-15 02:22:21,077 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-03-15 02:22:21,085 [IPC Server listener on 41473] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 41473: starting
2023-03-15 02:22:21,093 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@55b78dad] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-03-15 02:22:21,094 [Listener at 0.0.0.0/37571] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:33917
2023-03-15 02:22:21,094 [Listener at 0.0.0.0/37571] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-03-15 02:22:21,095 [Listener at 0.0.0.0/37571] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-03-15 02:22:21,096 [Listener at 0.0.0.0/37571] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-03-15 02:22:21,097 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-03-15 02:22:21,098 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-03-15 02:22:21,098 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-15 02:22:21,098 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-15 02:22:21,099 [Listener at 0.0.0.0/37571] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/ozone-meta/webserver
2023-03-15 02:22:21,099 [Listener at 0.0.0.0/37571] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 33917
2023-03-15 02:22:21,100 [Listener at 0.0.0.0/37571] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-03-15 02:22:21,101 [Listener at 0.0.0.0/37571] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-03-15 02:22:21,102 [Listener at 0.0.0.0/37571] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-03-15 02:22:21,102 [Listener at 0.0.0.0/37571] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-03-15 02:22:21,102 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7bc3c59f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-03-15 02:22:21,103 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1454339d{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-03-15 02:22:21,105 [Listener at 0.0.0.0/37571] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3ec6f3f1{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-03-15 02:22:21,110 [Listener at 0.0.0.0/37571] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6e70861{HTTP/1.1, (http/1.1)}{0.0.0.0:33917}
2023-03-15 02:22:21,110 [Listener at 0.0.0.0/37571] INFO  server.Server (Server.java:doStart(415)) - Started @195987ms
2023-03-15 02:22:21,110 [Listener at 0.0.0.0/37571] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-03-15 02:22:21,111 [Listener at 0.0.0.0/37571] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:33917
2023-03-15 02:22:21,221 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:21,247 [IPC Server handler 1 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 132d3d80-0103-4f41-b942-b9d80c35d5a5(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:21,255 [IPC Server handler 2 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 5650ff5c-2f39-425b-bee4-adddfcfb793b(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:21,296 [IPC Server handler 3 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 00dcba52-510b-4641-a1c5-22cfbaaa7f01(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:21,301 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:21,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:21,303 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:21,315 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:21,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-03-15 02:22:21,762 [IPC Server handler 4 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode 646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:21,795 [IPC Server handler 5 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:21,796 [IPC Server handler 6 on default port 41473] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(106)) - SCM received heartbeat from an unregistered datanode b83605a3-0dba-4f7c-9b88-55eff2caaffe(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23). Asking datanode to re-register.
2023-03-15 02:22:21,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:22,222 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:22,233 [IPC Server handler 1 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/132d3d80-0103-4f41-b942-b9d80c35d5a5
2023-03-15 02:22:22,234 [IPC Server handler 1 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 132d3d80-0103-4f41-b942-b9d80c35d5a5{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=40211, RATIS=46755, RATIS_ADMIN=46755, RATIS_SERVER=46755, RATIS_DATASTREAM=43593, STANDALONE=39053], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:22,243 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-15 02:22:22,243 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-03-15 02:22:22,244 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-03-15 02:22:22,251 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:22,258 [IPC Server handler 2 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/5650ff5c-2f39-425b-bee4-adddfcfb793b
2023-03-15 02:22:22,258 [IPC Server handler 2 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 5650ff5c-2f39-425b-bee4-adddfcfb793b{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=36691, RATIS=33051, RATIS_ADMIN=33051, RATIS_SERVER=33051, RATIS_DATASTREAM=43637, STANDALONE=36993], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:22,258 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:22,261 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-03-15 02:22:22,261 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-15 02:22:22,261 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-03-15 02:22:22,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:22,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-03-15 02:22:22,296 [IPC Server handler 3 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/00dcba52-510b-4641-a1c5-22cfbaaa7f01
2023-03-15 02:22:22,296 [IPC Server handler 3 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 00dcba52-510b-4641-a1c5-22cfbaaa7f01{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=33971, RATIS=42113, RATIS_ADMIN=42113, RATIS_SERVER=42113, RATIS_DATASTREAM=41049, STANDALONE=36357], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:22,296 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:22,300 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-03-15 02:22:22,300 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-03-15 02:22:22,300 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-03-15 02:22:22,300 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-03-15 02:22:22,300 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-03-15 02:22:22,301 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:22,303 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:22,300 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-03-15 02:22:22,303 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:22,303 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-03-15 02:22:22,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:22,306 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-03-15 02:22:22,315 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:22,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:22,762 [IPC Server handler 4 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/646e529a-a01f-4b15-a31a-2706cdf8d47d
2023-03-15 02:22:22,762 [IPC Server handler 4 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : 646e529a-a01f-4b15-a31a-2706cdf8d47d{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=34565, RATIS=38099, RATIS_ADMIN=38099, RATIS_SERVER=38099, RATIS_DATASTREAM=36605, STANDALONE=43083], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:22,766 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-03-15 02:22:22,766 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-03-15 02:22:22,766 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 2
2023-03-15 02:22:22,766 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-03-15 02:22:22,766 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-15 02:22:22,766 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-15 02:22:22,766 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-15 02:22:22,767 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-03-15 02:22:22,767 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-03-15 02:22:22,767 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-03-15 02:22:22,767 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1156)) - Service ReplicationManager transitions to RUNNING.
2023-03-15 02:22:22,767 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-15 02:22:22,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-15 02:22:22,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-15 02:22:22,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=false, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-15 02:22:22,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-15 02:22:22,767 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-03-15 02:22:22,767 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-03-15 02:22:22,767 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=false, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-03-15 02:22:22,767 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-03-15 02:22:22,768 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:22,796 [IPC Server handler 5 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ed5356af-2dee-4266-b55e-559e8c0d6889
2023-03-15 02:22:22,796 [IPC Server handler 5 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : ed5356af-2dee-4266-b55e-559e8c0d6889{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=46635, RATIS=46587, RATIS_ADMIN=46587, RATIS_SERVER=46587, RATIS_DATASTREAM=45375, STANDALONE=46781], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:22,807 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:22,808 [IPC Server handler 7 on default port 41473] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/b83605a3-0dba-4f7c-9b88-55eff2caaffe
2023-03-15 02:22:22,809 [IPC Server handler 7 on default port 41473] INFO  node.SCMNodeManager (SCMNodeManager.java:register(404)) - Registered Data node : b83605a3-0dba-4f7c-9b88-55eff2caaffe{ip: 10.1.0.23, host: fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net, ports: [REPLICATION=37347, RATIS=46445, RATIS_ADMIN=46445, RATIS_SERVER=46445, RATIS_DATASTREAM=42333, STANDALONE=44263], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-03-15 02:22:22,809 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-03-15 02:22:22,810 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-03-15 02:22:22,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:23,222 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:23,301 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:23,303 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:23,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:23,316 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:23,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:23,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:24,222 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:24,301 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:24,303 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:24,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:24,316 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:24,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:24,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(346)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-03-15 02:22:25,222 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:25,302 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:25,304 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:25,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:25,316 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:25,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:25,969 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:25,971 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:25,973 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-03-15 02:22:25,973 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL to 132d3d80-0103-4f41-b942-b9d80c35d5a5(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:25,973 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2023-03-15 02:22:25,973 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId: 3, replicaIndex: 0, sourceNodes: [646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL to 132d3d80-0103-4f41-b942-b9d80c35d5a5(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:25,973 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2199)) - Container #6 is under replicated. Expected replica count is 3, but found 2.
2023-03-15 02:22:25,973 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1454)) - Sending replicateContainerCommand: containerId: 6, replicaIndex: 0, sourceNodes: [646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL to b83605a3-0dba-4f7c-9b88-55eff2caaffe(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)
2023-03-15 02:22:25,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2023-03-15 02:22:26,223 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:26,302 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:26,304 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:26,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:26,316 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:26,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:26,969 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:26,971 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:26,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:27,223 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:27,302 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:27,304 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:27,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:27,316 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:27,323 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:27,809 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 6 from [646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)] using NO_COMPRESSION
2023-03-15 02:22:27,815 [grpc-default-executor-8] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(62)) - Streaming container data (6) to other datanode with compression NO_COMPRESSION
2023-03-15 02:22:27,844 [grpc-default-executor-8] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 11776 bytes for container 6
2023-03-15 02:22:27,845 [grpc-default-executor-8] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 11776 bytes for container 6
2023-03-15 02:22:27,845 [grpc-default-executor-6] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(218)) - Container 6 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-6/data-0/containers/tmp/container-copy/container-6.tar
2023-03-15 02:22:27,850 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 6 is downloaded with size 11776, starting to import.
2023-03-15 02:22:27,878 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 6 is replicated successfully
2023-03-15 02:22:27,878 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(218)) - Successful ReplicationTask{status=DONE, cmd={replicateContainerCommand: containerId: 6, replicaIndex: 0, sourceNodes: [646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL}, queued=2023-03-15T02:22:27.809Z}
2023-03-15 02:22:27,969 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:27,971 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:27,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:28,223 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:28,234 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 1 from [646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)] using NO_COMPRESSION
2023-03-15 02:22:28,236 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 3 from [646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)] using NO_COMPRESSION
2023-03-15 02:22:28,243 [grpc-default-executor-5] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(62)) - Streaming container data (3) to other datanode with compression NO_COMPRESSION
2023-03-15 02:22:28,244 [grpc-default-executor-8] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(62)) - Streaming container data (1) to other datanode with compression NO_COMPRESSION
2023-03-15 02:22:28,257 [grpc-default-executor-5] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 11776 bytes for container 3
2023-03-15 02:22:28,258 [grpc-default-executor-6] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(218)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-5/data-0/containers/tmp/container-copy/container-3.tar
2023-03-15 02:22:28,258 [grpc-default-executor-5] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 11776 bytes for container 3
2023-03-15 02:22:28,263 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 3 is downloaded with size 11776, starting to import.
2023-03-15 02:22:28,972 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:28,972 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:28,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:28,976 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:28,979 [JvmPauseMonitor51] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 361455179ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,980 [JvmPauseMonitor54] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-c86f293d-b980-46b7-b4bb-ca602f6dc485: Detected pause in JVM or host machine (eg GC): pause of approximately 464942821ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,980 [JvmPauseMonitor53] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-42380981-9e90-41f5-811d-3bbbf08d47d9: Detected pause in JVM or host machine (eg GC): pause of approximately 498380061ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,981 [JvmPauseMonitor57] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-1847c06b-5456-44fe-a2e2-332407f19896: Detected pause in JVM or host machine (eg GC): pause of approximately 562588522ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,981 [JvmPauseMonitor56] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-6b109e20-fb43-4126-a2d0-e01a40c07237: Detected pause in JVM or host machine (eg GC): pause of approximately 566006447ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,983 [JvmPauseMonitor58] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-bb24641f-ac05-4a48-a34b-331e584b8427: Detected pause in JVM or host machine (eg GC): pause of approximately 608722853ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,985 [JvmPauseMonitor39] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-132d3d80-0103-4f41-b942-b9d80c35d5a5: Detected pause in JVM or host machine (eg GC): pause of approximately 630931112ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,985 [JvmPauseMonitor48] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-9f4b8ec3-f353-4948-b4fc-413f1dfec88e: Detected pause in JVM or host machine (eg GC): pause of approximately 631174014ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,985 [JvmPauseMonitor42] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-9b1f5799-4694-44ac-95a8-dde5d0689021: Detected pause in JVM or host machine (eg GC): pause of approximately 631242614ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,985 [JvmPauseMonitor38] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-5650ff5c-2f39-425b-bee4-adddfcfb793b: Detected pause in JVM or host machine (eg GC): pause of approximately 653327573ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,986 [JvmPauseMonitor34] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-ed5356af-2dee-4266-b55e-559e8c0d6889: Detected pause in JVM or host machine (eg GC): pause of approximately 653410373ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,986 [JvmPauseMonitor45] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-6a4dbde0-2827-4051-b593-1eb8ab0ee225: Detected pause in JVM or host machine (eg GC): pause of approximately 653459574ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,986 [JvmPauseMonitor43] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-cdc3fd6e-e759-42d4-8e19-947196a05030: Detected pause in JVM or host machine (eg GC): pause of approximately 653957777ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:28,987 [JvmPauseMonitor33] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 667272373ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,987 [JvmPauseMonitor55] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-71dc2d0c-c132-482e-adc3-0da69386d6d8: Detected pause in JVM or host machine (eg GC): pause of approximately 666597768ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,989 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:28,989 [JvmPauseMonitor52] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-dda7196a-19a1-4ef5-a6eb-ce99792637b5: Detected pause in JVM or host machine (eg GC): pause of approximately 680632368ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,989 [JvmPauseMonitor46] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-59495bd3-eca8-4664-a537-a989ac7b0d80: Detected pause in JVM or host machine (eg GC): pause of approximately 681468775ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,989 [JvmPauseMonitor40] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-b83605a3-0dba-4f7c-9b88-55eff2caaffe: Detected pause in JVM or host machine (eg GC): pause of approximately 681491175ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,989 [JvmPauseMonitor44] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-480de393-893d-4d82-b81f-696ceb757cb1: Detected pause in JVM or host machine (eg GC): pause of approximately 681600476ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,989 [JvmPauseMonitor41] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 681672076ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:28,989 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:28,990 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:28,992 [JvmPauseMonitor37] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-00dcba52-510b-4641-a1c5-22cfbaaa7f01: Detected pause in JVM or host machine (eg GC): pause of approximately 666204566ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,992 [JvmPauseMonitor36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-646e529a-a01f-4b15-a31a-2706cdf8d47d: Detected pause in JVM or host machine (eg GC): pause of approximately 663793748ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:28,994 [JvmPauseMonitor47] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-f66a9549-37e5-4f01-8484-0c21eaa44150: Detected pause in JVM or host machine (eg GC): pause of approximately 663382545ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=565ms
GC pool 'PS Scavenge' had collection(s): count=1 time=138ms
2023-03-15 02:22:29,027 [grpc-default-executor-8] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 12800 bytes for container 1
2023-03-15 02:22:29,028 [grpc-default-executor-5] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(218)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-5/data-0/containers/tmp/container-copy/container-1.tar
2023-03-15 02:22:29,028 [grpc-default-executor-8] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 12800 bytes for container 1
2023-03-15 02:22:29,065 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 3 is replicated successfully
2023-03-15 02:22:29,066 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(218)) - Successful ReplicationTask{status=DONE, cmd={replicateContainerCommand: containerId: 3, replicaIndex: 0, sourceNodes: [646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL}, queued=2023-03-15T02:22:28.233Z}
2023-03-15 02:22:29,151 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 1 is downloaded with size 12800, starting to import.
2023-03-15 02:22:29,167 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 1 is replicated successfully
2023-03-15 02:22:29,167 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(218)) - Successful ReplicationTask{status=DONE, cmd={replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [646e529a-a01f-4b15-a31a-2706cdf8d47d(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23), ed5356af-2dee-4266-b55e-559e8c0d6889(fv-az260-852.44fmlilepbzu5fnkfno1iqmhhf.dx.internal.cloudapp.net/10.1.0.23)], priority: NORMAL}, queued=2023-03-15T02:22:28.232Z}
2023-03-15 02:22:29,223 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:29,632 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:29,972 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:29,973 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:29,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:29,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:29,989 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:29,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:29,990 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:29,990 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:30,078 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:30,223 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:30,654 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:30,972 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:30,973 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:30,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:30,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:30,989 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:30,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:30,990 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:30,991 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:31,137 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:31,224 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:31,742 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:31,972 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:31,973 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:31,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-15 02:22:31,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:31,989 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:31,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:31,991 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:31,991 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:32,222 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:32,224 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:32,973 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:32,973 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:32,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:32,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:32,989 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:32,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:32,991 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:32,991 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:33,224 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:33,973 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:33,973 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:33,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:33,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:33,989 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:33,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:33,991 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:33,991 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:34,224 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:34,973 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:34,973 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:34,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:34,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:34,990 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:34,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:34,991 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:34,991 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:35,225 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:35,973 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:35,974 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:35,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:35,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:35,990 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:35,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:35,991 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:35,992 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:36,225 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:36,974 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:36,974 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:36,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:36,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:36,991 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:36,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:36,992 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:36,992 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:37,225 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:37,974 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:37,975 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:37,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-15 02:22:37,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:37,991 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:37,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:37,992 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:37,993 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:38,225 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:38,974 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:38,975 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:38,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:38,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:38,991 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:38,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:38,992 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:38,993 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:39,226 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:39,974 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:39,975 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:39,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:39,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:39,991 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:39,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:39,992 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:39,993 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:40,226 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:40,974 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:40,975 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:40,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:40,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:40,992 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:40,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:40,993 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:40,993 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:41,226 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:41,975 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:41,975 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:41,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:41,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:41,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:41,992 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:41,993 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:41,993 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:42,226 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:42,976 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:42,977 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:42,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2023-03-15 02:22:42,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:42,993 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:42,993 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:42,994 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:42,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:43,226 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:43,977 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:43,977 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:43,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:43,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:43,993 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:43,994 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:43,994 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:43,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:44,229 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:44,977 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:44,977 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:44,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-15 02:22:44,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:44,994 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:44,994 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:44,994 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:44,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:45,230 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:45,977 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:45,977 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:45,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:45,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:45,994 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:45,994 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:45,994 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:45,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:46,230 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:46,977 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:46,978 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:46,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:46,994 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:46,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:46,997 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:46,997 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:47,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:47,230 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:47,978 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:47,978 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:47,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:47,994 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:47,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:47,997 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:47,997 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:48,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:48,230 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:48,978 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:48,978 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:48,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-03-15 02:22:48,994 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:48,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:48,997 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:49,000 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:49,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:49,230 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:49,978 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:49,978 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:49,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:49,995 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:49,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:49,997 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:50,000 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:50,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:50,079 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:50,231 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:50,974 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:50,978 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:50,978 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:50,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-03-15 02:22:50,995 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:50,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:51,000 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:51,000 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:51,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(379)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-03-15 02:22:51,231 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(113)) - Processed 0 containers with health state counts {},failed processing 0
2023-03-15 02:22:51,327 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(450)) - Shutting down the Mini Ozone Cluster
2023-03-15 02:22:51,327 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(465)) - Stopping the Mini Ozone Cluster
2023-03-15 02:22:51,327 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(547)) - Stopping the OzoneManager
2023-03-15 02:22:51,327 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(2166)) - om1[localhost:0]: Stopping Ozone Manager
2023-03-15 02:22:51,327 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 34223
2023-03-15 02:22:51,335 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-03-15 02:22:51,337 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-03-15 02:22:51,338 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-03-15 02:22:51,338 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:51,339 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:51,339 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-03-15 02:22:51,339 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2023-03-15 02:22:51,339 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-03-15 02:22:51,339 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:51,373 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 88
2023-03-15 02:22:51,373 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:88)
2023-03-15 02:22:51,400 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 88
2023-03-15 02:22:51,400 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 88
2023-03-15 02:22:51,400 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-15 02:22:51,401 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(540)) - Stopping OMDoubleBuffer flush thread
2023-03-15 02:22:51,401 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(625)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-03-15 02:22:51,402 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 88
2023-03-15 02:22:51,402 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:51,403 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-03-15 02:22:51,404 [JvmPauseMonitor33] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-03-15 02:22:51,404 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-03-15 02:22:51,404 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(549)) - OMDoubleBuffer flush thread is not running.
2023-03-15 02:22:51,404 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-03-15 02:22:51,404 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-03-15 02:22:51,405 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-03-15 02:22:51,405 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-03-15 02:22:51,405 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SnapshotDeletingService
2023-03-15 02:22:51,406 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@75c44a04{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-03-15 02:22:51,407 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@576db38e{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-03-15 02:22:51,407 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-03-15 02:22:51,407 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2afb1247{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-03-15 02:22:51,407 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@12eac57e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-03-15 02:22:51,411 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(524)) - Stopping the HddsDatanodes
2023-03-15 02:22:51,418 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:51,419 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b: close
2023-03-15 02:22:51,423 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B: shutdown
2023-03-15 02:22:51,425 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A3695F9F7B6B,id=5650ff5c-2f39-425b-bee4-adddfcfb793b
2023-03-15 02:22:51,425 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b: shutdown 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-FollowerState
2023-03-15 02:22:51,426 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:51,427 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-StateMachineUpdater: set stopIndex = 39
2023-03-15 02:22:51,430 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b: installSnapshot onError, lastRequest: 00dcba52-510b-4641-a1c5-22cfbaaa7f01->5650ff5c-2f39-425b-bee4-adddfcfb793b#422-t1,previous=(t:1, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:39), METADATAENTRY(c:38): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-15 02:22:51,434 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 00dcba52-510b-4641-a1c5-22cfbaaa7f01 Close channels
2023-03-15 02:22:51,434 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-15 02:22:51,435 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->5650ff5c-2f39-425b-bee4-adddfcfb793b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-15 02:22:51,435 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->5650ff5c-2f39-425b-bee4-adddfcfb793b: nextIndex: updateUnconditionally 40 -> 39
2023-03-15 02:22:51,436 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC: shutdown
2023-03-15 02:22:51,436 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-43A976C52AFC,id=5650ff5c-2f39-425b-bee4-adddfcfb793b
2023-03-15 02:22:51,436 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b: shutdown 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-LeaderStateImpl
2023-03-15 02:22:51,436 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:51,436 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->5650ff5c-2f39-425b-bee4-adddfcfb793b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-15 02:22:51,436 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->5650ff5c-2f39-425b-bee4-adddfcfb793b: nextIndex: updateUnconditionally 39 -> 38
2023-03-15 02:22:51,436 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:51,437 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-FollowerState was interrupted
2023-03-15 02:22:51,437 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-43A976C52AFC: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-4/data/ratis/4b3bf28d-4a43-4a8c-b8ef-43a976c52afc/sm/snapshot.1_0
2023-03-15 02:22:51,437 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-A3695F9F7B6B: Taking a snapshot at:(t:1, i:39) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-4/data/ratis/6172db30-ce81-4dfa-a1f1-a3695f9f7b6b/sm/snapshot.1_39
2023-03-15 02:22:51,437 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(423)) - Attempting to stop container services.
2023-03-15 02:22:51,438 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-43A976C52AFC: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-4/data/ratis/4b3bf28d-4a43-4a8c-b8ef-43a976c52afc/sm/snapshot.1_0 took: 1 ms
2023-03-15 02:22:51,438 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:51,438 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:51,438 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC: closes. applyIndex: 0
2023-03-15 02:22:51,439 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-A3695F9F7B6B: Finished taking a snapshot at:(t:1, i:39) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-4/data/ratis/6172db30-ce81-4dfa-a1f1-a3695f9f7b6b/sm/snapshot.1_39 took: 1 ms
2023-03-15 02:22:51,439 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-StateMachineUpdater: Took a snapshot at index 39
2023-03-15 02:22:51,439 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 39
2023-03-15 02:22:51,440 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B: closes. applyIndex: 39
2023-03-15 02:22:51,440 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:51,447 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 132d3d80-0103-4f41-b942-b9d80c35d5a5 Close channels
2023-03-15 02:22:51,450 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:51,450 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: close
2023-03-15 02:22:51,450 [5650ff5c-2f39-425b-bee4-adddfcfb793b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x08e09fb4, L:/0:0:0:0:0:0:0:0:43637] CLOSE
2023-03-15 02:22:51,450 [5650ff5c-2f39-425b-bee4-adddfcfb793b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x08e09fb4, L:/0:0:0:0:0:0:0:0:43637] INACTIVE
2023-03-15 02:22:51,450 [5650ff5c-2f39-425b-bee4-adddfcfb793b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x08e09fb4, L:/0:0:0:0:0:0:0:0:43637] UNREGISTERED
2023-03-15 02:22:51,454 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: shutdown
2023-03-15 02:22:51,456 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B57DF5C92125,id=646e529a-a01f-4b15-a31a-2706cdf8d47d
2023-03-15 02:22:51,457 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: shutdown 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState
2023-03-15 02:22:51,455 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05: shutdown
2023-03-15 02:22:51,455 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-A3695F9F7B6B-SegmentedRaftLogWorker close()
2023-03-15 02:22:51,457 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B78625B56C05,id=646e529a-a01f-4b15-a31a-2706cdf8d47d
2023-03-15 02:22:51,457 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: shutdown 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-LeaderStateImpl
2023-03-15 02:22:51,457 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->5650ff5c-2f39-425b-bee4-adddfcfb793b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:51,455 [5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:51,454 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: shutdown server GrpcServerProtocolService now
2023-03-15 02:22:51,457 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->5650ff5c-2f39-425b-bee4-adddfcfb793b: nextIndex: updateUnconditionally 39 -> 38
2023-03-15 02:22:51,457 [5650ff5c-2f39-425b-bee4-adddfcfb793b-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 5650ff5c-2f39-425b-bee4-adddfcfb793b@group-43A976C52AFC-SegmentedRaftLogWorker close()
2023-03-15 02:22:51,458 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->5650ff5c-2f39-425b-bee4-adddfcfb793b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-03-15 02:22:51,458 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 00dcba52-510b-4641-a1c5-22cfbaaa7f01@group-A3695F9F7B6B->5650ff5c-2f39-425b-bee4-adddfcfb793b: nextIndex: updateUnconditionally 38 -> 37
2023-03-15 02:22:51,457 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-PendingRequests: sendNotLeaderResponses
2023-03-15 02:22:51,461 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:51,461 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-B78625B56C05: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/cae797b3-564b-4fe3-a143-b78625b56c05/sm/snapshot.1_0
2023-03-15 02:22:51,462 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-B78625B56C05: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/cae797b3-564b-4fe3-a143-b78625b56c05/sm/snapshot.1_0 took: 1 ms
2023-03-15 02:22:51,463 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:51,463 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:51,463 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05: closes. applyIndex: 0
2023-03-15 02:22:51,476 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-StateMachineUpdater: set stopIndex = 0
2023-03-15 02:22:51,477 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(330)) - group-B57DF5C92125: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125/sm/snapshot.1_0
2023-03-15 02:22:51,477 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-FollowerState was interrupted
2023-03-15 02:22:51,477 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-15 02:22:51,478 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(341)) - group-B57DF5C92125: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-59b91c09-8b07-4c70-997f-cc8d5df695e6/datanode-2/data/ratis/e2467591-d6d0-4055-98f0-b57df5c92125/sm/snapshot.1_0 took: 2 ms
2023-03-15 02:22:51,478 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-StateMachineUpdater: Took a snapshot at index 0
2023-03-15 02:22:51,478 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-03-15 02:22:51,479 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125: closes. applyIndex: 0
2023-03-15 02:22:51,482 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - ed5356af-2dee-4266-b55e-559e8c0d6889 Close channels
2023-03-15 02:22:51,483 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125->646e529a-a01f-4b15-a31a-2706cdf8d47d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-15 02:22:51,483 [BlockDeletingService#1] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-03-15 02:22:51,483 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125->646e529a-a01f-4b15-a31a-2706cdf8d47d-GrpcLogAppender: Leader has not got in touch with Follower b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125->646e529a-a01f-4b15-a31a-2706cdf8d47d(c0,m0,n1, attendVote=true, lastRpcSendTime=1145, lastRpcResponseTime=1144) yet, just keep nextIndex unchanged and retry.
2023-03-15 02:22:51,483 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125->646e529a-a01f-4b15-a31a-2706cdf8d47d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-03-15 02:22:51,484 [grpc-default-executor-8] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125->646e529a-a01f-4b15-a31a-2706cdf8d47d-GrpcLogAppender: Leader has not got in touch with Follower b83605a3-0dba-4f7c-9b88-55eff2caaffe@group-B57DF5C92125->646e529a-a01f-4b15-a31a-2706cdf8d47d(c0,m0,n1, attendVote=true, lastRpcSendTime=1145, lastRpcResponseTime=1145) yet, just keep nextIndex unchanged and retry.
2023-03-15 02:22:51,487 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:51,487 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B78625B56C05-SegmentedRaftLogWorker close()
2023-03-15 02:22:51,489 [646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-03-15 02:22:51,489 [646e529a-a01f-4b15-a31a-2706cdf8d47d-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d@group-B57DF5C92125-SegmentedRaftLogWorker close()
2023-03-15 02:22:51,490 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: installSnapshot onError, lastRequest: b83605a3-0dba-4f7c-9b88-55eff2caaffe->646e529a-a01f-4b15-a31a-2706cdf8d47d#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "ed5356af-2dee-4266-b55e-559e8c0d6889"
address: "10.1.0.23:46587"
dataStreamAddress: "10.1.0.23:45375"
clientAddress: "10.1.0.23:46587"
adminAddress: "10.1.0.23:46587"
startupRole: FOLLOWER
,id: "646e529a-a01f-4b15-a31a-2706cdf8d47d"
address: "10.1.0.23:38099"
dataStreamAddress: "10.1.0.23:36605"
clientAddress: "10.1.0.23:38099"
adminAddress: "10.1.0.23:38099"
startupRole: FOLLOWER
,id: "b83605a3-0dba-4f7c-9b88-55eff2caaffe"
address: "10.1.0.23:46445"
priority: 1
dataStreamAddress: "10.1.0.23:42333"
clientAddress: "10.1.0.23:46445"
adminAddress: "10.1.0.23:46445"
startupRole: FOLLOWER
, old:): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-03-15 02:22:51,497 [JvmPauseMonitor38] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-5650ff5c-2f39-425b-bee4-adddfcfb793b: Stopped
2023-03-15 02:22:51,505 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - b83605a3-0dba-4f7c-9b88-55eff2caaffe Close channels
2023-03-15 02:22:51,507 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 646e529a-a01f-4b15-a31a-2706cdf8d47d: shutdown server GrpcServerProtocolService successfully
2023-03-15 02:22:51,508 [646e529a-a01f-4b15-a31a-2706cdf8d47d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x28e21ee4, L:/0:0:0:0:0:0:0:0:36605] CLOSE
2023-03-15 02:22:51,508 [646e529a-a01f-4b15-a31a-2706cdf8d47d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x28e21ee4, L:/0:0:0:0:0:0:0:0:36605] INACTIVE
2023-03-15 02:22:51,508 [646e529a-a01f-4b15-a31a-2706cdf8d47d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x28e21ee4, L:/0:0:0:0:0:0:0:0:36605] UNREGISTERED
2023-03-15 02:22:51,536 [JvmPauseMonitor36] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-646e529a-a01f-4b15-a31a-2706cdf8d47d: Stopped
]]></system-out>
    <system-err><![CDATA[Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1451, target=10.1.0.23:35687} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1477, target=10.1.0.23:39223} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1475, target=10.1.0.23:46619} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1335, target=10.1.0.23:35687} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1504, target=10.1.0.23:42235} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1423, target=10.1.0.23:46619} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1508, target=10.1.0.23:35687} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1339, target=10.1.0.23:42235} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1337, target=10.1.0.23:39223} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1446, target=10.1.0.23:42235} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1382, target=10.1.0.23:39223} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1502, target=10.1.0.23:46023} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1421, target=10.1.0.23:46023} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1417, target=10.1.0.23:42235} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1415, target=10.1.0.23:39223} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1380, target=10.1.0.23:37277} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1384, target=10.1.0.23:38125} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1444, target=10.1.0.23:37277} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1449, target=10.1.0.23:39223} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1469, target=10.1.0.23:35687} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1510, target=10.1.0.23:37277} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1471, target=10.1.0.23:42235} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1333, target=10.1.0.23:46619} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1341, target=10.1.0.23:37277} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1442, target=10.1.0.23:38125} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1506, target=10.1.0.23:39223} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1473, target=10.1.0.23:46023} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1378, target=10.1.0.23:46619} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1419, target=10.1.0.23:37277} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Mar 15, 2023 2:22:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1386, target=10.1.0.23:42235} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:102)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:421)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:402)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:355)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:576)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:560)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

]]></system-err>
  </testcase>
  <testcase name="testEnteringMaintenanceNodeCompletesAfterSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="15.503"/>
  <testcase name="testDecommissioningNodesCompleteDecommissionOnSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="32.081"/>
</testsuite>