<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.ozone.dn.scanner.TestBackgroundContainerMetadataScannerIntegration" time="69.742" tests="6" errors="1" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.94.Final/netty-codec-http2-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.94.Final/netty-common-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.94.Final/netty-buffer-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.94.Final/netty-codec-http-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.94.Final/netty-handler-proxy-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.94.Final/netty-codec-socks-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.61.Final/netty-tcnative-classes-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.6/hadoop-hdfs-client-3.3.6.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/3.4.0/okio-3.4.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio-jvm/3.4.0/okio-jvm-3.4.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/1.8.0/kotlin-stdlib-jdk8-1.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/1.8.0/kotlin-stdlib-jdk7-1.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/32.0.0-jre/guava-32.0.0-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.33.0/checker-qual-3.33.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.10.0/commons-text-1.10.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-managed-rocksdb/1.4.0-SNAPSHOT/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/commons-fileupload/commons-fileupload/1.5/commons-fileupload-1.5.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.51.v20230217/jetty-util-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.51.v20230217/jetty-server-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.51.v20230217/jetty-http-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.51.v20230217/jetty-io-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.51.v20230217/jetty-servlet-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.51.v20230217/jetty-security-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.51.v20230217/jetty-util-ajax-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.51.v20230217/jetty-webapp-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.51.v20230217/jetty-xml-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.5.1/ratis-server-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.4/ratis-thirdparty-misc-1.0.4.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.5.1/ratis-proto-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.5.1/ratis-common-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.5.1/ratis-client-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.5.1/ratis-server-api-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.5.1/ratis-metrics-2.5.1.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-core/1.0.1/jgrapht-core-1.0.1.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-ext/1.0.1/jgrapht-ext-1.0.1.jar:/home/runner/.m2/repository/org/tinyjee/jgraphx/jgraphx/2.0.0.1/jgraphx-2.0.0.1.jar:/home/runner/.m2/repository/jgraph/jgraph/5.13.0.0/jgraph-5.13.0.0.jar:/home/runner/.m2/repository/org/antlr/antlr4-runtime/4.5.3/antlr4-runtime-4.5.3.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.51.v20230217/jetty-client-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.13/httpcore-nio-4.4.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-rocks-native/1.4.0-SNAPSHOT/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.6/hadoop-minikdc-3.3.6.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.94.Final/netty-transport-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.94.Final/netty-resolver-4.1.94.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.94.Final/netty-transport-native-epoll-4.1.94.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.94.Final/netty-transport-classes-epoll-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.94.Final/netty-transport-native-unix-common-4.1.94.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/guice/5.1.0/guice-5.1.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/5.1.0/guice-assistedinject-5.1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/5.1.0/guice-servlet-5.1.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.41.2.2/sqlite-jdbc-3.41.2.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.27/spring-jdbc-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.27/spring-beans-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.27/spring-core-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.27/spring-tx-5.3.27.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.5.1/ratis-tools-2.5.1.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.5.1/ratis-netty-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.5.1/ratis-grpc-2.5.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/3.5.9/mockito-core-3.5.9.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.6/hadoop-auth-3.3.6.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/github/pjfanning/jersey-json/1.20/jersey-json-1.20.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/5.2.0/curator-recipes-5.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.94.Final/netty-codec-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.94.Final/netty-handler-4.1.94.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.6/hadoop-mapreduce-client-jobclient-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.6/hadoop-mapreduce-client-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.6/hadoop-yarn-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.6/hadoop-yarn-api-3.3.6.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.6/hadoop-yarn-client-3.3.6.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.51.v20230217/websocket-client-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.51.v20230217/websocket-common-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.51.v20230217/websocket-api-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.6/hadoop-mapreduce-client-core-3.3.6.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.6/hadoop-annotations-3.3.6.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="java.vm.vendor" value="Temurin"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://adoptium.net/"/>
    <property name="user.timezone" value="Etc/UTC"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter7052852193924552292.jar /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire 2023-08-10T16-59-14_486-jvmRun1 surefire6031440554689225466tmp surefire_33306279287756373248tmp"/>
    <property name="native.lib.tmp.dir" value="/tmp"/>
    <property name="surefire.test.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.94.Final/netty-codec-http2-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.94.Final/netty-common-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.94.Final/netty-buffer-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.94.Final/netty-codec-http-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.94.Final/netty-handler-proxy-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.94.Final/netty-codec-socks-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.61.Final/netty-tcnative-classes-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.6/hadoop-hdfs-client-3.3.6.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/3.4.0/okio-3.4.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio-jvm/3.4.0/okio-jvm-3.4.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/1.8.0/kotlin-stdlib-jdk8-1.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/1.8.0/kotlin-stdlib-jdk7-1.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/32.0.0-jre/guava-32.0.0-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.33.0/checker-qual-3.33.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.10.0/commons-text-1.10.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-managed-rocksdb/1.4.0-SNAPSHOT/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/commons-fileupload/commons-fileupload/1.5/commons-fileupload-1.5.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.51.v20230217/jetty-util-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.51.v20230217/jetty-server-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.51.v20230217/jetty-http-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.51.v20230217/jetty-io-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.51.v20230217/jetty-servlet-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.51.v20230217/jetty-security-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.51.v20230217/jetty-util-ajax-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.51.v20230217/jetty-webapp-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.51.v20230217/jetty-xml-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.5.1/ratis-server-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.4/ratis-thirdparty-misc-1.0.4.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.5.1/ratis-proto-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.5.1/ratis-common-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.5.1/ratis-client-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.5.1/ratis-server-api-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.5.1/ratis-metrics-2.5.1.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-core/1.0.1/jgrapht-core-1.0.1.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-ext/1.0.1/jgrapht-ext-1.0.1.jar:/home/runner/.m2/repository/org/tinyjee/jgraphx/jgraphx/2.0.0.1/jgraphx-2.0.0.1.jar:/home/runner/.m2/repository/jgraph/jgraph/5.13.0.0/jgraph-5.13.0.0.jar:/home/runner/.m2/repository/org/antlr/antlr4-runtime/4.5.3/antlr4-runtime-4.5.3.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.51.v20230217/jetty-client-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.13/httpcore-nio-4.4.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-rocks-native/1.4.0-SNAPSHOT/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.6/hadoop-minikdc-3.3.6.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.94.Final/netty-transport-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.94.Final/netty-resolver-4.1.94.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.94.Final/netty-transport-native-epoll-4.1.94.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.94.Final/netty-transport-classes-epoll-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.94.Final/netty-transport-native-unix-common-4.1.94.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/guice/5.1.0/guice-5.1.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/5.1.0/guice-assistedinject-5.1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/5.1.0/guice-servlet-5.1.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.41.2.2/sqlite-jdbc-3.41.2.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.27/spring-jdbc-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.27/spring-beans-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.27/spring-core-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.27/spring-tx-5.3.27.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.5.1/ratis-tools-2.5.1.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.5.1/ratis-netty-2.5.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.5.1/ratis-grpc-2.5.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/3.5.9/mockito-core-3.5.9.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.6/hadoop-auth-3.3.6.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/github/pjfanning/jersey-json/1.20/jersey-json-1.20.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/5.2.0/curator-recipes-5.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.94.Final/netty-codec-4.1.94.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.94.Final/netty-handler-4.1.94.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.6/hadoop-mapreduce-client-jobclient-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.6/hadoop-mapreduce-client-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.6/hadoop-yarn-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.6/hadoop-yarn-api-3.3.6.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.6/hadoop-yarn-client-3.3.6.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.51.v20230217/websocket-client-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.51.v20230217/websocket-common-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.51.v20230217/websocket-api-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.6/hadoop-mapreduce-client-core-3.3.6.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.6/hadoop-annotations-3.3.6.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/runner"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="skip.installnpx" value="true"/>
    <property name="surefire.real.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter7052852193924552292.jar:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar"/>
    <property name="hadoop.log.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="skip.npx" value="true"/>
    <property name="java.runtime.version" value="1.8.0_382-b05"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="runner"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="5.15.0-1042-azure"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/runner/.m2/repository"/>
    <property name="jetty.git.hash" value="b45c405e4544384de066f814ed42ae3dceacdd49"/>
    <property name="java.vendor.url.bug" value="https://github.com/adoptium/adoptium-support/issues"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_382"/>
    <property name="user.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="org.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads" value="false"/>
    <property name="hadoop.tmp.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="Temurin"/>
    <property name="java.vm.version" value="25.382-b05"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testCorruptionDetected" classname="TestBackgroundContainerMetadataScannerIntegration" time="16.726">
    <system-out><![CDATA[2023-08-10 17:02:02,749 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(155)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-08-10 17:02:02,955 [main] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 152 ms to scan 7 urls, producing 161 keys and 379 values 
2023-08-10 17:02:03,106 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(155)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-08-10 17:02:03,109 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(210)) - ServiceID for StorageContainerManager is null
2023-08-10 17:02:03,116 [main] WARN  ha.SCMHANodeDetails (SCMHANodeDetails.java:validateSCMHAConfig(183)) - Invalid config ozone.scm.ratis.enable. The config was not specified, but the default value true conflicts with the expected config value false. Falling back to the expected value. Current State of SCM: SCM is running in Non-HA without Ratis Ratis SCM -> Non Ratis SCM or Non HA SCM -> HA SCM is not supported
2023-08-10 17:02:03,116 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(215)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-08-10 17:02:03,686 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(339)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-08-10 17:02:03,829 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(166)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-08-10 17:02:04,032 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-08-10 17:02:04,034 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-08-10 17:02:04,072 [main] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2023-08-10 17:02:04,085 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2023-08-10 17:02:04,253 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(365)) - upgrade localId to 111677748019200000
2023-08-10 17:02:04,254 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(375)) - upgrade delTxnId to 0
2023-08-10 17:02:04,260 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(392)) - upgrade containerId to 0
2023-08-10 17:02:04,262 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(428)) - upgrade rootCertificateId to 1
2023-08-10 17:02:04,264 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(236)) - Init the HA SequenceIdGenerator.
2023-08-10 17:02:04,312 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(80)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2023-08-10 17:02:04,312 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(80)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2023-08-10 17:02:04,317 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(157)) - Entering startup safe mode.
2023-08-10 17:02:04,332 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2023-08-10 17:02:04,335 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-08-10 17:02:04,345 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2023-08-10 17:02:04,358 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-08-10 17:02:04,358 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-08-10 17:02:04,364 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-08-10 17:02:04,364 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-08-10 17:02:04,370 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-08-10 17:02:04,374 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-08-10 17:02:04,381 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-08-10 17:02:04,382 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-08-10 17:02:04,404 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-08-10 17:02:04,404 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-08-10 17:02:04,411 [main] WARN  util.MBeans (MBeans.java:register(111)) - Failed to register MBean "Hadoop:service=BlockManager,name=BlockManagerImpl"
javax.management.NotCompliantMBeanException: MBean class org.apache.hadoop.hdds.scm.block.BlockManagerImpl does not implement DynamicMBean, and neither follows the Standard MBean conventions (javax.management.NotCompliantMBeanException: Class org.apache.hadoop.hdds.scm.block.BlockManagerImpl is not a JMX compliant Standard MBean) nor the MXBean conventions (javax.management.NotCompliantMBeanException: org.apache.hadoop.hdds.scm.block.BlockManagerImpl: Class org.apache.hadoop.hdds.scm.block.BlockManagerImpl is not a JMX compliant MXBean)
	at com.sun.jmx.mbeanserver.Introspector.checkCompliance(Introspector.java:176)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:317)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:100)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:73)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.<init>(BlockManagerImpl.java:94)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.initializeSystemManagers(StorageContainerManager.java:787)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.<init>(StorageContainerManager.java:401)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.createSCM(StorageContainerManager.java:598)
	at org.apache.hadoop.hdds.scm.HddsTestUtils.getScmSimple(HddsTestUtils.java:604)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createSCM(MiniOzoneClusterImpl.java:745)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:593)
	at org.apache.hadoop.ozone.dn.scanner.TestContainerScannerIntegrationAbstract.buildCluster(TestContainerScannerIntegrationAbstract.java:107)
	at org.apache.hadoop.ozone.dn.scanner.TestBackgroundContainerMetadataScannerIntegration.init(TestBackgroundContainerMetadataScannerIntegration.java:80)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:42)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:80)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:72)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
2023-08-10 17:02:04,427 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-08-10 17:02:04,497 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(287)) - Starting Replication Monitor Thread.
2023-08-10 17:02:04,498 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-08-10 17:02:04,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:04,508 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2023-08-10 17:02:04,511 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 0, healthy pipeline threshold count is 0
2023-08-10 17:02:04,513 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-08-10 17:02:04,569 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(425)) - SCM start with adminUsers: [runner]
2023-08-10 17:02:04,909 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(126)) - Refresh DebugCmdSet for SCMAudit to [].
2023-08-10 17:02:04,939 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-08-10 17:02:04,970 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15002
2023-08-10 17:02:04,974 [Socket Reader #1 for port 15002] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15002
2023-08-10 17:02:05,037 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(126)) - Refresh DebugCmdSet for SCMAudit to [].
2023-08-10 17:02:05,043 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-08-10 17:02:05,043 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15001
2023-08-10 17:02:05,044 [Socket Reader #1 for port 15001] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15001
2023-08-10 17:02:05,083 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(126)) - Refresh DebugCmdSet for SCMAudit to [].
2023-08-10 17:02:05,100 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-08-10 17:02:05,100 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15000
2023-08-10 17:02:05,101 [Socket Reader #1 for port 15000] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15000
2023-08-10 17:02:05,146 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-08-10 17:02:05,146 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(438)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-08-10 17:02:05,147 [main] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-08-10 17:02:05,150 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1483)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15000
2023-08-10 17:02:05,209 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-08-10 17:02:05,220 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-08-10 17:02:05,220 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-08-10 17:02:05,461 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(201)) - RPC server for Client  is listening at /0.0.0.0:15000
2023-08-10 17:02:05,461 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2023-08-10 17:02:05,463 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15000: starting
2023-08-10 17:02:05,480 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1496)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15001
2023-08-10 17:02:05,480 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:15001
2023-08-10 17:02:05,481 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2023-08-10 17:02:05,482 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15001: starting
2023-08-10 17:02:05,487 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15002
2023-08-10 17:02:05,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:05,505 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15002: starting
2023-08-10 17:02:05,505 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2023-08-10 17:02:05,516 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-6202be86-8f9e-4ecb-b217-ab7a852b6048: Started
2023-08-10 17:02:05,524 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for scm at: http://0.0.0.0:15003
2023-08-10 17:02:05,524 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-08-10 17:02:05,547 [main] INFO  util.log (Log.java:initialized(170)) - Logging initialized @4213ms to org.eclipse.jetty.util.log.Slf4jLog
2023-08-10 17:02:05,635 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-08-10 17:02:05,640 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.scm is not defined
2023-08-10 17:02:05,645 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-08-10 17:02:05,648 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-08-10 17:02:05,648 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-08-10 17:02:05,648 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-08-10 17:02:05,684 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/ozone-meta/webserver
2023-08-10 17:02:05,685 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 15003
2023-08-10 17:02:05,687 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 1.8.0_382-b05
2023-08-10 17:02:05,712 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-08-10 17:02:05,713 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-08-10 17:02:05,715 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-08-10 17:02:05,726 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3a70acd5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-08-10 17:02:05,727 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4c7d19bf{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-08-10 17:02:05,774 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@589cc8eb{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-08-10 17:02:05,782 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@234dfc8e{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2023-08-10 17:02:05,783 [main] INFO  server.Server (Server.java:doStart(415)) - Started @4448ms
2023-08-10 17:02:05,785 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-08-10 17:02:05,786 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-08-10 17:02:05,787 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of scm listening at http://0.0.0.0:15003
2023-08-10 17:02:05,791 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(311)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-08-10 17:02:05,852 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(126)) - Refresh DebugCmdSet for OMAudit to [].
2023-08-10 17:02:05,927 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-08-10 17:02:05,930 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:15004
2023-08-10 17:02:05,930 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-08-10 17:02:05,930 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2023-08-10 17:02:05,934 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(311)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-08-10 17:02:05,937 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = QUOTA (version = 6), software layout = QUOTA (version = 6)
2023-08-10 17:02:06,037 [main] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 95 ms to scan 2 urls, producing 188 keys and 512 values [using 2 cores]
2023-08-10 17:02:06,040 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2023-08-10 17:02:06,042 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2023-08-10 17:02:06,045 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(311)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-08-10 17:02:06,219 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2023-08-10 17:02:06,256 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2023-08-10 17:02:06,471 [main] INFO  om.OzoneManager (OzoneManager.java:<init>(662)) - OM start with adminUsers: [runner]
2023-08-10 17:02:06,500 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(311)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-08-10 17:02:06,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:06,527 [main] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2023-08-10 17:02:06,779 [main] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(791)) - S3 Multi-Tenancy is disabled
2023-08-10 17:02:06,810 [main] INFO  om.OmSnapshotManager (OmSnapshotManager.java:<init>(175)) - Ozone filesystem snapshot feature is enabled.
2023-08-10 17:02:06,818 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(311)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-08-10 17:02:06,859 [main] INFO  utils.NativeLibraryLoader (NativeLibraryLoader.java:loadLibrary(105)) - Loading Library: ozone_rocksdb_tools
2023-08-10 17:02:06,860 [main] INFO  snapshot.SnapshotDiffManager (SnapshotDiffManager.java:closeExecutorService(1720)) - Shutting down executorService: 'SstDumpToolExecutor'
2023-08-10 17:02:06,934 [main] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4287)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2023-08-10 17:02:07,007 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(323)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-08-10 17:02:07,007 [main] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(461)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2023-08-10 17:02:07,021 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(323)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-08-10 17:02:07,044 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(163)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:15007
2023-08-10 17:02:07,053 [main] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(687)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2023-08-10 17:02:07,109 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-08-10 17:02:07,117 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-08-10 17:02:07,119 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15007 (fallback to raft.grpc.server.port)
2023-08-10 17:02:07,119 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-08-10 17:02:07,120 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15007 (fallback to raft.grpc.server.port)
2023-08-10 17:02:07,120 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-08-10 17:02:07,120 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15007 (custom)
2023-08-10 17:02:07,121 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2023-08-10 17:02:07,122 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:07,122 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-08-10 17:02:07,123 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-08-10 17:02:07,134 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-08-10 17:02:07,137 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-08-10 17:02:07,138 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-08-10 17:02:07,333 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2023-08-10 17:02:07,335 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-08-10 17:02:07,336 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-08-10 17:02:07,336 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-08-10 17:02:07,336 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-08-10 17:02:07,338 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/ozone-meta/ratis] (custom)
2023-08-10 17:02:07,349 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(98)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:15007|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@78a7a3ca[Not completed]
2023-08-10 17:02:07,349 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2128)) - OzoneManager Ratis server initialized at port 15007
2023-08-10 17:02:07,354 [main] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1193)) - Creating RPC Server
2023-08-10 17:02:07,380 [om1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(198)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:15007|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
2023-08-10 17:02:07,383 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2023-08-10 17:02:07,387 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2023-08-10 17:02:07,387 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-08-10 17:02:07,387 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-08-10 17:02:07,387 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-08-10 17:02:07,388 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-08-10 17:02:07,402 [om1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(120)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:localhost:15007|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-08-10 17:02:07,403 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/ozone-meta/ratis] (custom)
2023-08-10 17:02:07,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:07,610 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-08-10 17:02:07,610 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-08-10 17:02:07,628 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2023-08-10 17:02:07,635 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2023-08-10 17:02:07,643 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2023-08-10 17:02:07,643 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-08-10 17:02:07,709 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2023-08-10 17:02:07,762 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-08-10 17:02:07,771 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-08-10 17:02:07,772 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-08-10 17:02:07,772 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-08-10 17:02:07,773 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-08-10 17:02:07,775 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-08-10 17:02:08,325 [main] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 671 ms to scan 19 urls, producing 70 keys and 5612 values [using 2 cores]
2023-08-10 17:02:08,485 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-08-10 17:02:08,485 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 127.0.0.1:15004
2023-08-10 17:02:08,486 [Socket Reader #1 for port 15004] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15004
2023-08-10 17:02:08,521 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2023-08-10 17:02:08,535 [main] INFO  om.OzoneManager (OzoneManager.java:start(1613)) - OzoneManager RPC server is listening at localhost/127.0.0.1:15004
2023-08-10 17:02:08,535 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(558)) - Starting OzoneManagerRatisServer om1 at port 15007
2023-08-10 17:02:08,538 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2023-08-10 17:02:08,542 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 4345@fv-az1292-188
2023-08-10 17:02:08,547 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2023-08-10 17:02:08,550 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-08-10 17:02:08,557 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-08-10 17:02:08,557 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:08,558 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-08-10 17:02:08,559 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-08-10 17:02:08,561 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-08-10 17:02:08,566 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-08-10 17:02:08,567 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-08-10 17:02:08,567 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:08,572 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2023-08-10 17:02:08,572 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-08-10 17:02:08,573 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2023-08-10 17:02:08,574 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-08-10 17:02:08,576 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2023-08-10 17:02:08,577 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-08-10 17:02:08,578 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-08-10 17:02:08,578 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-08-10 17:02:08,578 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-08-10 17:02:08,586 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-08-10 17:02:08,586 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:08,591 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-08-10 17:02:08,592 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-08-10 17:02:08,592 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2023-08-10 17:02:08,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:08,632 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-08-10 17:02:08,634 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-08-10 17:02:08,635 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(342)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:localhost:15007|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:08,639 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(329)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-08-10 17:02:08,641 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2023-08-10 17:02:08,642 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-08-10 17:02:08,644 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-08-10 17:02:08,649 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2023-08-10 17:02:08,649 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2023-08-10 17:02:08,650 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2023-08-10 17:02:08,655 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2023-08-10 17:02:08,656 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(400)) - om1: start RPC server
2023-08-10 17:02:08,657 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2023-08-10 17:02:08,702 [main] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - om1: GrpcService started, listening on 15007
2023-08-10 17:02:08,705 [main] INFO  om.OzoneManager (OzoneManager.java:start(1629)) - Version File has different layout version (6) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2023-08-10 17:02:08,710 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-om1: Started
2023-08-10 17:02:08,737 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for ozoneManager at: http://0.0.0.0:15005
2023-08-10 17:02:08,737 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-08-10 17:02:08,739 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-08-10 17:02:08,739 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.ozoneManager is not defined
2023-08-10 17:02:08,741 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-08-10 17:02:08,742 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2023-08-10 17:02:08,742 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-08-10 17:02:08,742 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-08-10 17:02:08,743 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/ozone-meta/webserver
2023-08-10 17:02:08,753 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 15005
2023-08-10 17:02:08,753 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 1.8.0_382-b05
2023-08-10 17:02:08,756 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-08-10 17:02:08,756 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-08-10 17:02:08,756 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-08-10 17:02:08,757 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@135e3c72{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-08-10 17:02:08,757 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@38cde4f2{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-08-10 17:02:08,761 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@578d4551{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-08-10 17:02:08,766 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7537f673{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2023-08-10 17:02:08,766 [main] INFO  server.Server (Server.java:doStart(415)) - Started @7432ms
2023-08-10 17:02:08,766 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-08-10 17:02:08,767 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of ozoneManager listening at http://0.0.0.0:15005
2023-08-10 17:02:08,767 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2023-08-10 17:02:08,767 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15004: starting
2023-08-10 17:02:08,770 [main] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2081)) - Trash Interval set to 0. Files deleted won't move to trash
2023-08-10 17:02:08,894 [main] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-08-10 17:02:08,894 [main] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-08-10 17:02:08,894 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-08-10 17:02:08,916 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(237)) - HddsDatanodeService host:fv-az1292-188 ip:10.1.0.6
2023-08-10 17:02:08,955 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2023-08-10 17:02:08,961 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(282)) - Datanode State Machine Task Thread Pool size 2
2023-08-10 17:02:09,014 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-08-10 17:02:09,016 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds to VolumeSet
2023-08-10 17:02:09,021 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis to VolumeSet
2023-08-10 17:02:09,033 [Thread-140] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(177)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds
2023-08-10 17:02:09,033 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(316)) - Build ContainerSet costs 0s
2023-08-10 17:02:09,080 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(126)) - Refresh DebugCmdSet for DNAudit to [].
2023-08-10 17:02:09,107 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-08-10 17:02:09,107 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-08-10 17:02:09,108 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15013 (custom)
2023-08-10 17:02:09,108 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-08-10 17:02:09,108 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15012 (custom)
2023-08-10 17:02:09,108 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-08-10 17:02:09,108 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15014 (custom)
2023-08-10 17:02:09,108 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-08-10 17:02:09,108 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:09,108 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-08-10 17:02:09,109 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-08-10 17:02:09,109 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-08-10 17:02:09,109 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-08-10 17:02:09,109 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-08-10 17:02:09,111 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-08-10 17:02:09,119 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-08-10 17:02:09,120 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-08-10 17:02:09,120 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-08-10 17:02:09,121 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-08-10 17:02:09,123 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-08-10 17:02:09,124 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-08-10 17:02:09,129 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-08-10 17:02:09,145 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-08-10 17:02:09,146 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-08-10 17:02:09,147 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15015 (custom)
2023-08-10 17:02:09,155 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-08-10 17:02:09,155 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-08-10 17:02:09,155 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-08-10 17:02:09,155 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-08-10 17:02:09,155 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis] (custom)
2023-08-10 17:02:09,164 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(258)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/tmp
2023-08-10 17:02:09,165 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(263)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/tmp is not a group directory; ignoring it. 
2023-08-10 17:02:09,168 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(81)) - Initializing replication server with thread count = 10
2023-08-10 17:02:09,179 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xabaa84f1] REGISTERED
2023-08-10 17:02:09,179 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xabaa84f1] BIND: 0.0.0.0/0.0.0.0:15015
2023-08-10 17:02:09,180 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xabaa84f1, L:/0:0:0:0:0:0:0:0:15015] ACTIVE
2023-08-10 17:02:09,190 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-08-10 17:02:09,221 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(155)) - Initializing replication supervisor with thread count = 10
2023-08-10 17:02:09,222 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(307)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2023-08-10 17:02:09,268 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(224)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15009
2023-08-10 17:02:09,269 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(111)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-08-10 17:02:09,270 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-08-10 17:02:09,272 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2023-08-10 17:02:09,274 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-08-10 17:02:09,275 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-08-10 17:02:09,275 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-08-10 17:02:09,275 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-08-10 17:02:09,276 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(190)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/meta/webserver
2023-08-10 17:02:09,276 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 15009
2023-08-10 17:02:09,276 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 1.8.0_382-b05
2023-08-10 17:02:09,281 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-08-10 17:02:09,281 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-08-10 17:02:09,281 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-08-10 17:02:09,282 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@8196ff1{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-08-10 17:02:09,282 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@52d1600c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-08-10 17:02:09,519 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4dbf26c7{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/meta/webserver/jetty-0_0_0_0-15009-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-5357807415770962171/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-08-10 17:02:09,521 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@60015b68{HTTP/1.1, (http/1.1)}{0.0.0.0:15009}
2023-08-10 17:02:09,521 [main] INFO  server.Server (Server.java:doStart(415)) - Started @8187ms
2023-08-10 17:02:09,521 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-08-10 17:02:09,523 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(344)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15009
2023-08-10 17:02:09,527 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-08-10 17:02:09,527 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15010
2023-08-10 17:02:09,528 [Socket Reader #1 for port 15010] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15010
2023-08-10 17:02:09,530 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(315)) - Datanode start with admins: [runner]
2023-08-10 17:02:09,532 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(72)) - RPC server for Client /0.0.0.0:15010
2023-08-10 17:02:09,532 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2023-08-10 17:02:09,535 [IPC Server listener on 15010] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15010: starting
2023-08-10 17:02:09,535 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for nodes to be ready. Got 0 of 1 DN Heartbeats.
2023-08-10 17:02:09,535 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - Waiting for cluster to exit safe mode
2023-08-10 17:02:09,535 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(229)) - SCM became leader
2023-08-10 17:02:09,534 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(538)) - Ozone container server started.
2023-08-10 17:02:09,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:09,661 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/meta/datanode.id
2023-08-10 17:02:09,746 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1105594206ns, electionTimeout:1088ms
2023-08-10 17:02:09,747 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2023-08-10 17:02:09,748 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(329)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-08-10 17:02:09,750 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-08-10 17:02:09,750 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection1
2023-08-10 17:02:09,757 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|rpc:localhost:15007|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:09,759 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2023-08-10 17:02:09,762 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:localhost:15007|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:09,762 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2023-08-10 17:02:09,762 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection1
2023-08-10 17:02:09,762 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(329)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-08-10 17:02:09,766 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setLeader(317)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 2136ms
2023-08-10 17:02:09,772 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-08-10 17:02:09,777 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-08-10 17:02:09,777 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-08-10 17:02:09,781 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2023-08-10 17:02:09,781 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-08-10 17:02:09,783 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-08-10 17:02:09,790 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-08-10 17:02:09,794 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-08-10 17:02:09,796 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2023-08-10 17:02:09,816 [om1@group-C5BA1605619E-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(447)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2023-08-10 17:02:09,848 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(434)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:localhost:15007|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:09,910 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(651)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2023-08-10 17:02:09,991 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(202)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:15007"
startupRole: FOLLOWER
]
2023-08-10 17:02:10,535 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for nodes to be ready. Got 0 of 1 DN Heartbeats.
2023-08-10 17:02:10,536 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - Waiting for cluster to exit safe mode
2023-08-10 17:02:10,536 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(229)) - SCM became leader
2023-08-10 17:02:10,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:11,536 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for nodes to be ready. Got 0 of 1 DN Heartbeats.
2023-08-10 17:02:11,536 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - Waiting for cluster to exit safe mode
2023-08-10 17:02:11,536 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(229)) - SCM became leader
2023-08-10 17:02:11,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:11,651 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(66)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/DS-7020d299-a092-4e1c-9bf0-831323a78756/container.db to cache
2023-08-10 17:02:11,652 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(422)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/DS-7020d299-a092-4e1c-9bf0-831323a78756/container.db for volume DS-7020d299-a092-4e1c-9bf0-831323a78756
2023-08-10 17:02:11,658 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds
2023-08-10 17:02:11,672 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(213)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds
2023-08-10 17:02:11,678 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis
2023-08-10 17:02:11,678 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(213)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis
2023-08-10 17:02:11,680 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(431)) - Attempting to start container services.
2023-08-10 17:02:11,688 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:11,697 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(130)) - ReplicationServer is started using port 15016
2023-08-10 17:02:11,698 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:11,700 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:11,705 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(400)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: start RPC server
2023-08-10 17:02:11,707 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: GrpcService started, listening on 15012
2023-08-10 17:02:11,708 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: GrpcService started, listening on 15014
2023-08-10 17:02:11,709 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: GrpcService started, listening on 15013
2023-08-10 17:02:11,710 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis a5e7e3ff-928d-400d-bbdd-ee28941f52d7 is started using port 15012 for RATIS
2023-08-10 17:02:11,710 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis a5e7e3ff-928d-400d-bbdd-ee28941f52d7 is started using port 15013 for RATIS_ADMIN
2023-08-10 17:02:11,710 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis a5e7e3ff-928d-400d-bbdd-ee28941f52d7 is started using port 15014 for RATIS_SERVER
2023-08-10 17:02:11,710 [EndpointStateMachine task thread for /0.0.0.0:15002 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis a5e7e3ff-928d-400d-bbdd-ee28941f52d7 is started using port 15015 for RATIS_DATASTREAM
2023-08-10 17:02:11,710 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-a5e7e3ff-928d-400d-bbdd-ee28941f52d7: Started
2023-08-10 17:02:11,725 [BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2023-08-10 17:02:12,536 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for nodes to be ready. Got 0 of 1 DN Heartbeats.
2023-08-10 17:02:12,537 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - Waiting for cluster to exit safe mode
2023-08-10 17:02:12,537 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(229)) - SCM became leader
2023-08-10 17:02:12,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:12,689 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 2, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:13,537 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Waiting for nodes to be ready. Got 0 of 1 DN Heartbeats.
2023-08-10 17:02:13,537 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - Waiting for cluster to exit safe mode
2023-08-10 17:02:13,537 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(229)) - SCM became leader
2023-08-10 17:02:13,579 [IPC Server handler 2 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:13,582 [IPC Server handler 2 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(405)) - Registered Data node : a5e7e3ff-928d-400d-bbdd-ee28941f52d7{ip: 10.1.0.6, host: fv-az1292-188, ports: [HTTP=15009, CLIENT_RPC=15010, REPLICATION=15016, RATIS=15012, RATIS_ADMIN=15013, RATIS_SERVER=15014, RATIS_DATASTREAM=15015, STANDALONE=15011], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-08-10 17:02:13,586 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(277)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-08-10 17:02:13,586 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-08-10 17:02:13,590 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2023-08-10 17:02:13,590 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-08-10 17:02:13,590 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-08-10 17:02:13,590 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-08-10 17:02:13,590 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(277)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-08-10 17:02:13,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:13,599 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614 to datanode:a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:13,600 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-08-10 17:02:13,620 [RatisPipelineUtilsThread - 0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(233)) - Created new pipeline Pipeline[ Id: 29bade7a-e7d2-479c-9e81-0feb90067614, Nodes: a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-08-10T17:02:13.595Z[Etc/UTC]]
2023-08-10 17:02:13,623 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:filterNodesWithSpace(286)) - Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 5368709120 bytes for data in healthy node set. Required 3. Found 1.
2023-08-10 17:02:13,624 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:filterNodesWithSpace(286)) - Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 5368709120 bytes for data in healthy node set. Required 3. Found 1.
2023-08-10 17:02:13,689 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 3, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:14,538 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Nodes are ready. Got 1 of 1 DN Heartbeats.
2023-08-10 17:02:14,538 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - Waiting for cluster to exit safe mode
2023-08-10 17:02:14,538 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(229)) - SCM became leader
2023-08-10 17:02:14,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:14,689 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 4, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:15,538 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Nodes are ready. Got 1 of 1 DN Heartbeats.
2023-08-10 17:02:15,538 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - Waiting for cluster to exit safe mode
2023-08-10 17:02:15,538 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(229)) - SCM became leader
2023-08-10 17:02:15,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:15,689 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 5, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:16,538 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Nodes are ready. Got 1 of 1 DN Heartbeats.
2023-08-10 17:02:16,539 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - Waiting for cluster to exit safe mode
2023-08-10 17:02:16,539 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(229)) - SCM became leader
2023-08-10 17:02:16,581 [PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(98)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: addNew group-0FEB90067614:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER] returns group-0FEB90067614:java.util.concurrent.CompletableFuture@3e3050d6[Not completed]
2023-08-10 17:02:16,591 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(198)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: new RaftServerImpl for group-0FEB90067614:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-08-10 17:02:16,592 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-08-10 17:02:16,592 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-08-10 17:02:16,592 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-08-10 17:02:16,592 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-08-10 17:02:16,592 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-08-10 17:02:16,592 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-08-10 17:02:16,592 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(120)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: ConfigurationManager, init=-1: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-08-10 17:02:16,592 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis] (custom)
2023-08-10 17:02:16,593 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-08-10 17:02:16,593 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-08-10 17:02:16,593 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-08-10 17:02:16,593 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2023-08-10 17:02:16,593 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-08-10 17:02:16,593 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-08-10 17:02:16,593 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2023-08-10 17:02:16,596 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-08-10 17:02:16,596 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-08-10 17:02:16,596 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-08-10 17:02:16,596 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-08-10 17:02:16,596 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-08-10 17:02:16,596 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-08-10 17:02:16,596 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/29bade7a-e7d2-479c-9e81-0feb90067614 does not exist. Creating ...
2023-08-10 17:02:16,598 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/29bade7a-e7d2-479c-9e81-0feb90067614/in_use.lock acquired by nodename 4345@fv-az1292-188
2023-08-10 17:02:16,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:16,600 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/29bade7a-e7d2-479c-9e81-0feb90067614 has been successfully formatted.
2023-08-10 17:02:16,604 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-0FEB90067614: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-08-10 17:02:16,604 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-08-10 17:02:16,604 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-08-10 17:02:16,604 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:16,604 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-08-10 17:02:16,604 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-08-10 17:02:16,605 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-08-10 17:02:16,606 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-08-10 17:02:16,606 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-08-10 17:02:16,606 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:16,606 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/29bade7a-e7d2-479c-9e81-0feb90067614
2023-08-10 17:02:16,607 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-08-10 17:02:16,607 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-08-10 17:02:16,607 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-08-10 17:02:16,607 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-08-10 17:02:16,607 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-08-10 17:02:16,607 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-08-10 17:02:16,607 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-08-10 17:02:16,607 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-08-10 17:02:16,608 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614
2023-08-10 17:02:16,608 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-08-10 17:02:16,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-08-10 17:02:16,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-08-10 17:02:16,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-08-10 17:02:16,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-08-10 17:02:16,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(255)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-08-10 17:02:16,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-08-10 17:02:16,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-08-10 17:02:16,611 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:16,612 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1366)) - Service ReplicationManager transitions to RUNNING.
2023-08-10 17:02:16,615 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-08-10 17:02:16,615 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-08-10 17:02:16,616 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-08-10 17:02:16,616 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(134)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-08-10 17:02:16,618 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-08-10 17:02:16,619 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-08-10 17:02:16,619 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(342)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: start as a follower, conf=-1: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:16,619 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(329)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-08-10 17:02:16,619 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: start a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState
2023-08-10 17:02:16,623 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FEB90067614,id=a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:16,624 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-08-10 17:02:16,624 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-08-10 17:02:16,624 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-08-10 17:02:16,624 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-08-10 17:02:16,624 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-08-10 17:02:16,624 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-08-10 17:02:16,632 [PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(804)) - Created group PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614
2023-08-10 17:02:16,633 [PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614.
2023-08-10 17:02:16,690 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 6, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:17,539 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(224)) - Nodes are ready. Got 1 of 1 DN Heartbeats.
2023-08-10 17:02:17,539 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(227)) - Cluster exits safe mode
2023-08-10 17:02:17,539 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(229)) - SCM became leader
2023-08-10 17:02:17,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:17,690 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 7, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:17,963 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(460)) - Creating Volume: b545a376-f764-489d-9409-072b4c9797f2, with runner as owner and space quota set to -1 bytes, counts quota set to -1
2023-08-10 17:02:18,009 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(196)) - created volume:b545a376-f764-489d-9409-072b4c9797f2 for user:runner
2023-08-10 17:02:18,035 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(687)) - Creating Bucket: b545a376-f764-489d-9409-072b4c9797f2/c276867f-c168-45a6-a2b3-b74788f11bf0, with server-side default bucket layout, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2023-08-10 17:02:18,049 [OM StateMachine ApplyTransaction Thread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(270)) - created bucket: c276867f-c168-45a6-a2b3-b74788f11bf0 of layout FILE_SYSTEM_OPTIMIZED in volume: b545a376-f764-489d-9409-072b4c9797f2
2023-08-10 17:02:18,134 [IPC Server handler 17 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(140)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2023-08-10 17:02:18,143 [IPC Server handler 17 on default port 15001] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(253)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-08-10 17:02:18,144 [IPC Server handler 17 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(140)) - Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
2023-08-10 17:02:18,254 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2023-08-10 17:02:18,255 [Time-limited test] INFO  lib.Interns (Interns.java:removeEldestEntry(50)) - Metrics intern cache overflow at 2011 for MetricsSystem={MetricsSystem=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem}, MetricsSystem record=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem record}}
2023-08-10 17:02:18,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:18,690 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 8, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:19,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(361)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-08-10 17:02:19,690 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 9, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:20,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 2 milliseconds for processing 1 containers.
2023-08-10 17:02:20,691 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 10, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:21,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2023-08-10 17:02:21,691 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 11, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:21,738 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5119438228ns, electionTimeout:5114ms
2023-08-10 17:02:21,739 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: shutdown a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState
2023-08-10 17:02:21,739 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(329)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-08-10 17:02:21,740 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-08-10 17:02:21,740 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: start a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2
2023-08-10 17:02:21,742 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:21,743 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2 PRE_VOTE round 0: result PASSED (term=0)
2023-08-10 17:02:21,744 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:21,744 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2 ELECTION round 0: result PASSED (term=1)
2023-08-10 17:02:21,744 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: shutdown a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2
2023-08-10 17:02:21,744 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(329)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-08-10 17:02:21,744 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(902)) - Leader change notification received for group: group-0FEB90067614 with new leaderId: a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:21,745 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setLeader(317)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: change Leader from null to a5e7e3ff-928d-400d-bbdd-ee28941f52d7 at term 1 for becomeLeader, leader elected after 5151ms
2023-08-10 17:02:21,745 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-08-10 17:02:21,746 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-08-10 17:02:21,746 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-08-10 17:02:21,746 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-08-10 17:02:21,746 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-08-10 17:02:21,746 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-08-10 17:02:21,746 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-08-10 17:02:21,746 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-08-10 17:02:21,747 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: start a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderStateImpl
2023-08-10 17:02:21,747 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(447)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-SegmentedRaftLogWorker: Starting segment from index:0
2023-08-10 17:02:21,748 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(651)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/29bade7a-e7d2-479c-9e81-0feb90067614/current/log_inprogress_0
2023-08-10 17:02:21,748 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(434)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: set configuration 0: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:22,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-08-10 17:02:22,691 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 12, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:23,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-08-10 17:02:23,691 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 13, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:24,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-08-10 17:02:24,691 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 14, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:25,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-08-10 17:02:25,692 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 15, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:26,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2023-08-10 17:02:26,692 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 16, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:27,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-08-10 17:02:27,692 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 17, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:28,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-08-10 17:02:28,692 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 18, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:29,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-08-10 17:02:29,693 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 19, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:30,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-08-10 17:02:30,693 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 20, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:31,137 [IPC Server handler 17 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:02:31,158 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: OPEN
2023-08-10 17:02:31,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2023-08-10T17:02:31.161Z, pipelineID=PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687521607 and scm deadline 1691687551607
2023-08-10 17:02:31,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2023-08-10 17:02:31,719 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 21, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:32,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2023-08-10T17:02:31.161Z, pipelineID=PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687522607 and scm deadline 1691687552607
2023-08-10 17:02:32,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-08-10 17:02:32,697 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 22, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:32,873 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 1 is synced with bcsId 4.
2023-08-10 17:02:32,873 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 1 is synced with bcsId 4.
2023-08-10 17:02:32,880 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(399)) - Container 1 is closed with bcsId 4.
2023-08-10 17:02:32,883 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(311)) - Moving container #1 to CLOSED state, datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reported CLOSED replica with index 0.
2023-08-10 17:02:33,274 [IPC Server handler 13 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:02:33,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 4 milliseconds for processing 2 containers.
2023-08-10 17:02:33,697 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [1]. Marking it UNHEALTHY.
java.io.FileNotFoundException: Chunks directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/1/chunks not found.
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:128)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
2023-08-10 17:02:33,700 [ContainerMetadataScanner] WARN  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerUnhealthy(366)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/1 to state UNHEALTHY from state:CLOSED
17:02:33.702 [ContainerMetadataScanner] ERROR ContainerLog - ID=1 | Index=0 | BCSID=4 | State=UNHEALTHY | MISSING_CHUNKS_DIR for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/1/chunks. Message: Chunks directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/1/chunks not found.
2023-08-10 17:02:33,710 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [2]. Marking it UNHEALTHY.
java.io.FileNotFoundException: Chunks directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/2/chunks not found.
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:128)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
2023-08-10 17:02:33,712 [ContainerMetadataScanner] WARN  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerUnhealthy(366)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/2 to state UNHEALTHY from state:OPEN
17:02:33.712 [ContainerMetadataScanner] ERROR ContainerLog - ID=2 | Index=0 | BCSID=13 | State=UNHEALTHY | MISSING_CHUNKS_DIR for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/2/chunks. Message: Chunks directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/2/chunks not found.
2023-08-10 17:02:33,713 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 23, Number of containers scanned in this iteration : 2, Number of unhealthy containers found in this iteration : 2
2023-08-10 17:02:33,714 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(260)) - Container #2 is in OPEN state, but the datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reports an UNHEALTHY replica.
2023-08-10 17:02:34,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 2 milliseconds for processing 2 containers.
2023-08-10 17:02:34,614 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: OPEN
2023-08-10 17:02:34,696 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 24, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
]]></system-out>
  </testcase>
  <testcase name="testCorruptionDetected" classname="TestBackgroundContainerMetadataScannerIntegration" time="4.181">
    <system-out><![CDATA[2023-08-10 17:02:34,871 [IPC Server handler 19 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:02:34,882 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #3, current state: OPEN
2023-08-10 17:02:35,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 3, pipelineID: PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, force: false] for container ContainerInfo{id=#3, state=CLOSING, stateEnterTime=2023-08-10T17:02:34.882Z, pipelineID=PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687525615 and scm deadline 1691687555615
2023-08-10 17:02:35,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2023-08-10 17:02:35,698 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 25, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:36,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 3, pipelineID: PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, force: false] for container ContainerInfo{id=#3, state=CLOSING, stateEnterTime=2023-08-10T17:02:34.882Z, pipelineID=PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687526616 and scm deadline 1691687556616
2023-08-10 17:02:36,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2023-08-10 17:02:36,704 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 26, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:36,842 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 3 is synced with bcsId 20.
2023-08-10 17:02:36,842 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 3 is synced with bcsId 20.
2023-08-10 17:02:36,844 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(399)) - Container 3 is closed with bcsId 20.
2023-08-10 17:02:36,847 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(311)) - Moving container #3 to CLOSED state, datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reported CLOSED replica with index 0.
2023-08-10 17:02:36,970 [IPC Server handler 11 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:02:37,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 4 containers.
2023-08-10 17:02:37,698 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [3]. Marking it UNHEALTHY.
java.io.FileNotFoundException: Metadata directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/3/metadata not found.
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:107)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
2023-08-10 17:02:37,699 [ContainerMetadataScanner] WARN  keyvalue.KeyValueHandler (KeyValueHandler.java:markContainerUnhealthy(1103)) - Unexpected error while marking container 3 unhealthy
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Error while creating/updating container file. ContainerID: 3, container path: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/3/metadata/3.container Temporary file could not be created.
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.writeToContainerFile(KeyValueContainer.java:282)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.updateContainerFile(KeyValueContainer.java:301)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.updateContainerData(KeyValueContainer.java:453)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.markContainerUnhealthy(KeyValueContainer.java:360)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.markContainerUnhealthy(KeyValueHandler.java:1101)
	at org.apache.hadoop.ozone.container.ozoneimpl.ContainerController.markContainerUnhealthy(ContainerController.java:119)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:83)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
Caused by: java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createTempFile(File.java:2063)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.createTempFile(KeyValueContainer.java:949)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.writeToContainerFile(KeyValueContainer.java:260)
	... 9 more
17:02:37.699 [ContainerMetadataScanner] ERROR ContainerLog - ID=3 | Index=0 | BCSID=20 | State=UNHEALTHY | MISSING_METADATA_DIR for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/3/metadata. Message: Metadata directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/3/metadata not found.
2023-08-10 17:02:37,699 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [4]. Marking it UNHEALTHY.
java.io.FileNotFoundException: Metadata directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/4/metadata not found.
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:107)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
2023-08-10 17:02:37,700 [ContainerMetadataScanner] WARN  keyvalue.KeyValueHandler (KeyValueHandler.java:markContainerUnhealthy(1103)) - Unexpected error while marking container 4 unhealthy
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Error while creating/updating container file. ContainerID: 4, container path: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/4/metadata/4.container Temporary file could not be created.
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.writeToContainerFile(KeyValueContainer.java:282)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.updateContainerFile(KeyValueContainer.java:301)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.updateContainerData(KeyValueContainer.java:453)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.markContainerUnhealthy(KeyValueContainer.java:360)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.markContainerUnhealthy(KeyValueHandler.java:1101)
	at org.apache.hadoop.ozone.container.ozoneimpl.ContainerController.markContainerUnhealthy(ContainerController.java:119)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:83)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
Caused by: java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.createTempFile(File.java:2063)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.createTempFile(KeyValueContainer.java:949)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.writeToContainerFile(KeyValueContainer.java:260)
	... 9 more
17:02:37.700 [ContainerMetadataScanner] ERROR ContainerLog - ID=4 | Index=0 | BCSID=29 | State=UNHEALTHY | MISSING_METADATA_DIR for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/4/metadata. Message: Metadata directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/4/metadata not found.
2023-08-10 17:02:37,700 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 27, Number of containers scanned in this iteration : 2, Number of unhealthy containers found in this iteration : 2
2023-08-10 17:02:37,703 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(260)) - Container #4 is in OPEN state, but the datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reports an UNHEALTHY replica.
2023-08-10 17:02:38,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 4 containers.
2023-08-10 17:02:38,618 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #4, current state: OPEN
2023-08-10 17:02:38,698 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 28, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
]]></system-out>
  </testcase>
  <testcase name="testCorruptionDetected" classname="TestBackgroundContainerMetadataScannerIntegration" time="3.661">
    <system-out><![CDATA[2023-08-10 17:02:39,048 [IPC Server handler 18 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:02:39,058 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #5, current state: OPEN
2023-08-10 17:02:39,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 5, pipelineID: PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, force: false] for container ContainerInfo{id=#5, state=CLOSING, stateEnterTime=2023-08-10T17:02:39.058Z, pipelineID=PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687529619 and scm deadline 1691687559619
2023-08-10 17:02:39,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 5 containers.
2023-08-10 17:02:39,700 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 29, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:40,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 5, pipelineID: PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, force: false] for container ContainerInfo{id=#5, state=CLOSING, stateEnterTime=2023-08-10T17:02:39.058Z, pipelineID=PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687530620 and scm deadline 1691687560620
2023-08-10 17:02:40,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 5 containers.
2023-08-10 17:02:40,702 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 30, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:40,710 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-1] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 5 is synced with bcsId 36.
2023-08-10 17:02:40,710 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-1] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 5 is synced with bcsId 36.
2023-08-10 17:02:40,712 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-1] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(399)) - Container 5 is closed with bcsId 36.
2023-08-10 17:02:40,715 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(311)) - Moving container #5 to CLOSED state, datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reported CLOSED replica with index 0.
2023-08-10 17:02:41,133 [IPC Server handler 12 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:02:41,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-08-10 17:02:41,703 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [5]. Marking it UNHEALTHY.
java.io.FileNotFoundException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/5/metadata/5.container (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainerFile(ContainerDataYaml.java:132)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.loadContainerData(KeyValueContainerCheck.java:435)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:116)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
2023-08-10 17:02:41,706 [ContainerMetadataScanner] WARN  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerUnhealthy(366)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/5 to state UNHEALTHY from state:CLOSED
17:02:41.706 [ContainerMetadataScanner] ERROR ContainerLog - ID=5 | Index=0 | BCSID=36 | State=UNHEALTHY | MISSING_CONTAINER_FILE for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/5/metadata/5.container. Message: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/5/metadata/5.container (No such file or directory)
2023-08-10 17:02:41,708 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [6]. Marking it UNHEALTHY.
java.io.FileNotFoundException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/6/metadata/6.container (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainerFile(ContainerDataYaml.java:132)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.loadContainerData(KeyValueContainerCheck.java:435)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:116)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
2023-08-10 17:02:41,710 [ContainerMetadataScanner] WARN  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerUnhealthy(366)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/6 to state UNHEALTHY from state:OPEN
17:02:41.710 [ContainerMetadataScanner] ERROR ContainerLog - ID=6 | Index=0 | BCSID=45 | State=UNHEALTHY | MISSING_CONTAINER_FILE for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/6/metadata/6.container. Message: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/6/metadata/6.container (No such file or directory)
2023-08-10 17:02:41,711 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(260)) - Container #6 is in OPEN state, but the datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reports an UNHEALTHY replica.
2023-08-10 17:02:41,711 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 31, Number of containers scanned in this iteration : 2, Number of unhealthy containers found in this iteration : 2
2023-08-10 17:02:42,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-08-10 17:02:42,622 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #6, current state: OPEN
]]></system-out>
  </testcase>
  <testcase name="testCorruptionDetected" classname="TestBackgroundContainerMetadataScannerIntegration" time="5.134">
    <error type="java.util.concurrent.TimeoutException"><![CDATA[java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2023-08-10 05:02:47,750

"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=235 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=21 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=281 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15000" daemon prio=5 tid=56 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=39 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 15000" daemon prio=5 tid=65 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (1210315704) connection to 0.0.0.0/0.0.0.0:15000 from runner" daemon prio=5 tid=310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"qtp518898781-156" daemon prio=5 tid=156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"process reaper" daemon prio=10 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=41 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=280 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15000" daemon prio=5 tid=33 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server listener on 15010" daemon prio=5 tid=197 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"qtp518898781-155" daemon prio=5 tid=155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"timer3" daemon prio=5 tid=267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1622662268-191" daemon prio=5 tid=191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15004" daemon prio=5 tid=175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15001" daemon prio=5 tid=84 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15002" daemon prio=5 tid=99 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=16 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$367/96865288.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=47 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 15002" daemon prio=5 tid=101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=31 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"om1-client-thread1" daemon prio=5 tid=247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=232 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15000" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15004"  prio=5 tid=136 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 15 on default port 15002" daemon prio=5 tid=104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-CloseContainerForCloseContainerEventHandler" daemon prio=5 tid=288 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 15001" daemon prio=5 tid=81 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Datanode State Machine Task Thread - 1"  prio=5 tid=213 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 15000" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15002" daemon prio=5 tid=97 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15001" daemon prio=5 tid=28 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 12 on default port 15004" daemon prio=5 tid=174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:116)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:90)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server handler 5 on default port 15002" daemon prio=5 tid=94 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=42 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15002" daemon prio=5 tid=216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=223 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp725543262-115" daemon prio=5 tid=115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15001" daemon prio=5 tid=73 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15004" daemon prio=5 tid=135 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"timer4" daemon prio=5 tid=268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EndpointStateMachine task thread for /0.0.0.0:15002 - 0 "  prio=5 tid=214 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=256 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:302)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:366)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=261 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:306)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:363)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=46 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=225 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1210315704) connection to 0.0.0.0/0.0.0.0:15001 from runner" daemon prio=5 tid=284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=230 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15004" daemon prio=5 tid=169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15000" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15004" daemon prio=5 tid=137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"BlockDeletingService#1" daemon prio=5 tid=231 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:307)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$745/204415189.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=241 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-46241f9-1"  prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"null-request--thread1" daemon prio=5 tid=263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-groupManagement"  prio=5 tid=132 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15001" daemon prio=5 tid=80 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMBlockDeletingService#0" daemon prio=5 tid=109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SnapshotDiffCleanupService#0" daemon prio=5 tid=128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15000" daemon prio=5 tid=52 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15001" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15002" daemon prio=5 tid=102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15001" daemon prio=5 tid=79 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer1" daemon prio=5 tid=259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp518898781-153" daemon prio=5 tid=153 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$452/1595659891.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=234 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp725543262-119" daemon prio=5 tid=119 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 15000" daemon prio=5 tid=58 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15000" daemon prio=5 tid=35 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds)" daemon prio=5 tid=221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:116)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:90)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=32 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=138 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 16 on default port 15002" daemon prio=5 tid=105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15000" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15001" daemon prio=5 tid=78 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-2" daemon prio=5 tid=260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 15001" daemon prio=5 tid=77 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=238 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15002" daemon prio=5 tid=23 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 1 on default port 15001" daemon prio=5 tid=70 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"OMDoubleBufferFlushThread" daemon prio=5 tid=130 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:627)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:278)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$558/1979095062.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-33-thread-1"  prio=5 tid=289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@342a3fad" daemon prio=5 tid=186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:198)
        at java.lang.Thread.run(Thread.java:750)
"qtp518898781-157" daemon prio=5 tid=157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15000" daemon prio=5 tid=66 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=248 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15001" daemon prio=5 tid=83 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=207 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer0" daemon prio=5 tid=293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 2 on default port 15004" daemon prio=5 tid=164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:352)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:539)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$846/2142120931.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 15004" daemon prio=5 tid=167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-0" daemon prio=5 tid=257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 15002" daemon prio=5 tid=98 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15004" daemon prio=5 tid=172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15002" daemon prio=5 tid=90 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15004" daemon prio=5 tid=177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15002" daemon prio=5 tid=107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15001" daemon prio=5 tid=87 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15001" daemon prio=5 tid=30 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Socket Reader #1 for port 15001"  prio=5 tid=29 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"Socket Reader #1 for port 15010"  prio=5 tid=198 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"Command processor thread" daemon prio=5 tid=209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:666)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$850/1131682461.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1622662268-190" daemon prio=5 tid=190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=254 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15002" daemon prio=5 tid=25 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 14 on default port 15000" daemon prio=5 tid=63 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 14 on default port 15004" daemon prio=5 tid=176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=17 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$367/96865288.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1622662268-194" daemon prio=5 tid=194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15001" daemon prio=5 tid=86 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer6" daemon prio=5 tid=270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Parameter Sending Thread for localhost/127.0.0.1:15004" daemon prio=5 tid=279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=48 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 17 on default port 15002" daemon prio=5 tid=106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15004" daemon prio=5 tid=166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Timer-0"  prio=5 tid=146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 19 on default port 15004" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15002" daemon prio=5 tid=92 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15002" daemon prio=5 tid=108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Datanode State Machine Task Thread - 0"  prio=5 tid=210 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=19 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 15002"  prio=5 tid=24 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15000" daemon prio=5 tid=317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 15000" daemon prio=5 tid=64 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp518898781-154-acceptor-0@5ff5e34-ServerConnector@7537f673{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}" daemon prio=3 tid=154 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor0" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:117)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:106)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$414/348921692.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=26 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 1 on default port 15000" daemon prio=5 tid=50 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"main"  prio=5 tid=1 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:426)
        at java.util.concurrent.FutureTask.get(FutureTask.java:204)
        at org.junit.internal.runners.statements.FailOnTimeout.getResult(FailOnTimeout.java:156)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluate(FailOnTimeout.java:129)
        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
        at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
        at org.junit.runners.Suite.runChild(Suite.java:128)
        at org.junit.runners.Suite.runChild(Suite.java:27)
        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
        at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
        at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
        at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:42)
        at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:80)
        at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:72)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$199/204684384.accept(Unknown Source)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
        at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
"PipelineCommandHandlerThread-0"  prio=5 tid=239 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15002" daemon prio=5 tid=89 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1622662268-192" daemon prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15002" daemon prio=5 tid=91 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15000"  prio=5 tid=34 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=14 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp518898781-160" daemon prio=5 tid=160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a5e7e3ff-928d-400d-bbdd-ee28941f52d7-impl-thread1"  prio=5 tid=185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 15004" daemon prio=5 tid=163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15000" daemon prio=5 tid=51 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15004" daemon prio=5 tid=173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15001" daemon prio=5 tid=88 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-70-thread-1" daemon prio=5 tid=219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Time-limited test" daemon prio=5 tid=314 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
        at org.apache.hadoop.ozone.dn.scanner.TestContainerScannerIntegrationAbstract.closeContainerAndWait(TestContainerScannerIntegrationAbstract.java:174)
        at org.apache.hadoop.ozone.dn.scanner.TestContainerScannerIntegrationAbstract.writeDataThenCloseContainer(TestContainerScannerIntegrationAbstract.java:167)
        at org.apache.hadoop.ozone.dn.scanner.TestContainerScannerIntegrationAbstract.writeDataThenCloseContainer(TestContainerScannerIntegrationAbstract.java:156)
        at org.apache.hadoop.ozone.dn.scanner.TestBackgroundContainerMetadataScannerIntegration.testCorruptionDetected(TestBackgroundContainerMetadataScannerIntegration.java:96)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:288)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:282)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.lang.Thread.run(Thread.java:750)
"qtp725543262-117" daemon prio=5 tid=117 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"timer2" daemon prio=5 tid=264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1622662268-189-acceptor-0@791ddd66-ServerConnector@60015b68{HTTP/1.1, (http/1.1)}{0.0.0.0:15009}" daemon prio=3 tid=189 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:702)
"IPC Server handler 5 on default port 15001" daemon prio=5 tid=74 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=36 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 7 on default port 15002" daemon prio=5 tid=96 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15002" daemon prio=5 tid=95 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Lease Manager-LeaseManager#LeaseMonitor" daemon prio=5 tid=110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
        at java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:409)
        at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:270)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp725543262-120" daemon prio=5 tid=120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=45 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=40 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15001" daemon prio=5 tid=72 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15000" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-34-thread-1"  prio=5 tid=112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=20 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.lang.Thread.run(Thread.java:750)
"qtp725543262-113" daemon prio=5 tid=113 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$452/1595659891.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15001" daemon prio=5 tid=82 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ChunkReader-ELG-0" daemon prio=5 tid=227 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:306)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:363)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 15004" daemon prio=5 tid=170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=250 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=233 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderStateImpl" daemon prio=5 tid=266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:702)
"qtp725543262-116" daemon prio=5 tid=116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15002" daemon prio=5 tid=93 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement"  prio=5 tid=240 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15000" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15004" daemon prio=5 tid=165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=255 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp518898781-159" daemon prio=5 tid=159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$365/675002551.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15000" daemon prio=5 tid=311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15000" daemon prio=5 tid=283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=222 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=43 runnable
java.lang.Thread.State: RUNNABLE
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=37 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=237 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=144 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:306)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:363)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15001" daemon prio=5 tid=285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15002" daemon prio=5 tid=103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 15004" daemon prio=5 tid=168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"DataNode DiskChecker thread 0" daemon prio=5 tid=218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15000" daemon prio=5 tid=62 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ReplicationMonitor" daemon prio=5 tid=18 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:913)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$381/1067809448.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15001" daemon prio=5 tid=76 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ChunkWriter-2-0" daemon prio=5 tid=224 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineActionsForPipelineActionHandler" daemon prio=5 tid=319 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15010" daemon prio=5 tid=199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=206 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor2" daemon prio=5 tid=226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:117)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:106)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$414/348921692.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at org.apache.maven.surefire.api.util.internal.Channels$3.readImpl(Channels.java:214)
        at org.apache.maven.surefire.api.util.internal.AbstractNoninterruptibleReadableChannel.read(AbstractNoninterruptibleReadableChannel.java:54)
        at org.apache.maven.surefire.booter.spi.LegacyMasterProcessChannelDecoder.decode(LegacyMasterProcessChannelDecoder.java:80)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:343)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15002" daemon prio=5 tid=100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15010" daemon prio=5 tid=202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"prometheus" daemon prio=5 tid=122 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=38 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SnapshotDeletingService#0" daemon prio=5 tid=151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 15001" daemon prio=5 tid=85 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp725543262-118" daemon prio=5 tid=118 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1622662268-188" daemon prio=5 tid=188 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$452/1595659891.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=200 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"grpc-default-executor-1" daemon prio=5 tid=258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1210315704) connection to 0.0.0.0/0.0.0.0:15000 from runner" daemon prio=5 tid=316 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"IPC Server handler 9 on default port 15004" daemon prio=5 tid=171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15004" daemon prio=5 tid=179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a5e7e3ff-928d-400d-bbdd-ee28941f52d7-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=184 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:879)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:526)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15000" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15000" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=236 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-86-thread-1"  prio=5 tid=187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer7" daemon prio=5 tid=292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 18 on default port 15004" daemon prio=5 tid=180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1622662268-195" daemon prio=5 tid=195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15004" daemon prio=5 tid=162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp518898781-158" daemon prio=5 tid=158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor1" daemon prio=5 tid=145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:117)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:106)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$414/348921692.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1210315704) connection to 0.0.0.0/0.0.0.0:15000 from runner" daemon prio=5 tid=282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"timer5" daemon prio=5 tid=269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 16 on default port 15004" daemon prio=5 tid=178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15000" daemon prio=5 tid=57 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp725543262-114-acceptor-0@6b286e05-ServerConnector@234dfc8e{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}" daemon prio=3 tid=114 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=249 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1210315704) connection to localhost/127.0.0.1:15004 from runner" daemon prio=5 tid=278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"IPC Client (1210315704) connection to 0.0.0.0/0.0.0.0:15002 from runner" daemon prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"CompactionDagPruningService" daemon prio=5 tid=127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-53106235-1"  prio=5 tid=161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-impl-thread1"  prio=5 tid=131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-ContainerActionsForContainerActionsHandler" daemon prio=5 tid=318 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1622662268-193" daemon prio=5 tid=193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"IPC Server handler 6 on default port 15001" daemon prio=5 tid=75 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15000" daemon prio=5 tid=67 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-3fe7c87c-1"  prio=5 tid=121 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15001" daemon prio=5 tid=71 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-65-thread-1"  prio=5 tid=152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=143 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:209)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:178)
        at java.lang.Thread.run(Thread.java:750)


	at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
	at org.apache.hadoop.ozone.dn.scanner.TestContainerScannerIntegrationAbstract.closeContainerAndWait(TestContainerScannerIntegrationAbstract.java:174)
	at org.apache.hadoop.ozone.dn.scanner.TestContainerScannerIntegrationAbstract.writeDataThenCloseContainer(TestContainerScannerIntegrationAbstract.java:167)
	at org.apache.hadoop.ozone.dn.scanner.TestContainerScannerIntegrationAbstract.writeDataThenCloseContainer(TestContainerScannerIntegrationAbstract.java:156)
	at org.apache.hadoop.ozone.dn.scanner.TestBackgroundContainerMetadataScannerIntegration.testCorruptionDetected(TestBackgroundContainerMetadataScannerIntegration.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:288)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:282)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:750)
]]></error>
    <system-out><![CDATA[2023-08-10 17:02:42,706 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 32, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:42,737 [IPC Server handler 19 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:02:42,748 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #7, current state: OPEN
2023-08-10 17:02:43,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 7, pipelineID: PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, force: false] for container ContainerInfo{id=#7, state=CLOSING, stateEnterTime=2023-08-10T17:02:42.748Z, pipelineID=PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687533624 and scm deadline 1691687563624
2023-08-10 17:02:43,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 7 containers.
2023-08-10 17:02:43,707 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 33, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:44,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 7, pipelineID: PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, force: false] for container ContainerInfo{id=#7, state=CLOSING, stateEnterTime=2023-08-10T17:02:42.748Z, pipelineID=PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687534625 and scm deadline 1691687564625
2023-08-10 17:02:44,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 7 containers.
2023-08-10 17:02:44,709 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [7]. Marking it UNHEALTHY.
java.io.FileNotFoundException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/7/metadata/7.container (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainerFile(ContainerDataYaml.java:132)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.loadContainerData(KeyValueContainerCheck.java:435)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:116)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
2023-08-10 17:02:44,718 [ContainerMetadataScanner] WARN  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerUnhealthy(366)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/7 to state UNHEALTHY from state:CLOSING
17:02:44.718 [ContainerMetadataScanner] ERROR ContainerLog - ID=7 | Index=0 | BCSID=50 | State=UNHEALTHY | MISSING_CONTAINER_FILE for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/7/metadata/7.container. Message: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/7/metadata/7.container (No such file or directory)
2023-08-10 17:02:44,719 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 34, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 1
2023-08-10 17:02:44,729 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #7, current state: CLOSING
2023-08-10 17:02:44,746 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-2] WARN  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(95)) - Operation: CloseContainer , Trace ID:  , Message: Cannot close container #7 while in UNHEALTHY state. , Result: CONTAINER_UNHEALTHY , StorageContainerException Occurred.
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Cannot close container #7 while in UNHEALTHY state.
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.closeContainer(KeyValueHandler.java:1157)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCloseContainer(KeyValueHandler.java:504)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:253)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:226)
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:324)
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:175)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:174)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:439)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:449)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$submitTask$8(ContainerStateMachine.java:857)
	at org.apache.ratis.util.TaskQueue.lambda$submit$0(TaskQueue.java:121)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
17:02:44.748 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-2] ERROR DNAudit - user=null | ip=null | op=CLOSE_CONTAINER {containerID=7} | ret=FAILURE
java.lang.Exception: Cannot close container #7 while in UNHEALTHY state.
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:398) ~[hdds-container-service-1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:175) ~[hdds-container-service-1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87) ~[hdds-server-framework-1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:174) ~[hdds-container-service-1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:439) ~[hdds-container-service-1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:449) ~[hdds-container-service-1.4.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$submitTask$8(ContainerStateMachine.java:857) ~[hdds-container-service-1.4.0-SNAPSHOT.jar:?]
	at org.apache.ratis.util.TaskQueue.lambda$submit$0(TaskQueue.java:121) ~[ratis-common-2.5.1.jar:2.5.1]
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38) [ratis-common-2.5.1.jar:2.5.1]
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79) [ratis-common-2.5.1.jar:2.5.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_382]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_382]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_382]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_382]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_382]
2023-08-10 17:02:44,754 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-2] ERROR ratis.ContainerStateMachine (ContainerStateMachine.java:lambda$applyTransaction$10(950)) - gid group-0FEB90067614 : ApplyTransaction failed. cmd CloseContainer logIndex 52 msg : Cannot close container #7 while in UNHEALTHY state. Container Result: CONTAINER_UNHEALTHY
2023-08-10 17:02:44,754 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(134)) - Can't close container #7
org.apache.ratis.protocol.exceptions.StateMachineException: org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException from Server a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: Cannot close container #7 while in UNHEALTHY state.
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$replyPendingRequest$41(RaftServerImpl.java:1743)
	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$10(ContainerStateMachine.java:959)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
	at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)
	at org.apache.ratis.util.TaskQueue.lambda$submit$0(TaskQueue.java:133)
	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Cannot close container #7 while in UNHEALTHY state.
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$10(ContainerStateMachine.java:949)
	... 12 more
2023-08-10 17:02:44,772 [ContainerOp-29bade7a-e7d2-479c-9e81-0feb90067614-2] ERROR ratis.XceiverServerRatis (XceiverServerRatis.java:triggerPipelineClose(719)) - pipeline Action CLOSE on pipeline PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614.Reason : Ratis Transaction failure in datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7 with role LEADER .Triggering pipeline close action.
2023-08-10 17:02:44,773 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineActionHandler (PipelineActionHandler.java:processPipelineAction(82)) - Received pipeline action CLOSE for PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614 from datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7. Reason : Ratis Transaction failure in datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7 with role LEADER .Triggering pipeline close action.
2023-08-10 17:02:44,774 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(510)) - Pipeline Pipeline[ Id: 29bade7a-e7d2-479c-9e81-0feb90067614, Nodes: a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:a5e7e3ff-928d-400d-bbdd-ee28941f52d7, CreationTimestamp2023-08-10T17:02:13.595Z[Etc/UTC]] moved to CLOSED state
2023-08-10 17:02:44,774 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614 close command to datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:44,775 [EventQueue-PipelineActionsForPipelineActionHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 29bade7a-e7d2-479c-9e81-0feb90067614, Nodes: a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:a5e7e3ff-928d-400d-bbdd-ee28941f52d7, CreationTimestamp2023-08-10T17:02:13.595Z[Etc/UTC]] removed.
2023-08-10 17:02:45,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 7 containers.
2023-08-10 17:02:45,709 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 35, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:46,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 7 containers.
2023-08-10 17:02:46,709 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 36, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:46,719 [PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(109)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: remove    LEADER a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614:t1, leader=a5e7e3ff-928d-400d-bbdd-ee28941f52d7, voted=a5e7e3ff-928d-400d-bbdd-ee28941f52d7, raftlog=Memoized:a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-SegmentedRaftLog:OPENED:c53, conf=0: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-08-10 17:02:46,720 [PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(466)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: shutdown
2023-08-10 17:02:46,721 [PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FEB90067614,id=a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:46,721 [PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: shutdown a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-LeaderStateImpl
2023-08-10 17:02:46,721 [PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-PendingRequests: sendNotLeaderResponses
2023-08-10 17:02:46,726 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-StateMachineUpdater] ERROR ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(324)) - Failed to take snapshot  for group-0FEB90067614 as the stateMachine is unhealthy. The last applied index is at (t:1, i:51)
2023-08-10 17:02:46,727 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-StateMachineUpdater] ERROR impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(286)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-StateMachineUpdater: Failed to take snapshot
org.apache.ratis.protocol.exceptions.StateMachineException: Failed to take snapshot  for group-0FEB90067614 as the stateMachine is unhealthy. The last applied index is at (t:1, i:51)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:323)
	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:274)
	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:266)
	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:185)
	at java.lang.Thread.run(Thread.java:750)
2023-08-10 17:02:46,727 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-StateMachineUpdater] ERROR ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(324)) - Failed to take snapshot  for group-0FEB90067614 as the stateMachine is unhealthy. The last applied index is at (t:1, i:51)
2023-08-10 17:02:46,727 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-StateMachineUpdater] ERROR impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(286)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-StateMachineUpdater: Failed to take snapshot
org.apache.ratis.protocol.exceptions.StateMachineException: Failed to take snapshot  for group-0FEB90067614 as the stateMachine is unhealthy. The last applied index is at (t:1, i:51)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:323)
	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:274)
	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:266)
	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:188)
	at java.lang.Thread.run(Thread.java:750)
2023-08-10 17:02:46,732 [PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(155)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-StateMachineUpdater: set stopIndex = 53
2023-08-10 17:02:46,737 [PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(472)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: closes. applyIndex: 51
2023-08-10 17:02:47,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 7 containers.
2023-08-10 17:02:47,709 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 37, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:47,719 [PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614-SegmentedRaftLogWorker close()
2023-08-10 17:02:47,722 [PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(436)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-0FEB90067614: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/29bade7a-e7d2-479c-9e81-0feb90067614
2023-08-10 17:02:47,723 [PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$0(87)) - Close Pipeline PipelineID=29bade7a-e7d2-479c-9e81-0feb90067614 command on datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7.
]]></system-out>
  </testcase>
  <testcase name="testCorruptionDetected" classname="TestBackgroundContainerMetadataScannerIntegration" time="16.029">
    <system-out><![CDATA[2023-08-10 17:02:47,824 [IPC Server handler 13 on default port 15001] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=3361fff7-addb-4a47-9300-6416635e21f5 to datanode:a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:48,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 7 containers.
2023-08-10 17:02:48,710 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 38, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:49,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 7 containers.
2023-08-10 17:02:49,710 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 39, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:49,768 [PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(98)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: addNew group-6416635E21F5:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER] returns group-6416635E21F5:java.util.concurrent.CompletableFuture@70319f22[Not completed]
2023-08-10 17:02:49,769 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(198)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: new RaftServerImpl for group-6416635E21F5:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-08-10 17:02:49,769 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-08-10 17:02:49,769 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-08-10 17:02:49,769 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-08-10 17:02:49,769 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-08-10 17:02:49,769 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-08-10 17:02:49,770 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-08-10 17:02:49,770 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(120)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5: ConfigurationManager, init=-1: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-08-10 17:02:49,770 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis] (custom)
2023-08-10 17:02:49,770 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-08-10 17:02:49,770 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-08-10 17:02:49,770 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-08-10 17:02:49,770 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2023-08-10 17:02:49,770 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-08-10 17:02:49,770 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-08-10 17:02:49,771 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2023-08-10 17:02:49,774 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-08-10 17:02:49,774 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-08-10 17:02:49,774 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-08-10 17:02:49,774 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-08-10 17:02:49,774 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-08-10 17:02:49,774 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-08-10 17:02:49,775 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/3361fff7-addb-4a47-9300-6416635e21f5 does not exist. Creating ...
2023-08-10 17:02:49,776 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/3361fff7-addb-4a47-9300-6416635e21f5/in_use.lock acquired by nodename 4345@fv-az1292-188
2023-08-10 17:02:49,777 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/3361fff7-addb-4a47-9300-6416635e21f5 has been successfully formatted.
2023-08-10 17:02:49,777 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(262)) - group-6416635E21F5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-08-10 17:02:49,777 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-08-10 17:02:49,777 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-08-10 17:02:49,777 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:49,778 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-08-10 17:02:49,778 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-08-10 17:02:49,778 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-08-10 17:02:49,778 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-08-10 17:02:49,778 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-08-10 17:02:49,778 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:49,778 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/3361fff7-addb-4a47-9300-6416635e21f5
2023-08-10 17:02:49,778 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-08-10 17:02:49,779 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=3361fff7-addb-4a47-9300-6416635e21f5
2023-08-10 17:02:49,779 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-08-10 17:02:49,779 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-08-10 17:02:49,779 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-08-10 17:02:49,779 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-08-10 17:02:49,779 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-08-10 17:02:49,779 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-08-10 17:02:49,779 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-08-10 17:02:49,780 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-08-10 17:02:49,781 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-08-10 17:02:49,784 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-08-10 17:02:49,784 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-08-10 17:02:49,784 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-08-10 17:02:49,784 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-08-10 17:02:49,784 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-08-10 17:02:49,785 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(342)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5: start as a follower, conf=-1: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:49,785 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(329)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-08-10 17:02:49,785 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: start a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState
2023-08-10 17:02:49,786 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-08-10 17:02:49,786 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-08-10 17:02:49,786 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6416635E21F5,id=a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:49,786 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-08-10 17:02:49,786 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-08-10 17:02:49,787 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-08-10 17:02:49,787 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-08-10 17:02:49,787 [PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(804)) - Created group PipelineID=3361fff7-addb-4a47-9300-6416635e21f5
2023-08-10 17:02:49,787 [PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=3361fff7-addb-4a47-9300-6416635e21f5.
2023-08-10 17:02:50,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 8 containers.
2023-08-10 17:02:50,710 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 40, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:51,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 8 containers.
2023-08-10 17:02:51,710 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 41, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:52,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 8 containers.
2023-08-10 17:02:52,711 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 42, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:53,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 8 containers.
2023-08-10 17:02:53,711 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 43, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:54,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 8 containers.
2023-08-10 17:02:54,711 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 44, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:54,875 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5090309064ns, electionTimeout:5089ms
2023-08-10 17:02:54,876 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: shutdown a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState
2023-08-10 17:02:54,876 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(329)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-08-10 17:02:54,876 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2023-08-10 17:02:54,876 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: start a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3
2023-08-10 17:02:54,882 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:54,882 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3 PRE_VOTE round 0: result PASSED (term=0)
2023-08-10 17:02:54,884 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:54,884 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3 ELECTION round 0: result PASSED (term=1)
2023-08-10 17:02:54,885 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: shutdown a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3
2023-08-10 17:02:54,885 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(329)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-08-10 17:02:54,885 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(902)) - Leader change notification received for group: group-6416635E21F5 with new leaderId: a5e7e3ff-928d-400d-bbdd-ee28941f52d7
2023-08-10 17:02:54,885 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServer$Division (ServerState.java:setLeader(317)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5: change Leader from null to a5e7e3ff-928d-400d-bbdd-ee28941f52d7 at term 1 for becomeLeader, leader elected after 5114ms
2023-08-10 17:02:54,885 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-08-10 17:02:54,885 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-08-10 17:02:54,885 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-08-10 17:02:54,886 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-08-10 17:02:54,886 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-08-10 17:02:54,886 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-08-10 17:02:54,886 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-08-10 17:02:54,886 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-08-10 17:02:54,886 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7: start a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderStateImpl
2023-08-10 17:02:54,887 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(447)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-SegmentedRaftLogWorker: Starting segment from index:0
2023-08-10 17:02:54,888 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(651)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data/ratis/3361fff7-addb-4a47-9300-6416635e21f5/current/log_inprogress_0
2023-08-10 17:02:54,891 [a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5-LeaderElection3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(434)) - a5e7e3ff-928d-400d-bbdd-ee28941f52d7@group-6416635E21F5: set configuration 0: peers:[a5e7e3ff-928d-400d-bbdd-ee28941f52d7|rpc:10.1.0.6:15014|admin:10.1.0.6:15013|client:10.1.0.6:15012|dataStream:10.1.0.6:15015|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-08-10 17:02:55,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 8 containers.
2023-08-10 17:02:55,711 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 45, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:56,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 8 containers.
2023-08-10 17:02:56,712 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 46, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:57,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 8 containers.
2023-08-10 17:02:57,712 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 47, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:58,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 8 containers.
2023-08-10 17:02:58,712 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 48, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:59,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 8 containers.
2023-08-10 17:02:59,714 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 49, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:02:59,733 [IPC Server handler 19 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:02:59,744 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #8, current state: OPEN
2023-08-10 17:03:00,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=3361fff7-addb-4a47-9300-6416635e21f5, force: false] for container ContainerInfo{id=#8, state=CLOSING, stateEnterTime=2023-08-10T17:02:59.744Z, pipelineID=PipelineID=3361fff7-addb-4a47-9300-6416635e21f5, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687550637 and scm deadline 1691687580637
2023-08-10 17:03:00,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 8 containers.
2023-08-10 17:03:00,715 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 50, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:03:01,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 8, pipelineID: PipelineID=3361fff7-addb-4a47-9300-6416635e21f5, force: false] for container ContainerInfo{id=#8, state=CLOSING, stateEnterTime=2023-08-10T17:02:59.744Z, pipelineID=PipelineID=3361fff7-addb-4a47-9300-6416635e21f5, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687551638 and scm deadline 1691687581638
2023-08-10 17:03:01,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 0 milliseconds for processing 8 containers.
2023-08-10 17:03:01,685 [ContainerOp-3361fff7-addb-4a47-9300-6416635e21f5-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 8 is synced with bcsId 5.
2023-08-10 17:03:01,686 [ContainerOp-3361fff7-addb-4a47-9300-6416635e21f5-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 8 is synced with bcsId 5.
2023-08-10 17:03:01,687 [ContainerOp-3361fff7-addb-4a47-9300-6416635e21f5-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(399)) - Container 8 is closed with bcsId 5.
2023-08-10 17:03:01,689 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(311)) - Moving container #8 to CLOSED state, datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reported CLOSED replica with index 0.
2023-08-10 17:03:01,716 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 51, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:03:01,840 [IPC Server handler 11 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:03:02,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 9 containers.
2023-08-10 17:03:02,716 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [8]. Marking it UNHEALTHY.
java.io.IOException: org.yaml.snakeyaml.error.YAMLException: java.nio.charset.MalformedInputException: Input length = 1
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainer(ContainerDataYaml.java:176)
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainerFile(ContainerDataYaml.java:133)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.loadContainerData(KeyValueContainerCheck.java:435)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:116)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
Caused by: org.yaml.snakeyaml.error.YAMLException: java.nio.charset.MalformedInputException: Input length = 1
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:214)
	at org.yaml.snakeyaml.reader.StreamReader.ensureEnoughData(StreamReader.java:172)
	at org.yaml.snakeyaml.reader.StreamReader.ensureEnoughData(StreamReader.java:167)
	at org.yaml.snakeyaml.reader.StreamReader.peek(StreamReader.java:122)
	at org.yaml.snakeyaml.scanner.ScannerImpl.scanToNextToken(ScannerImpl.java:1204)
	at org.yaml.snakeyaml.scanner.ScannerImpl.fetchMoreTokens(ScannerImpl.java:320)
	at org.yaml.snakeyaml.scanner.ScannerImpl.checkToken(ScannerImpl.java:238)
	at org.yaml.snakeyaml.parser.ParserImpl$ParseImplicitDocumentStart.produce(ParserImpl.java:212)
	at org.yaml.snakeyaml.parser.ParserImpl.peekEvent(ParserImpl.java:162)
	at org.yaml.snakeyaml.parser.ParserImpl.checkEvent(ParserImpl.java:152)
	at org.yaml.snakeyaml.composer.Composer.getSingleNode(Composer.java:156)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:178)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:493)
	at org.yaml.snakeyaml.Yaml.load(Yaml.java:434)
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainer(ContainerDataYaml.java:172)
	... 8 more
Caused by: java.nio.charset.MalformedInputException: Input length = 1
	at java.nio.charset.CoderResult.throwException(CoderResult.java:281)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:339)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at org.yaml.snakeyaml.reader.UnicodeReader.read(UnicodeReader.java:118)
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:179)
	... 22 more
2023-08-10 17:03:02,718 [ContainerMetadataScanner] WARN  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerUnhealthy(366)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/8 to state UNHEALTHY from state:CLOSED
17:03:02.718 [ContainerMetadataScanner] ERROR ContainerLog - ID=8 | Index=0 | BCSID=5 | State=UNHEALTHY | CORRUPT_CONTAINER_FILE for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/8/metadata/8.container. Message: org.yaml.snakeyaml.error.YAMLException: java.nio.charset.MalformedInputException: Input length = 1
2023-08-10 17:03:02,720 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [9]. Marking it UNHEALTHY.
java.io.IOException: org.yaml.snakeyaml.error.YAMLException: java.nio.charset.MalformedInputException: Input length = 1
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainer(ContainerDataYaml.java:176)
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainerFile(ContainerDataYaml.java:133)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.loadContainerData(KeyValueContainerCheck.java:435)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:116)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
Caused by: org.yaml.snakeyaml.error.YAMLException: java.nio.charset.MalformedInputException: Input length = 1
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:214)
	at org.yaml.snakeyaml.reader.StreamReader.ensureEnoughData(StreamReader.java:172)
	at org.yaml.snakeyaml.reader.StreamReader.ensureEnoughData(StreamReader.java:167)
	at org.yaml.snakeyaml.reader.StreamReader.peek(StreamReader.java:122)
	at org.yaml.snakeyaml.scanner.ScannerImpl.scanToNextToken(ScannerImpl.java:1204)
	at org.yaml.snakeyaml.scanner.ScannerImpl.fetchMoreTokens(ScannerImpl.java:320)
	at org.yaml.snakeyaml.scanner.ScannerImpl.checkToken(ScannerImpl.java:238)
	at org.yaml.snakeyaml.parser.ParserImpl$ParseImplicitDocumentStart.produce(ParserImpl.java:212)
	at org.yaml.snakeyaml.parser.ParserImpl.peekEvent(ParserImpl.java:162)
	at org.yaml.snakeyaml.parser.ParserImpl.checkEvent(ParserImpl.java:152)
	at org.yaml.snakeyaml.composer.Composer.getSingleNode(Composer.java:156)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:178)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:493)
	at org.yaml.snakeyaml.Yaml.load(Yaml.java:434)
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainer(ContainerDataYaml.java:172)
	... 8 more
Caused by: java.nio.charset.MalformedInputException: Input length = 1
	at java.nio.charset.CoderResult.throwException(CoderResult.java:281)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:339)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at org.yaml.snakeyaml.reader.UnicodeReader.read(UnicodeReader.java:118)
	at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:179)
	... 22 more
2023-08-10 17:03:02,722 [ContainerMetadataScanner] WARN  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerUnhealthy(366)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/9 to state UNHEALTHY from state:OPEN
17:03:02.722 [ContainerMetadataScanner] ERROR ContainerLog - ID=9 | Index=0 | BCSID=14 | State=UNHEALTHY | CORRUPT_CONTAINER_FILE for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/9/metadata/9.container. Message: org.yaml.snakeyaml.error.YAMLException: java.nio.charset.MalformedInputException: Input length = 1
2023-08-10 17:03:02,723 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 52, Number of containers scanned in this iteration : 2, Number of unhealthy containers found in this iteration : 2
2023-08-10 17:03:02,724 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(260)) - Container #9 is in OPEN state, but the datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reports an UNHEALTHY replica.
2023-08-10 17:03:03,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 9 containers.
2023-08-10 17:03:03,641 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #9, current state: OPEN
2023-08-10 17:03:03,716 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 53, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
]]></system-out>
  </testcase>
  <testcase name="testCorruptionDetected" classname="TestBackgroundContainerMetadataScannerIntegration" time="4.154">
    <system-out><![CDATA[2023-08-10 17:03:03,918 [IPC Server handler 18 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:03:03,926 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #10, current state: OPEN
2023-08-10 17:03:04,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 10, pipelineID: PipelineID=3361fff7-addb-4a47-9300-6416635e21f5, force: false] for container ContainerInfo{id=#10, state=CLOSING, stateEnterTime=2023-08-10T17:03:03.926Z, pipelineID=PipelineID=3361fff7-addb-4a47-9300-6416635e21f5, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687554642 and scm deadline 1691687584642
2023-08-10 17:03:04,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 10 containers.
2023-08-10 17:03:04,718 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 54, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:03:05,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(669)) - Sending command [closeContainerCommand: containerID: 10, pipelineID: PipelineID=3361fff7-addb-4a47-9300-6416635e21f5, force: false] for container ContainerInfo{id=#10, state=CLOSING, stateEnterTime=2023-08-10T17:03:03.926Z, pipelineID=PipelineID=3361fff7-addb-4a47-9300-6416635e21f5, owner=om1} to a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) with datanode deadline 1691687555643 and scm deadline 1691687585643
2023-08-10 17:03:05,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 10 containers.
2023-08-10 17:03:05,720 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 55, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2023-08-10 17:03:05,885 [ContainerOp-3361fff7-addb-4a47-9300-6416635e21f5-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 10 is synced with bcsId 20.
2023-08-10 17:03:05,885 [ContainerOp-3361fff7-addb-4a47-9300-6416635e21f5-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(484)) - Container 10 is synced with bcsId 20.
2023-08-10 17:03:05,887 [ContainerOp-3361fff7-addb-4a47-9300-6416635e21f5-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(399)) - Container 10 is closed with bcsId 20.
2023-08-10 17:03:05,890 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(311)) - Moving container #10 to CLOSED state, datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reported CLOSED replica with index 0.
2023-08-10 17:03:05,994 [IPC Server handler 12 on default port 15001] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodesByAddress(1373)) - Cannot find node for address 127.0.0.1
2023-08-10 17:03:06,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 2 milliseconds for processing 11 containers.
2023-08-10 17:03:06,719 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [10]. Marking it UNHEALTHY.
java.io.IOException: Failed to load container file. File is empty.
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainer(ContainerDataYaml.java:183)
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainerFile(ContainerDataYaml.java:133)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.loadContainerData(KeyValueContainerCheck.java:435)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:116)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
2023-08-10 17:03:06,721 [ContainerMetadataScanner] WARN  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerUnhealthy(366)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/10 to state UNHEALTHY from state:CLOSED
17:03:06.721 [ContainerMetadataScanner] ERROR ContainerLog - ID=10 | Index=0 | BCSID=20 | State=UNHEALTHY | CORRUPT_CONTAINER_FILE for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/10/metadata/10.container. Message: Failed to load container file. File is empty.
2023-08-10 17:03:06,721 [ContainerMetadataScanner] ERROR ozoneimpl.BackgroundContainerMetadataScanner (BackgroundContainerMetadataScanner.java:scanContainer(80)) - Corruption detected in container [11]. Marking it UNHEALTHY.
java.io.IOException: Failed to load container file. File is empty.
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainer(ContainerDataYaml.java:183)
	at org.apache.hadoop.ozone.container.common.impl.ContainerDataYaml.readContainerFile(ContainerDataYaml.java:133)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.loadContainerData(KeyValueContainerCheck.java:435)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainerCheck.fastCheck(KeyValueContainerCheck.java:116)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.scanMetaData(KeyValueContainer.java:909)
	at org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner.scanContainer(BackgroundContainerMetadataScanner.java:78)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.scanContainers(AbstractBackgroundContainerScanner.java:98)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:73)
	at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:56)
2023-08-10 17:03:06,725 [ContainerMetadataScanner] WARN  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerUnhealthy(366)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/11 to state UNHEALTHY from state:OPEN
17:03:06.725 [ContainerMetadataScanner] ERROR ContainerLog - ID=11 | Index=0 | BCSID=29 | State=UNHEALTHY | CORRUPT_CONTAINER_FILE for file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-86769829-ab8d-46b5-b7e6-48e7d1c34e2f/datanode-0/data-0/containers/hdds/86769829-ab8d-46b5-b7e6-48e7d1c34e2f/current/containerDir0/11/metadata/11.container. Message: Failed to load container file. File is empty.
2023-08-10 17:03:06,726 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 56, Number of containers scanned in this iteration : 2, Number of unhealthy containers found in this iteration : 2
2023-08-10 17:03:06,728 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(260)) - Container #11 is in OPEN state, but the datanode a5e7e3ff-928d-400d-bbdd-ee28941f52d7(fv-az1292-188/10.1.0.6) reports an UNHEALTHY replica.
2023-08-10 17:03:07,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(389)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-08-10 17:03:07,646 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #11, current state: OPEN
2023-08-10 17:03:07,719 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(80)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 57, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
]]></system-out>
  </testcase>
</testsuite>